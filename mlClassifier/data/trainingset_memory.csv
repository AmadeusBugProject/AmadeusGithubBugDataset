,created,user,body,closed,commitsDetails,url,ttf,labels,title,numCommits,changesInPackagesSPOON,filteredCommits,statsSkippedReason,changesInPackagesGIT,gitStatsSummary.insertions,gitStatsSummary.deletions,gitStatsSummary.lines,gitStatsSummary.gitFilesChange,spoonStatsSummary.UPD,spoonStatsSummary.spoonMethodsChanged,spoonStatsSummary.TOT,spoonStatsSummary.MOV,spoonStatsSummary.INS,spoonStatsSummary.DEL,spoonStatsSummary.spoonFilesChanged,filteredCommitsReason.unavailable,filteredCommitsReason.moreThanOneParent,filteredCommitsReason.mergeCommitUsed,filteredCommitsReason.duplicated,filteredCommitsReason.multipleIssueFixes,filteredCommitsReason.alsoFixesPhrase,projectName
1236,2015-10-21 02:21:04,codenameone,"This seems to be a recent regression
",2015-11-16 19:58:43,"[{'nameRev': '97f91cc154bb3cfd3adeea5298ad2f1b3737cc2a remotes/origin/FloatingButton~93', 'commitMessage': 'Fixed stream closed error in video component on iOS.  https://github.com/codenameone/CodenameOne/issues/1595\nAlso removed unnecessary retain in creating video component that could cause memory leak.\n', 'commitParents': ['1be67ab3be0536292b04ec9eb0b50666f1c8eb4b'], 'spoonStatsSkippedReason': '', 'commitHash': '97f91cc154bb3cfd3adeea5298ad2f1b3737cc2a', 'authoredDateTime': '2015-11-02 10:42:27', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 0, 'deletions': 3, 'lines': 3, 'filePath': 'Ports/iOSPort/nativeSources/IOSNative.m'}, {'insertions': 13, 'deletions': 11, 'lines': 24, 'filePath': 'Ports/iOSPort/src/com/codename1/impl/ios/IOSImplementation.java'}], 'commitDateTime': '2015-11-02 10:42:27', 'commitUser': 'shannah', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 1, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSImplementation.IOSMedia.getVideoComponent()'}], 'spoonFilePath': 'IOSImplementation.java'}]}, {'nameRev': '67a193b52213af03853f2e99f16ac692de7851db remotes/origin/FloatingButton~68^2~7', 'commitMessage': 'Added support for onCompletionCallback for video components in iOS.  Related to https://github.com/codenameone/CodenameOne/issues/1595\n', 'commitParents': ['c548d24bdd0851e0ffc8d8635bd22506865a2116'], 'spoonStatsSkippedReason': '', 'commitHash': '67a193b52213af03853f2e99f16ac692de7851db', 'authoredDateTime': '2015-11-16 11:57:42', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 61, 'deletions': 28, 'lines': 89, 'filePath': 'Ports/iOSPort/nativeSources/IOSNative.m'}, {'insertions': 12, 'deletions': 6, 'lines': 18, 'filePath': 'Ports/iOSPort/src/com/codename1/impl/ios/IOSNative.java'}, {'insertions': 89, 'deletions': 9, 'lines': 98, 'filePath': 'Ports/iOSPort/src/com/codename1/impl/ios/IOSImplementation.java'}], 'commitDateTime': '2015-11-16 11:57:42', 'commitUser': 'shannah', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 1, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSNative.createVideoComponentNSData(long)'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSNative.createNativeVideoComponent(byte[],int)'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSNative.removeNotificationCenterObserver(long)'}, {'UPD': 0, 'TOT': 1, 'MOV': 1, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSNative.createNativeVideoComponent(byte[])'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSNative.createVideoComponent(java.lang.String,int)'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSNative.createVideoComponentNSData(long,int)'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSNative.createNativeVideoComponentNSData(long,int)'}, {'UPD': 0, 'TOT': 1, 'MOV': 1, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSNative.createNativeVideoComponent(java.lang.String)'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSNative.createVideoComponent(byte[],int)'}, {'UPD': 0, 'TOT': 1, 'MOV': 1, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSNative.createNativeVideoComponentNSData(long)'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSNative.createNativeVideoComponent(java.lang.String,int)'}], 'spoonFilePath': 'IOSNative.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSImplementation.IOSMediaCallback'}, {'UPD': 3, 'TOT': 11, 'MOV': 2, 'INS': 3, 'DEL': 3, 'spoonMethodName': 'com.codename1.impl.ios.IOSImplementation.IOSMedia'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSImplementation.removeMediaCallback(int)'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSImplementation.fireMediaCallback(int)'}, {'UPD': 0, 'TOT': 2, 'MOV': 0, 'INS': 2, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSImplementation'}, {'UPD': 0, 'TOT': 5, 'MOV': 2, 'INS': 3, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSImplementation.IOSMedia.play()'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSImplementation.bindNSObserverPeerToMediaCallback(long,int)'}, {'UPD': 0, 'TOT': 2, 'MOV': 0, 'INS': 2, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSImplementation.IOSMedia.cleanup()'}, {'UPD': 0, 'TOT': 4, 'MOV': 2, 'INS': 2, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSImplementation.IOSMedia.getVideoComponent()'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.impl.ios.IOSImplementation.registerMediaCallback(java.lang.Runnable)'}], 'spoonFilePath': 'IOSImplementation.java'}]}]",https://github.com/codenameone/CodenameOne/issues/1595,26.00027777777778,['bug'],KitchenSink video playback has an IOException on iOS,2.0,"['com.codename1.impl.ios.IOSImplementation.IOSMedia', 'com.codename1.impl.ios.IOSNative.removeNotificationCenterObserver(long)', 'com.codename1.impl.ios.IOSNative.createVideoComponent(byte[],int)', 'com.codename1.impl.ios.IOSNative.createNativeVideoComponent(java.lang.String)', 'com.codename1.impl.ios.IOSNative.createVideoComponentNSData(long,int)', 'com.codename1.impl.ios.IOSImplementation.fireMediaCallback(int)', 'com.codename1.impl.ios.IOSImplementation.bindNSObserverPeerToMediaCallback(long,int)', 'com.codename1.impl.ios.IOSNative.createNativeVideoComponent(byte[])', 'com.codename1.impl.ios.IOSImplementation.IOSMedia.play()', 'com.codename1.impl.ios.IOSNative.createNativeVideoComponentNSData(long,int)', 'com.codename1.impl.ios.IOSImplementation.registerMediaCallback(java.lang.Runnable)', 'com.codename1.impl.ios.IOSImplementation.IOSMediaCallback', 'com.codename1.impl.ios.IOSNative.createNativeVideoComponent(byte[],int)', 'com.codename1.impl.ios.IOSImplementation.removeMediaCallback(int)', 'com.codename1.impl.ios.IOSNative.createVideoComponent(java.lang.String,int)', 'com.codename1.impl.ios.IOSImplementation.IOSMedia.getVideoComponent()', 'com.codename1.impl.ios.IOSImplementation.IOSMedia.cleanup()', 'com.codename1.impl.ios.IOSImplementation', 'com.codename1.impl.ios.IOSNative.createNativeVideoComponentNSData(long)', 'com.codename1.impl.ios.IOSNative.createVideoComponentNSData(long)', 'com.codename1.impl.ios.IOSNative.createNativeVideoComponent(java.lang.String,int)']","['67a193b52213af03853f2e99f16ac692de7851db', '97f91cc154bb3cfd3adeea5298ad2f1b3737cc2a']",,"['Ports/iOSPort/nativeSources/IOSNative.m', 'Ports/iOSPort/src/com/codename1/impl/ios']",175.0,57.0,232.0,3.0,3.0,21.0,42.0,11.0,25.0,3.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,CodenameOne
1237,2015-05-20 19:55:58,shannah,"The GC seems to be collecting static final strings under certain conditions with the New VM
Test case:

```
package com.codename1.issue1156;

import com.codename1.io.FileSystemStorage;
import java.io.IOException;

import com.codename1.io.Log;
import com.codename1.ui.Button;
import com.codename1.ui.CheckBox;
import com.codename1.ui.Command;
import com.codename1.ui.Container;
import com.codename1.ui.Display;
import com.codename1.ui.Font;
import com.codename1.ui.Form;
import com.codename1.ui.TextArea;
import com.codename1.ui.TextField;
import com.codename1.ui.Transform;
import com.codename1.ui.events.ActionEvent;
import com.codename1.ui.layouts.BoxLayout;
import com.codename1.ui.plaf.UIManager;
import com.codename1.ui.util.Resources;
import java.io.OutputStream;
import java.util.ArrayList;
import java.util.Arrays;

public class BadAccessTest {

    private Form current;
    private TextField input;
    private TextField output;
    private CheckBox lowerCaseCb;

    public void init(Object context) {
        try {
            final Resources theme = Resources.openLayered(""/theme"");
            UIManager.getInstance().setThemeProps(theme.getTheme(theme.getThemeResourceNames()[0]));
        } catch (final IOException e) {
            e.printStackTrace();
        }
    }
 public static final String EDirFMapDef = ""FMap"" + FConnector.EFolderSepCh;

    public void destroy() {

    }

    public void stop() {

    }

    public void start() {

        Form f = new Form(""Test Bad Access"");
        f.addComponent(new Button(new Command(""Run Test"") {
            @Override
            public void actionPerformed(ActionEvent e) {
                Display.getInstance().invokeAndBlock(new Runnable() {
                    @Override
                    public void run() {
                        for (int i = 0; i < 1000; i++) {
                            String root = LogF.getRoot();
                            /** EDirFMapDef every time should be FMap/ but sometimes is random text or unexpect data cause error
                             * EXC_BAD_ACCESS in java_lang_String_getChars___int_int_char_1ARRAY_int
                             */
                            root += EDirFMapDef;
                            LogF.p(i + "" root:"" + root);
                        }
                    }
                });
            }
        }));
        f.show();

    }

    public static final String EFolderSepSTR = ""/""; //+FileSystemStorage.getInstance().getFileSystemSeparator(); //""/"";  
    /* separator character as defined by FC specification */
    public static final char EFolderSepCh = EFolderSepSTR.charAt(0);

   public static class LogF {

    private static TextArea iText;
    private static Container gLogCont;

    public static void setContainer(Container aContainer) {
        gLogCont = aContainer;
    }

    private static void add2LogContainer(final String aStr) {
        if (aStr == null) {
            return;
        }

//            Label label = new Label(str); //.substring(0, pos));
//            sItem.setLabelForComponent(label);
//          if(LogF.systemVer() == LogF.ESysSym2st||LogF.systemVer() == LogF.ESysSym1st)
//            sItem.setPreferredSize(320, -1); //on N6300 form is show 1 font wide without this
//          sItem.setFont(EFont);
//          sItem.addCommand(EComOK);
//          sItem.setDefaultCommand(LogF.EComOK);// new Command(""OK"",Command.OK, 0));
//          sItem.setItemCommandListener(iLog);
        // sItem.setPreferredSize(-1, EFont.getHeight());
        if (gLogCont != null) {
            Display.getInstance().callSeriallyAndWait(new Runnable() {
                public void run() {
                    Font f = Font.createSystemFont(Font.FACE_SYSTEM, Font.STYLE_PLAIN, Font.SIZE_SMALL);
                    TextArea sItem = new TextArea(aStr); //(text.length() == 0 ? "" "" : text));
                    sItem.setEditable(false);
                    sItem.getStyle().setFont(f);
                    sItem.getStyle().setMargin(0, 0, 0, 0);
                    sItem.getStyle().setPadding(0, 0, 0, 0);
                    sItem.setWidth(gLogCont.getWidth());
                    sItem.setScrollVisible(false);
                    sItem.getStyle().setBorder(null);
                    sItem.setSelectedStyle(sItem.getStyle());
                    gLogCont.addComponent(sItem);
                    gLogCont.scrollComponentToVisible(sItem);
                    //               gLogCont.repaint();
                    gLogCont.revalidate();
                }
            });

        }

    }

    static void e(String string, Throwable e) {
        Log.p(string);
        if (e != null) {
            Log.e(e);
            string = string + "" error:"" + e.toString();
            e.printStackTrace();
        }
        add2LogContainer(string);
    }

    static void p(String string) {
        e(string, null);
    }

    static void e(String string) {
        e(string, null);
    }

    static void p2Dim(String eTest1, String[][] ETest) {
        if (ETest == null) {
            LogF.p(eTest1 + "" is null"");
            return;
        }
        LogF.p(""vvvvvvvvvvv "" + eTest1 + "" vvvvvvvv"");
        for (int i = 0; i < ETest.length; i++) {
            if (ETest[i] == null) {
                LogF.p(eTest1 + ""["" + i + ""] is null"");
            } else {
                for (int j = 0; j < ETest[i].length; j++) {
                    LogF.p(eTest1 + ""["" + i + ""]["" + j + ""]"" + ETest[i][j]);
                }
            }
        }
        LogF.p(""^^^^^^^^^^ "" + eTest1 + "" ^^^^^^^"");
    }

    static String getRoot() {
        String root = """";
        try {
            String[] rootEnum = FileSystemStorage.getInstance().getRoots();

            //find last R/W root
            for (String rootEnum1 : rootEnum) {
                String folder = rootEnum1; 
                if (folder.length() == 0 || !folder.endsWith(FConnector.EFolderSepSTR)) {
                    folder = folder + FConnector.EFolderSepSTR;
                }
                boolean canWrite = canWrite(folder);

                if (canWrite/*&&counter-->0*/) {
                    root = folder;
                }
            }
        } catch (Throwable e) {
            LogF.e(""[Log.getRoot]error:"", e);
        }
        //    p(""[Log.getRoot] new iRootCur:"" + root);
        return root;
    }

    /**
     * check if root/path is read or read/write
     *
     * @param aRoot path with file:///
     * @return false for error or read only folder or if free space is below 1MB
     */
    public static boolean canWrite(String aRoot) {

        boolean canWrite = true;
        try {
            //test if we can write
            FileSystemStorage.getInstance().mkdir(aRoot + ""~t~t"");
            if (!FileSystemStorage.getInstance().exists(aRoot + ""~t~t"")) {
                return false;
            }
            FileSystemStorage.getInstance().delete(aRoot + ""~t~t"");
            OutputStream os = FileSystemStorage.getInstance().openOutputStream(aRoot + ""~t~t~"");
            os.write(128);
            os.close();
            FileSystemStorage.getInstance().delete(aRoot + ""~t~t~"");
//            long free = FileSystemStorage.getInstance().getRootAvailableSpace(aRoot);
            p(""[Log.canWrite]roots:"" + aRoot + "" "" + (canWrite ? "" R/W"" : "" R"")); //+ "";free:"" + free);
//            if (free < 1024 * 1024) {
//                canWrite = canWrite; //false;
//            }
        } catch (Throwable ee) {
            canWrite = false;
            LogF.e(""[Log.canWrite] root("" + aRoot + "") error:"", ee);
        }
        return canWrite;
    }
}

static class FConnector {
    /* separator string as defined by FC specification */
    public static final String EFolderSepSTR = ""/""; 
    /* separator character as defined by FC specification */
    public static final char EFolderSepCh = EFolderSepSTR.charAt(0);    
}




}

```

Open this and click ""Run Test"".  It will run for a couple of hundred iterations (on iPhone 4S) before you get an EXC_BAD_ACCESS trying to do `root += EDirFMapDef;`

It seems that the char array inside the `EDirFMapDef` variable becomes invalid.

If I change 

```
public static final String EDirFMapDef = ""FMap"" + FConnector.EFolderSepCh;
```

to

```
public static String EDirFMapDef = ""FMap"" + FConnector.EFolderSepCh;
```

It runs through to completion (999 iterations) without a problem

This is related to this forum post:

https://groups.google.com/d/msgid/codenameone-discussions/475473b7-268d-4b5a-9788-18ffe76002ce%40googlegroups.com?utm_medium=email&utm_source=footer
",2015-05-21 07:50:50,"[{'nameRev': 'd067ef3aa4955509d2f23ee353f2318c06585914 remotes/origin/Version-3.1~79', 'commitMessage': 'Fix for potential regression in #1505 edge case\n', 'commitParents': ['4acc0e2ff6cac3ca6576dae2939439e79f59230b'], 'spoonStatsSkippedReason': '', 'commitHash': 'd067ef3aa4955509d2f23ee353f2318c06585914', 'authoredDateTime': '2015-05-26 13:30:19', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'vm/ByteCodeTranslator/src/com/codename1/tools/translator/ByteCodeClass.java'}], 'commitDateTime': '2015-05-26 15:06:28', 'commitUser': 'codenameone', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 1, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'com.codename1.tools.translator.ByteCodeClass.generateCCode(java.util.List)'}], 'spoonFilePath': 'ByteCodeClass.java'}]}, {'nameRev': '9835f23c9a9549879817b8711f6e9bfa6882240f remotes/origin/Version-3.1~86^2~1', 'commitMessage': 'Fix for issue #1505 static final strings were removed from the GC but their internal char array was not... ', 'commitParents': ['18d619b9268f55d9d81c60dfe6e4b2a9563e0bb2'], 'spoonStatsSkippedReason': '', 'commitHash': '9835f23c9a9549879817b8711f6e9bfa6882240f', 'authoredDateTime': '2015-05-21 10:06:26', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'vm/ByteCodeTranslator/src/com/codename1/tools/translator/ByteCodeField.java'}, {'insertions': 5, 'deletions': 1, 'lines': 6, 'filePath': 'vm/ByteCodeTranslator/src/com/codename1/tools/translator/ByteCodeClass.java'}], 'commitDateTime': '2015-05-21 10:06:26', 'commitUser': 'codenameone', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 7, 'MOV': 4, 'INS': 2, 'DEL': 1, 'spoonMethodName': 'com.codename1.tools.translator.ByteCodeClass.generateCCode(java.util.List)'}], 'spoonFilePath': 'ByteCodeClass.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 1, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.codename1.tools.translator.ByteCodeField.shouldRemoveFromHeapCollection()'}], 'spoonFilePath': 'ByteCodeField.java'}]}]",https://github.com/codenameone/CodenameOne/issues/1505,0.0002777777777777778,['bug'],NewVM: GC collecting static final string,2.0,"['com.codename1.tools.translator.ByteCodeClass.generateCCode(java.util.List)', 'com.codename1.tools.translator.ByteCodeField.shouldRemoveFromHeapCollection()']","['d067ef3aa4955509d2f23ee353f2318c06585914', '9835f23c9a9549879817b8711f6e9bfa6882240f']",,['vm/ByteCodeTranslator/src/com/codename1/tools/translator'],7.0,3.0,10.0,2.0,1.0,2.0,10.0,5.0,3.0,1.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,CodenameOne
1733,2017-01-12 12:06:47,bene25,"Hello.
We have m3u8 file format such as:
```

#EXTM3U
#EXT-X-STREAM-INF:BANDWIDTH=490000,RESOLUTION=640x360
http://XXX.XXX.XX.XXX:31213/MEDIA/76336503.....583609776254/161/4161/
#EXT-X-STREAM-INF:BANDWIDTH=1500000,RESOLUTION=720x576
http://XXX.XXX.XX.XXX:31213/MEDIA/76336503.....583609776254/161/3161/
#EXT-X-STREAM-INF:BANDWIDTH=2500000,RESOLUTION=1280x720
http://XXX.XXX.XX.XXX:31213/MEDIA/76336503.....583609776254/161/2161/

```
Each EXT-X-STREAM-INF tag link to file like:
```
#EXTM3U
#EXT-X-TARGETDURATION:5
#EXT-X-VERSION:3
#EXT-X-MEDIA-SEQUENCE:35156
#EXT-X-START:TIME-OFFSET=-25,PRECISE=YES
#EXT-X-KEY:METHOD=AES-128,URI=""http://XXX.XXX.XX.XXX:02444/xxXXXXX/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/191/2191/aeskey_191_
#EXTINF:5,
http://XXX.XXX.XX.XXX:XXXXX/SSEGMENT/3020314583628416652818934133893/191/2191/seg_XXXXX.ts
#EXTINF:5,
http://XXX.XXX.XX.XXX:XXXXX/SSEGMENT/6545456465456456465454564/191/2191/seg_191_XXXXX.ts
#EXTINF:5,
http://XXX.XXX.XX.XXX:XXXXX/SSEGMENT/6545456465456456465454564/191/2191/seg_191_XXXXX.ts
#EXTINF:5,
http://XXX.XXX.XX.XXX:XXXXX/SSEGMENT/6545456465456456465454564/191/2191/seg_191_XXXXX.ts
#EXTINF:5,
http://XXX.XXX.XX.XXX:XXXXX/SSEGMENT/6545456465456456465454564/191/2191/seg_191_XXXXX.ts
```
Large heap set to true.
After 2-3 hours of playing we have this video freeze and log is - [Log2.zip](https://github.com/google/ExoPlayer/files/701610/Log2.zip)

If we set large heap to false, then video freezes much faster and then we have out of memory exception.
",2017-01-20 19:44:53,"[{'nameRev': '63604493b41d232602eca3f658dacd4d6690ec9e tags/r2.2.0^2~30', 'commitMessage': ""Fix memory leak in HlsMediaChunk's\n\nIssue:#2319\n\n-------------\nCreated by MOE: https://github.com/google/moe\nMOE_MIGRATED_REVID=145089668\n"", 'commitParents': ['26b303a4496b89a96aeea7e758174b7c80aa0f9e'], 'spoonStatsSkippedReason': '', 'commitHash': '63604493b41d232602eca3f658dacd4d6690ec9e', 'authoredDateTime': '2017-01-20 08:40:37', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 19, 'deletions': 15, 'lines': 34, 'filePath': 'library/src/main/java/com/google/android/exoplayer2/source/hls/HlsMediaChunk.java'}], 'commitDateTime': '2017-01-20 19:26:34', 'commitUser': 'ojw28', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 3, 'MOV': 1, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'com.google.android.exoplayer2.source.hls.HlsMediaChunk.init(com.google.android.exoplayer2.source.hls.HlsSampleStreamWrapper)'}, {'UPD': 1, 'TOT': 5, 'MOV': 1, 'INS': 1, 'DEL': 2, 'spoonMethodName': 'com.google.android.exoplayer2.source.hls.HlsMediaChunk.buildExtractorByExtension()'}, {'UPD': 1, 'TOT': 4, 'MOV': 2, 'INS': 0, 'DEL': 1, 'spoonMethodName': 'com.google.android.exoplayer2.source.hls.HlsMediaChunk.maybeLoadInitData()'}, {'UPD': 3, 'TOT': 34, 'MOV': 13, 'INS': 12, 'DEL': 6, 'spoonMethodName': 'com.google.android.exoplayer2.source.hls.HlsMediaChunk'}], 'spoonFilePath': 'HlsMediaChunk.java'}]}]",https://github.com/google/ExoPlayer/issues/2319,8.000277777777777,['bug'],Memory leak in HlsMediaChunk,1.0,"['com.google.android.exoplayer2.source.hls.HlsMediaChunk.init(com.google.android.exoplayer2.source.hls.HlsSampleStreamWrapper)', 'com.google.android.exoplayer2.source.hls.HlsMediaChunk.buildExtractorByExtension()', 'com.google.android.exoplayer2.source.hls.HlsMediaChunk.maybeLoadInitData()', 'com.google.android.exoplayer2.source.hls.HlsMediaChunk']",['63604493b41d232602eca3f658dacd4d6690ec9e'],,['library/src/main/java/com/google/android/exoplayer2/source/hls'],19.0,15.0,34.0,1.0,5.0,4.0,46.0,17.0,14.0,10.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,ExoPlayer
1874,2015-12-16 10:17:22,ptanov,"It seems that there is some kind of leak in `ExoPlayer`. I'm working on project for Android set-top box so the application should be able to work for a long time without being stopped.
I want to be able to create many `ExoPlayer` instances in a single activity, too.
So I'm experiencing the following issue after about 227 of start-release cycles of `ExoPlayer` in the same activity:

```
12-15 16:12:16.210: I/OMXClient(3163): Using client-side OMX mux.
12-15 16:12:16.210: D/EventLogger(3163): state [0.19, true, B]
12-15 16:12:16.210: E/ACodec(3163): [OMX.Intel.VideoDecoder.AVC] storeMetaDataInBuffers failed w/ err -2147483648
12-15 16:12:16.210: D/EventLogger(3163): videoFormat [0.19, 0, 0]
12-15 16:12:16.260: D/EventLogger(3163): decoderInitialized [0.25, OMX.Intel.VideoDecoder.AVC]
12-15 16:12:16.270: I/OMXClient(3163): Using client-side OMX mux.
12-15 16:12:16.280: D/EventLogger(3163): decoderInitialized [0.27, OMX.Intel.aac.decoder]
12-15 16:12:16.360: E/Surface(3163): dequeueBuffer: IGraphicBufferProducer::requestBuffer failed: -22
12-15 16:12:16.360: E/ACodec(3163): dequeueBuffer failed: Invalid argument (22)
12-15 16:12:16.360: E/ACodec(3163): Failed to allocate output port buffers after port reconfiguration (error 0xffffffea)
12-15 16:12:16.360: E/MediaCodec(3163): Codec reported an error. (omx error 0x80001001, internalError -22)
12-15 16:12:16.370: E/ExoPlayerImplInternal(3163): Internal runtime error.
12-15 16:12:16.370: E/ExoPlayerImplInternal(3163): java.lang.IllegalStateException
12-15 16:12:16.370: E/ExoPlayerImplInternal(3163):  at android.media.MediaCodec.dequeueOutputBuffer(Native Method)
12-15 16:12:16.370: E/ExoPlayerImplInternal(3163):  at com.google.android.exoplayer.MediaCodecTrackRenderer.drainOutputBuffer(MediaCodecTrackRenderer.java:816)
12-15 16:12:16.370: E/ExoPlayerImplInternal(3163):  at com.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:472)
12-15 16:12:16.370: E/ExoPlayerImplInternal(3163):  at com.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:431)
12-15 16:12:16.370: E/ExoPlayerImplInternal(3163):  at com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:213)
12-15 16:12:16.370: E/ExoPlayerImplInternal(3163):  at android.os.Handler.dispatchMessage(Handler.java:98)
12-15 16:12:16.370: E/ExoPlayerImplInternal(3163):  at android.os.Looper.loop(Looper.java:149)
12-15 16:12:16.370: E/ExoPlayerImplInternal(3163):  at android.os.HandlerThread.run(HandlerThread.java:61)
12-15 16:12:16.370: E/ExoPlayerImplInternal(3163):  at com.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)
12-15 16:12:16.380: E/EventLogger(3163): playerFailed [0.36]
12-15 16:12:16.380: E/EventLogger(3163): com.google.android.exoplayer.ExoPlaybackException: java.lang.IllegalStateException
12-15 16:12:16.380: E/EventLogger(3163):    at com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:246)
12-15 16:12:16.380: E/EventLogger(3163):    at android.os.Handler.dispatchMessage(Handler.java:98)
12-15 16:12:16.380: E/EventLogger(3163):    at android.os.Looper.loop(Looper.java:149)
12-15 16:12:16.380: E/EventLogger(3163):    at android.os.HandlerThread.run(HandlerThread.java:61)
12-15 16:12:16.380: E/EventLogger(3163):    at com.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)
12-15 16:12:16.380: E/EventLogger(3163): Caused by: java.lang.IllegalStateException
12-15 16:12:16.380: E/EventLogger(3163):    at android.media.MediaCodec.dequeueOutputBuffer(Native Method)
12-15 16:12:16.380: E/EventLogger(3163):    at com.google.android.exoplayer.MediaCodecTrackRenderer.drainOutputBuffer(MediaCodecTrackRenderer.java:816)
12-15 16:12:16.380: E/EventLogger(3163):    at com.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:472)
12-15 16:12:16.380: E/EventLogger(3163):    at com.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:431)
12-15 16:12:16.380: E/EventLogger(3163):    at com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:213)
12-15 16:12:16.380: E/EventLogger(3163):    ... 4 more
12-15 16:12:17.360: A/ACodec(3163): frameworks/av/media/libstagefright/ACodec.cpp:4301 CHECK_EQ( mCodec->mOMX->freeNode(mCodec->mNode),(status_t)OK) failed: -2147483648 vs. 0
12-15 16:12:17.370: A/libc(3163): Fatal signal 4 (SIGILL) at 0x4004829d (code=2), thread 7429 (CodecLooper)
12-15 16:12:18.680: E/IMGSRV(7440): :0: PVRDRMOpen: TP3, ret = 50
12-15 16:12:18.680: E/IMGSRV(7440): :0: PVRDRMOpen: TP3, ret = 53
12-15 16:12:18.680: E/IMGSRV(7440): :0: PVRDRMOpen: TP3, ret = 54
12-15 16:12:18.680: E/IMGSRV(7440): :0: PVRDRMOpen: TP3, ret = 54
12-15 16:12:18.680: E/IMGSRV(7440): :0: PVRDRMOpen: TP3, ret = 54
12-15 16:12:18.690: E/IMGSRV(7440): :0: PVRDRMOpen: TP3, ret = 56
12-15 16:12:18.720: D/OpenGLRenderer(7440): Enabling debug mode 0
```

The application is able to switch many sources when I'm using a single instance of `ExoPlayer` (start-stop-change url) so I think that calling `release()` of `ExoPlayer` does not actually release all resources.
I have tried to investigate and debug `ExoPlayer` implementation and as a result I have found that the problem is potentially in `VideoFrameReleaseTimeHelper->Choreographer`.
The very fast fix is to remove `context` passing when creating `VideoFrameReleaseTimeHelper` in `MediaCodecVideoTrackRenderer` constructor:
    `this.frameReleaseTimeHelper = new VideoFrameReleaseTimeHelper(context);`
to be
    `this.frameReleaseTimeHelper = new VideoFrameReleaseTimeHelper();`

I know that this changes the way `Choreographer` is used, but allow me to do more than 227 start-release cycles.

To demonstrate the problem I have changed the project in `ExoPlayer/demo` - I'm creating a new `ExoPlayer` every single second and then I'm releasing that instance. My tests are using ""Apple TS media playlist"" stream from the URL list.

``` java
diff --git a/demo/src/main/java/com/google/android/exoplayer/demo/PlayerActivity.java b/demo/src/main/java/com/google/android/exoplayer/demo/PlayerActivity.java
index d515873..eb7355e 100644
--- a/demo/src/main/java/com/google/android/exoplayer/demo/PlayerActivity.java
+++ b/demo/src/main/java/com/google/android/exoplayer/demo/PlayerActivity.java
@@ -49,6 +49,7 @@
 import android.content.pm.PackageManager;
 import android.net.Uri;
 import android.os.Bundle;
+import android.os.Handler;
 import android.text.TextUtils;
 import android.util.Log;
 import android.view.KeyEvent;
@@ -214,6 +215,7 @@
     if (player == null) {
       if (!maybeRequestPermission()) {
         preparePlayer(true);
+        startReleaseAgain();
       }
     } else {
       player.setBackgrounded(false);
@@ -348,6 +350,21 @@
     player.setPlayWhenReady(playWhenReady);
   }

+  private int startReleaseCount = 0;
+  private void startReleaseAgain() {
+    startReleaseCount++;
+    Log.e(TAG, ""count is ""+startReleaseCount);
+    final Handler handler = new Handler();
+    handler.postDelayed(new Runnable() {
+      @Override
+      public void run() {
+        releasePlayer();
+        preparePlayer(true);
+        startReleaseAgain();
+      }
+    }, 1000);
+  }
+
   private void releasePlayer() {
    if (player != null) {
      debugViewHelper.stop();
      debugViewHelper = null;
      playerPosition = player.getCurrentPosition();
      player.release();
      player = null;
      eventLogger.endSession();
      eventLogger = null;
    }
```

Last thing I noticed while searching for leaks - if I comment the lines bellow I can create-release many `ExoPlayers` without problems:

``` java
diff --git a/library/src/main/java/com/google/android/exoplayer/VideoFrameReleaseTimeHelper.java b/library/src/main/java/com/google/android/exoplayer/VideoFrameReleaseTimeHelper.java
index 7aeff78..d4c1fa8 100644
--- a/library/src/main/java/com/google/android/exoplayer/VideoFrameReleaseTimeHelper.java
+++ b/library/src/main/java/com/google/android/exoplayer/VideoFrameReleaseTimeHelper.java
@@ -86,8 +86,8 @@
     haveSync = false;
     if (useDefaultDisplayVsync) {
       sampledVsyncTimeNs = 0;
-      choreographer = Choreographer.getInstance();
-      choreographer.postFrameCallback(this);
+      // choreographer = Choreographer.getInstance();
+      // choreographer.postFrameCallback(this);
     }
   }

@@ -96,7 +96,7 @@
    */
   public void disable() {
     if (useDefaultDisplayVsync) {
-      choreographer.removeFrameCallback(this);
+      // choreographer.removeFrameCallback(this);
       choreographer = null;
     }
   }
@@ -104,7 +104,8 @@
   @Override
   public void doFrame(long vsyncTimeNs) {
     sampledVsyncTimeNs = vsyncTimeNs;
-    choreographer.postFrameCallbackDelayed(this, CHOREOGRAPHER_SAMPLE_DELAY_MILLIS);
+    
+    // choreographer.postFrameCallbackDelayed(this, CHOREOGRAPHER_SAMPLE_DELAY_MILLIS);
   }

   /**
```

but if I uncomment
`+      // choreographer = Choreographer.getInstance();`

then the problem occurs - `Choreographer` creates instance in `ThreadLocal` `initValue()`:

``` java
    private static final ThreadLocal<Choreographer> sThreadInstance =
            new ThreadLocal<Choreographer>() {
        @Override
        protected Choreographer initialValue() {
            Looper looper = Looper.myLooper();
            if (looper == null) {
                throw new IllegalStateException(""The current thread must have a looper!"");
            }
            return new Choreographer(looper);
        }
    };
```

`MediaCodecVideoTrackRenderer.onEnabled()` is called in new thread (`ExoPlayerImplInternal:Handler`) for each `ExoPlayer` so new `Choreographer` is created but I'm not sure what remains after garbage collection and causes the problem...

For these tests I'm using `dev-1.5.3-rc` commit `345e4ec74e81c4413022d5952017e9e71f3c6af6` on Nexus 5 Android 6. The same problem exists in other devices (Android 4.2 and 4.4), too.
",2016-01-04 21:02:26,"[{'nameRev': 'c31473c5964a6f1faa75934d31d8b333e99e712c tags/r1.5.4^2~78', 'commitMessage': ""Work around for the Choreographer's resource leak.\n\nThis CL adds a class responsible for managing the lifecycle\nof a single Choreographer to be shared among all\nVideoFrameReleaseTimeHelper instances.\n\nIssue: #1066\n-------------\nCreated by MOE: https://github.com/google/moe\nMOE_MIGRATED_REVID=110839824\n"", 'commitParents': ['f2fd57cde17e1b62ce2b3c1b5ce6cf20f9958ca9'], 'spoonStatsSkippedReason': '', 'commitHash': 'c31473c5964a6f1faa75934d31d8b333e99e712c', 'authoredDateTime': '2015-12-23 07:40:05', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 110, 'deletions': 17, 'lines': 127, 'filePath': 'library/src/main/java/com/google/android/exoplayer/VideoFrameReleaseTimeHelper.java'}], 'commitDateTime': '2016-01-04 20:58:39', 'commitUser': 'AquilesCanta', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 7, 'TOT': 18, 'MOV': 9, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper.enable()'}, {'UPD': 0, 'TOT': 2, 'MOV': 0, 'INS': 2, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper.VSyncSampler'}, {'UPD': 0, 'TOT': 8, 'MOV': 4, 'INS': 3, 'DEL': 1, 'spoonMethodName': 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper.adjustReleaseTime(long,long)'}, {'UPD': 0, 'TOT': 6, 'MOV': 3, 'INS': 3, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper'}, {'UPD': 4, 'TOT': 9, 'MOV': 3, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper.disable()'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper.VSyncSampler.addObserverInternal()'}, {'UPD': 4, 'TOT': 10, 'MOV': 6, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper.doFrame(long)'}], 'spoonFilePath': 'VideoFrameReleaseTimeHelper.java'}]}]",https://github.com/google/ExoPlayer/issues/1066,19.00027777777778,['bug'],Resource leak: E/Surface(3163): dequeueBuffer: IGraphicBufferProducer::requestBuffer failed: -22,1.0,"['com.google.android.exoplayer.VideoFrameReleaseTimeHelper.enable()', 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper.VSyncSampler', 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper.adjustReleaseTime(long,long)', 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper', 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper.disable()', 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper.doFrame(long)', 'com.google.android.exoplayer.VideoFrameReleaseTimeHelper.VSyncSampler.addObserverInternal()']",['c31473c5964a6f1faa75934d31d8b333e99e712c'],,['library/src/main/java/com/google/android/exoplayer'],110.0,17.0,127.0,1.0,15.0,7.0,54.0,25.0,11.0,3.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,ExoPlayer
2240,2018-05-14 06:41:33,AdamGrzybkowski,"### Issue description
LeakCanary detects a leak when closing activity with PlayerView.

I'm using the ExoPlayer with Rtmp extensions to display the live stream. When the url is invalid (there is no live stream there) the leak occurs. 

This is how the releasePlayer method looks like
```
private fun releasePlayer() {
        player?.release()
        player = null
        playerView.player = null
        mediaSource = null
        trackSelector = null
}
```

![screenshot_20180514-081829](https://user-images.githubusercontent.com/12660801/39981425-d7a85e26-5750-11e8-8459-e509f8e63483.jpg)

### Version of ExoPlayer being used
2.8.0


",2019-09-01 22:26:45,"[{'nameRev': 'a5820b7535048cde26928fdc7f4868d7c1ead225 tags/r2.9.0^2~419', 'commitMessage': ""Explicitly null MediaPeriod callbacks on release\n\nIf a MediaPeriod uses a Loadable, then there are typically\nreference chains of the form:\n\nLoadingThread[GCroot]->Loadable->MediaPeriod->Player\n\nWhere the player is the MediaPeriod callback. When the\nplayer is released, this reference chain prevents the\nplayer from being GC'd until Loadable cancellation\ncompletes, which may not always be fast. This in turn\nwill typically prevent the application's activity from\nbeing GC'd, since it'll normally be registered as a\nlistener on the player (directly or indirectly via\nsomething like a view).\n\nThis change mitigates the issue by removing references\nthat the MediaPeriod holds back to the player. The\nMediaPeriod will still not be eligible for GC, but the\nplayer and application activity will be, which in most\ncases will be most of the leak (in terms of size).\n\nIssue: #4249\n\n-------------\nCreated by MOE: https://github.com/google/moe\nMOE_MIGRATED_REVID=199143646\n"", 'commitParents': ['810e06c33887833fb2c39d8e72c75bd5c01939b5'], 'spoonStatsSkippedReason': '', 'commitHash': 'a5820b7535048cde26928fdc7f4868d7c1ead225', 'authoredDateTime': '2018-06-04 09:24:05', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 3, 'deletions': 1, 'lines': 4, 'filePath': 'library/dash/src/main/java/com/google/android/exoplayer2/source/dash/DashMediaPeriod.java'}, {'insertions': 3, 'deletions': 1, 'lines': 4, 'filePath': 'library/hls/src/main/java/com/google/android/exoplayer2/source/hls/HlsMediaPeriod.java'}, {'insertions': 3, 'deletions': 1, 'lines': 4, 'filePath': 'library/smoothstreaming/src/main/java/com/google/android/exoplayer2/source/smoothstreaming/SsMediaPeriod.java'}, {'insertions': 2, 'deletions': 1, 'lines': 3, 'filePath': 'library/core/src/main/java/com/google/android/exoplayer2/source/ExtractorMediaPeriod.java'}], 'commitDateTime': '2018-06-05 12:43:59', 'commitUser': 'ojw28', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.dash.DashMediaPeriod.release()'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.dash.DashMediaPeriod'}], 'spoonFilePath': 'DashMediaPeriod.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.hls.HlsMediaPeriod'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.hls.HlsMediaPeriod.release()'}], 'spoonFilePath': 'HlsMediaPeriod.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.ExtractorMediaPeriod.release()'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.ExtractorMediaPeriod'}], 'spoonFilePath': 'ExtractorMediaPeriod.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.smoothstreaming.SsMediaPeriod'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.smoothstreaming.SsMediaPeriod.release()'}], 'spoonFilePath': 'SsMediaPeriod.java'}]}, {'nameRev': '6a82f99ca15c09ca95742cdc9d96bebca832a29e tags/r2.8.2^2~26', 'commitMessage': ""Explicitly null MediaPeriod callbacks on release\n\nIf a MediaPeriod uses a Loadable, then there are typically\nreference chains of the form:\n\nLoadingThread[GCroot]->Loadable->MediaPeriod->Player\n\nWhere the player is the MediaPeriod callback. When the\nplayer is released, this reference chain prevents the\nplayer from being GC'd until Loadable cancellation\ncompletes, which may not always be fast. This in turn\nwill typically prevent the application's activity from\nbeing GC'd, since it'll normally be registered as a\nlistener on the player (directly or indirectly via\nsomething like a view).\n\nThis change mitigates the issue by removing references\nthat the MediaPeriod holds back to the player. The\nMediaPeriod will still not be eligible for GC, but the\nplayer and application activity will be, which in most\ncases will be most of the leak (in terms of size).\n\nIssue: #4249\n\n-------------\nCreated by MOE: https://github.com/google/moe\nMOE_MIGRATED_REVID=199143646\n"", 'commitParents': ['5a6507b72da90d8589af5f557a368ae065a36835'], 'spoonStatsSkippedReason': '', 'commitHash': '6a82f99ca15c09ca95742cdc9d96bebca832a29e', 'authoredDateTime': '2018-06-04 09:24:05', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 3, 'deletions': 1, 'lines': 4, 'filePath': 'library/dash/src/main/java/com/google/android/exoplayer2/source/dash/DashMediaPeriod.java'}, {'insertions': 3, 'deletions': 1, 'lines': 4, 'filePath': 'library/hls/src/main/java/com/google/android/exoplayer2/source/hls/HlsMediaPeriod.java'}, {'insertions': 3, 'deletions': 1, 'lines': 4, 'filePath': 'library/smoothstreaming/src/main/java/com/google/android/exoplayer2/source/smoothstreaming/SsMediaPeriod.java'}, {'insertions': 2, 'deletions': 1, 'lines': 3, 'filePath': 'library/core/src/main/java/com/google/android/exoplayer2/source/ExtractorMediaPeriod.java'}], 'commitDateTime': '2018-06-05 15:18:33', 'commitUser': 'ojw28', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.dash.DashMediaPeriod.release()'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.dash.DashMediaPeriod'}], 'spoonFilePath': 'DashMediaPeriod.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.hls.HlsMediaPeriod'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.hls.HlsMediaPeriod.release()'}], 'spoonFilePath': 'HlsMediaPeriod.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.ExtractorMediaPeriod.release()'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.ExtractorMediaPeriod'}], 'spoonFilePath': 'ExtractorMediaPeriod.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.smoothstreaming.SsMediaPeriod'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.source.smoothstreaming.SsMediaPeriod.release()'}], 'spoonFilePath': 'SsMediaPeriod.java'}]}, {'nameRev': '69b4aa9e36b854ee34a2b104d9569ab7d0767ea7 tags/r2.9.0^2~433', 'commitMessage': ""Explicitly null out LoadTask.callback on release\n\nAs highlighted by the ref'd issue, we can end up with\nmemory leaks if Loadable.load implementations take a long\ntime to return upon cancelation. This change cuts off one\nof the two problematic reference chains.\n\nThis doesn't do much about the ref'd issue, since there's\na second reference chain that's much harder to deal with:\nThread->LoadTask->loadable. But since it's easy just to\ncut this one off, I figure it makes sense to do so.\n\nIssue: #4249\n\n-------------\nCreated by MOE: https://github.com/google/moe\nMOE_MIGRATED_REVID=198735386\n"", 'commitParents': ['27f009d239c819cd6a0eb109087ec372701f7ec9'], 'spoonStatsSkippedReason': '', 'commitHash': '69b4aa9e36b854ee34a2b104d9569ab7d0767ea7', 'authoredDateTime': '2018-05-31 09:52:18', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 8, 'deletions': 2, 'lines': 10, 'filePath': 'library/core/src/main/java/com/google/android/exoplayer2/upstream/Loader.java'}], 'commitDateTime': '2018-06-05 12:30:11', 'commitUser': 'ojw28', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 4, 'MOV': 2, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'com.google.android.exoplayer2.upstream.Loader.LoadTask'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.upstream.Loader.LoadTask.cancel(boolean)'}], 'spoonFilePath': 'Loader.java'}]}, {'nameRev': '7d0769249f7d88c03c984b37849cea8bbdddff54 tags/r2.8.2^2~34', 'commitMessage': ""Avoid possibility of leaking an activity/service context\n\nThe bug here was that we'd create a VideoFrameReleaseTimeHelper\nusing whatever context DefaultRenderersFactory has, and it would\nthen hold a reference to that context via DisplayManager. A leak\ncould then occur if the player outlived the life of the context\nused to create it (which would be strange/unusual, but not\nimpossible).\n\nIssue: #4249\n\n-------------\nCreated by MOE: https://github.com/google/moe\nMOE_MIGRATED_REVID=198747599\n"", 'commitParents': ['4ecce9802bf549fc563ce46fdd8725e67654696f'], 'spoonStatsSkippedReason': '', 'commitHash': '7d0769249f7d88c03c984b37849cea8bbdddff54', 'authoredDateTime': '2018-05-31 11:04:00', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 6, 'deletions': 2, 'lines': 8, 'filePath': 'library/core/src/main/java/com/google/android/exoplayer2/video/VideoFrameReleaseTimeHelper.java'}, {'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'library/core/src/main/java/com/google/android/exoplayer2/video/MediaCodecVideoRenderer.java'}], 'commitDateTime': '2018-06-05 15:15:49', 'commitUser': 'ojw28', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 6, 'MOV': 4, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'com.google.android.exoplayer2.video.VideoFrameReleaseTimeHelper'}], 'spoonFilePath': 'VideoFrameReleaseTimeHelper.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 0, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'com.google.android.exoplayer2.video.MediaCodecVideoRenderer'}], 'spoonFilePath': 'MediaCodecVideoRenderer.java'}]}, {'nameRev': '29b9320fb9ce9b0ee592c1192d795caee86e8be0 tags/r2.9.0^2~432', 'commitMessage': ""Avoid possibility of leaking an activity/service context\n\nThe bug here was that we'd create a VideoFrameReleaseTimeHelper\nusing whatever context DefaultRenderersFactory has, and it would\nthen hold a reference to that context via DisplayManager. A leak\ncould then occur if the player outlived the life of the context\nused to create it (which would be strange/unusual, but not\nimpossible).\n\nIssue: #4249\n\n-------------\nCreated by MOE: https://github.com/google/moe\nMOE_MIGRATED_REVID=198747599\n"", 'commitParents': ['69b4aa9e36b854ee34a2b104d9569ab7d0767ea7'], 'spoonStatsSkippedReason': '', 'commitHash': '29b9320fb9ce9b0ee592c1192d795caee86e8be0', 'authoredDateTime': '2018-05-31 11:04:00', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 6, 'deletions': 2, 'lines': 8, 'filePath': 'library/core/src/main/java/com/google/android/exoplayer2/video/VideoFrameReleaseTimeHelper.java'}, {'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'library/core/src/main/java/com/google/android/exoplayer2/video/MediaCodecVideoRenderer.java'}], 'commitDateTime': '2018-06-05 12:31:11', 'commitUser': 'ojw28', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 6, 'MOV': 4, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'com.google.android.exoplayer2.video.VideoFrameReleaseTimeHelper'}], 'spoonFilePath': 'VideoFrameReleaseTimeHelper.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 0, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'com.google.android.exoplayer2.video.MediaCodecVideoRenderer'}], 'spoonFilePath': 'MediaCodecVideoRenderer.java'}]}, {'nameRev': '4ecce9802bf549fc563ce46fdd8725e67654696f tags/r2.8.2^2~35', 'commitMessage': ""Explicitly null out LoadTask.callback on release\n\nAs highlighted by the ref'd issue, we can end up with\nmemory leaks if Loadable.load implementations take a long\ntime to return upon cancelation. This change cuts off one\nof the two problematic reference chains.\n\nThis doesn't do much about the ref'd issue, since there's\na second reference chain that's much harder to deal with:\nThread->LoadTask->loadable. But since it's easy just to\ncut this one off, I figure it makes sense to do so.\n\nIssue: #4249\n\n-------------\nCreated by MOE: https://github.com/google/moe\nMOE_MIGRATED_REVID=198735386\n"", 'commitParents': ['cd65cc85e21a1c890760fab132c4e4d8a8b2f7da'], 'spoonStatsSkippedReason': '', 'commitHash': '4ecce9802bf549fc563ce46fdd8725e67654696f', 'authoredDateTime': '2018-05-31 09:52:18', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 8, 'deletions': 2, 'lines': 10, 'filePath': 'library/core/src/main/java/com/google/android/exoplayer2/upstream/Loader.java'}], 'commitDateTime': '2018-06-05 15:15:41', 'commitUser': 'ojw28', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 4, 'MOV': 2, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'com.google.android.exoplayer2.upstream.Loader.LoadTask'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.upstream.Loader.LoadTask.cancel(boolean)'}], 'spoonFilePath': 'Loader.java'}]}]",https://github.com/google/ExoPlayer/issues/4249,475.0002777777778,['bug: in dependency'],ExoPlayer set up with Rtmp extension leaks memory when closing the activity with playerView,3.0,"['com.google.android.exoplayer2.source.hls.HlsMediaPeriod', 'com.google.android.exoplayer2.video.MediaCodecVideoRenderer', 'com.google.android.exoplayer2.source.hls.HlsMediaPeriod.release()', 'com.google.android.exoplayer2.source.dash.DashMediaPeriod.release()', 'com.google.android.exoplayer2.source.ExtractorMediaPeriod', 'com.google.android.exoplayer2.source.smoothstreaming.SsMediaPeriod', 'com.google.android.exoplayer2.source.smoothstreaming.SsMediaPeriod.release()', 'com.google.android.exoplayer2.source.ExtractorMediaPeriod.release()', 'com.google.android.exoplayer2.upstream.Loader.LoadTask', 'com.google.android.exoplayer2.upstream.Loader.LoadTask.cancel(boolean)', 'com.google.android.exoplayer2.source.dash.DashMediaPeriod', 'com.google.android.exoplayer2.video.VideoFrameReleaseTimeHelper']","['a5820b7535048cde26928fdc7f4868d7c1ead225', '69b4aa9e36b854ee34a2b104d9569ab7d0767ea7', '29b9320fb9ce9b0ee592c1192d795caee86e8be0']",,"['library/hls/src/main/java/com/google/android/exoplayer2/source', 'library/core/src/main/java/com/google/android/exoplayer2/upstream', 'library/core/src/main/java/com/google/android/exoplayer2/video', 'library/smoothstreaming/src/main/java/com/google/android/exoplayer2/source', 'library/core/src/main/java/com/google/android/exoplayer2/source', 'library/dash/src/main/java/com/google/android/exoplayer2/source']",26.0,9.0,35.0,7.0,0.0,12.0,21.0,6.0,12.0,3.0,7.0,0.0,0.0,0.0,3.0,0.0,0.0,ExoPlayer
2243,2018-04-12 09:50:55,MajDroid,"### Issue description
Using IMA Extension and in the sample main demo app, a memory leak happens when you serve a VMAP and quit the player activity during content playback and after ad/pods playback.

In my opinion, it's an IMA problem and managed to reproduce the issue even without an IMA Extension and following exactly their integration guide but according to them they're claiming it's an IMA-Extension problem and not theirs
https://groups.google.com/forum/#!topic/ima-sdk/ZM-WsPL1xdQ


### Reproduction steps
- In the Main Demo app, use any video and set the following sample adtag uri:
https://pubads.g.doubleclick.net/gampad/ads?sz=640x480&iu=/124319096/external/ad_rule_samples&ciu_szs=300x250&ad_rule=1&impl=s&gdfp_req=1&env=vp&output=vmap&unviewed_position_start=1&cust_params=deployment%3Ddevsite%26sample_ar%3Dpremidpostlongpod&cmsid=496&vid=short_tencue&correlator=
- When pre-roll finishes and content video plays for few seconds, press back to return to the home screen, PlayerActivity gets leaked


### Link to test content
Provide a link to media that reproduces the issue. If you don't wish to post it
publicly, please submit the issue, then email the link to
dev.exoplayer@gmail.com using a subject in the format ""Issue #1234"".


### Version of ExoPlayer being used
V2.7.3


### Device(s) and version(s) of Android being used
Tested on Pixel XL (Oreo 8.1), Xperia XZ (Oreo 8.0) but can be reproduced on any device",2019-01-30 19:56:29,"[{'nameRev': '0cf43fc64ea80ff34ed4dc650260286c5535fd1f tags/r2.10.0^2~398', 'commitMessage': 'Update IMA to 3.10.6\n\nThis brings in a memory leak fix.\n\nIssue: #4114\nPiperOrigin-RevId: 230880521\n', 'commitParents': ['582adb748ae1c1beff071b962f5a3ef08d6f01b7'], 'spoonStatsSkippedReason': '', 'commitHash': '0cf43fc64ea80ff34ed4dc650260286c5535fd1f', 'authoredDateTime': '2019-01-25 12:07:37', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 3, 'deletions': 3, 'lines': 6, 'filePath': 'extensions/ima/build.gradle'}], 'commitDateTime': '2019-01-29 16:42:39', 'commitUser': 'ojw28', 'commitSpoonAstDiffStats': []}, {'nameRev': 'aec2b19c7d5853381043b6189c2771e4e755468d tags/r2.9.5^2~20', 'commitMessage': 'Update IMA to 3.10.6\n\nThis brings in a memory leak fix.\n\nIssue: #4114\nPiperOrigin-RevId: 230880521\n', 'commitParents': ['c176789927985183d292482c31eda760dd31f978'], 'spoonStatsSkippedReason': '', 'commitHash': 'aec2b19c7d5853381043b6189c2771e4e755468d', 'authoredDateTime': '2019-01-25 12:07:37', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 3, 'deletions': 3, 'lines': 6, 'filePath': 'extensions/ima/build.gradle'}], 'commitDateTime': '2019-01-30 19:45:00', 'commitUser': 'ojw28', 'commitSpoonAstDiffStats': []}, {'nameRev': '13638f1c29327bfec7d1e887771bcce8fb2bfd34 tags/r2.9.4^2~31', 'commitMessage': 'Remove AdsLoader listeners on releasing ImaAdsLoader\n\nIssue: #4114\nPiperOrigin-RevId: 227516509\n', 'commitParents': ['e448ecdff88ded7304ba7bb308b0fc114e0f3639'], 'spoonStatsSkippedReason': '', 'commitHash': '13638f1c29327bfec7d1e887771bcce8fb2bfd34', 'authoredDateTime': '2019-01-02 15:04:20', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 2, 'deletions': 0, 'lines': 2, 'filePath': 'extensions/ima/src/main/java/com/google/android/exoplayer2/ext/ima/ImaAdsLoader.java'}, {'insertions': 5, 'deletions': 0, 'lines': 5, 'filePath': 'RELEASENOTES.md'}], 'commitDateTime': '2019-01-15 14:05:00', 'commitUser': 'ojw28', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 0, 'INS': 2, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.ext.ima.ImaAdsLoader.release()'}], 'spoonFilePath': 'ImaAdsLoader.java'}]}, {'nameRev': '1e992240194b24663803a6f11e33227f32d58d14 tags/r2.10.0^2~481', 'commitMessage': 'Remove AdsLoader listeners on releasing ImaAdsLoader\n\nIssue: #4114\nPiperOrigin-RevId: 227516509\n', 'commitParents': ['3a9557c72f9f8be786a6bdecd8ff5d477d2a8354'], 'spoonStatsSkippedReason': '', 'commitHash': '1e992240194b24663803a6f11e33227f32d58d14', 'authoredDateTime': '2019-01-02 15:04:20', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 2, 'deletions': 0, 'lines': 2, 'filePath': 'extensions/ima/src/main/java/com/google/android/exoplayer2/ext/ima/ImaAdsLoader.java'}, {'insertions': 2, 'deletions': 0, 'lines': 2, 'filePath': 'RELEASENOTES.md'}], 'commitDateTime': '2019-01-08 07:32:31', 'commitUser': 'ojw28', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 0, 'INS': 2, 'DEL': 0, 'spoonMethodName': 'com.google.android.exoplayer2.ext.ima.ImaAdsLoader.release()'}], 'spoonFilePath': 'ImaAdsLoader.java'}]}]",https://github.com/google/ExoPlayer/issues/4114,293.0002777777778,['bug: in dependency'],IMA Extension Memory Leak,2.0,['com.google.android.exoplayer2.ext.ima.ImaAdsLoader.release()'],"['0cf43fc64ea80ff34ed4dc650260286c5535fd1f', '1e992240194b24663803a6f11e33227f32d58d14']",,"['extensions/ima', 'extensions/ima/src/main/java/com/google/android/exoplayer2/ext']",5.0,3.0,8.0,2.0,0.0,1.0,2.0,0.0,2.0,0.0,1.0,0.0,0.0,0.0,2.0,0.0,0.0,ExoPlayer
2507,2018-06-22 07:14:19,gumandy,"#### Environment
```
HikariCP version: x.x.x
```
when ThreadPoolA borrow an entry and ThreadPoolB requite that entry, ThreadPoolA just borrow but never requite，ThreadPoolB just requite but never borrow， then ThreadPoolB's threadList OOM.

I think `ThreadLocal<List<Object>> threadList;` should be with a max size, 
or just be `ThreadLocal<Object> threadList;`.
",2018-07-11 12:18:56,"[{'nameRev': '52b3811e4dba1ed04f8efd1230661ad38af9d660 tags/HikariCP-3.3.0~23', 'commitMessage': 'Fixes #1186 limit the number of items in the ThreadLocal list in the ConcurrentBag.\n', 'commitParents': ['d0cb0f8dab5e3edaea7c4d3c5807f006d3695880'], 'spoonStatsSkippedReason': '', 'commitHash': '52b3811e4dba1ed04f8efd1230661ad38af9d660', 'authoredDateTime': '2018-07-11 21:18:47', 'commitGHEventType': 'closed', 'commitGitStats': [{'insertions': 3, 'deletions': 1, 'lines': 4, 'filePath': 'src/main/java/com/zaxxer/hikari/util/ConcurrentBag.java'}], 'commitDateTime': '2018-07-11 21:18:47', 'commitUser': 'brettwooldridge', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 1, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.zaxxer.hikari.util.ConcurrentBag.requite(com.zaxxer.hikari.util.ConcurrentBag$IConcurrentBagEntry)'}], 'spoonFilePath': 'ConcurrentBag.java'}]}]",https://github.com/brettwooldridge/HikariCP/issues/1186,19.00027777777778,['bug'],ConcurrentBag threadList OOM,1.0,['com.zaxxer.hikari.util.ConcurrentBag.requite(com.zaxxer.hikari.util.ConcurrentBag$IConcurrentBagEntry)'],['52b3811e4dba1ed04f8efd1230661ad38af9d660'],,['src/main/java/com/zaxxer/hikari/util'],3.0,1.0,4.0,1.0,0.0,1.0,2.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,HikariCP
2524,2015-10-19 15:37:19,dfex55,"I tried 2.4.2 RC1 in replacement to 2.4.1.

Without any changes to the app, HikariCP reports a connection leak after pool-initialization.
But there is no leaking connection: one connection in pool, one idle, one connection to the database.

Excerpt from log (pool configuration and leak alert):

```
[#| 16.10.2015 14:01:05.887 | ... | DEBUG com.zaxxer.hikari.HikariConfig 
dev - configuration:
allowPoolSuspension.............false
autoCommit......................true
catalog.........................
connectionInitSql...............
connectionTestQuery.............
connectionTimeout...............2000
dataSource......................
dataSourceClassName.............org.postgresql.ds.PGSimpleDataSource
dataSourceJNDI..................
dataSourceProperties............{serverName=…, socketTimeout=15, user=…, databaseName=…, tcpKeepAlive=true, prepareThreshold=0, password=<masked>, portNumber=, loginTimeout=15}
driverClassName.................
healthCheckProperties...........{}
healthCheckRegistry.............
idleTimeout.....................1200000
initializationFailFast..........true
isolateInternalQueries..........false
jdbc4ConnectionTest.............false
jdbcUrl.........................
leakDetectionThreshold..........10000
maxLifetime.....................43200000
maximumPoolSize.................50
metricRegistry..................com.codahale.metrics.MetricRegistry@148da145
metricsTrackerFactory...........
minimumIdle.....................0
password........................<masked>
poolName........................dev
readOnly........................false
registerMbeans..................true
scheduledExecutorService........
threadFactory……………….<customClass>$1@21540445
transactionIsolation............
username........................
validationTimeout...............2000
dev - is starting.
dev - Connection.setNetworkTimeout() is not supported (...)
|#]

[#| 16.10.2015 14:01:05.927 | … | DEBUG com.zaxxer.hikari.pool.HikariPool 
dev - Added connection org.postgresql.jdbc4.Jdbc4Connection@3a4a6161
|#]

[#| 16.10.2015 14:01:05.928 | ... | DEBUG com.zaxxer.hikari.pool.PoolBase 
dev - Closing connection org.postgresql.jdbc4.Jdbc4Connection@3a4a6161: (connection evicted by user)
|#]


…<no action from app>...


[#| 16.10.2015 14:01:15.948 | ... | WARN  com.zaxxer.hikari.pool.ProxyLeakTask 
Connection leak detection triggered for connection org.postgresql.jdbc4.Jdbc4Connection@3a4a6161, stack trace follows
java.lang.Exception: Apparent connection leak detected
    at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:138) ~[HikariCP-2.4.2-RC1.jar:na]
    at com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:71) ~[HikariCP-2.4.2-RC1.jar:na]
    ...
|#]

[#| 16.10.2015 14:01:35.897 | … | DEBUG com.zaxxer.hikari.pool.HikariPool 
Before cleanup  pool dev stats (total=1, active=0, idle=1, waiting=0)
```
",2015-10-21 13:49:41,"[{'nameRev': '37b96f1ed93ca3cd60a121659e3acb1e73cb8522 tags/HikariCP-2.4.2~7^2', 'commitMessage': 'Fixes #465 fix apparent leak of one connection leak at startup when minimumIdle=0 ... the connection is not leaked, but the ProxyLeakTask was not cancelled.\n', 'commitParents': ['755f2da615bc6a431cd8c25cab2fa5ccf66bfaff'], 'spoonStatsSkippedReason': '', 'commitHash': '37b96f1ed93ca3cd60a121659e3acb1e73cb8522', 'authoredDateTime': '2015-10-21 15:52:15', 'commitGHEventType': 'closed', 'commitGitStats': [{'insertions': 8, 'deletions': 8, 'lines': 16, 'filePath': 'src/main/java/com/zaxxer/hikari/pool/ProxyConnection.java'}, {'insertions': 6, 'deletions': 3, 'lines': 9, 'filePath': 'src/main/java/com/zaxxer/hikari/pool/HikariPool.java'}], 'commitDateTime': '2015-10-21 15:52:15', 'commitUser': 'brettwooldridge', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 1, 'TOT': 3, 'MOV': 0, 'INS': 2, 'DEL': 0, 'spoonMethodName': 'com.zaxxer.hikari.pool.HikariPool.evictConnection(java.sql.Connection)'}], 'spoonFilePath': 'HikariPool.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.zaxxer.hikari.pool.ProxyConnection.cancelLeakTask()'}], 'spoonFilePath': 'ProxyConnection.java'}]}]",https://github.com/brettwooldridge/HikariCP/issues/465,1.0002777777777778,['bug'],2.4.2 RC1: Connection leak detection false positive,1.0,"['com.zaxxer.hikari.pool.ProxyConnection.cancelLeakTask()', 'com.zaxxer.hikari.pool.HikariPool.evictConnection(java.sql.Connection)']",['37b96f1ed93ca3cd60a121659e3acb1e73cb8522'],,['src/main/java/com/zaxxer/hikari/pool'],14.0,11.0,25.0,2.0,1.0,2.0,4.0,0.0,3.0,0.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,HikariCP
2566,2014-11-25 11:03:53,danielfernandez,"We are testing a high-load database tool that requires the execution of a big amount of queries on a MySQL server. For this, we are using HikariCP (`HikariCP-java6:2.2.5`) and the MySQL JDBC Driver (`mysql-connector-java:5.1.34`). 

We use Hikari's default configuration: we only set the driver class (`com.mysql.jdbc.Driver`), JDBC URL, user and password. And sometimes the `connectionTestQuery`, which seems to make a big difference.

It was our understanding that the newest versions of the MySQL driver would implement the `isValid()` method and therefore not need a `connectionTestQuery` property to be set. However, when we run one of our tests --which creates and shutdowns 1,002 different instances of the Hikari pool in sequence-- with such setup, we observe a growing number of unclosed connections (orange):

![mysql_novalidationquery](https://cloud.githubusercontent.com/assets/1492299/5181387/2d9af060-7496-11e4-97a6-222aa448e4fc.png)

However, if we run exactly the same test setting having set the `connectionTestQuery` property like:

``` java
properties.setProperty(""connectionTestQuery"", ""/* ping */ SELECT 1"");
```

...this doesn't happen at all, and everything looks fine:

![mysql_validationquery](https://cloud.githubusercontent.com/assets/1492299/5181334/9757ad14-7495-11e4-8068-245a8467c2c8.png)

The profiler shows to us that our test actually uses and _closes_ the same amount of connections in both cases (29,058), but in the first case many more connections are open and never closed. Also, the profiler shows that these unclosed connections are not strongly-reachable after the test has finished executing all the queries, but that a good number of connections are still weak and/or soft reachable (and forcing a GC execution doesn't change things):

![mysql_novalidationreachability](https://cloud.githubusercontent.com/assets/1492299/5181730/8e6c8bb2-7499-11e4-8ac5-da43ac7832e4.png)

Note that, when we use `connectionTestQuery`, we also see a comparable number of weak/softly reachable connections at the end. The difference seems to be that the connections are closed this time...

![mysql_validationreachability](https://cloud.githubusercontent.com/assets/1492299/5181840/a5fad8aa-749a-11e4-81e3-a9990277c787.png)

At first we thought this could be some kind of issue at the MySQL JDBC Driver, but the fact is, we run this same test using Commons-DBCP with its default configuration (no connection validation query), and we obtained no unclosed connections...
",2014-11-28 00:25:50,"[{'nameRev': '87be72362109df6300e9d5c500395f414b450732 tags/HikariCP-2.3.0~137', 'commitMessage': 'Issue #206 suppress noisy exceptions in ""quiteSleep()"" method.\n', 'commitParents': ['5a90be91991b04fe510d65168edf2574a2cec450'], 'spoonStatsSkippedReason': '', 'commitHash': '87be72362109df6300e9d5c500395f414b450732', 'authoredDateTime': '2014-11-27 13:11:43', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'hikaricp-java6/src/main/java/com/zaxxer/hikari/util/PoolUtilities.java'}, {'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'hikaricp/src/main/java/com/zaxxer/hikari/util/PoolUtilities.java'}], 'commitDateTime': '2014-11-27 13:11:43', 'commitUser': 'brettwooldridge', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 1, 'spoonMethodName': 'com.zaxxer.hikari.util.PoolUtilities.quietlySleep(long)'}], 'spoonFilePath': 'PoolUtilities.java'}]}, {'nameRev': '527c8ce59c1c59b317618a3521ab5d4f84e08246 tags/HikariCP-2.3.0~146', 'commitMessage': 'Issue #206 Throw an exception if the bag is closed, this will cause addConnection() to cleanly close the opened connection and correctly decrement the pool count.\n', 'commitParents': ['396ecf4008a3a43223f83da3bc94326402fe3f2a'], 'spoonStatsSkippedReason': '', 'commitHash': '527c8ce59c1c59b317618a3521ab5d4f84e08246', 'authoredDateTime': '2014-11-25 23:43:17', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'hikaricp/src/main/java/com/zaxxer/hikari/util/ConcurrentBag.java'}, {'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'hikaricp-java6/src/main/java/com/zaxxer/hikari/util/ConcurrentBag.java'}], 'commitDateTime': '2014-11-25 23:43:17', 'commitUser': 'brettwooldridge', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 0, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'com.zaxxer.hikari.util.ConcurrentBag.add(com.zaxxer.hikari.util.ConcurrentBag$BagEntry)'}], 'spoonFilePath': 'ConcurrentBag.java'}]}, {'nameRev': 'f0b735cb0241a32dbda31bc2d7abd56921651986 tags/HikariCP-2.3.0~136', 'commitMessage': ""Issue #206 Use a discard policy rather than an abort policy for the housekeeping thread, the abort policy causes unnecessary looping in addConnection() during shutdown() due to the housekeeping thread being used as the executor for the setNetworkTImeout() call.  We could create another executor just for that, but it doesn't really make sense or matter.\n"", 'commitParents': ['87be72362109df6300e9d5c500395f414b450732'], 'spoonStatsSkippedReason': '', 'commitHash': 'f0b735cb0241a32dbda31bc2d7abd56921651986', 'authoredDateTime': '2014-11-27 13:14:08', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 3, 'deletions': 1, 'lines': 4, 'filePath': 'hikaricp-common/src/main/java/com/zaxxer/hikari/pool/BaseHikariPool.java'}], 'commitDateTime': '2014-11-27 13:14:08', 'commitUser': 'brettwooldridge', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 1, 'TOT': 3, 'MOV': 1, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.zaxxer.hikari.pool.BaseHikariPool'}], 'spoonFilePath': 'BaseHikariPool.java'}]}]",https://github.com/brettwooldridge/HikariCP/issues/206,2.000277777777778,['bug'],Unclosed MySQL connections when not using connectionTestQuery,3.0,"['com.zaxxer.hikari.util.PoolUtilities.quietlySleep(long)', 'com.zaxxer.hikari.pool.BaseHikariPool', 'com.zaxxer.hikari.util.ConcurrentBag.add(com.zaxxer.hikari.util.ConcurrentBag$BagEntry)']","['f0b735cb0241a32dbda31bc2d7abd56921651986', '527c8ce59c1c59b317618a3521ab5d4f84e08246', '87be72362109df6300e9d5c500395f414b450732']",,"['hikaricp-java6/src/main/java/com/zaxxer/hikari/util', 'hikaricp-common/src/main/java/com/zaxxer/hikari/pool', 'hikaricp/src/main/java/com/zaxxer/hikari/util']",7.0,5.0,12.0,5.0,1.0,3.0,6.0,1.0,2.0,2.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,HikariCP
2574,2014-09-26 21:46:01,arpol1993,"I am using HikariCP 2.0.1 with Tomcat 8.0.12. The latter keeps complaining about non-cleared ConcurrentBag threadlocal:

27-Sep-2014 00:14:49.001 SEVERE [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoader.checkThreadLocalMapForLeaks The web application [/medex] created a ThreadLocal with key of type [java.lang.ThreadLocal](value [java.lang.ThreadLocal@4437ca25]) and a value of type [com.zaxxer.hikari.util.FastList](value [com.zaxxer.hikari.util.FastList@62b24a7b]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.

ConcurrentBag uses FastList threadlocal but never removes it. Consequently, this thread cannot be processed by garbage collector.

The easiest and most obvious fix is to provide some shutdown hook for ConcurrentBag allowing to remove it's threadlocal and then use it in pool shutdown routine. As ConcurrentBag will get ""corrupted"" after shutdown call, it makes sense to track it's state in some property and throw IllegalStateException on subsequent attempts to use this concurrent bag (if necessary).

Best regards, Arthur
",2014-09-27 13:29:36,"[{'nameRev': '3b7095b4778598b36141e6ce9777afe1ee3bbf30 tags/HikariCP-2.1.0~19', 'commitMessage': 'Fixed #148 revert to using LinkedList rather than FastList in ConcurrentBag due to Tomcat leak detection.\n', 'commitParents': ['fd156489794dbc4c2ec803db39336265348b9c4f'], 'spoonStatsSkippedReason': '', 'commitHash': '3b7095b4778598b36141e6ce9777afe1ee3bbf30', 'authoredDateTime': '2014-09-27 22:29:30', 'commitGHEventType': 'closed', 'commitGitStats': [{'insertions': 6, 'deletions': 5, 'lines': 11, 'filePath': 'hikaricp/src/main/java/com/zaxxer/hikari/util/ConcurrentBag.java'}, {'insertions': 6, 'deletions': 5, 'lines': 11, 'filePath': 'hikaricp-java6/src/main/java/com/zaxxer/hikari/util/ConcurrentBag.java'}], 'commitDateTime': '2014-09-27 22:29:30', 'commitUser': 'brettwooldridge', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 1, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'com.zaxxer.hikari.util.ConcurrentBag.1'}, {'UPD': 1, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'com.zaxxer.hikari.util.ConcurrentBag.borrow(long,java.util.concurrent.TimeUnit)'}, {'UPD': 2, 'TOT': 2, 'MOV': 0, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'com.zaxxer.hikari.util.ConcurrentBag.1.initialValue()'}], 'spoonFilePath': 'ConcurrentBag.java'}]}, {'nameRev': '66c63a13db7ce53fb0e2dd897db7ff6421dea3b8 tags/HikariCP-2.1.0~17', 'commitMessage': 'Fixed #148 remove static ThreadLocal, causes a regression with multiple-pools.\n', 'commitParents': ['aea005d4ea9c6f525ecd74f1e1f0794f7c7be8e9'], 'spoonStatsSkippedReason': '', 'commitHash': '66c63a13db7ce53fb0e2dd897db7ff6421dea3b8', 'authoredDateTime': '2014-09-28 13:30:02', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 17, 'deletions': 16, 'lines': 33, 'filePath': 'hikaricp/src/main/java/com/zaxxer/hikari/util/ConcurrentBag.java'}, {'insertions': 17, 'deletions': 16, 'lines': 33, 'filePath': 'hikaricp-java6/src/main/java/com/zaxxer/hikari/util/ConcurrentBag.java'}], 'commitDateTime': '2014-09-28 13:30:02', 'commitUser': 'brettwooldridge', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 4, 'MOV': 0, 'INS': 2, 'DEL': 2, 'spoonMethodName': 'com.zaxxer.hikari.util.ConcurrentBag'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.zaxxer.hikari.util.ConcurrentBag.Synchronizer'}, {'UPD': 0, 'TOT': 3, 'MOV': 1, 'INS': 2, 'DEL': 0, 'spoonMethodName': 'com.zaxxer.hikari.util.ConcurrentBag.borrow(long,java.util.concurrent.TimeUnit)'}, {'UPD': 0, 'TOT': 6, 'MOV': 2, 'INS': 3, 'DEL': 1, 'spoonMethodName': 'com.zaxxer.hikari.util.ConcurrentBag.requite(com.zaxxer.hikari.util.ConcurrentBag$BagEntry)'}], 'spoonFilePath': 'ConcurrentBag.java'}]}]",https://github.com/brettwooldridge/HikariCP/issues/148,0.0002777777777777778,['bug'],Possible memory leak due to usage of ThreadLocals,2.0,"['com.zaxxer.hikari.util.ConcurrentBag.borrow(long,java.util.concurrent.TimeUnit)', 'com.zaxxer.hikari.util.ConcurrentBag.requite(com.zaxxer.hikari.util.ConcurrentBag$BagEntry)', 'com.zaxxer.hikari.util.ConcurrentBag', 'com.zaxxer.hikari.util.ConcurrentBag.1', 'com.zaxxer.hikari.util.ConcurrentBag.Synchronizer', 'com.zaxxer.hikari.util.ConcurrentBag.1.initialValue()']","['66c63a13db7ce53fb0e2dd897db7ff6421dea3b8', '3b7095b4778598b36141e6ce9777afe1ee3bbf30']",,"['hikaricp-java6/src/main/java/com/zaxxer/hikari/util', 'hikaricp/src/main/java/com/zaxxer/hikari/util']",46.0,42.0,88.0,2.0,4.0,6.0,18.0,3.0,8.0,3.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,HikariCP
2601,2014-03-19 06:48:51,TuomasKiviaho,"There seems to be slight a possibility to connection leak in the pool between acquiring a connection and adding it to the pool. Connection state reset has similar problem as well.

Steps to fix the issue (HikariPool.addConnection):
1. Obtaining of a datasource connection should be closed (try/catch) in case of a failure prior it has been added to the pool
2. initSql block should be followed by resetConnectionState in any case (try/finally)
",2014-03-19 08:58:42,"[{'nameRev': '99b2b765cea806ab91f947ca1bea7cd037211a1c tags/HikariCP-1.3.4~1^2~46', 'commitMessage': 'closes #44 potential connection leak during connection creation in some failure scenarios.\n', 'commitParents': ['079bf9e8c2d461012d7c403081c5f9cf29372d28'], 'spoonStatsSkippedReason': '', 'commitHash': '99b2b765cea806ab91f947ca1bea7cd037211a1c', 'authoredDateTime': '2014-03-19 17:58:30', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 19, 'deletions': 1, 'lines': 20, 'filePath': 'src/main/java/com/zaxxer/hikari/HikariPool.java'}], 'commitDateTime': '2014-03-19 17:58:30', 'commitUser': 'brettwooldridge', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.zaxxer.hikari.HikariPool.quietlyCloseConnection(java.sql.Connection)'}, {'UPD': 0, 'TOT': 5, 'MOV': 1, 'INS': 3, 'DEL': 1, 'spoonMethodName': 'com.zaxxer.hikari.HikariPool.addConnection(long)'}], 'spoonFilePath': 'HikariPool.java'}]}]",https://github.com/brettwooldridge/HikariCP/issues/44,0.0002777777777777778,['bug'],Pool leaks connections open if customization/initSql fails,1.0,"['com.zaxxer.hikari.HikariPool.quietlyCloseConnection(java.sql.Connection)', 'com.zaxxer.hikari.HikariPool.addConnection(long)']",['99b2b765cea806ab91f947ca1bea7cd037211a1c'],,['src/main/java/com/zaxxer/hikari'],19.0,1.0,20.0,1.0,0.0,2.0,6.0,1.0,4.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,HikariCP
4275,2015-08-26 09:10:20,haraldk,"The TIFFs are probably incorrectly compressed (compressed around boundaries), however a larger buffer should handle it.
",2015-08-26 09:18:08,"[{'nameRev': '867ca61755584921eea2882b6b6ebac3bd42e8bf tags/twelvemonkeys-3.2~13', 'commitMessage': 'TMI #172: Fix IIOBE/Buffer overflow issue.\n', 'commitParents': ['2bdfa4fccb7a1914271aae65db02557cef82555c'], 'spoonStatsSkippedReason': '', 'commitHash': '867ca61755584921eea2882b6b6ebac3bd42e8bf', 'authoredDateTime': '2015-08-26 11:16:35', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 1, 'deletions': 0, 'lines': 1, 'filePath': 'imageio/imageio-tiff/src/test/java/com/twelvemonkeys/imageio/plugins/tiff/TIFFImageReaderTest.java'}, {'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'imageio/imageio-tiff/src/main/java/com/twelvemonkeys/imageio/plugins/tiff/TIFFImageReader.java'}, {'insertions': 0, 'deletions': 0, 'lines': 0, 'filePath': 'imageio/imageio-tiff/src/test/resources/tiff/lzw-buffer-overflow.tif'}], 'commitDateTime': '2015-08-26 11:16:35', 'commitUser': 'haraldk', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.twelvemonkeys.imageio.plugins.tiff.TIFFImageReaderTest.getTestData()'}], 'spoonFilePath': 'TIFFImageReaderTest.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 1, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.twelvemonkeys.imageio.plugins.tiff.TIFFImageReader.createDecompressorStream(int,int,int,java.io.InputStream)'}], 'spoonFilePath': 'TIFFImageReader.java'}]}]",https://github.com/haraldk/TwelveMonkeys/issues/172,0.0002777777777777778,['Bug'],TIFF: Some LZW encoded TIFFs may throw IndexOutOfBoundsException due to buffer overflow,1.0,"['com.twelvemonkeys.imageio.plugins.tiff.TIFFImageReader.createDecompressorStream(int,int,int,java.io.InputStream)']",['867ca61755584921eea2882b6b6ebac3bd42e8bf'],,['imageio/imageio-tiff/src/main/java/com/twelvemonkeys/imageio/plugins/tiff'],1.0,1.0,2.0,1.0,0.0,1.0,2.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,TwelveMonkeys
4623,2017-09-25 13:49:33,slandelle,`DefaultChannelPool#removeAll` fails to properly remove entry from partition as it tries to remove a `Channel` instead of an `IdleChannel`.,2017-09-25 13:50:59,"[{'nameRev': '45a8b4b33efa4298f6ba5d5174e15208d1e205ac tags/async-http-client-project-2.0.37~3', 'commitMessage': 'Properly remove entry from partition, close #1461\n\nMotivation:\n\nDefaultChannelPool#removeAll fails to properly remove entry from\npartition.\n\nModification:\n\nRemove an `IdleChannel` instead of a `Channel`.\n\nResult:\n\nNo more leak.\n', 'commitParents': ['7b60e7128b5cd186bc06acd0015d313bfa2e083a'], 'spoonStatsSkippedReason': '', 'commitHash': '45a8b4b33efa4298f6ba5d5174e15208d1e205ac', 'authoredDateTime': '2017-09-25 15:50:50', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'client/src/main/java/org/asynchttpclient/netty/channel/DefaultChannelPool.java'}], 'commitDateTime': '2017-09-25 16:46:25', 'commitUser': 'slandelle', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 0, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'org.asynchttpclient.netty.channel.DefaultChannelPool.removeAll(io.netty.channel.Channel)'}], 'spoonFilePath': 'DefaultChannelPool.java'}]}, {'nameRev': '468b98f59d364732ec912719e96dfdc53d3ee92b tags/async-http-client-project-2.1.0-alpha25~3', 'commitMessage': 'Properly remove entry from partition, close #1461\n\nMotivation:\n\nDefaultChannelPool#removeAll fails to properly remove entry from\npartition.\n\nModification:\n\nRemove an `IdleChannel` instead of a `Channel`.\n\nResult:\n\nNo more leak.\n', 'commitParents': ['3975e729aea7b83b985d03e8bd5c7fbfaf61d027'], 'spoonStatsSkippedReason': '', 'commitHash': '468b98f59d364732ec912719e96dfdc53d3ee92b', 'authoredDateTime': '2017-09-25 15:50:50', 'commitGHEventType': 'closed', 'commitGitStats': [{'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'client/src/main/java/org/asynchttpclient/netty/channel/DefaultChannelPool.java'}], 'commitDateTime': '2017-09-25 15:50:50', 'commitUser': 'slandelle', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 0, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'org.asynchttpclient.netty.channel.DefaultChannelPool.removeAll(io.netty.channel.Channel)'}], 'spoonFilePath': 'DefaultChannelPool.java'}]}]",https://github.com/AsyncHttpClient/async-http-client/issues/1461,0.0002777777777777778,['Defect'],DefaultChannelPool leaks IdleChannels,1.0,['org.asynchttpclient.netty.channel.DefaultChannelPool.removeAll(io.netty.channel.Channel)'],['45a8b4b33efa4298f6ba5d5174e15208d1e205ac'],,['client/src/main/java/org/asynchttpclient/netty/channel'],1.0,1.0,2.0,1.0,0.0,1.0,2.0,0.0,1.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,async-http-client
4631,2017-05-24 20:14:06,patrick-bergeron,"Running Java command line application on machine with the following specs:

Windows 7 Professional - 64 bit
Service Pack 1
32 GB RAM
Java Version 1.8.0_91
Java SE Runtime Environment (build 1.8.0_91-b15)
Java HotSpot 64-bit Server VM (build 25.91-b15, mixed mode)

If synchronous execute() method called and UnknownHostException thrown, FilePart file is not closed and a subsequent ATOMIC_MOVE call fails with error: 'The process cannot access the file because it is being used by another process.'

```
    // code snippet with sensitive portions removed
    void transmit(final File file) {
        try {
            String authorization = """";

           ** stuff here to get authorization code

            BoundRequestBuilder request = client.preparePost(String.format(""%s/api/files/save"", url))
                    .addHeader(""Authorization"", authorization)
                    .addHeader(""Content-Type"", ""multipart/form-data"")
                    .addBodyPart(new StringPart(""transferId"", UUID.randomUUID().toString()))
                    .addBodyPart(new StringPart(""timestamp"", Timestamp.from(Instant.now()).toString()))
                    .addBodyPart(new FilePart(""file"", file, ""text/plain""));

            Response response = request.execute().get();
            if ( response != null ) {
                 // do stuff with response here
            }
        } catch ( Exception ex ) {
           // code to copy file to a different folder fails here
           // Reason: The process cannot access the file because it is being used by another process.
           // using the following code to move the file
           Files.move(<source path>, <dest path>, ATOMIC_MOVE);
        }
    }

```",2017-12-12 19:53:37,"[{'nameRev': '887a71b0cc5a89322d3eab260fe3f1d69e47d69a tags/async-http-client-project-2.0.38~1', 'commitMessage': 'Fix FileChannel leak when request fails before FileMultipartPart gets written, close #1418\n\nMotivation:\n\nWe currently eagerly open FileChannel in FileMultipartPart prior to\ntrying to send the request.\nIf we can’t even try to send the body, eg because connection fails, we\nnever close this FileChannel.\n\nModification:\n\nLazily open FileChannel when writing.\n\nResult:\n\nNo more file descriptor leak\n', 'commitParents': ['ffdbe47fa5e1920fc52ac1797dad2bfadfda9afc'], 'spoonStatsSkippedReason': '', 'commitHash': '887a71b0cc5a89322d3eab260fe3f1d69e47d69a', 'authoredDateTime': '2017-12-12 20:53:23', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 19, 'deletions': 13, 'lines': 32, 'filePath': 'client/src/main/java/org/asynchttpclient/request/body/multipart/part/FileMultipartPart.java'}], 'commitDateTime': '2017-12-12 20:55:29', 'commitUser': 'slandelle', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 1, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.request.body.multipart.part.FileMultipartPart.transferContentTo(java.nio.channels.WritableByteChannel)'}, {'UPD': 0, 'TOT': 2, 'MOV': 0, 'INS': 2, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.request.body.multipart.part.FileMultipartPart.getChannel()'}, {'UPD': 3, 'TOT': 19, 'MOV': 10, 'INS': 2, 'DEL': 4, 'spoonMethodName': 'org.asynchttpclient.request.body.multipart.part.FileMultipartPart'}, {'UPD': 0, 'TOT': 2, 'MOV': 1, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.request.body.multipart.part.FileMultipartPart.transferContentTo(io.netty.buffer.ByteBuf)'}], 'spoonFilePath': 'FileMultipartPart.java'}]}, {'nameRev': '93860f9fc316b42d930ec2aeb9bc02d6aacd8ec5 tags/async-http-client-project-2.1.0-RC2~1', 'commitMessage': 'Fix FileChannel leak when request fails before FileMultipartPart gets written, close #1418\n\nMotivation:\n\nWe currently eagerly open FileChannel in FileMultipartPart prior to\ntrying to send the request.\nIf we can’t even try to send the body, eg because connection fails, we\nnever close this FileChannel.\n\nModification:\n\nLazily open FileChannel when writing.\n\nResult:\n\nNo more file descriptor leak\n', 'commitParents': ['d2f3c198e6ed05eafea86e11e59f7b8adea97c06'], 'spoonStatsSkippedReason': '', 'commitHash': '93860f9fc316b42d930ec2aeb9bc02d6aacd8ec5', 'authoredDateTime': '2017-12-12 20:53:23', 'commitGHEventType': 'closed', 'commitGitStats': [{'insertions': 19, 'deletions': 13, 'lines': 32, 'filePath': 'client/src/main/java/org/asynchttpclient/request/body/multipart/part/FileMultipartPart.java'}], 'commitDateTime': '2017-12-12 20:53:23', 'commitUser': 'slandelle', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 2, 'MOV': 1, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.request.body.multipart.part.FileMultipartPart.transferContentTo(java.nio.channels.WritableByteChannel)'}, {'UPD': 0, 'TOT': 2, 'MOV': 0, 'INS': 2, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.request.body.multipart.part.FileMultipartPart.getChannel()'}, {'UPD': 2, 'TOT': 18, 'MOV': 10, 'INS': 2, 'DEL': 4, 'spoonMethodName': 'org.asynchttpclient.request.body.multipart.part.FileMultipartPart'}, {'UPD': 0, 'TOT': 2, 'MOV': 1, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.request.body.multipart.part.FileMultipartPart.transferContentTo(io.netty.buffer.ByteBuf)'}], 'spoonFilePath': 'FileMultipartPart.java'}]}]",https://github.com/AsyncHttpClient/async-http-client/issues/1418,201.00027777777777,['Defect'],FilePart file not properly closed on UnknownHostException,1.0,"['org.asynchttpclient.request.body.multipart.part.FileMultipartPart', 'org.asynchttpclient.request.body.multipart.part.FileMultipartPart.transferContentTo(java.nio.channels.WritableByteChannel)', 'org.asynchttpclient.request.body.multipart.part.FileMultipartPart.getChannel()', 'org.asynchttpclient.request.body.multipart.part.FileMultipartPart.transferContentTo(io.netty.buffer.ByteBuf)']",['887a71b0cc5a89322d3eab260fe3f1d69e47d69a'],,['client/src/main/java/org/asynchttpclient/request/body/multipart/part'],19.0,13.0,32.0,1.0,3.0,4.0,25.0,12.0,6.0,4.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,async-http-client
4649,2017-02-14 23:02:41,slandelle,"When multiple non US-ASCII chars are split over several chunks, Utf8ByteBufCharsetDecoder crashes with BufferOverflowException.

This happens because we don't clear the `splitCharBuffer` in-between and only do so once decoding is done.",2017-02-14 23:05:32,"[{'nameRev': '28e543cdf357bb8bc627fb51a7504c684ad4bafe tags/async-http-client-project-2.1.0-alpha5~2', 'commitMessage': ""Clear Utf8ByteBufCharsetDecoder#splitCharBuffer once char is complete, close #1357\n\nMotivation:\n\nWhen multiple non US-ASCII chars are split over several chunks,\nUtf8ByteBufCharsetDecoder crashes with BufferOverflowException.\n\nThis happens because we don't clear the splitCharBuffer in-between and\nonly do so once decoding is done.\n\nModifications:\n\nClear Utf8ByteBufCharsetDecoder#splitCharBuffer once char is complete\n\nResult:\n\nNo more BufferOverflowException\n"", 'commitParents': ['b0374260cd59a344abd910cbd730b116c16cf253'], 'spoonStatsSkippedReason': '', 'commitHash': '28e543cdf357bb8bc627fb51a7504c684ad4bafe', 'authoredDateTime': '2017-02-14 23:04:37', 'commitGHEventType': 'closed', 'commitGitStats': [{'insertions': 2, 'deletions': 1, 'lines': 3, 'filePath': 'netty-utils/src/main/java/org/asynchttpclient/netty/util/Utf8ByteBufCharsetDecoder.java'}, {'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'netty-utils/src/test/java/org/asynchttpclient/netty/util/{ByteBufUtilsTest.java => Utf8ByteBufCharsetDecoderTest.java}'}], 'commitDateTime': '2017-02-14 23:05:21', 'commitUser': 'slandelle', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.handleSplitCharBuffer(java.nio.ByteBuffer,boolean)'}, {'UPD': 0, 'TOT': 5, 'MOV': 3, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.decodePartial(java.nio.ByteBuffer,boolean)'}], 'spoonFilePath': 'Utf8ByteBufCharsetDecoder.java'}, {'spoonMethods': [{'UPD': 1, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest.byteBufs2StringShouldBeAbleToDealWithCharsWithVariableBytesLength()'}, {'UPD': 1, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest.testByteBuf2BytesNoBackingArray()'}, {'UPD': 1, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest.testByteBuf2BytesHasBackingArray()'}, {'UPD': 1, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest'}], 'spoonFilePath': 'Utf8ByteBufCharsetDecoderTest.java'}]}, {'nameRev': 'fab7b39e91a07fecde9bb0761b632b7b88e3d943 tags/async-http-client-project-2.0.29~1', 'commitMessage': ""Clear Utf8ByteBufCharsetDecoder#splitCharBuffer once char is complete, close #1357\n\nMotivation:\n\nWhen multiple non US-ASCII chars are split over several chunks,\nUtf8ByteBufCharsetDecoder crashes with BufferOverflowException.\n\nThis happens because we don't clear the splitCharBuffer in-between and\nonly do so once decoding is done.\n\nModifications:\n\nClear Utf8ByteBufCharsetDecoder#splitCharBuffer once char is complete\n\nResult:\n\nNo more BufferOverflowException\n"", 'commitParents': ['bb7652a525712adde5e93fa080b31234dc3f24a9'], 'spoonStatsSkippedReason': '', 'commitHash': 'fab7b39e91a07fecde9bb0761b632b7b88e3d943', 'authoredDateTime': '2017-02-14 23:04:37', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 2, 'deletions': 1, 'lines': 3, 'filePath': 'netty-utils/src/main/java/org/asynchttpclient/netty/util/Utf8ByteBufCharsetDecoder.java'}, {'insertions': 1, 'deletions': 1, 'lines': 2, 'filePath': 'netty-utils/src/test/java/org/asynchttpclient/netty/util/{ByteBufUtilsTest.java => Utf8ByteBufCharsetDecoderTest.java}'}], 'commitDateTime': '2017-02-14 23:04:37', 'commitUser': 'slandelle', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.handleSplitCharBuffer(java.nio.ByteBuffer,boolean)'}, {'UPD': 0, 'TOT': 5, 'MOV': 3, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.decodePartial(java.nio.ByteBuffer,boolean)'}], 'spoonFilePath': 'Utf8ByteBufCharsetDecoder.java'}, {'spoonMethods': [{'UPD': 1, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest.byteBufs2StringShouldBeAbleToDealWithCharsWithVariableBytesLength()'}, {'UPD': 1, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest.testByteBuf2BytesNoBackingArray()'}, {'UPD': 1, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest.testByteBuf2BytesHasBackingArray()'}, {'UPD': 1, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest'}], 'spoonFilePath': 'Utf8ByteBufCharsetDecoderTest.java'}]}]",https://github.com/AsyncHttpClient/async-http-client/issues/1357,0.0002777777777777778,['Defect'],Utf8ByteBufCharsetDecoder BufferOverflowException when several non US-ASCII chars are split,1.0,"['org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.handleSplitCharBuffer(java.nio.ByteBuffer,boolean)', 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.decodePartial(java.nio.ByteBuffer,boolean)']",['28e543cdf357bb8bc627fb51a7504c684ad4bafe'],,['netty-utils/src/main/java/org/asynchttpclient/netty/util'],2.0,1.0,3.0,1.0,0.0,2.0,6.0,3.0,2.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,async-http-client
4658,2017-01-15 08:21:30,slandelle,Utf8ByteBufCharsetDecoder doesn't reset splitCharBuffer' capacity between runs.,2017-01-15 08:34:31,"[{'nameRev': '4a946b59243305a596eed5e493a810441488af57 tags/async-http-client-project-2.1.0-alpha3~12', 'commitMessage': 'Reset Utf8ByteBufCharsetDecoder splitCharBuffer, close #1325\n\nMotivation:\n\nUtf8ByteBufCharsetDecoder crashes with BufferOverflow when trying to\ndecode a char whose byte length is larger than the one of the first\nsplit char that was decoded.\n\nThis happens because we only reset position while we should be\nresetting capacity too.\n\nModifications:\n\nUser ByteBuffer reset instead os `position(0)`.\n\nResult:\n\nNo more BufferOverflow\n', 'commitParents': ['f4a4d15c2a268ae7d437e9319b624af02d8a4b4b'], 'spoonStatsSkippedReason': '', 'commitHash': '4a946b59243305a596eed5e493a810441488af57', 'authoredDateTime': '2017-01-15 09:34:19', 'commitGHEventType': 'closed', 'commitGitStats': [{'insertions': 6, 'deletions': 12, 'lines': 18, 'filePath': 'netty-utils/src/main/java/org/asynchttpclient/netty/util/Utf8ByteBufCharsetDecoder.java'}, {'insertions': 34, 'deletions': 8, 'lines': 42, 'filePath': 'netty-utils/src/test/java/org/asynchttpclient/netty/util/ByteBufUtilsTest.java'}], 'commitDateTime': '2017-01-15 09:34:19', 'commitUser': 'slandelle', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.reset()'}, {'UPD': 0, 'TOT': 8, 'MOV': 2, 'INS': 4, 'DEL': 2, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 1, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.handleSplitCharBuffer(java.nio.ByteBuffer,boolean)'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 1, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.decodePartial(java.nio.ByteBuffer,boolean)'}, {'UPD': 0, 'TOT': 3, 'MOV': 2, 'INS': 0, 'DEL': 1, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.initSplitCharBuffer()'}], 'spoonFilePath': 'Utf8ByteBufCharsetDecoder.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest.byteBufs2StringShouldBeAbleToDealWithCharsWithVariableBytesLength()'}, {'UPD': 3, 'TOT': 11, 'MOV': 5, 'INS': 1, 'DEL': 2, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest.testByteBuf2BytesNoBackingArray()'}, {'UPD': 2, 'TOT': 7, 'MOV': 3, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest.testByteBuf2BytesHasBackingArray()'}], 'spoonFilePath': 'ByteBufUtilsTest.java'}]}, {'nameRev': 'c8783ffe11adca79f854e2146383b84004089d5b tags/async-http-client-project-2.0.26~1', 'commitMessage': 'Reset Utf8ByteBufCharsetDecoder splitCharBuffer, close #1325\n\nMotivation:\n\nUtf8ByteBufCharsetDecoder crashes with BufferOverflow when trying to\ndecode a char whose byte length is larger than the one of the first\nsplit char that was decoded.\n\nThis happens because we only reset position while we should be\nresetting capacity too.\n\nModifications:\n\nUser ByteBuffer reset instead os `position(0)`.\n\nResult:\n\nNo more BufferOverflow\n', 'commitParents': ['968358a8835e7aac27e0c6184209f0a6f36d488f'], 'spoonStatsSkippedReason': '', 'commitHash': 'c8783ffe11adca79f854e2146383b84004089d5b', 'authoredDateTime': '2017-01-15 09:34:19', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 6, 'deletions': 12, 'lines': 18, 'filePath': 'netty-utils/src/main/java/org/asynchttpclient/netty/util/Utf8ByteBufCharsetDecoder.java'}, {'insertions': 34, 'deletions': 8, 'lines': 42, 'filePath': 'netty-utils/src/test/java/org/asynchttpclient/netty/util/ByteBufUtilsTest.java'}], 'commitDateTime': '2017-01-15 09:57:37', 'commitUser': 'slandelle', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.reset()'}, {'UPD': 0, 'TOT': 8, 'MOV': 2, 'INS': 4, 'DEL': 2, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 1, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.handleSplitCharBuffer(java.nio.ByteBuffer,boolean)'}, {'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 0, 'DEL': 1, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.decodePartial(java.nio.ByteBuffer,boolean)'}, {'UPD': 0, 'TOT': 3, 'MOV': 2, 'INS': 0, 'DEL': 1, 'spoonMethodName': 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.initSplitCharBuffer()'}], 'spoonFilePath': 'Utf8ByteBufCharsetDecoder.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest.byteBufs2StringShouldBeAbleToDealWithCharsWithVariableBytesLength()'}, {'UPD': 3, 'TOT': 11, 'MOV': 5, 'INS': 1, 'DEL': 2, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest.testByteBuf2BytesNoBackingArray()'}, {'UPD': 2, 'TOT': 7, 'MOV': 3, 'INS': 1, 'DEL': 1, 'spoonMethodName': 'org.asynchttpclient.netty.util.ByteBufUtilsTest.testByteBuf2BytesHasBackingArray()'}], 'spoonFilePath': 'ByteBufUtilsTest.java'}]}]",https://github.com/AsyncHttpClient/async-http-client/issues/1325,0.0002777777777777778,['Defect'],Utf8ByteBufCharsetDecoder BufferOverflowException,1.0,"['org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.reset()', 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder', 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.handleSplitCharBuffer(java.nio.ByteBuffer,boolean)', 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.decodePartial(java.nio.ByteBuffer,boolean)', 'org.asynchttpclient.netty.util.Utf8ByteBufCharsetDecoder.initSplitCharBuffer()']",['4a946b59243305a596eed5e493a810441488af57'],,['netty-utils/src/main/java/org/asynchttpclient/netty/util'],6.0,12.0,18.0,1.0,0.0,5.0,14.0,4.0,5.0,5.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,async-http-client
4730,2015-12-22 13:11:52,elrodro83,"Hi,

We are using grizzly through AHC to perform some HTTP requests. After those requests have finished, in a thread dump i can still see the response objects being referenced, and not being garbage collected. Attached is a screenshot of there references from a heap dump:

![screen shot 2015-12-22 at 9 37 37 am](https://cloud.githubusercontent.com/assets/8010105/11955732/211f42b4-a893-11e5-8885-4c7eb7553764.png)

In a case where the size of the transferred data is big, i see some heavy memory usage.

The problem seems to be with the reference chain TCPNIOConnection -> IndexedAttributeHolder -> $Snapshot -> HttpTransactionContext. Perhaps at least one of those references should be discarded after the request has completed, or provide a way to an app to clear that.

The following test can reproduce this issue.

```
    @Test
    public void referencedResponseHC() throws InterruptedException
    {
        AsyncHttpClientConfig config = new AsyncHttpClientConfig.Builder().build();
        AsyncHttpClient client = new AsyncHttpClient(new GrizzlyAsyncHttpProvider(config), config);

        final CountDownLatch responseLatch = new CountDownLatch(1);
        final AtomicReference<Response> responseRef = new AtomicReference<>();

        client.prepareGet(""http://www.ning.com/"").execute(new AsyncCompletionHandler<Response>()
        {

            @Override
            public Response onCompleted(Response response) throws Exception
            {
                responseLatch.countDown();
                responseRef.set(response);
                return response;
            }

            @Override
            public void onThrowable(Throwable t)
            {
                // Something wrong happened.
            }
        });

        responseLatch.await(5, TimeUnit.SECONDS);
        verifyNotLeaked(new PhantomReference<>(responseRef.getAndSet(null), new ReferenceQueue<>()));
    }

    private void verifyNotLeaked(PhantomReference possibleLeakPhantomRef) throws InterruptedException
    {
        for (int i = 0; i < 10; ++i)
        {
            System.gc();
            Thread.sleep(100);
            if (possibleLeakPhantomRef.isEnqueued())
            {
                break;
            }
        }
        assertTrue(possibleLeakPhantomRef.isEnqueued());
    }
```

Thanks in advance,
",2015-12-23 17:52:40,"[{'nameRev': '2c3e12a6af0cf255476f7fc2ee8dcfbb2b3422df tags/async-http-client-1.9.32~2', 'commitMessage': '+ fix issue #1067\nhttps://github.com/AsyncHttpClient/async-http-client/issues/1067\n""GrizzlyResponse object reachable from SelectorRunner thread local""', 'commitParents': ['f6fd24c385e65cf537c9e2c02a00de999db76d88'], 'spoonStatsSkippedReason': '', 'commitHash': '2c3e12a6af0cf255476f7fc2ee8dcfbb2b3422df', 'authoredDateTime': '2015-12-23 00:08:18', 'commitGHEventType': 'referenced', 'commitGitStats': [{'insertions': 1, 'deletions': 0, 'lines': 1, 'filePath': 'src/main/java/com/ning/http/client/providers/grizzly/HttpTransactionContext.java'}, {'insertions': 76, 'deletions': 0, 'lines': 76, 'filePath': 'src/test/java/com/ning/http/client/ws/grizzly/ResponseRefLeak.java'}], 'commitDateTime': '2015-12-23 00:08:43', 'commitUser': 'oleksiys', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.ning.http.client.ws.grizzly.ResponseRefLeak'}], 'spoonFilePath': 'ResponseRefLeak.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'MOV': 0, 'INS': 1, 'DEL': 0, 'spoonMethodName': 'com.ning.http.client.providers.grizzly.HttpTransactionContext.cleanupTransaction(org.glassfish.grizzly.http.HttpContext)'}], 'spoonFilePath': 'HttpTransactionContext.java'}]}]",https://github.com/AsyncHttpClient/async-http-client/issues/1067,1.0002777777777778,"['Defect', 'Grizzly']",GrizzlyResponse object reachable from SelectorRunner thread local,1.0,"['com.ning.http.client.providers.grizzly.HttpTransactionContext.cleanupTransaction(org.glassfish.grizzly.http.HttpContext)', 'com.ning.http.client.ws.grizzly.ResponseRefLeak']",['2c3e12a6af0cf255476f7fc2ee8dcfbb2b3422df'],,['src/main/java/com/ning/http/client/providers/grizzly'],1.0,0.0,1.0,1.0,0.0,2.0,2.0,0.0,2.0,0.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,async-http-client
11768,2016-10-04 08:48:39,AndyScherzinger,"Bug reported on oC tracker, also valid for Nc:

---
### Actual behaviour

-database cursor may be left open
### Expected behaviour

-cursors even empty ones (moveToFirst returns false) should be closed

The database cursor used by the delete() method (Line 94) in FileContentProvider class may be left unclosed if cursor.moveToFirst() returns false:

https://github.com/owncloud/android/blob/master/src/com/owncloud/android/providers/FileContentProvider.java

```
if (c != null && c.moveToFirst()) {
                    remoteId = c.getString(c.getColumnIndex(ProviderTableMeta.FILE_REMOTE_ID));
                    //ThumbnailsCacheManager.removeFileFromCache(remoteId);
                    c.close();
                }
```

---

I'll open a PR right away.
",2016-10-05 17:15:35,"[{'commitMessage': 'pur cursor close in finally block to make sure no resource leak occurs - #305\n\nResolves: #305\n', 'commitParents': ['e8f5c573297ea35696aea8bbfa58e8582f8dae28'], 'commitHash': '2704a0da478f4a94b590109495631f86178cbde0', 'commitSpoonAstDiffStats': [{'spoonFilePath': 'FileContentProvider.java', 'spoonMethods': [{'spoonMethodName': 'com.owncloud.android.providers.FileContentProvider.delete(android.database.sqlite.SQLiteDatabase,android.net.Uri,java.lang.String,java.lang.String[])', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 4, 'TOT': 5}]}], 'nameRev': '2704a0da478f4a94b590109495631f86178cbde0 tags/stable-2.0.1~698^2', 'commitUser': 'AndyScherzinger', 'authoredDateTime': '2016-10-04 12:03:14', 'commitGHEventType': 'referenced', 'commitGitStats': [{'lines': 31, 'filePath': 'src/com/owncloud/android/providers/FileContentProvider.java', 'insertions': 19, 'deletions': 12}], 'commitDateTime': '2016-10-04 12:03:14', 'spoonStatsSkippedReason': ''}]",https://github.com/nextcloud/android/issues/305,1.0002777777777778,"['bug', 'hacktoberfest', 'pr exists']",database cursor not closed in certain scenarios,1.0,"['com.owncloud.android.providers.FileContentProvider.delete(android.database.sqlite.SQLiteDatabase,android.net.Uri,java.lang.String,java.lang.String[])']",['2704a0da478f4a94b590109495631f86178cbde0'],,['src/com/owncloud/android/providers'],19.0,12.0,31.0,1.0,0.0,1.0,5.0,4.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,android
12202,2017-04-04 13:42:12,joakime,"If an environment has a URLStreamHandler installed, its possible for a StackOverflowError to occur when in the WebAppClassloader ...

```
Exception in thread ""FelixStartLevel"" java.lang.StackOverflowError
 	at org.apache.felix.framework.URLHandlers.createURLStreamHandler(URLHandlers.java:495)
 	at java.net.URL.getURLStreamHandler(URL.java:1142)
 	at java.net.URL.<init>(URL.java:599)
 	at java.net.URL.<init>(URL.java:490)
 	at java.net.URL.<init>(URL.java:439)
 	at org.eclipse.jetty.util.resource.Resource.newResource(Resource.java:166)
 	at org.eclipse.jetty.util.resource.Resource.newResource(Resource.java:149)
 	at org.eclipse.jetty.util.TypeUtil.getLoadedFrom(TypeUtil.java:726)
 	at org.eclipse.jetty.webapp.ClasspathPattern.match(ClasspathPattern.java:518)
 	at org.eclipse.jetty.webapp.WebAppContext.isServerClass(WebAppContext.java:811)
 	at org.eclipse.jetty.webapp.WebAppClassLoader.loadClass(WebAppClassLoader.java:563)
 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
 	at org.apache.felix.framework.URLHandlers.createURLStreamHandler(URLHandlers.java:495)
 	at java.net.URL.getURLStreamHandler(URL.java:1142)
 	at java.net.URL.<init>(URL.java:599)
 	at java.net.URL.<init>(URL.java:490)
 	at java.net.URL.<init>(URL.java:439)
 	at org.eclipse.jetty.util.resource.Resource.newResource(Resource.java:166)
 	at org.eclipse.jetty.util.resource.Resource.newResource(Resource.java:149)
 	at org.eclipse.jetty.util.TypeUtil.getLoadedFrom(TypeUtil.java:726)
 	at org.eclipse.jetty.webapp.ClasspathPattern.match(ClasspathPattern.java:518)
 	at org.eclipse.jetty.webapp.WebAppContext.isServerClass(WebAppContext.java:811)
 	at org.eclipse.jetty.webapp.WebAppClassLoader.loadClass(WebAppClassLoader.java:563)
 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
 	at org.apache.felix.framework.URLHandlers.createURLStreamHandler(URLHandlers.java:495)
 	at java.net.URL.getURLStreamHandler(URL.java:1142)
 	at java.net.URL.<init>(URL.java:599)
 	at java.net.URL.<init>(URL.java:490)
```",2017-04-26 17:23:59,"[{'commitMessage': 'Issue #1448 - Reduce unncessary URL creation\n', 'commitParents': ['c285d6f8bbd839906e8c39d23db2f343be22c6ca'], 'commitHash': 'f53776628f15b22899026f05fed00b9610d06c8d', 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebAppClassLoaderTest.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.jetty.webapp.WebAppClassLoaderTest.testResources()', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}, {'spoonMethodName': 'org.eclipse.jetty.webapp.WebAppClassLoaderTest', 'DEL': 0, 'INS': 0, 'UPD': 1, 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'URLStreamHandlerUtil.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.jetty.webapp.URLStreamHandlerUtil', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'TypeUtil.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.jetty.util.TypeUtil.getLoadedFrom(java.lang.Class)', 'DEL': 0, 'INS': 0, 'UPD': 1, 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'WebAppClassLoaderUrlStreamTest.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.jetty.webapp.WebAppClassLoaderUrlStreamTest', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}]}], 'nameRev': 'f53776628f15b22899026f05fed00b9610d06c8d tags/jetty-9.4.4.v20170410~12', 'commitUser': 'joakime', 'authoredDateTime': '2017-04-04 09:08:44', 'commitGHEventType': 'referenced', 'commitGitStats': [{'lines': 78, 'filePath': 'jetty-webapp/src/test/java/org/eclipse/jetty/webapp/URLStreamHandlerUtil.java', 'insertions': 78, 'deletions': 0}, {'lines': 113, 'filePath': 'jetty-webapp/src/test/java/org/eclipse/jetty/webapp/WebAppClassLoaderUrlStreamTest.java', 'insertions': 113, 'deletions': 0}, {'lines': 16, 'filePath': 'jetty-webapp/src/test/java/org/eclipse/jetty/webapp/WebAppClassLoaderTest.java', 'insertions': 11, 'deletions': 5}, {'lines': 4, 'filePath': 'jetty-util/src/main/java/org/eclipse/jetty/util/TypeUtil.java', 'insertions': 1, 'deletions': 3}], 'commitDateTime': '2017-04-04 09:08:44', 'spoonStatsSkippedReason': ''}, {'commitMessage': 'Issue #1448 - Eliminating Resource creation from TypeUtil.getLoadedFrom()\n\n+ Replaced with URI TypeUtil.getLocationOfClass(Class clazz)\n+ and File TypeUtil.getLocationOfClassAsFile(Class clazz)\n+ This is done to eliminate extraneous ""new URL"" and ""URI.toURL"" calls\n  that can trigger URL Stream Handler creation and initialization\n  which is the cause of the StackOverflowError\n', 'commitParents': ['8c26eddbc642855d669d794625d6eb0411ce73c0'], 'commitHash': '6ca9bacee6039483fa138c1cfbd29e26e744fdeb', 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ClasspathPattern.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.jetty.webapp.ClasspathPattern.match(java.lang.Class)', 'DEL': 3, 'INS': 2, 'UPD': 5, 'MOV': 3, 'TOT': 13}, {'spoonMethodName': 'org.eclipse.jetty.webapp.ClasspathPattern.match(java.lang.String,java.net.URL)', 'DEL': 2, 'INS': 2, 'UPD': 1, 'MOV': 4, 'TOT': 9}]}, {'spoonFilePath': 'AnnotationConfiguration.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.jetty.annotations.AnnotationConfiguration.getJarFor(javax.servlet.ServletContainerInitializer)', 'DEL': 0, 'INS': 2, 'UPD': 2, 'MOV': 1, 'TOT': 5}]}, {'spoonFilePath': 'TypeUtilTest.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.jetty.util.TypeUtilTest.testGetLocationOfClass()', 'DEL': 0, 'INS': 2, 'UPD': 0, 'MOV': 0, 'TOT': 2}, {'spoonMethodName': 'org.eclipse.jetty.util.TypeUtilTest.testLoadedFrom()', 'DEL': 2, 'INS': 0, 'UPD': 5, 'MOV': 8, 'TOT': 15}, {'spoonMethodName': 'org.eclipse.jetty.util.TypeUtilTest.testLoadedFrom9()', 'DEL': 2, 'INS': 0, 'UPD': 3, 'MOV': 3, 'TOT': 8}]}, {'spoonFilePath': 'TypeUtil.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.jetty.util.TypeUtil.getLocationOfClassAsFile(java.lang.Class)', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}, {'spoonMethodName': 'org.eclipse.jetty.util.TypeUtil.getLoadedFrom(java.lang.Class)', 'DEL': 1, 'INS': 0, 'UPD': 6, 'MOV': 9, 'TOT': 16}]}, {'spoonFilePath': 'ClasspathPatternTest.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.jetty.webapp.ClasspathPatternTest.testIncludedLocations()', 'DEL': 1, 'INS': 0, 'UPD': 10, 'MOV': 1, 'TOT': 12}, {'spoonMethodName': 'org.eclipse.jetty.webapp.ClasspathPatternTest.testExcludeLocations()', 'DEL': 1, 'INS': 0, 'UPD': 10, 'MOV': 1, 'TOT': 12}]}], 'nameRev': '6ca9bacee6039483fa138c1cfbd29e26e744fdeb tags/jetty-9.4.5.v20170502~28', 'commitUser': 'gregw', 'authoredDateTime': '2017-04-24 09:36:38', 'commitGHEventType': 'referenced', 'commitGitStats': [{'lines': 28, 'filePath': 'jetty-util/src/test/java/org/eclipse/jetty/util/TypeUtilTest.java', 'insertions': 13, 'deletions': 15}, {'lines': 17, 'filePath': 'jetty-webapp/src/main/java/org/eclipse/jetty/webapp/ClasspathPattern.java', 'insertions': 10, 'deletions': 7}, {'lines': 27, 'filePath': 'jetty-webapp/src/test/java/org/eclipse/jetty/webapp/ClasspathPatternTest.java', 'insertions': 14, 'deletions': 13}, {'lines': 5, 'filePath': 'jetty-annotations/src/main/java/org/eclipse/jetty/annotations/AnnotationConfiguration.java', 'insertions': 4, 'deletions': 1}, {'lines': 62, 'filePath': 'jetty-util/src/main/java/org/eclipse/jetty/util/TypeUtil.java', 'insertions': 38, 'deletions': 24}], 'commitDateTime': '2017-04-26 13:43:35', 'spoonStatsSkippedReason': ''}, {'commitMessage': '', 'commitParents': [], 'commitHash': '975f88b950151de7888b40a7d26e8695cfcc146d', 'commitSpoonAstDiffStats': [], 'nameRev': '', 'commitUser': 'joakime', 'authoredDateTime': '', 'commitGHEventType': 'referenced', 'commitGitStats': [], 'commitDateTime': '', 'spoonStatsSkippedReason': ''}, {'commitMessage': 'Issue #1448\n\nOptimized excluded by name handling\n', 'commitParents': ['6ca9bacee6039483fa138c1cfbd29e26e744fdeb'], 'commitHash': 'a3ace98a8dc56603daa755fee639b9510cfe1385', 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ClasspathPattern.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.jetty.webapp.ClasspathPattern.match(java.lang.Class)', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}, {'spoonMethodName': 'org.eclipse.jetty.webapp.ClasspathPattern.match(java.lang.String,java.net.URL)', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}]}], 'nameRev': 'a3ace98a8dc56603daa755fee639b9510cfe1385 tags/jetty-9.4.5.v20170502~27', 'commitUser': 'gregw', 'authoredDateTime': '2017-04-26 13:50:58', 'commitGHEventType': 'referenced', 'commitGitStats': [{'lines': 5, 'filePath': 'jetty-webapp/src/main/java/org/eclipse/jetty/webapp/ClasspathPattern.java', 'insertions': 5, 'deletions': 0}], 'commitDateTime': '2017-04-26 13:50:58', 'spoonStatsSkippedReason': ''}]",https://github.com/eclipse/jetty.project/issues/1448,22.00027777777778,['Bug'],StackOverflowError when using URLStreamHandlerFactory in WebAppClassloader,3.0,"['org.eclipse.jetty.webapp.ClasspathPattern.match(java.lang.Class)', 'org.eclipse.jetty.util.TypeUtil.getLocationOfClassAsFile(java.lang.Class)', 'org.eclipse.jetty.util.TypeUtil.getLoadedFrom(java.lang.Class)', 'org.eclipse.jetty.webapp.URLStreamHandlerUtil', 'org.eclipse.jetty.annotations.AnnotationConfiguration.getJarFor(javax.servlet.ServletContainerInitializer)', 'org.eclipse.jetty.webapp.ClasspathPattern.match(java.lang.String,java.net.URL)']","['f53776628f15b22899026f05fed00b9610d06c8d', '6ca9bacee6039483fa138c1cfbd29e26e744fdeb', 'a3ace98a8dc56603daa755fee639b9510cfe1385']",,"['jetty-util/src/main/java/org/eclipse/jetty/util', 'jetty-webapp/src/main/java/org/eclipse/jetty/webapp', 'jetty-annotations/src/main/java/org/eclipse/jetty/annotations']",58.0,35.0,93.0,3.0,15.0,6.0,48.0,17.0,10.0,6.0,4.0,0.0,0.0,0.0,1.0,0.0,0.0,jetty.project
12359,2016-02-25 10:55:41,vaandr,"In PoolingHttpDestination:process(final C connection, boolean dispatch) a check is performed to ensure the request was not aborted before being associated with a connection and if it was then the connection is neither released or closed. Might be useful to move the connection release code below in a separate method and use it for both cases - i.e. when there's no exchange or the request was aborted prior to creation of the exchange.

```
public void process(final C connection, boolean dispatch)
    {
        HttpClient client = getHttpClient();
        final HttpExchange exchange = getHttpExchanges().poll();
        if (LOG.isDebugEnabled())
            LOG.debug(""Processing exchange {} on {} of {}"", exchange, connection, this);
        if (exchange == null)
        {
            if (!connectionPool.release(connection))
                connection.close();

            if (!client.isRunning())
            {
                if (LOG.isDebugEnabled())
                    LOG.debug(""{} is stopping"", client);
                connection.close();
            }
        }
        else
        {
            final Request request = exchange.getRequest();
            Throwable cause = request.getAbortCause();
            if (cause != null)
            {
                if (LOG.isDebugEnabled())
                    LOG.debug(""Aborted before processing {}: {}"", exchange, cause);
                // It may happen that the request is aborted before the exchange
                // is created. Aborting the exchange a second time will result in
                // a no-operation, so we just abort here to cover that edge case.
                exchange.abort(cause);
            }
            else
            {
                if (dispatch)
                {
                    client.getExecutor().execute(new Runnable()
                    {
                        @Override
                        public void run()
                        {
                            send(connection, exchange);
                        }
                    });
                }
                else
                {
                    send(connection, exchange);
                }
            }
        }
    }
```
",2016-03-01 14:36:14,"[{'commitMessage': 'Issue #365 (Potential connection leakage in case of aborted request)\n\nFixed by releasing the connection that will not be used to the pool.\n', 'commitParents': ['1a1a8dd806a7ea585b1bfd4230c39eec1528de42'], 'commitHash': 'd53766f6fe0cfa03579c7e0053c9d72e0037df2d', 'commitSpoonAstDiffStats': [{'spoonFilePath': 'HttpRequestAbortTest.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.jetty.client.HttpRequestAbortTest.testAbortBeforeQueued()', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'PoolingHttpDestination.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.jetty.client.PoolingHttpDestination.process(org.eclipse.jetty.client.api.Connection,boolean)', 'DEL': 0, 'INS': 2, 'UPD': 0, 'MOV': 3, 'TOT': 5}]}], 'nameRev': 'd53766f6fe0cfa03579c7e0053c9d72e0037df2d tags/jetty-9.3.8.v20160311~19^2~4', 'commitUser': 'sbordet', 'authoredDateTime': '2016-03-01 15:18:28', 'commitGHEventType': 'referenced', 'commitGitStats': [{'lines': 28, 'filePath': 'jetty-client/src/test/java/org/eclipse/jetty/client/HttpRequestAbortTest.java', 'insertions': 28, 'deletions': 0}, {'lines': 3, 'filePath': 'jetty-client/src/main/java/org/eclipse/jetty/client/PoolingHttpDestination.java', 'insertions': 3, 'deletions': 0}], 'commitDateTime': '2016-03-01 15:19:02', 'spoonStatsSkippedReason': ''}]",https://github.com/eclipse/jetty.project/issues/365,5.000277777777778,['Bug'],Potential connection leakage in case of aborted request,1.0,"['org.eclipse.jetty.client.PoolingHttpDestination.process(org.eclipse.jetty.client.api.Connection,boolean)']",['d53766f6fe0cfa03579c7e0053c9d72e0037df2d'],,['jetty-client/src/main/java/org/eclipse/jetty/client'],3.0,0.0,3.0,1.0,0.0,1.0,5.0,3.0,2.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,jetty.project
16376,2020-01-10 18:27:56,romani,"https://sonarcloud.io/project/issues?id=org.checkstyle%3Acheckstyle&resolved=false&rules=java%3AS5164&types=BUG

such code it is resulted in incomplete Multithreading implementation.
Violation looks valid.

Should we update code with execution of `remove` ? or remove ThreadLocal ? Or mark this as ""Won't fix"" ?",2020-01-17 15:08:43,"[{'commitMessage': ""Issue #7458: 'ThreadLocal' variables should be cleaned up when no longer used\n"", 'commitParents': ['b572373f5a21610f781564bf06cff0c7ffd92a23'], 'commitHash': '62f8f162e98cffaaac49d2d029697f3df7ba46bf', 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AbstractJavadocCheck.java', 'spoonMethods': [{'spoonMethodName': 'com.puppycrawl.tools.checkstyle.checks.javadoc.AbstractJavadocCheck.destroy()', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'AbstractCheck.java', 'spoonMethods': [{'spoonMethodName': 'com.puppycrawl.tools.checkstyle.api.AbstractCheck.destroy()', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'SuppressWarningsHolder.java', 'spoonMethods': [{'spoonMethodName': 'com.puppycrawl.tools.checkstyle.checks.SuppressWarningsHolder.destroy()', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'AbstractFileSetCheck.java', 'spoonMethods': [{'spoonMethodName': 'com.puppycrawl.tools.checkstyle.api.AbstractFileSetCheck.destroy()', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}]}], 'nameRev': '62f8f162e98cffaaac49d2d029697f3df7ba46bf tags/checkstyle-8.29~18', 'commitUser': 'rnveach', 'authoredDateTime': '2020-01-13 14:17:13', 'commitGHEventType': 'referenced', 'commitGitStats': [{'lines': 7, 'filePath': 'src/main/java/com/puppycrawl/tools/checkstyle/checks/javadoc/AbstractJavadocCheck.java', 'insertions': 7, 'deletions': 0}, {'lines': 33, 'filePath': 'pom.xml', 'insertions': 31, 'deletions': 2}, {'lines': 2, 'filePath': 'src/main/java/com/puppycrawl/tools/checkstyle/api/AbstractFileSetCheck.java', 'insertions': 1, 'deletions': 1}, {'lines': 6, 'filePath': 'src/main/java/com/puppycrawl/tools/checkstyle/checks/SuppressWarningsHolder.java', 'insertions': 6, 'deletions': 0}, {'lines': 2, 'filePath': 'src/main/java/com/puppycrawl/tools/checkstyle/api/AbstractCheck.java', 'insertions': 1, 'deletions': 1}], 'commitDateTime': '2020-01-17 10:08:23', 'spoonStatsSkippedReason': ''}]",https://github.com/checkstyle/checkstyle/issues/7458,6.000277777777778,"['approved', 'bug']","Sonar violation: ""ThreadLocal"" variables should be cleaned up when no longer used",1.0,"['com.puppycrawl.tools.checkstyle.api.AbstractFileSetCheck.destroy()', 'com.puppycrawl.tools.checkstyle.checks.SuppressWarningsHolder.destroy()', 'com.puppycrawl.tools.checkstyle.checks.javadoc.AbstractJavadocCheck.destroy()', 'com.puppycrawl.tools.checkstyle.api.AbstractCheck.destroy()']",['62f8f162e98cffaaac49d2d029697f3df7ba46bf'],,"['src/main/java/com/puppycrawl/tools/checkstyle/api', 'src/main/java/com/puppycrawl/tools/checkstyle/checks/javadoc', 'src/main/java/com/puppycrawl/tools/checkstyle/checks']",15.0,2.0,17.0,4.0,0.0,4.0,4.0,0.0,4.0,0.0,4.0,0.0,0.0,0.0,0.0,0.0,0.0,checkstyle
16520,2017-03-08 22:02:22,gaganis,"## Overview
I have been looking into this checkstyle plugin related gradle issue https://github.com/gradle/gradle/issues/1416. One of the issues the original author has is a problem with the import-control.xml file remaining open after gradle has finished execution.

I have managed to replicate the issue on my Linux box using the provided project and checkstyle configuration.

I have tracked the problem to be in ImportControlLoader which opens an InputStream but not closes it in case there is a parse exception.


## Reproduction steps

_Setup project as described in https://github.com/gradle/gradle/issues/1416_
```
$ $JAVA_HOME/bin/jps                      
26515 RemoteMavenServer
28548 Main
17143 Jps
15103 Launcher
```
```
$ /home/gaganis/workspace/gradle-development/gradle/bin/gradle clean build --stacktrace --refresh-dependencies

...
Execution failed for task ':checkstyleMain'.
> Unable to create Root Module: configLocation {/home/gaganis/programming/gradle/issue-1416/project/config/checkstyle/checkstyle.xml}, classpath {/home/gaganis/programming/gradle/issue-1416/project/build/classes/main:/home/gaganis/programming/gradle/issue-1416/project/build/resources/main}.

...
Caused by: com.puppycrawl.tools.checkstyle.api.CheckstyleException: unable to parse file:/home/gaganis/programming/gradle/issue-1416/project/config/checkstyle/import-control.xml - The content of element type ""import-control"" must match ""((allow|disallow)*,subpackage*)"".
        at com.puppycrawl.tools.checkstyle.checks.imports.ImportControlLoader.load(ImportControlLoader.java:194)
        at com.puppycrawl.tools.checkstyle.checks.imports.ImportControlLoader.load(ImportControlLoader.java:175)
        at com.puppycrawl.tools.checkstyle.checks.imports.ImportControlCheck.setFile(ImportControlCheck.java:185)
        ... 107 more
```

```
lsof -n|grep checkstyle                                                                                     
java      17293                gaganis  221r      REG                8,5       371    1791156 /home/gaganis/programming/gradle/issue-1416/project/config/checkstyle/import-control.xml
...
```


---------------

When checkstyle library fails to read import-control.xml for whatever reason it should not leave unclosed streams in the containing jvm.

--------------

_I have tries applying a fix using a try-with-resources construct but I got stuck because it drops coverage in cobertura. I have researched this quite a bit https://github.com/cobertura/cobertura/issues/289 but was unable to find a solution._
",2017-03-22 13:46:12,"[{'commitMessage': 'Issue #3962: Use Use try-catch to fix leaking unclosed InputStream in ImportControlLoader\n', 'commitParents': ['e76321214095de771762216c5dbbe3db0203c541'], 'commitHash': 'e6eb91a09f457233873370cea1725f47bef9637f', 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ImportControlLoaderTest.java', 'spoonMethods': [{'spoonMethodName': 'com.puppycrawl.tools.checkstyle.checks.imports.ImportControlLoaderTest', 'DEL': 0, 'INS': 2, 'UPD': 0, 'MOV': 0, 'TOT': 2}, {'spoonMethodName': 'com.puppycrawl.tools.checkstyle.checks.imports.ImportControlLoaderTest.testInputStreamThatFailsOnClose()', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}, {'spoonMethodName': 'com.puppycrawl.tools.checkstyle.checks.imports.ImportControlLoaderTest.testInputStreamFailsOnRead()', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'ImportControlLoader.java', 'spoonMethods': [{'spoonMethodName': 'com.puppycrawl.tools.checkstyle.checks.imports.ImportControlLoader.load(java.net.URI)', 'DEL': 1, 'INS': 2, 'UPD': 0, 'MOV': 2, 'TOT': 5}, {'spoonMethodName': 'com.puppycrawl.tools.checkstyle.checks.imports.ImportControlLoader.closeStream(java.io.InputStream)', 'DEL': 0, 'INS': 1, 'UPD': 0, 'MOV': 0, 'TOT': 1}]}], 'nameRev': 'e6eb91a09f457233873370cea1725f47bef9637f tags/checkstyle-7.6.1~14', 'commitUser': 'rnveach', 'authoredDateTime': '2017-03-21 13:57:32', 'commitGHEventType': 'referenced', 'commitGitStats': [{'lines': 54, 'filePath': 'src/test/java/com/puppycrawl/tools/checkstyle/checks/imports/ImportControlLoaderTest.java', 'insertions': 54, 'deletions': 0}, {'lines': 26, 'filePath': 'src/main/java/com/puppycrawl/tools/checkstyle/checks/imports/ImportControlLoader.java', 'insertions': 23, 'deletions': 3}], 'commitDateTime': '2017-03-22 09:41:49', 'spoonStatsSkippedReason': ''}]",https://github.com/checkstyle/checkstyle/issues/3962,13.000277777777777,"['approved', 'bug']",ImportControlLoader does not close InputStream and leaks filehandles when xml is malformed,1.0,"['com.puppycrawl.tools.checkstyle.checks.imports.ImportControlLoader.load(java.net.URI)', 'com.puppycrawl.tools.checkstyle.checks.imports.ImportControlLoader.closeStream(java.io.InputStream)']",['e6eb91a09f457233873370cea1725f47bef9637f'],,['src/main/java/com/puppycrawl/tools/checkstyle/checks/imports'],23.0,3.0,26.0,1.0,0.0,2.0,6.0,2.0,3.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,checkstyle
17573,2018-03-07 06:55:41,gogo111007,"#### Issue Description

i use KMeansClustering like KMeansTest.java
every client request, i get new kmeans object by KMeansClustering.setup()
but there is no way to destroy threads allocate by KMeansClustering 
after thousands or more request, too many threads cause crash

#### Version Information

* deeplearning4j ver newest
* windows 7 and centos 6.x
",2018-03-22 06:02:37,"[{'commitGitStats': [{'filePath': 'deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/text/invertedindex/InvertedIndex.java', 'deletions': 4, 'insertions': 4, 'lines': 8}, {'filePath': 'deeplearning4j-nn/src/main/java/org/deeplearning4j/optimize/solvers/accumulation/EncodedGradientsAccumulator.java', 'deletions': 1, 'insertions': 0, 'lines': 1}, {'filePath': 'deeplearning4j-nlp-parent/deeplearning4j-nlp/pom.xml', 'deletions': 0, 'insertions': 7, 'lines': 7}, {'filePath': 'deeplearning4j-nearestneighbors-parent/nearestneighbor-core/pom.xml', 'deletions': 0, 'insertions': 6, 'lines': 6}, {'filePath': 'deeplearning4j-nn/src/main/java/org/deeplearning4j/util/DiskBasedQueue.java', 'deletions': 6, 'insertions': 4, 'lines': 10}, {'filePath': 'deeplearning4j-nearestneighbors-parent/nearestneighbor-core/src/main/java/org/deeplearning4j/clustering/cluster/ClusterUtils.java', 'deletions': 11, 'insertions': 12, 'lines': 23}, {'filePath': 'deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/paragraphvectors/ParagraphVectors.java', 'deletions': 3, 'insertions': 7, 'lines': 10}, {'filePath': 'deeplearning4j-graph/src/main/java/org/deeplearning4j/graph/models/deepwalk/DeepWalk.java', 'deletions': 22, 'insertions': 11, 'lines': 33}, {'filePath': 'pom.xml', 'deletions': 0, 'insertions': 1, 'lines': 1}, {'filePath': 'deeplearning4j-nn/pom.xml', 'deletions': 0, 'insertions': 6, 'lines': 6}, {'filePath': 'deeplearning4j-scaleout/deeplearning4j-aws/pom.xml', 'deletions': 0, 'insertions': 5, 'lines': 5}, {'filePath': 'deeplearning4j-graph/pom.xml', 'deletions': 0, 'insertions': 7, 'lines': 7}, {'filePath': 'deeplearning4j-scaleout/deeplearning4j-aws/src/main/java/org/deeplearning4j/aws/ec2/provision/ClusterSetup.java', 'deletions': 5, 'insertions': 4, 'lines': 9}, {'filePath': 'deeplearning4j-nearestneighbors-parent/nearestneighbor-core/src/main/java/org/deeplearning4j/clustering/algorithm/BaseClusteringAlgorithm.java', 'deletions': 2, 'insertions': 2, 'lines': 4}, {'filePath': 'deeplearning4j-nearestneighbors-parent/nearestneighbor-core/src/main/java/org/deeplearning4j/clustering/util/MultiThreadUtils.java', 'deletions': 13, 'insertions': 5, 'lines': 18}, {'filePath': 'deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/word2vec/wordstore/VocabConstructor.java', 'deletions': 2, 'insertions': 2, 'lines': 4}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ParagraphVectors.java', 'spoonMethods': [{'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.models.paragraphvectors.ParagraphVectors', 'MOV': 0, 'TOT': 1}, {'INS': 1, 'UPD': 0, 'DEL': 1, 'spoonMethodName': 'org.deeplearning4j.models.paragraphvectors.ParagraphVectors.initInference()', 'MOV': 2, 'TOT': 4}]}, {'spoonFilePath': 'MultiThreadUtils.java', 'spoonMethods': [{'INS': 0, 'UPD': 2, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.util.MultiThreadUtils.parallelTasks(java.util.List,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 2}, {'INS': 1, 'UPD': 0, 'DEL': 2, 'spoonMethodName': 'org.deeplearning4j.clustering.util.MultiThreadUtils.newExecutorService()', 'MOV': 1, 'TOT': 4}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.util.MultiThreadUtils.parallelTasks(java.util.List,java.util.concurrent.ExecutorService).2', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 0, 'DEL': 1, 'spoonMethodName': 'org.deeplearning4j.clustering.util.MultiThreadUtils', 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'DeepWalk.java', 'spoonMethods': [{'INS': 0, 'UPD': 3, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.graph.models.deepwalk.DeepWalk.fit(org.deeplearning4j.graph.iterator.parallel.GraphWalkIteratorProvider).1.newThread(java.lang.Runnable)', 'MOV': 1, 'TOT': 4}, {'INS': 3, 'UPD': 3, 'DEL': 5, 'spoonMethodName': 'org.deeplearning4j.graph.models.deepwalk.DeepWalk.fit(org.deeplearning4j.graph.iterator.parallel.GraphWalkIteratorProvider)', 'MOV': 4, 'TOT': 15}, {'INS': 0, 'UPD': 0, 'DEL': 1, 'spoonMethodName': 'org.deeplearning4j.graph.models.deepwalk.DeepWalk', 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'DiskBasedQueue.java', 'spoonMethods': [{'INS': 4, 'UPD': 1, 'DEL': 2, 'spoonMethodName': 'org.deeplearning4j.util.DiskBasedQueue', 'MOV': 1, 'TOT': 8}]}, {'spoonFilePath': 'EncodedGradientsAccumulator.java', 'spoonMethods': []}, {'spoonFilePath': 'InvertedIndex.java', 'spoonMethods': [{'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.text.invertedindex.eachDocWithLabels(com.google.common.base.Function,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.text.invertedindex.eachDoc(com.google.common.base.Function,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.text.invertedindex.eachDocWithLabel(com.google.common.base.Function,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'VocabConstructor.java', 'spoonMethods': [{'INS': 0, 'UPD': 2, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.models.word2vec.wordstore.VocabConstructor.buildJointVocabulary(boolean,boolean)', 'MOV': 0, 'TOT': 2}]}, {'spoonFilePath': 'BaseClusteringAlgorithm.java', 'spoonMethods': [{'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.algorithm.BaseClusteringAlgorithm', 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'ClusterUtils.java', 'spoonMethods': [{'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.cluster.ClusterUtils.splitClusters(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,java.util.List,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.cluster.ClusterUtils.splitClustersWhereMaximumDistanceFromCenterGreaterThan(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,double,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.cluster.ClusterUtils.splitClusters(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,java.util.List,double,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.cluster.ClusterUtils.computeSquareDistancesFromNearestCluster(org.deeplearning4j.clustering.cluster.ClusterSet,java.util.List,org.nd4j.linalg.api.ndarray.INDArray,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.cluster.ClusterUtils.splitMostPopulatedClusters(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,int,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.cluster.ClusterUtils.splitClustersWhereAverageDistanceFromCenterGreaterThan(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,double,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.cluster.ClusterUtils.classifyPoints(org.deeplearning4j.clustering.cluster.ClusterSet,java.util.List,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.cluster.ClusterUtils.refreshClustersCenters(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.cluster.ClusterUtils.applyOptimization(org.deeplearning4j.clustering.strategy.OptimisationStrategy,org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.cluster.ClusterUtils.splitMostSpreadOutClusters(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,int,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}, {'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.clustering.cluster.ClusterUtils.computeClusterSetInfo(org.deeplearning4j.clustering.cluster.ClusterSet,java.util.concurrent.ExecutorService)', 'MOV': 0, 'TOT': 1}]}, {'spoonFilePath': 'ClusterSetup.java', 'spoonMethods': [{'INS': 0, 'UPD': 1, 'DEL': 0, 'spoonMethodName': 'org.deeplearning4j.aws.ec2.provision.ClusterSetup', 'MOV': 0, 'TOT': 1}, {'INS': 1, 'UPD': 1, 'DEL': 1, 'spoonMethodName': 'org.deeplearning4j.aws.ec2.provision.ClusterSetup.provisionWorkers(java.util.List)', 'MOV': 1, 'TOT': 4}]}], 'spoonStatsSkippedReason': '', 'authoredDateTime': '2018-03-12 20:26:19', 'commitMessage': ""Resolve thread leaks by switching to threadly\n\nThis resolves #4766 as well as a couple other thread leaks I found.\nThreadly pools perform great, are robust (often times with greater garuntees than java.util), and in this case wont leak threads if garbage collected.\nNot all cases updated in this commit were leaks, but I did update several places to maintain consistency in the project.  I think in the future we may want to make the lifecycle of these schedulers a bit cleaner, but this provides an immediate win.\n`ExecutorService` was updated to the more generic `Executor` where the executor is only needed for execution (and lifecycle is not managed)\n\nBy default threadly schedulers are daemon threads, so in many cases the code was simplified as well.\nThreadly's version at the time of this commit is 5.14, which does offer further performance gains and features.  But does require java 8.  So this commit depends on 4.10.0 which works with java 6+.\n"", 'commitUser': 'AlexDBlack', 'commitDateTime': '2018-03-12 20:35:13', 'commitParents': ['ae70246223774cb391b625c9f539bf033b2ec2ce'], 'commitGHEventType': 'closed', 'nameRev': '75601e77ecbc719d469b9ff547f744f0e18eb1a0 tags/_old/deeplearning4j-1.0.0-alpha~40^2~1', 'commitHash': '75601e77ecbc719d469b9ff547f744f0e18eb1a0'}]",https://github.com/eclipse/deeplearning4j/issues/4766,14.000277777777777,['Bug'],KMeansClustering cause thread leak,1.0,"['org.deeplearning4j.clustering.util.MultiThreadUtils.parallelTasks(java.util.List,java.util.concurrent.ExecutorService).2', 'org.deeplearning4j.aws.ec2.provision.ClusterSetup.provisionWorkers(java.util.List)', 'org.deeplearning4j.clustering.util.MultiThreadUtils.newExecutorService()', 'org.deeplearning4j.models.paragraphvectors.ParagraphVectors', 'org.deeplearning4j.clustering.cluster.ClusterUtils.computeClusterSetInfo(org.deeplearning4j.clustering.cluster.ClusterSet,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.text.invertedindex.eachDocWithLabels(com.google.common.base.Function,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.clustering.cluster.ClusterUtils.splitClustersWhereAverageDistanceFromCenterGreaterThan(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,double,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.clustering.cluster.ClusterUtils.splitClusters(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,java.util.List,double,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.models.paragraphvectors.ParagraphVectors.initInference()', 'org.deeplearning4j.clustering.cluster.ClusterUtils.splitMostPopulatedClusters(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,int,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.graph.models.deepwalk.DeepWalk.fit(org.deeplearning4j.graph.iterator.parallel.GraphWalkIteratorProvider).1.newThread(java.lang.Runnable)', 'org.deeplearning4j.clustering.algorithm.BaseClusteringAlgorithm', 'org.deeplearning4j.clustering.cluster.ClusterUtils.applyOptimization(org.deeplearning4j.clustering.strategy.OptimisationStrategy,org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.graph.models.deepwalk.DeepWalk.fit(org.deeplearning4j.graph.iterator.parallel.GraphWalkIteratorProvider)', 'org.deeplearning4j.clustering.cluster.ClusterUtils.computeSquareDistancesFromNearestCluster(org.deeplearning4j.clustering.cluster.ClusterSet,java.util.List,org.nd4j.linalg.api.ndarray.INDArray,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.models.word2vec.wordstore.VocabConstructor.buildJointVocabulary(boolean,boolean)', 'org.deeplearning4j.graph.models.deepwalk.DeepWalk', 'org.deeplearning4j.clustering.util.MultiThreadUtils.parallelTasks(java.util.List,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.clustering.cluster.ClusterUtils.splitMostSpreadOutClusters(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,int,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.util.DiskBasedQueue', 'org.deeplearning4j.clustering.cluster.ClusterUtils.splitClusters(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,java.util.List,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.clustering.cluster.ClusterUtils.splitClustersWhereMaximumDistanceFromCenterGreaterThan(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,double,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.clustering.cluster.ClusterUtils.classifyPoints(org.deeplearning4j.clustering.cluster.ClusterSet,java.util.List,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.clustering.util.MultiThreadUtils', 'org.deeplearning4j.text.invertedindex.eachDoc(com.google.common.base.Function,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.clustering.cluster.ClusterUtils.refreshClustersCenters(org.deeplearning4j.clustering.cluster.ClusterSet,org.deeplearning4j.clustering.info.ClusterSetInfo,java.util.concurrent.ExecutorService)', 'org.deeplearning4j.aws.ec2.provision.ClusterSetup', 'org.deeplearning4j.text.invertedindex.eachDocWithLabel(com.google.common.base.Function,java.util.concurrent.ExecutorService)']",['75601e77ecbc719d469b9ff547f744f0e18eb1a0'],,"['deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/word2vec/wordstore', 'deeplearning4j-nn/src/main/java/org/deeplearning4j/util', 'deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/text/invertedindex', 'deeplearning4j-nearestneighbors-parent/nearestneighbor-core/src/main/java/org/deeplearning4j/clustering/cluster', 'deeplearning4j-nearestneighbors-parent/nearestneighbor-core/src/main/java/org/deeplearning4j/clustering/util', 'deeplearning4j-nn/src/main/java/org/deeplearning4j/optimize/solvers/accumulation', 'deeplearning4j-graph/src/main/java/org/deeplearning4j/graph/models/deepwalk', 'deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/paragraphvectors', 'deeplearning4j-scaleout/deeplearning4j-aws/src/main/java/org/deeplearning4j/aws/ec2/provision', 'deeplearning4j-nearestneighbors-parent/nearestneighbor-core/src/main/java/org/deeplearning4j/clustering/algorithm']",51.0,69.0,120.0,10.0,30.0,28.0,63.0,10.0,10.0,13.0,9.0,0.0,0.0,0.0,0.0,0.0,0.0,deeplearning4j
20507,2017-04-14 10:09:17,anatoly21,"ES version: 5.2.2.
JDK: 1.8.0_65
OS version: Ubuntu 14.04.4 

We faced high memory usage issue when using percolator.
Dedicated index is configured for percolator.
It works as expected and JVM heap usage picture is 

![without_nested_queries](https://cloud.githubusercontent.com/assets/27484990/25040396/b5e6e152-2111-11e7-92db-3182e11dc73c.JPG)

After registering a nested nested query the picture changes and there is a steady grow of used memory and CPU on the same input document set

![with_nested_query](https://cloud.githubusercontent.com/assets/27484990/25040463/2acc2f0e-2112-11e7-8a10-2edc730e4fc9.JPG)

Input documents contain up to hundred of nested documents. Caching settings are by default.

Memory dump:
![memory1](https://cloud.githubusercontent.com/assets/27484990/25040531/a17841ba-2112-11e7-98d3-b1060a68ad4a.JPG)
![memory2](https://cloud.githubusercontent.com/assets/27484990/25040536/a59bfbe2-2112-11e7-8e43-16212e0d7333.JPG)
",2017-04-26 09:27:48,"[{'commitGitStats': [{'lines': 8, 'insertions': 8, 'deletions': 0, 'filePath': 'core/src/test/java/org/elasticsearch/search/aggregations/AggregatorTestCase.java'}, {'lines': 201, 'insertions': 201, 'deletions': 0, 'filePath': 'modules/percolator/src/test/java/org/elasticsearch/percolator/PercolatorQuerySearchIT.java'}, {'lines': 47, 'insertions': 43, 'deletions': 4, 'filePath': 'modules/percolator/src/main/java/org/elasticsearch/percolator/PercolateQueryBuilder.java'}, {'lines': 4, 'insertions': 2, 'deletions': 2, 'filePath': 'core/src/test/java/org/elasticsearch/search/aggregations/bucket/nested/ReverseNestedAggregatorTests.java'}, {'lines': 3, 'insertions': 1, 'deletions': 2, 'filePath': 'core/src/main/java/org/elasticsearch/index/cache/bitset/BitsetFilterCache.java'}], 'spoonStatsSkippedReason': '', 'commitParents': ['4b9e02da8753f84877d6dd4b7215c16317d3d500'], 'commitUser': 'martijnvg', 'commitDateTime': '2017-04-26 11:41:16', 'commitHash': '6cc4615cf63636d7349abd10dab0c9b360eb3bdc', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.bucket.nested.ReverseNestedAggregatorTests.testNoDocs()', 'INS': 1, 'MOV': 1}, {'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.bucket.nested.ReverseNestedAggregatorTests.testMaxFromParentDocs()', 'INS': 1, 'MOV': 1}], 'spoonFilePath': 'ReverseNestedAggregatorTests.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolateQueryBuilder.wrap(org.elasticsearch.index.query.QueryShardContext)', 'INS': 1, 'MOV': 0}, {'DEL': 3, 'TOT': 5, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolateQueryBuilder.doToQuery(org.elasticsearch.index.query.QueryShardContext)', 'INS': 2, 'MOV': 0}], 'spoonFilePath': 'PercolateQueryBuilder.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolatorQuerySearchIT.testPercolateQueryWithNestedDocuments_doNotLeakBitsetCacheEntries()', 'INS': 1, 'MOV': 0}, {'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolatorQuerySearchIT.testPercolatorQueryViaMultiSearch()', 'INS': 1, 'MOV': 0}, {'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolatorQuerySearchIT.CustomScriptPlugin.pluginScripts()', 'INS': 1, 'MOV': 0}, {'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolatorQuerySearchIT.testPercolateQueryWithNestedDocuments_doLeakFieldDataCacheEntries()', 'INS': 1, 'MOV': 0}], 'spoonFilePath': 'PercolatorQuerySearchIT.java'}, {'spoonMethods': [{'DEL': 1, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.index.cache.bitset.BitsetFilterCache.getAndLoadIfNotPresent(org.apache.lucene.search.Query,org.apache.lucene.index.LeafReaderContext)', 'INS': 0, 'MOV': 1}], 'spoonFilePath': 'BitsetFilterCache.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.AggregatorTestCase.wrap(org.apache.lucene.index.DirectoryReader)', 'INS': 1, 'MOV': 0}], 'spoonFilePath': 'AggregatorTestCase.java'}], 'nameRev': '6cc4615cf63636d7349abd10dab0c9b360eb3bdc tags/v5.4.0~24', 'commitGHEventType': 'referenced', 'commitMessage': ""[percolator] Fix memory leak when percolator uses bitset or field data cache.\n\nThe percolator doesn't close the IndexReader of the memory index any more.\nPrior to 2.x the percolator had its own SearchContext (PercolatorContext) that did this,\nbut that was removed when the percolator was refactored as part of the 5.0 release.\n\nI think an alternative way to fix this is to let percolator not use the bitset and fielddata caches,\nthat way we prevent the memory leak.\n\nCloses #24108\n"", 'authoredDateTime': '2017-04-19 20:37:20'}, {'commitGitStats': [{'lines': 8, 'insertions': 8, 'deletions': 0, 'filePath': 'core/src/test/java/org/elasticsearch/search/aggregations/AggregatorTestCase.java'}, {'lines': 122, 'insertions': 122, 'deletions': 0, 'filePath': 'modules/percolator/src/test/java/org/elasticsearch/percolator/PercolatorQuerySearchIT.java'}, {'lines': 3, 'insertions': 1, 'deletions': 2, 'filePath': 'core/src/main/java/org/elasticsearch/index/cache/bitset/BitsetFilterCache.java'}, {'lines': 10, 'insertions': 5, 'deletions': 5, 'filePath': 'core/src/test/java/org/elasticsearch/search/aggregations/bucket/nested/NestedAggregatorTests.java'}, {'lines': 47, 'insertions': 43, 'deletions': 4, 'filePath': 'modules/percolator/src/main/java/org/elasticsearch/percolator/PercolateQueryBuilder.java'}, {'lines': 4, 'insertions': 2, 'deletions': 2, 'filePath': 'core/src/test/java/org/elasticsearch/search/aggregations/bucket/nested/ReverseNestedAggregatorTests.java'}], 'spoonStatsSkippedReason': '', 'commitParents': ['51b33f1fd549b474e901e70a460440d73a1751ce'], 'commitUser': 'martijnvg', 'commitDateTime': '2017-04-26 11:08:15', 'commitHash': 'c17de49a6dc1d54fcfee3754211ae67a06bdcec7', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.bucket.nested.ReverseNestedAggregatorTests.testNoDocs()', 'INS': 1, 'MOV': 1}, {'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.bucket.nested.ReverseNestedAggregatorTests.testMaxFromParentDocs()', 'INS': 1, 'MOV': 1}], 'spoonFilePath': 'ReverseNestedAggregatorTests.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolateQueryBuilder.wrap(org.elasticsearch.index.query.QueryShardContext)', 'INS': 1, 'MOV': 0}, {'DEL': 2, 'TOT': 3, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolateQueryBuilder.doToQuery(org.elasticsearch.index.query.QueryShardContext)', 'INS': 1, 'MOV': 0}], 'spoonFilePath': 'PercolateQueryBuilder.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolatorQuerySearchIT.testPercolateQueryWithNestedDocuments_doNotLeakBitsetCacheEntries()', 'INS': 1, 'MOV': 0}, {'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolatorQuerySearchIT.CustomScriptPlugin.pluginScripts()', 'INS': 1, 'MOV': 0}, {'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolatorQuerySearchIT.testPercolateQueryWithNestedDocuments_doLeakFieldDataCacheEntries()', 'INS': 1, 'MOV': 0}], 'spoonFilePath': 'PercolatorQuerySearchIT.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.AggregatorTestCase.wrap(org.apache.lucene.index.DirectoryReader)', 'INS': 1, 'MOV': 0}], 'spoonFilePath': 'AggregatorTestCase.java'}, {'spoonMethods': [{'DEL': 1, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.index.cache.bitset.BitsetFilterCache.getAndLoadIfNotPresent(org.apache.lucene.search.Query,org.apache.lucene.index.LeafReaderContext)', 'INS': 0, 'MOV': 1}], 'spoonFilePath': 'BitsetFilterCache.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.bucket.nested.NestedAggregatorTests.testOrphanedDocs()', 'INS': 1, 'MOV': 1}, {'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.bucket.nested.NestedAggregatorTests.testNoDocs()', 'INS': 1, 'MOV': 1}, {'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.bucket.nested.NestedAggregatorTests.testDoubleNestingMax()', 'INS': 1, 'MOV': 1}, {'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.bucket.nested.NestedAggregatorTests.testSingleNestingMax()', 'INS': 1, 'MOV': 1}, {'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.bucket.nested.NestedAggregatorTests.testResetRootDocId()', 'INS': 1, 'MOV': 1}], 'spoonFilePath': 'NestedAggregatorTests.java'}], 'nameRev': 'c17de49a6dc1d54fcfee3754211ae67a06bdcec7 tags/v6.0.0-alpha1~130', 'commitGHEventType': 'closed', 'commitMessage': ""[percolator] Fix memory leak when percolator uses bitset or field data cache.\n\nThe percolator doesn't close the IndexReader of the memory index any more.\nPrior to 2.x the percolator had its own SearchContext (PercolatorContext) that did this,\nbut that was removed when the percolator was refactored as part of the 5.0 release.\n\nI think an alternative way to fix this is to let percolator not use the bitset and fielddata caches,\nthat way we prevent the memory leak.\n\nCloses #24108\n"", 'authoredDateTime': '2017-04-19 20:37:20'}, {'commitGitStats': [{'lines': 8, 'insertions': 8, 'deletions': 0, 'filePath': 'core/src/test/java/org/elasticsearch/search/aggregations/AggregatorTestCase.java'}, {'lines': 201, 'insertions': 201, 'deletions': 0, 'filePath': 'modules/percolator/src/test/java/org/elasticsearch/percolator/PercolatorQuerySearchIT.java'}, {'lines': 47, 'insertions': 43, 'deletions': 4, 'filePath': 'modules/percolator/src/main/java/org/elasticsearch/percolator/PercolateQueryBuilder.java'}, {'lines': 4, 'insertions': 2, 'deletions': 2, 'filePath': 'core/src/test/java/org/elasticsearch/search/aggregations/bucket/nested/ReverseNestedAggregatorTests.java'}, {'lines': 3, 'insertions': 1, 'deletions': 2, 'filePath': 'core/src/main/java/org/elasticsearch/index/cache/bitset/BitsetFilterCache.java'}], 'spoonStatsSkippedReason': '', 'commitParents': ['99e5fa07e8f16af577c3a4867348c8fb5d5c581d'], 'commitUser': 'martijnvg', 'commitDateTime': '2017-04-26 11:38:18', 'commitHash': 'd3e754b281bf69392b7015d82622d0c686415011', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.bucket.nested.ReverseNestedAggregatorTests.testNoDocs()', 'INS': 1, 'MOV': 1}, {'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.bucket.nested.ReverseNestedAggregatorTests.testMaxFromParentDocs()', 'INS': 1, 'MOV': 1}], 'spoonFilePath': 'ReverseNestedAggregatorTests.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolateQueryBuilder.wrap(org.elasticsearch.index.query.QueryShardContext)', 'INS': 1, 'MOV': 0}, {'DEL': 3, 'TOT': 5, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolateQueryBuilder.doToQuery(org.elasticsearch.index.query.QueryShardContext)', 'INS': 2, 'MOV': 0}], 'spoonFilePath': 'PercolateQueryBuilder.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolatorQuerySearchIT.testPercolateQueryWithNestedDocuments_doNotLeakBitsetCacheEntries()', 'INS': 1, 'MOV': 0}, {'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolatorQuerySearchIT.testPercolatorQueryViaMultiSearch()', 'INS': 1, 'MOV': 0}, {'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolatorQuerySearchIT.CustomScriptPlugin.pluginScripts()', 'INS': 1, 'MOV': 0}, {'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.percolator.PercolatorQuerySearchIT.testPercolateQueryWithNestedDocuments_doLeakFieldDataCacheEntries()', 'INS': 1, 'MOV': 0}], 'spoonFilePath': 'PercolatorQuerySearchIT.java'}, {'spoonMethods': [{'DEL': 1, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.index.cache.bitset.BitsetFilterCache.getAndLoadIfNotPresent(org.apache.lucene.search.Query,org.apache.lucene.index.LeafReaderContext)', 'INS': 0, 'MOV': 1}], 'spoonFilePath': 'BitsetFilterCache.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.search.aggregations.AggregatorTestCase.wrap(org.apache.lucene.index.DirectoryReader)', 'INS': 1, 'MOV': 0}], 'spoonFilePath': 'AggregatorTestCase.java'}], 'nameRev': 'd3e754b281bf69392b7015d82622d0c686415011 tags/v5.5.0~416', 'commitGHEventType': 'referenced', 'commitMessage': ""[percolator] Fix memory leak when percolator uses bitset or field data cache.\n\nThe percolator doesn't close the IndexReader of the memory index any more.\nPrior to 2.x the percolator had its own SearchContext (PercolatorContext) that did this,\nbut that was removed when the percolator was refactored as part of the 5.0 release.\n\nI think an alternative way to fix this is to let percolator not use the bitset and fielddata caches,\nthat way we prevent the memory leak.\n\nCloses #24108\n"", 'authoredDateTime': '2017-04-19 20:37:20'}]",https://github.com/elastic/elasticsearch/issues/24108,11.000277777777777,"[':Search/Percolator', '>bug']",Percolator: High memory usage issue when nested query is registered,1.0,"['org.elasticsearch.search.aggregations.bucket.nested.ReverseNestedAggregatorTests.testNoDocs()', 'org.elasticsearch.percolator.PercolateQueryBuilder.wrap(org.elasticsearch.index.query.QueryShardContext)', 'org.elasticsearch.percolator.PercolatorQuerySearchIT.CustomScriptPlugin.pluginScripts()', 'org.elasticsearch.percolator.PercolatorQuerySearchIT.testPercolatorQueryViaMultiSearch()', 'org.elasticsearch.percolator.PercolatorQuerySearchIT.testPercolateQueryWithNestedDocuments_doLeakFieldDataCacheEntries()', 'org.elasticsearch.index.cache.bitset.BitsetFilterCache.getAndLoadIfNotPresent(org.apache.lucene.search.Query,org.apache.lucene.index.LeafReaderContext)', 'org.elasticsearch.percolator.PercolatorQuerySearchIT.testPercolateQueryWithNestedDocuments_doNotLeakBitsetCacheEntries()', 'org.elasticsearch.search.aggregations.bucket.nested.ReverseNestedAggregatorTests.testMaxFromParentDocs()', 'org.elasticsearch.percolator.PercolateQueryBuilder.doToQuery(org.elasticsearch.index.query.QueryShardContext)', 'org.elasticsearch.search.aggregations.AggregatorTestCase.wrap(org.apache.lucene.index.DirectoryReader)']",['6cc4615cf63636d7349abd10dab0c9b360eb3bdc'],,"['core/src/main/java/org/elasticsearch/index/cache/bitset', 'modules/percolator/src/main/java/org/elasticsearch/percolator']",44.0,6.0,50.0,2.0,0.0,10.0,17.0,3.0,10.0,4.0,5.0,0.0,0.0,0.0,2.0,0.0,0.0,elasticsearch
21543,2015-02-24 16:04:08,rjernst,"In #9843, HunspellServiceTests leak scheduler and timer thread pools.  In this test class, there are 2 tests which check excepetion cases.  When those 2 tests are @Ignored, there are no more thread leaks.
",2015-03-27 09:12:36,"[{'commitGitStats': [{'lines': 2, 'insertions': 0, 'deletions': 2, 'filePath': 'src/test/java/org/elasticsearch/indices/analyze/HunspellServiceTests.java'}, {'lines': 11, 'insertions': 9, 'deletions': 2, 'filePath': 'src/main/java/org/elasticsearch/indices/analysis/HunspellService.java'}], 'spoonStatsSkippedReason': '', 'commitParents': ['aa1d0f2841dc2089913efe7261cfa50ebb39be71'], 'commitUser': 'tlrx', 'commitDateTime': '2015-03-27 10:45:59', 'commitHash': '1baa16700bf98764d69a9520aba2e496e123b9e4', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'DEL': 1, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.indices.analyze.HunspellServiceTests.testDicWithTwoAffs()', 'INS': 0, 'MOV': 0}, {'DEL': 1, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.indices.analyze.HunspellServiceTests.testDicWithNoAff()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'HunspellServiceTests.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.indices.analysis.HunspellService.scanAndLoadDictionaries()', 'INS': 1, 'MOV': 1}], 'spoonFilePath': 'HunspellService.java'}], 'nameRev': '1baa16700bf98764d69a9520aba2e496e123b9e4 tags/v1.6.0~427', 'commitGHEventType': 'referenced', 'commitMessage': 'Fix thread leak in Hunspell service\n\nAn unchecked exception might be thrown when instantiating the HunspellService, leading to thread leaks in tests.\n\nCloses #9849\n', 'authoredDateTime': '2015-03-27 10:45:59'}, {'commitGitStats': [{'lines': 3, 'insertions': 0, 'deletions': 3, 'filePath': 'src/test/java/org/elasticsearch/indices/analyze/HunspellServiceTests.java'}, {'lines': 11, 'insertions': 9, 'deletions': 2, 'filePath': 'src/main/java/org/elasticsearch/indices/analysis/HunspellService.java'}], 'spoonStatsSkippedReason': '', 'commitParents': ['a008fc17a7451b97a191e9518f8a7125d8c7e703'], 'commitUser': 'tlrx', 'commitDateTime': '2015-03-27 11:03:51', 'commitHash': '2d5f0ce04bae9a12f9002e03148e49f0169a7381', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'DEL': 1, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.indices.analyze.HunspellServiceTests.testDicWithTwoAffs()', 'INS': 0, 'MOV': 0}, {'DEL': 1, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.indices.analyze.HunspellServiceTests.testDicWithNoAff()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'HunspellServiceTests.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 2, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.indices.analysis.HunspellService.scanAndLoadDictionaries()', 'INS': 1, 'MOV': 1}], 'spoonFilePath': 'HunspellService.java'}], 'nameRev': '2d5f0ce04bae9a12f9002e03148e49f0169a7381 tags/v1.5.1~69', 'commitGHEventType': 'referenced', 'commitMessage': 'Fix thread leak in Hunspell service\n\nAn unchecked exception might be thrown when instantiating the HunspellService, leading to thread leaks in tests.\n\nCloses #9849\n', 'authoredDateTime': '2015-03-27 11:03:51'}]",https://github.com/elastic/elasticsearch/issues/9849,30.00027777777778,"['>bug', '>test']",Scheduling threads can be leaked on exception,1.0,"['org.elasticsearch.indices.analyze.HunspellServiceTests.testDicWithTwoAffs()', 'org.elasticsearch.indices.analyze.HunspellServiceTests.testDicWithNoAff()', 'org.elasticsearch.indices.analysis.HunspellService.scanAndLoadDictionaries()']",['1baa16700bf98764d69a9520aba2e496e123b9e4'],,['src/main/java/org/elasticsearch/indices/analysis'],9.0,2.0,11.0,1.0,0.0,3.0,4.0,1.0,1.0,2.0,2.0,0.0,0.0,0.0,1.0,0.0,0.0,elasticsearch
22617,2011-07-26 19:42:58,kimchy,"Get API: a get for a document that does not exists can cause open file handles leak
",2011-07-26 19:57:46,"[{'commitGitStats': [{'lines': 14, 'insertions': 10, 'deletions': 4, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/get/TransportGetAction.java'}, {'lines': 6, 'insertions': 6, 'deletions': 0, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/index/engine/Engine.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java'}], 'spoonStatsSkippedReason': '', 'commitParents': ['b34314fd5e41d8ba46d9b5e8a106041f05401748'], 'commitUser': 'kimchy', 'commitDateTime': '2011-07-26 22:57:34', 'commitHash': '995f33bd0fba21fb2897a7230a3c1f875f255d37', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'DEL': 2, 'TOT': 16, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.action.get.TransportGetAction.load(org.elasticsearch.common.logging.ESLogger,org.elasticsearch.script.ScriptService,org.elasticsearch.index.service.IndexService,org.elasticsearch.index.shard.service.IndexShard,java.lang.String,java.lang.String,java.lang.String,java.lang.String[],boolean)', 'INS': 7, 'MOV': 7}], 'spoonFilePath': 'TransportGetAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.index.engine.GetResult.release()', 'INS': 1, 'MOV': 0}], 'spoonFilePath': 'Engine.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.index.engine.robin.RobinEngine.get(org.elasticsearch.index.engine.robin.Get)', 'INS': 1, 'MOV': 0}], 'spoonFilePath': 'RobinEngine.java'}], 'nameRev': '995f33bd0fba21fb2897a7230a3c1f875f255d37 tags/v0.17.2~2', 'commitGHEventType': 'closed', 'commitMessage': 'Get API: a get for a document that does not exists can cause open file handles leak, closes #1167.\n', 'authoredDateTime': '2011-07-26 22:57:34'}]",https://github.com/elastic/elasticsearch/issues/1167,0.0002777777777777778,"['>bug', 'v0.17.2', 'v0.18.0']",Get API: a get for a document that does not exists can cause open file handles leak,1.0,"['org.elasticsearch.index.engine.GetResult.release()', 'org.elasticsearch.action.get.TransportGetAction.load(org.elasticsearch.common.logging.ESLogger,org.elasticsearch.script.ScriptService,org.elasticsearch.index.service.IndexService,org.elasticsearch.index.shard.service.IndexShard,java.lang.String,java.lang.String,java.lang.String,java.lang.String[],boolean)', 'org.elasticsearch.index.engine.robin.RobinEngine.get(org.elasticsearch.index.engine.robin.Get)']",['995f33bd0fba21fb2897a7230a3c1f875f255d37'],,"['modules/elasticsearch/src/main/java/org/elasticsearch/index/engine', 'modules/elasticsearch/src/main/java/org/elasticsearch/action/get', 'modules/elasticsearch/src/main/java/org/elasticsearch/index/engine/robin']",17.0,5.0,22.0,3.0,0.0,3.0,18.0,7.0,9.0,2.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,elasticsearch
22638,2011-07-12 22:46:03,kimchy,"An internal memory leak when using GarbageCollectorMXBean#getLastGcInfo in the JVM. Disable using it...
",2011-07-12 22:46:33,"[{'commitGitStats': [{'lines': 4, 'insertions': 3, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java'}, {'lines': 35, 'insertions': 35, 'deletions': 0, 'filePath': 'modules/test/integration/src/test/java/org/elasticsearch/test/stress/leaks/JvmStatsLeak.java'}, {'lines': 56, 'insertions': 33, 'deletions': 23, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/monitor/jvm/JvmStats.java'}, {'lines': 46, 'insertions': 46, 'deletions': 0, 'filePath': 'modules/test/integration/src/test/java/org/elasticsearch/test/stress/leaks/GenericStatsLeak.java'}], 'spoonStatsSkippedReason': '', 'commitParents': ['fdbcec8a84945626cc1db76e7c52c4bdb4c95b6a'], 'commitUser': 'kimchy', 'commitDateTime': '2011-07-13 01:46:22', 'commitHash': '1033249f0c971ea099ccbce6d9fe3cd720c7c800', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.test.stress.leaks.GenericStatsLeak', 'INS': 1, 'MOV': 0}], 'spoonFilePath': 'GenericStatsLeak.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.test.stress.leaks.JvmStatsLeak', 'INS': 1, 'MOV': 0}], 'spoonFilePath': 'JvmStatsLeak.java'}, {'spoonMethods': [{'DEL': 2, 'TOT': 9, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.monitor.jvm.JvmStats', 'INS': 4, 'MOV': 2}, {'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.monitor.jvm.JvmStats.jvmStats()', 'INS': 0, 'MOV': 0}, {'DEL': 0, 'TOT': 1, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.monitor.jvm.JvmStats.isLastGcEnabled()', 'INS': 1, 'MOV': 0}], 'spoonFilePath': 'JvmStats.java'}, {'spoonMethods': [{'DEL': 1, 'TOT': 3, 'UPD': 0, 'spoonMethodName': 'org.elasticsearch.monitor.jvm.JvmMonitorService', 'INS': 2, 'MOV': 0}], 'spoonFilePath': 'JvmMonitorService.java'}], 'nameRev': '1033249f0c971ea099ccbce6d9fe3cd720c7c800 tags/v0.17.0~29', 'commitGHEventType': 'closed', 'commitMessage': 'Native (java) process memory leak, closes #1118.\n', 'authoredDateTime': '2011-07-13 01:46:22'}]",https://github.com/elastic/elasticsearch/issues/1118,0.0002777777777777778,"['>bug', 'v0.16.4', 'v0.17.0']",Native (java) process memory leak,1.0,"['org.elasticsearch.monitor.jvm.JvmStats', 'org.elasticsearch.monitor.jvm.JvmMonitorService', 'org.elasticsearch.test.stress.leaks.GenericStatsLeak', 'org.elasticsearch.monitor.jvm.JvmStats.jvmStats()', 'org.elasticsearch.test.stress.leaks.JvmStatsLeak', 'org.elasticsearch.monitor.jvm.JvmStats.isLastGcEnabled()']",['1033249f0c971ea099ccbce6d9fe3cd720c7c800'],,['modules/elasticsearch/src/main/java/org/elasticsearch/monitor/jvm'],36.0,24.0,60.0,2.0,2.0,6.0,16.0,2.0,9.0,3.0,4.0,0.0,0.0,0.0,0.0,0.0,0.0,elasticsearch
22642,2011-06-30 18:20:53,jordansissel,"I observed this with logstash.

Recreate:
- start with a fresh elasticsearch (no data dir)
- start indexing fast (1000s per second)
- a few seconds later, OOM due to thread creation explosion

This only seems to occur when heavy write rates hit an index that isn't created yet, causing ES to create the index and that seems to stall out writes and threads balloon waiting for that to happen.
",2011-06-30 18:22:37,"[{'commitGitStats': [{'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/mapping/put/TransportPutMappingAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/settings/TransportUpdateSettingsAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/alias/TransportIndicesAliasesAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/close/TransportCloseIndexAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportRefreshAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/delete/TransportDeleteIndexAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/mapping/delete/TransportDeleteMappingAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/exists/TransportIndicesExistsAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/open/TransportOpenIndexAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/gateway/snapshot/TransportGatewaySnapshotAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/template/put/TransportPutIndexTemplateAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/cache/clear/TransportClearIndicesCacheAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/template/delete/TransportDeleteIndexTemplateAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/create/TransportCreateIndexAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/flush/TransportFlushAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/analyze/TransportAnalyzeAction.java'}, {'lines': 2, 'insertions': 1, 'deletions': 1, 'filePath': 'modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/segments/TransportIndicesSegmentsAction.java'}], 'spoonStatsSkippedReason': '', 'commitParents': ['4c913693a90088aefa1b8184159b41fb747ac3f5'], 'commitUser': 'kimchy', 'commitDateTime': '2011-06-30 21:22:21', 'commitHash': 'a8969cd672cd025ecb2cd82356113980dd204327', 'commitSpoonAstDiffStats': [{'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.template.put.TransportPutIndexTemplateAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportPutIndexTemplateAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.exists.TransportIndicesExistsAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportIndicesExistsAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.flush.TransportFlushAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportFlushAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.optimize.TransportOptimizeAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportOptimizeAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.settings.TransportUpdateSettingsAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportUpdateSettingsAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.cache.clear.TransportClearIndicesCacheAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportClearIndicesCacheAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.segments.TransportIndicesSegmentsAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportIndicesSegmentsAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.gateway.snapshot.TransportGatewaySnapshotAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportGatewaySnapshotAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.analyze.TransportAnalyzeAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportAnalyzeAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.template.delete.TransportDeleteIndexTemplateAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportDeleteIndexTemplateAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.close.TransportCloseIndexAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportCloseIndexAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.mapping.put.TransportPutMappingAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportPutMappingAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.refresh.TransportRefreshAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportRefreshAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.mapping.delete.TransportDeleteMappingAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportDeleteMappingAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.open.TransportOpenIndexAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportOpenIndexAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.create.TransportCreateIndexAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportCreateIndexAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.alias.TransportIndicesAliasesAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportIndicesAliasesAction.java'}, {'spoonMethods': [{'DEL': 0, 'TOT': 1, 'UPD': 1, 'spoonMethodName': 'org.elasticsearch.action.admin.indices.delete.TransportDeleteIndexAction.executor()', 'INS': 0, 'MOV': 0}], 'spoonFilePath': 'TransportDeleteIndexAction.java'}], 'nameRev': 'a8969cd672cd025ecb2cd82356113980dd204327 tags/v0.17.0~81', 'commitGHEventType': 'closed', 'commitMessage': 'Without pre-creating index, heavy write rates OOM with too many threads, closes #1081.\n', 'authoredDateTime': '2011-06-30 21:22:21'}]",https://github.com/elastic/elasticsearch/issues/1081,0.0002777777777777778,"['>bug', 'v0.17.0']","Without pre-creating index, heavy write rates OOM with too many threads",1.0,"['org.elasticsearch.action.admin.indices.alias.TransportIndicesAliasesAction.executor()', 'org.elasticsearch.action.admin.indices.template.delete.TransportDeleteIndexTemplateAction.executor()', 'org.elasticsearch.action.admin.indices.delete.TransportDeleteIndexAction.executor()', 'org.elasticsearch.action.admin.indices.optimize.TransportOptimizeAction.executor()', 'org.elasticsearch.action.admin.indices.refresh.TransportRefreshAction.executor()', 'org.elasticsearch.action.admin.indices.settings.TransportUpdateSettingsAction.executor()', 'org.elasticsearch.action.admin.indices.cache.clear.TransportClearIndicesCacheAction.executor()', 'org.elasticsearch.action.admin.indices.exists.TransportIndicesExistsAction.executor()', 'org.elasticsearch.action.admin.indices.create.TransportCreateIndexAction.executor()', 'org.elasticsearch.action.admin.indices.mapping.delete.TransportDeleteMappingAction.executor()', 'org.elasticsearch.action.admin.indices.open.TransportOpenIndexAction.executor()', 'org.elasticsearch.action.admin.indices.gateway.snapshot.TransportGatewaySnapshotAction.executor()', 'org.elasticsearch.action.admin.indices.mapping.put.TransportPutMappingAction.executor()', 'org.elasticsearch.action.admin.indices.segments.TransportIndicesSegmentsAction.executor()', 'org.elasticsearch.action.admin.indices.flush.TransportFlushAction.executor()', 'org.elasticsearch.action.admin.indices.close.TransportCloseIndexAction.executor()', 'org.elasticsearch.action.admin.indices.template.put.TransportPutIndexTemplateAction.executor()', 'org.elasticsearch.action.admin.indices.analyze.TransportAnalyzeAction.executor()']",['a8969cd672cd025ecb2cd82356113980dd204327'],,['modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices'],18.0,18.0,36.0,18.0,18.0,18.0,18.0,0.0,0.0,0.0,18.0,0.0,0.0,0.0,0.0,0.0,0.0,elasticsearch
23926,2017-05-15 10:20:40,karolmie1,"### OrientDB Version: 2.2.20 

`SELECT * FROM Project WHERE status in :status`

if status is enum array (tested with 2 elements), it will fall into infinite recursion during parsing named parameters, and end in stackoverflow.

This one works, if :status is Enum:
`SELECT * FROM Project WHERE status = :status`


```
// toParsedTree function
 ...
      while (iterator.hasNext()) {
        Object o = iterator.next();
        OExpression exp = new OExpression(-1);
        exp.value = toParsedTree(o); //recursive call, returns itself, one time for each element in array
        coll.expressions.add(exp);
      }
...
```

Not particulary painfull, as I can map Enum to String on my own, but confusing, since status = :status, where status is enum works.

Part of stack: 

> ERROR [2017-05-15 09:54:47,472] io.dropwizard.jersey.errors.LoggingExceptionMapper: Error handling a request: f8918bc72cb46f84
> ! java.lang.StackOverflowError: null
> ! at com.orientechnologies.common.collection.OMultiValue.isMultiValue(OMultiValue.java:50)
> ! at com.orientechnologies.common.collection.OMultiValue.isMultiValue(OMultiValue.java:62)
> ! at com.orientechnologies.orient.core.sql.parser.OInputParameter.toParsedTree(OInputParameter.java:77)
> ! at com.orientechnologies.orient.core.sql.parser.ONamedParameter.bindFromInputParams(ONamedParameter.java:49)
> ! at com.orientechnologies.orient.core.sql.parser.ONamedParameter.toString(ONamedParameter.java:31)
> ! at com.orientechnologies.orient.core.sql.parser.OExpression.toString(OExpression.java:104)
> ! at com.orientechnologies.orient.core.sql.parser.OCollection.toString(OCollection.java:35)
> ! at com.orientechnologies.orient.core.sql.parser.ONamedParameter.toString(ONamedParameter.java:39)
> ! at com.orientechnologies.orient.core.sql.parser.OExpression.toString(OExpression.java:104)
> ! at com.orientechnologies.orient.core.sql.parser.OCollection.toString(OCollection.java:35)
> ! at com.orientechnologies.orient.core.sql.parser.ONamedParameter.toString(ONamedParameter.java:39)
> ! at com.orientechnologies.orient.core.sql.parser.OExpression.toString(OExpression.java:104)
> ! at com.orientechnologies.orient.core.sql.parser.OCollection.toString(OCollection.java:35)
> ! at com.orientechnologies.orient.core.sql.parser.ONamedParameter.toString(ONamedParameter.java:39)
> ! at com.orientechnologies.orient.core.sql.parser.OExpression.toString(OExpression.java:104)
> ! at com.orientechnologies.orient.core.sql.parser.OCollection.toString(OCollection.java:35)
>  ...",2017-07-25 13:36:20,"[{'commitUser': 'luigidellaquila', 'commitDateTime': '2017-07-25 15:34:25', 'commitHash': '7ee92c1f77bfa93bbabd653a13c9acda22bb4d72', 'commitParents': ['db7a926b141c11fd818cc44b1d60cceba0aa810c'], 'commitGHEventType': 'referenced', 'nameRev': '7ee92c1f77bfa93bbabd653a13c9acda22bb4d72 tags/2.2.25~22', 'commitGitStats': [{'insertions': 21, 'lines': 21, 'filePath': 'core/src/test/java/com/orientechnologies/orient/core/sql/OCommandExecutorSQLSelectTest.java', 'deletions': 0}, {'insertions': 3, 'lines': 3, 'filePath': 'core/src/main/java/com/orientechnologies/orient/core/sql/parser/OInputParameter.java', 'deletions': 0}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'com.orientechnologies.orient.core.sql.parser.OInputParameter.toParsedTree(java.lang.Object)'}], 'spoonFilePath': 'OInputParameter.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelectTest.testEnumAsParams()'}], 'spoonFilePath': 'OCommandExecutorSQLSelectTest.java'}], 'commitMessage': 'Fix StackOverflow when list of enums is passed as SQL param\n\nResolves: #7418\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2017-07-25 15:34:25'}, {'commitUser': 'luigidellaquila', 'commitDateTime': '2017-07-25 16:25:12', 'commitHash': 'fa5599d13aa3ef97cd2ddd319e266dd334b9a398', 'commitParents': ['77484d22afdc5993b28c4ef8836091a09d62f4c5'], 'commitGHEventType': 'referenced', 'nameRev': 'fa5599d13aa3ef97cd2ddd319e266dd334b9a398 tags/3.0.0m2~12', 'commitGitStats': [{'insertions': 21, 'lines': 21, 'filePath': 'core/src/test/java/com/orientechnologies/orient/core/sql/OCommandExecutorSQLSelectTest.java', 'deletions': 0}, {'insertions': 3, 'lines': 3, 'filePath': 'core/src/main/java/com/orientechnologies/orient/core/sql/parser/OInputParameter.java', 'deletions': 0}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'com.orientechnologies.orient.core.sql.parser.OInputParameter.toParsedTree(java.lang.Object)'}], 'spoonFilePath': 'OInputParameter.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelectTest.testEnumAsParams()'}], 'spoonFilePath': 'OCommandExecutorSQLSelectTest.java'}], 'commitMessage': 'Fix StackOverflow when list of enums is passed as SQL param\n\nResolves: #7418\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2017-07-25 15:34:25'}]",https://github.com/orientechnologies/orientdb/issues/7418,71.00027777777778,['bug'],"Prepared params, IN clause, array of enums: stackoverflow exception",1.0,['com.orientechnologies.orient.core.sql.parser.OInputParameter.toParsedTree(java.lang.Object)'],['7ee92c1f77bfa93bbabd653a13c9acda22bb4d72'],,['core/src/main/java/com/orientechnologies/orient/core/sql/parser'],3.0,0.0,3.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,orientdb
24689,2015-08-17 08:53:36,sepetukas,"We have OrientDB  version 2.1.0 in production (before were other versions starting from 2.0.8). 
Db is used as follows:
 4 to  5 remote clients are continuously pushing data to the database. 
There are around 88k inserts in hour. Records older then some date are deleted every 10 min.
The problem is that OrientDB eats all the ram (16 Gbytes) in about 4 days. Heap consumption is quite stable around 800 MB. So my guess would be that the problem is with the native memory leakage.

Any suggestions how to solve this problem?  
",2016-05-07 07:34:13,"[{'commitUser': 'laa', 'commitDateTime': '2015-09-09 08:03:42', 'commitHash': '18ffe4a2a9fcf7205fd5a1937b9cacb80a14ae86', 'commitParents': ['67b44e38d6982f4b915b71290548d72dbd5aaa00'], 'commitGHEventType': 'referenced', 'nameRev': '18ffe4a2a9fcf7205fd5a1937b9cacb80a14ae86 tags/2.2.0-beta~515^2~7', 'commitGitStats': [{'insertions': 228, 'lines': 228, 'filePath': 'core/src/main/java/com/orientechnologies/common/directmemory/OTrackedDirectMemoryPointer.java', 'deletions': 0}, {'insertions': 3, 'lines': 6, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/IntegerSerializerTest.java', 'deletions': 3}, {'insertions': 2, 'lines': 3, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/CharSerializerTest.java', 'deletions': 1}, {'insertions': 4, 'lines': 6, 'filePath': 'tests/src/test/java/com/orientechnologies/orient/test/internal/StringSerializerSpeedTest.java', 'deletions': 2}, {'insertions': 16, 'lines': 24, 'filePath': 'core/src/test/java/com/orientechnologies/orient/core/index/sbtree/local/SBTreeLeafBucketTest.java', 'deletions': 8}, {'insertions': 8, 'lines': 11, 'filePath': 'core/src/main/java/com/orientechnologies/orient/core/config/OGlobalConfiguration.java', 'deletions': 3}, {'insertions': 8, 'lines': 12, 'filePath': 'core/src/test/java/com/orientechnologies/orient/core/index/sbtree/local/SBTreeNonLeafBucketTest.java', 'deletions': 4}, {'insertions': 242, 'lines': 242, 'filePath': 'core/src/main/java/com/orientechnologies/common/directmemory/OUntrackedDirectMemoryPointer.java', 'deletions': 0}, {'insertions': 3, 'lines': 6, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/DateSerializerTest.java', 'deletions': 3}, {'insertions': 3, 'lines': 6, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/FloatSerializerTest.java', 'deletions': 3}, {'insertions': 0, 'lines': 1, 'filePath': 'core/src/main/java/com/orientechnologies/orient/core/storage/impl/local/paginated/wal/OWALChangesTree.java', 'deletions': 1}, {'insertions': 162, 'lines': 162, 'filePath': 'core/src/main/java/com/orientechnologies/common/directmemory/ODirectMemoryPointerFactory.java', 'deletions': 0}, {'insertions': 4, 'lines': 8, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/BooleanSerializerTest.java', 'deletions': 4}, {'insertions': 3, 'lines': 4, 'filePath': 'core/src/main/java/com/orientechnologies/orient/core/storage/impl/memory/ODirectMemoryOnlyDiskCache.java', 'deletions': 1}, {'insertions': 8, 'lines': 15, 'filePath': 'core/src/test/java/com/orientechnologies/orient/core/storage/impl/local/paginated/wal/WALChangesTreeTest.java', 'deletions': 7}, {'insertions': 25, 'lines': 49, 'filePath': 'core/src/test/java/com/orientechnologies/orient/core/index/hashindex/local/cache/LRUListTest.java', 'deletions': 24}, {'insertions': 3, 'lines': 6, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/LongSerializerTest.java', 'deletions': 3}, {'insertions': 3, 'lines': 4, 'filePath': 'core/src/test/java/com/orientechnologies/orient/core/index/OCompositeKeyTest.java', 'deletions': 1}, {'insertions': 2, 'lines': 3, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/DateTimeSerializerTest.java', 'deletions': 1}, {'insertions': 3, 'lines': 6, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/ByteSerializerTest.java', 'deletions': 3}, {'insertions': 3, 'lines': 6, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/ShortSerializerTest.java', 'deletions': 3}, {'insertions': 79, 'lines': 119, 'filePath': 'core/src/test/java/com/orientechnologies/orient/core/storage/impl/local/paginated/ClusterPageTest.java', 'deletions': 40}, {'insertions': 3, 'lines': 6, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/BinarySerializerTest.java', 'deletions': 3}, {'insertions': 1, 'lines': 2, 'filePath': 'tests/src/test/java/com/orientechnologies/orient/test/database/auto/LiveQueryTest.java', 'deletions': 1}, {'insertions': 2, 'lines': 3, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/StringSerializerTest.java', 'deletions': 1}, {'insertions': 7, 'lines': 11, 'filePath': 'core/src/test/java/com/orientechnologies/orient/core/index/sbtree/local/SBTreeValuePageTest.java', 'deletions': 4}, {'insertions': 3, 'lines': 6, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/DecimalSerializerTest.java', 'deletions': 3}, {'insertions': 3, 'lines': 6, 'filePath': 'core/src/test/java/com/orientechnologies/common/serialization/types/DoubleSerializerTest.java', 'deletions': 3}, {'insertions': 7, 'lines': 14, 'filePath': 'core/src/main/java/com/orientechnologies/orient/core/storage/impl/local/paginated/wal/ODiskWriteAheadLog.java', 'deletions': 7}, {'insertions': 13, 'lines': 17, 'filePath': 'core/src/test/java/com/orientechnologies/orient/core/index/sbtree/local/ONullBucketTest.java', 'deletions': 4}, {'insertions': 9, 'lines': 17, 'filePath': 'core/src/test/java/com/orientechnologies/orient/core/index/sbtreebonsai/local/OSBTreeBonsaiLeafBucketTest.java', 'deletions': 8}, {'insertions': 19, 'lines': 221, 'filePath': 'core/src/main/java/com/orientechnologies/common/directmemory/ODirectMemoryPointer.java', 'deletions': 202}, {'insertions': 3, 'lines': 7, 'filePath': 'core/src/main/java/com/orientechnologies/orient/core/storage/cache/local/OWOWCache.java', 'deletions': 4}, {'insertions': 7, 'lines': 9, 'filePath': 'core/src/main/java/com/orientechnologies/orient/core/storage/cache/OCachePointer.java', 'deletions': 2}, {'insertions': 8, 'lines': 12, 'filePath': 'core/src/test/java/com/orientechnologies/orient/core/index/sbtreebonsai/local/OSBTreeBonsaiNonLeafBucketTest.java', 'deletions': 4}, {'insertions': 15, 'lines': 15, 'filePath': 'core/src/main/java/com/orientechnologies/common/directmemory/ODirectMemoryMXBean.java', 'deletions': 0}, {'insertions': 0, 'lines': 17, 'filePath': 'core/src/main/java/com/orientechnologies/orient/core/storage/impl/local/paginated/OLocalPaginatedStorage.java', 'deletions': 17}], 'commitSpoonAstDiffStats': [], 'commitMessage': 'Issue #4807, memory leak detection was added.\n', 'spoonStatsSkippedReason': 'tooManyFiles', 'authoredDateTime': '2015-09-09 08:03:42'}, {'commitUser': 'laa', 'commitDateTime': '2015-09-09 09:40:54', 'commitHash': '248732b24c71efff3f40acb5296e64af9d5497e4', 'commitParents': ['18ffe4a2a9fcf7205fd5a1937b9cacb80a14ae86'], 'commitGHEventType': 'referenced', 'nameRev': '248732b24c71efff3f40acb5296e64af9d5497e4 tags/2.2.0-beta~515^2~6', 'commitGitStats': [{'insertions': 2, 'lines': 4, 'filePath': 'core/src/main/java/com/orientechnologies/common/directmemory/ODirectMemoryPointerFactory.java', 'deletions': 2}, {'insertions': 2, 'lines': 5, 'filePath': 'core/src/main/java/com/orientechnologies/common/directmemory/OUntrackedDirectMemoryPointer.java', 'deletions': 3}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 2, 'DEL': 2, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'com.orientechnologies.common.directmemory.OUntrackedDirectMemoryPointer'}], 'spoonFilePath': 'OUntrackedDirectMemoryPointer.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'com.orientechnologies.common.directmemory.ODirectMemoryPointerFactory.createPointer(byte[])'}, {'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'com.orientechnologies.common.directmemory.ODirectMemoryPointerFactory.createPointer(long)'}], 'spoonFilePath': 'ODirectMemoryPointerFactory.java'}], 'commitMessage': 'Issue #4807 build was failed.\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2015-09-09 09:40:54'}, {'commitUser': 'tglman', 'commitDateTime': '2015-11-06 13:43:22', 'commitHash': 'daa89846a07faf0215b5d99ec4121ebd7395c41e', 'commitParents': ['49c19376950bbd8b59df53643f3f87276f22fcba'], 'commitGHEventType': 'referenced', 'nameRev': 'daa89846a07faf0215b5d99ec4121ebd7395c41e tags/2.2.0-beta~300^2', 'commitGitStats': [{'insertions': 2, 'lines': 4, 'filePath': 'server/src/main/java/com/orientechnologies/orient/server/network/protocol/binary/ONetworkProtocolBinary.java', 'deletions': 2}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 3, 'DEL': 0, 'INS': 2, 'MOV': 1, 'spoonMethodName': 'com.orientechnologies.orient.server.network.protocol.binary.ONetworkProtocolBinary.openDatabase()'}], 'spoonFilePath': 'ONetworkProtocolBinary.java'}], 'commitMessage': 'moved token generation in token flag check, issue #4807\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2015-11-06 13:43:22'}]",https://github.com/orientechnologies/orientdb/issues/4807,263.0002777777778,['bug'],Suggestions how to track down or solve memory leakage problem on OrientDb,3.0,"['com.orientechnologies.orient.server.network.protocol.binary.ONetworkProtocolBinary.openDatabase()', 'com.orientechnologies.common.directmemory.OUntrackedDirectMemoryPointer', 'com.orientechnologies.common.directmemory.ODirectMemoryPointerFactory.createPointer(long)', 'com.orientechnologies.common.directmemory.ODirectMemoryPointerFactory.createPointer(byte[])']","['18ffe4a2a9fcf7205fd5a1937b9cacb80a14ae86', '248732b24c71efff3f40acb5296e64af9d5497e4', 'daa89846a07faf0215b5d99ec4121ebd7395c41e']",,"['core/src/main/java/com/orientechnologies/orient/core/config', 'core/src/main/java/com/orientechnologies/orient/core/storage/cache', 'server/src/main/java/com/orientechnologies/orient/server/network/protocol', 'core/src/main/java/com/orientechnologies/common/directmemory', 'core/src/main/java/com/orientechnologies/orient/core/storage/impl']",700.0,244.0,944.0,13.0,0.0,4.0,7.0,1.0,2.0,4.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,orientdb
26003,2018-09-06 18:31:05,tcfurrer,"## Overview

I work on a large project which runs Junit 5 under Gradle (currently version 4.8).  One of our test suites which previously ran fine with a 8 GB max heap size now requires an ~11 GB heap to run without OutOfMemoryError (~12 GB to run without OutOfMemoryError AND without GC overhead slowing things down significantly).

Looking at the release notes, I see nothing that should cause such a significant increase in memory usage from Junit 5 itself, so I was surprised to see this new problem while upgrading versions.

I only found one other open issue mentioning OutOfMemoryError and it involves dynamic tests, which my suite isn't using at all.

I suppose it's possible that some small behavior change in Junit 5.3 sensitizes an issue with my test suite that increases memory consumption, but I can't think of what that might be. 

Are there any changes in Junit 5.3 that are known to increase memory consumption, and thus increase risk of OutOfMemoryError while running tests?

My apologies if this issue seems more like a question and not a real bug report... but I figured it was better to raise the issue quickly after Junit 5.3 release just in case others are going to start hitting the same problem soon.

Unfortunately, I can't share my unit tests from this project.  However, I am going to try to pare down the test suite to see if I can narrow down where the memory increase is happening.  I may or may not be able to come back here later and provide more specific information, after doing that work.

## Deliverables

**Team Decision**:

- [x] Implement the _quick fix_ mentioned by @sbrannen.
- [x] Investigate other possibilities for freeing up unnecessary memory consumption in the `HierarchicalTestEngine` and related infrastructure (specifically in `NodeTestTask`).
- [x] Backport fix and release notes to a new `5.3.1` branch.",2018-09-09 13:45:30,"[{'commitUser': 'sbrannen', 'commitDateTime': '2018-09-07 14:48:58', 'commitHash': '05b4bc29dc6984e0c11954aa25520ded3a4e95a5', 'commitParents': ['d2be8112df7e8506f6b525181b5017a00993a928'], 'commitGHEventType': 'referenced', 'nameRev': '05b4bc29dc6984e0c11954aa25520ded3a4e95a5 tags/r5.6.0-M1~1055', 'commitGitStats': [{'insertions': 78, 'lines': 78, 'filePath': 'platform-tests/src/test/java/org/junit/platform/engine/support/hierarchical/MemoryLeakTests.java', 'deletions': 0}, {'insertions': 5, 'lines': 6, 'filePath': 'documentation/src/docs/asciidoc/release-notes/release-notes-5.3.1.adoc', 'deletions': 1}, {'insertions': 8, 'lines': 8, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeTestTask.java', 'deletions': 0}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.MemoryLeakTests'}], 'spoonFilePath': 'MemoryLeakTests.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare()'}, {'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.cleanUp()'}], 'spoonFilePath': 'NodeTestTask.java'}], 'commitMessage': 'Fix OutOfMemoryError regression in JUnit 5.3.0\n\nJUnit 5.3.0 introduced support for parallel test execution that\nincluded a new NodeTestTask class that is used internally by\nHierarchicalTestEngine implementations such as the Jupiter and Vintage\ntest engines.\n\nPrior to this commit, each NodeTestTask permanently held references to\ncontext state for itself and its parent node. In the case of the JUnit\nJupiter test engine, this context state held a reference to the test\nclass instance. Consequently, if test class instances across a test\nsuite collectively allocated large amounts of memory, an\nOutOfMemoryError would result due to insufficient heap space.\n\nThis commit fixes the core issue by clearing references to the parent\nand local contexts in NodeTestTask after they are no longer needed,\nallowing them to be properly garbage collected by the JVM.\n\nIssue: #1578\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2018-09-07 14:13:45'}, {'commitUser': 'sbrannen', 'commitDateTime': '2018-09-09 15:35:24', 'commitHash': 'ba35a7527d8ce13070b12db9d5bc0c7b458c25d1', 'commitParents': ['5782395fdbb0a456f182a66b1bdbc2fb4ea355a7'], 'commitGHEventType': 'referenced', 'nameRev': 'ba35a7527d8ce13070b12db9d5bc0c7b458c25d1 tags/r5.3.1~10', 'commitGitStats': [{'insertions': 0, 'lines': 47, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeTestTaskWalker.java', 'deletions': 47}, {'insertions': 0, 'lines': 104, 'filePath': 'platform-tests/src/test/java/org/junit/platform/engine/support/hierarchical/NodeTestTaskWalkerIntegrationTests.java', 'deletions': 104}, {'insertions': 48, 'lines': 48, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeTestTaskContext.java', 'deletions': 0}, {'insertions': 3, 'lines': 3, 'filePath': 'documentation/src/docs/asciidoc/release-notes/release-notes-5.3.1.adoc', 'deletions': 0}, {'insertions': 60, 'lines': 60, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeTreeWalker.java', 'deletions': 0}, {'insertions': 43, 'lines': 43, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeExecutionAdvisor.java', 'deletions': 0}, {'insertions': 100, 'lines': 100, 'filePath': 'platform-tests/src/test/java/org/junit/platform/engine/support/hierarchical/NodeTreeWalkerIntegrationTests.java', 'deletions': 0}, {'insertions': 6, 'lines': 16, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/HierarchicalTestExecutor.java', 'deletions': 10}, {'insertions': 33, 'lines': 33, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeUtils.java', 'deletions': 0}, {'insertions': 25, 'lines': 90, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeTestTask.java', 'deletions': 65}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.setForcedExecutionMode(org.junit.platform.engine.support.hierarchical.Node.ExecutionMode)'}, {'UPD': 3, 'TOT': 10, 'DEL': 0, 'INS': 3, 'MOV': 4, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.reportCompletion()'}, {'UPD': 1, 'TOT': 3, 'DEL': 0, 'INS': 1, 'MOV': 1, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.execute()'}, {'UPD': 8, 'TOT': 30, 'DEL': 16, 'INS': 0, 'MOV': 6, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask'}, {'UPD': 0, 'TOT': 2, 'DEL': 1, 'INS': 0, 'MOV': 1, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.getChildren()'}, {'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.setResourceLock(org.junit.platform.engine.support.hierarchical.ResourceLock)'}, {'UPD': 5, 'TOT': 17, 'DEL': 1, 'INS': 6, 'MOV': 5, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.executeDynamicTest(org.junit.platform.engine.TestDescriptor,java.util.List)'}, {'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.asNode(org.junit.platform.engine.TestDescriptor)'}, {'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.setParentContext(org.junit.platform.engine.support.hierarchical.EngineExecutionContext)'}, {'UPD': 2, 'TOT': 15, 'DEL': 3, 'INS': 7, 'MOV': 3, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively()'}, {'UPD': 0, 'TOT': 2, 'DEL': 1, 'INS': 0, 'MOV': 1, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.getExclusiveResources()'}, {'UPD': 0, 'TOT': 4, 'DEL': 2, 'INS': 1, 'MOV': 1, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.getResourceLock()'}, {'UPD': 2, 'TOT': 6, 'DEL': 1, 'INS': 1, 'MOV': 2, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.getExecutionMode()'}], 'spoonFilePath': 'NodeTestTask.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeExecutionAdvisor'}], 'spoonFilePath': 'NodeExecutionAdvisor.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTreeWalkerIntegrationTests'}], 'spoonFilePath': 'NodeTreeWalkerIntegrationTests.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTaskContext'}], 'spoonFilePath': 'NodeTestTaskContext.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeUtils'}], 'spoonFilePath': 'NodeUtils.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTreeWalker'}], 'spoonFilePath': 'NodeTreeWalker.java'}, {'spoonMethods': [{'UPD': 7, 'TOT': 14, 'DEL': 1, 'INS': 0, 'MOV': 6, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.prepareNodeTestTaskTree()'}, {'UPD': 1, 'TOT': 7, 'DEL': 1, 'INS': 1, 'MOV': 4, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute()'}], 'spoonFilePath': 'HierarchicalTestExecutor.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTaskWalkerIntegrationTests'}], 'spoonFilePath': 'NodeTestTaskWalkerIntegrationTests.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTaskWalker'}], 'spoonFilePath': 'NodeTestTaskWalker.java'}], 'commitMessage': 'Further reduce memory footprint of parallel execution\n\nPrior to this commit, the complete `TestDescriptor` tree of a\n`TestEngine` that extends `HierarchicalTestEngine` (such as the Jupiter\nengine) was wrapped in `NodeTestTask` instances prior to its execution.\nThis was done in order to store the `ResourceLock` and the forced\n`ExecutionMode` as determined by the `NodeTestTaskWalker` class (in\norder to ensure deadlock-free execution).\n\nNow, the (renamed) `NodeTreeWalker` returns a `NodeExecutionAdvisor`\nwhich stores this information and provides it to `NodeTestTask`\ninstances. Thus, `NodeTestTask` instances are created on the fly instead\nof up front.\n\nIn addition, the new `NodeTestTaskContext` class provides access to\n`EngineExecutionListener`, `HierarchicalTestExecutorService`,\n`ThrowableCollector.Factory`, and `NodeExecutionAdvisor` which are\nidentical for all `NodeTestTasks`. Previously, each `NodeTestTask`\nhad separate references to the first three of these.\n\nResolves #1578.\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2018-09-07 21:00:17'}, {'commitUser': 'marcphilipp', 'commitDateTime': '2018-09-07 21:10:12', 'commitHash': '6aac24297d660f347b7e0517cc4a84a75c68a3d5', 'commitParents': ['f445e5c1e744ece68f04830aedc0931aecb210a2'], 'commitGHEventType': 'closed', 'nameRev': '6aac24297d660f347b7e0517cc4a84a75c68a3d5 tags/r5.6.0-M1~1047', 'commitGitStats': [{'insertions': 0, 'lines': 47, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeTestTaskWalker.java', 'deletions': 47}, {'insertions': 0, 'lines': 104, 'filePath': 'platform-tests/src/test/java/org/junit/platform/engine/support/hierarchical/NodeTestTaskWalkerIntegrationTests.java', 'deletions': 104}, {'insertions': 48, 'lines': 48, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeTestTaskContext.java', 'deletions': 0}, {'insertions': 3, 'lines': 3, 'filePath': 'documentation/src/docs/asciidoc/release-notes/release-notes-5.3.1.adoc', 'deletions': 0}, {'insertions': 60, 'lines': 60, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeTreeWalker.java', 'deletions': 0}, {'insertions': 43, 'lines': 43, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeExecutionAdvisor.java', 'deletions': 0}, {'insertions': 100, 'lines': 100, 'filePath': 'platform-tests/src/test/java/org/junit/platform/engine/support/hierarchical/NodeTreeWalkerIntegrationTests.java', 'deletions': 0}, {'insertions': 6, 'lines': 16, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/HierarchicalTestExecutor.java', 'deletions': 10}, {'insertions': 33, 'lines': 33, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeUtils.java', 'deletions': 0}, {'insertions': 25, 'lines': 90, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeTestTask.java', 'deletions': 65}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.setForcedExecutionMode(org.junit.platform.engine.support.hierarchical.Node.ExecutionMode)'}, {'UPD': 3, 'TOT': 10, 'DEL': 0, 'INS': 3, 'MOV': 4, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.reportCompletion()'}, {'UPD': 1, 'TOT': 3, 'DEL': 0, 'INS': 1, 'MOV': 1, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.execute()'}, {'UPD': 8, 'TOT': 30, 'DEL': 16, 'INS': 0, 'MOV': 6, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask'}, {'UPD': 0, 'TOT': 2, 'DEL': 1, 'INS': 0, 'MOV': 1, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.getChildren()'}, {'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.setResourceLock(org.junit.platform.engine.support.hierarchical.ResourceLock)'}, {'UPD': 5, 'TOT': 17, 'DEL': 1, 'INS': 6, 'MOV': 5, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.executeDynamicTest(org.junit.platform.engine.TestDescriptor,java.util.List)'}, {'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.asNode(org.junit.platform.engine.TestDescriptor)'}, {'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.setParentContext(org.junit.platform.engine.support.hierarchical.EngineExecutionContext)'}, {'UPD': 2, 'TOT': 15, 'DEL': 3, 'INS': 7, 'MOV': 3, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively()'}, {'UPD': 0, 'TOT': 2, 'DEL': 1, 'INS': 0, 'MOV': 1, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.getExclusiveResources()'}, {'UPD': 0, 'TOT': 4, 'DEL': 2, 'INS': 1, 'MOV': 1, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.getResourceLock()'}, {'UPD': 2, 'TOT': 6, 'DEL': 1, 'INS': 1, 'MOV': 2, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.getExecutionMode()'}], 'spoonFilePath': 'NodeTestTask.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeExecutionAdvisor'}], 'spoonFilePath': 'NodeExecutionAdvisor.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTreeWalkerIntegrationTests'}], 'spoonFilePath': 'NodeTreeWalkerIntegrationTests.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTaskContext'}], 'spoonFilePath': 'NodeTestTaskContext.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeUtils'}], 'spoonFilePath': 'NodeUtils.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTreeWalker'}], 'spoonFilePath': 'NodeTreeWalker.java'}, {'spoonMethods': [{'UPD': 7, 'TOT': 14, 'DEL': 1, 'INS': 0, 'MOV': 6, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.prepareNodeTestTaskTree()'}, {'UPD': 1, 'TOT': 7, 'DEL': 1, 'INS': 1, 'MOV': 4, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute()'}], 'spoonFilePath': 'HierarchicalTestExecutor.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTaskWalkerIntegrationTests'}], 'spoonFilePath': 'NodeTestTaskWalkerIntegrationTests.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTaskWalker'}], 'spoonFilePath': 'NodeTestTaskWalker.java'}], 'commitMessage': 'Further reduce memory footprint of parallel execution\n\nPrior to this commit, the complete `TestDescriptor` tree of a\n`TestEngine` that extends `HierarchicalTestEngine` (such as the Jupiter\nengine) was wrapped in `NodeTestTask` instances prior to its execution.\nThis was done in order to store the `ResourceLock` and the forced\n`ExecutionMode` as determined by the `NodeTestTaskWalker` class (in\norder to ensure deadlock-free execution).\n\nNow, the (renamed) `NodeTreeWalker` returns a `NodeExecutionAdvisor`\nwhich stores this information and provides it to `NodeTestTask`\ninstances. Thus, `NodeTestTask` instances are created on the fly instead\nof up front.\n\nIn addition, the new `NodeTestTaskContext` class provides access to\n`EngineExecutionListener`, `HierarchicalTestExecutorService`,\n`ThrowableCollector.Factory`, and `NodeExecutionAdvisor` which are\nidentical for all `NodeTestTasks`. Previously, each `NodeTestTask`\nhad separate references to the first three of these.\n\nResolves #1578.\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2018-09-07 21:00:17'}, {'commitUser': 'sbrannen', 'commitDateTime': '2018-09-07 15:16:47', 'commitHash': '9608ae3af774baedbc643a731aa517757ee9ba91', 'commitParents': ['05b4bc29dc6984e0c11954aa25520ded3a4e95a5'], 'commitGHEventType': 'referenced', 'nameRev': '9608ae3af774baedbc643a731aa517757ee9ba91 tags/r5.6.0-M1~1054', 'commitGitStats': [{'insertions': 3, 'lines': 6, 'filePath': 'platform-tests/src/test/java/org/junit/platform/engine/support/hierarchical/MemoryLeakTests.java', 'deletions': 3}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 2, 'TOT': 2, 'DEL': 0, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.MemoryLeakTests'}], 'spoonFilePath': 'MemoryLeakTests.java'}], 'commitMessage': 'Reduce test instance state to 500 MB\n\nIssue: #1578\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2018-09-07 15:16:47'}, {'commitUser': 'sbrannen', 'commitDateTime': '2018-09-09 15:33:52', 'commitHash': '51e655ea21f084a14789627bb388b1a1d31408c9', 'commitParents': ['a7b96022d0360de850e978be921ed1ecf4145d7f'], 'commitGHEventType': 'referenced', 'nameRev': '51e655ea21f084a14789627bb388b1a1d31408c9 tags/r5.3.1~17', 'commitGitStats': [{'insertions': 3, 'lines': 6, 'filePath': 'platform-tests/src/test/java/org/junit/platform/engine/support/hierarchical/MemoryLeakTests.java', 'deletions': 3}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 2, 'TOT': 2, 'DEL': 0, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.MemoryLeakTests'}], 'spoonFilePath': 'MemoryLeakTests.java'}], 'commitMessage': 'Reduce test instance state to 500 MB\n\nIssue: #1578\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2018-09-07 15:16:47'}, {'commitUser': 'sbrannen', 'commitDateTime': '2018-09-09 15:33:40', 'commitHash': 'a7b96022d0360de850e978be921ed1ecf4145d7f', 'commitParents': ['8af8c9c8ccbc4b2eda1a98f82e77a4984d81224e'], 'commitGHEventType': 'referenced', 'nameRev': 'a7b96022d0360de850e978be921ed1ecf4145d7f tags/r5.3.1~18', 'commitGitStats': [{'insertions': 78, 'lines': 78, 'filePath': 'platform-tests/src/test/java/org/junit/platform/engine/support/hierarchical/MemoryLeakTests.java', 'deletions': 0}, {'insertions': 5, 'lines': 6, 'filePath': 'documentation/src/docs/asciidoc/release-notes/release-notes-5.3.1.adoc', 'deletions': 1}, {'insertions': 8, 'lines': 8, 'filePath': 'junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical/NodeTestTask.java', 'deletions': 0}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.MemoryLeakTests'}], 'spoonFilePath': 'MemoryLeakTests.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare()'}, {'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.junit.platform.engine.support.hierarchical.NodeTestTask.cleanUp()'}], 'spoonFilePath': 'NodeTestTask.java'}], 'commitMessage': 'Fix OutOfMemoryError regression in JUnit 5.3.0\n\nJUnit 5.3.0 introduced support for parallel test execution that\nincluded a new NodeTestTask class that is used internally by\nHierarchicalTestEngine implementations such as the Jupiter and Vintage\ntest engines.\n\nPrior to this commit, each NodeTestTask permanently held references to\ncontext state for itself and its parent node. In the case of the JUnit\nJupiter test engine, this context state held a reference to the test\nclass instance. Consequently, if test class instances across a test\nsuite collectively allocated large amounts of memory, an\nOutOfMemoryError would result due to insufficient heap space.\n\nThis commit fixes the core issue by clearing references to the parent\nand local contexts in NodeTestTask after they are no longer needed,\nallowing them to be properly garbage collected by the JVM.\n\nIssue: #1578\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2018-09-07 14:13:45'}]",https://github.com/junit-team/junit5/issues/1578,2.000277777777778,"['component: Jupiter', 'component: Platform', 'theme: execution', 'type: bug']",OutOfMemoryError in test suite when upgrading from JUnit 5.2 to 5.3,1.0,"['org.junit.platform.engine.support.hierarchical.NodeExecutionAdvisor', 'org.junit.platform.engine.support.hierarchical.NodeUtils', 'org.junit.platform.engine.support.hierarchical.NodeTreeWalker']","['9608ae3af774baedbc643a731aa517757ee9ba91', '05b4bc29dc6984e0c11954aa25520ded3a4e95a5', '6aac24297d660f347b7e0517cc4a84a75c68a3d5']",,['junit-platform-engine/src/main/java/org/junit/platform/engine/support/hierarchical'],136.0,0.0,136.0,3.0,0.0,3.0,3.0,0.0,3.0,0.0,3.0,0.0,0.0,0.0,3.0,0.0,0.0,junit5
26222,2015-04-10 07:13:13,jandam,"Config: BTreeMap with values outside nodes

BTreeMap::put2 with parameter putOnlyIfAbsent=true, <key> is already in Map so there is nothing to change. But value is stored to engine at line 1034.
",2015-05-03 07:38:59,"[{'commitUser': 'jankotek', 'commitDateTime': '2015-05-03 10:06:56', 'commitHash': 'cb1f659041ac04fca9e95a7c055d89c21668fff6', 'commitParents': ['feb207777a2175205b13b664a1aa1efb68afa6b5'], 'commitGHEventType': 'closed', 'nameRev': 'cb1f659041ac04fca9e95a7c055d89c21668fff6 tags/mapdb-2.0-alpha3~59', 'commitGitStats': [{'insertions': 15, 'lines': 22, 'filePath': 'src/main/java/org/mapdb/BTreeMap.java', 'deletions': 7}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 4, 'DEL': 0, 'INS': 2, 'MOV': 2, 'spoonMethodName': 'org.mapdb.BTreeMap.put2(java.lang.Object,java.lang.Object,boolean)'}], 'spoonFilePath': 'BTreeMap.java'}], 'commitMessage': 'BTreeMap: possible disk leak with value. Fix #479\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2015-05-03 10:06:56'}]",https://github.com/jankotek/mapdb/issues/479,23.00027777777778,"['2.0', 'bug']",BTreeMap: possible value leak,1.0,"['org.mapdb.BTreeMap.put2(java.lang.Object,java.lang.Object,boolean)']",['cb1f659041ac04fca9e95a7c055d89c21668fff6'],,['src/main/java/org/mapdb'],15.0,7.0,22.0,1.0,0.0,1.0,4.0,2.0,2.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,MapDB
26259,2014-11-18 09:55:14,jankotek,"I have a simple prototype application BTreeMap based application which
includes a b-tree called ""id2entry"" mapping longs to byte arrays:

```
db = DBMaker.newFileDB(DB_FILE)
    .mmapFileEnableIfSupported()
    .closeOnJvmShutdown()
    .commitFileSyncDisable()
    .make();

id2entry = db.createTreeMap(""id2entry"")
    .valueSerializer(Serializer.BYTE_ARRAY)
    .valuesOutsideNodesEnable()
    .makeLongMap();

```

If I perform repeated updates to id2entry, where a random key is selected
and its value replaced, i.e. no new keys are added and none are deleted, I
notice that the DB size grows rapidly on disk at a rate proportional to the
amount of data being replaced. In other words, if I replace 10MB of values
the DB grows by 10MB.

I have chosen to use the option valuesOutsideNodesEnable() because the
values are of variable length ranging from 0.5KB to several MBs (in my
testing I'm only using 512B values). If I remove the option I notice that
the DB size remains quite stable.

Note that I am using the latest MapDB 2.0 snapshot, although I have seen
similar behavior with 1.0.x. Is this behavior expected? I assume it is an
extreme manifestation of https://github.com/jankotek/MapDB/issues/97. What
do you think? It pretty much renders the valuesOutsideNodesEnable() option
unusable for normal use (I don't want to have to stop the application to
perform a compaction every few minutes). However, the side effect is that I
may not be able to efficiently store large values.
",2015-08-18 16:11:20,"[{'commitUser': 'jankotek', 'commitDateTime': '2015-08-18 18:10:47', 'commitHash': '056ff9cbcbcffcfe510523d7bff2be19c002cf69', 'commitParents': ['09ad5ffff24cee29d88ebf117a13dde8d7f069d6'], 'commitGHEventType': 'closed', 'nameRev': '056ff9cbcbcffcfe510523d7bff2be19c002cf69 tags/mapdb-2.0-beta6~1', 'commitGitStats': [{'insertions': 43, 'lines': 43, 'filePath': 'src/test/java/org/mapdb/BTreeMapTest.java', 'deletions': 0}, {'insertions': 27, 'lines': 53, 'filePath': 'src/main/java/org/mapdb/BTreeMap.java', 'deletions': 26}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 7, 'TOT': 20, 'DEL': 3, 'INS': 2, 'MOV': 8, 'spoonMethodName': 'org.mapdb.BTreeMap.removeOrReplace(java.lang.Object,java.lang.Object,java.lang.Object)'}, {'UPD': 3, 'TOT': 23, 'DEL': 6, 'INS': 5, 'MOV': 9, 'spoonMethodName': 'org.mapdb.BTreeMap.put2(java.lang.Object,java.lang.Object,boolean)'}], 'spoonFilePath': 'BTreeMap.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.BTreeMapTest.issue403_store_grows_with_values_outside_nodes()'}], 'spoonFilePath': 'BTreeMapTest.java'}], 'commitMessage': 'BTreeMap: storage space leak with valuesOutsideNodesEnable(). Fix #403\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2015-08-18 18:10:47'}]",https://github.com/jankotek/mapdb/issues/403,273.0002777777778,"['2.0', 'bug']",Extremely fast database growth when using BTreeMapMaker.valuesOutsideNodesEnable(),1.0,"['org.mapdb.BTreeMap.removeOrReplace(java.lang.Object,java.lang.Object,java.lang.Object)', 'org.mapdb.BTreeMap.put2(java.lang.Object,java.lang.Object,boolean)']",['056ff9cbcbcffcfe510523d7bff2be19c002cf69'],,['src/main/java/org/mapdb'],27.0,26.0,53.0,1.0,10.0,2.0,43.0,17.0,7.0,9.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,MapDB
26265,2014-09-16 18:09:28,niclash,"If you run the test below TWICE on mapdb-1.0.6 it throws a nasty Exception on the second run. If it is run a third time, it gets worse.
If the clear() method is removed, then it can be run as many times as one wants.

```
@Test
public void testCorruption()
    throws Exception
{
    final int INSTANCES = 100000;
    File applicationDbFile = new File( databaseDir, ""testing"" );
    DBMaker maker = DBMaker.newFileDB( applicationDbFile );
    TxMaker txMaker = maker.makeTxMaker();
    DB tx = txMaker.makeTx();
    byte[] data = new byte[128];
    try
    {
        ConcurrentMap<Long, byte[]> map = tx.getHashMap( ""persons"" );
        map.clear();
        for( int i = 0; i < INSTANCES; i++ )
        {
            map.put( (long) i, data );
        }
        tx.commit();
    }
    catch( RuntimeException ex )
    {
        tx.rollback();
        throw ex;
    }
    finally
    {
        tx.close();
    }
}
```

And the Excepiton is;

```
java.lang.AssertionError: unknown trans log instruction '0' at log offset: 5111834
    at org.mapdb.StoreWAL.replayLogFile(StoreWAL.java:858)
    at org.mapdb.StoreWAL.commit(StoreWAL.java:637)
    at org.mapdb.EngineWrapper.commit(EngineWrapper.java:94)
    at org.mapdb.EngineWrapper.commit(EngineWrapper.java:94)
    at org.mapdb.TxEngine.superCommit(TxEngine.java:310)
    at org.mapdb.TxEngine$Tx.commit(TxEngine.java:558)
    at org.mapdb.EngineWrapper.commit(EngineWrapper.java:94)
    at org.mapdb.TxEngine.commit(TxEngine.java:287)
    at org.mapdb.DB.commit(DB.java:1595)
    at org.mapdb.CorruptionTest.testCorruption(CorruptionTest.java:50)
```
",2015-02-17 12:56:17,"[{'commitUser': 'jankotek', 'commitDateTime': '2015-02-17 14:55:09', 'commitHash': '2fa873ef0a9c782db566d02020825b18a51b8758', 'commitParents': ['d0d1c060a0a5cdec025fe6d1c72c2bf6313e8ecf'], 'commitGHEventType': 'referenced', 'nameRev': '2fa873ef0a9c782db566d02020825b18a51b8758 tags/mapdb-1.0.7~6', 'commitGitStats': [{'insertions': 2, 'lines': 3, 'filePath': 'src/main/java/org/mapdb/StoreWAL.java', 'deletions': 1}, {'insertions': 60, 'lines': 60, 'filePath': 'src/test/java/org/mapdb/Issue381Test.java', 'deletions': 0}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.Issue381Test'}], 'spoonFilePath': 'Issue381Test.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 0, 'MOV': 1, 'spoonMethodName': 'org.mapdb.StoreWAL.delete(long,org.mapdb.Serializer)'}], 'spoonFilePath': 'StoreWAL.java'}], 'commitMessage': 'Fix #381, small chance for WAL corruption with deletes\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2015-02-17 14:53:50'}, {'commitUser': 'jankotek', 'commitDateTime': '2015-02-17 12:37:16', 'commitHash': '5e2cb5ecf8bae2e996aac82ed81ca4c73468c1d1', 'commitParents': ['41e3e8059121314a64ef32611bad68ab176b8a8f'], 'commitGHEventType': 'referenced', 'nameRev': '5e2cb5ecf8bae2e996aac82ed81ca4c73468c1d1 tags/mapdb-2.0-alpha2~66', 'commitGitStats': [{'insertions': 1, 'lines': 1, 'filePath': 'src/main/java/org/mapdb/StoreWAL.java', 'deletions': 0}, {'insertions': 35, 'lines': 35, 'filePath': 'src/test/java/org/mapdb/Issue381Test.java', 'deletions': 0}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.Issue381Test'}], 'spoonFilePath': 'Issue381Test.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.StoreWAL.replayWAL()'}], 'spoonFilePath': 'StoreWAL.java'}], 'commitMessage': 'Fix for #381, file descriptors were not closed, causing leak\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2015-02-17 12:37:16'}]",https://github.com/jankotek/mapdb/issues/381,153.00027777777777,"['2.0', 'bug']",Map.clear() causes corruption of Database.,2.0,"['org.mapdb.StoreWAL.delete(long,org.mapdb.Serializer)', 'org.mapdb.StoreWAL.replayWAL()']","['2fa873ef0a9c782db566d02020825b18a51b8758', '5e2cb5ecf8bae2e996aac82ed81ca4c73468c1d1']",,['src/main/java/org/mapdb'],3.0,1.0,4.0,1.0,0.0,2.0,2.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,MapDB
26312,2014-01-30 00:44:00,tea-dragon,"You have each engine register a shutdown hook with an anonymous class creation. Each of those threads has a reference to the engine being made (not that leaking threads themselves is great). These are kept in a special jdk store and will prevent garbage collection. You can unregister shutdown hooks if you keep a reference to them or you could lazily register a single static hook equipped with something similar to a listenable future and add/remove things to/from it.

Definitely not what you want to happen if you naively try to do something like create a temporary map for disk backed sorts.
",2014-02-18 14:56:54,"[{'commitUser': 'jankotek', 'commitDateTime': '2014-02-10 14:07:45', 'commitHash': '2353ab68949d7bebf1854f0c1b730865d4a8694c', 'commitParents': ['dacdd0165c0353ffd81bf81e5e429be1dcaba0f7'], 'commitGHEventType': 'referenced', 'nameRev': '2353ab68949d7bebf1854f0c1b730865d4a8694c tags/mapdb-0.9.10~21', 'commitGitStats': [{'insertions': 39, 'lines': 39, 'filePath': 'src/main/java/org/mapdb/EngineWrapper.java', 'deletions': 0}, {'insertions': 1, 'lines': 30, 'filePath': 'src/main/java/org/mapdb/DBMaker.java', 'deletions': 29}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.EngineWrapper.CloseOnJVMShutdown'}], 'spoonFilePath': 'EngineWrapper.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.mapdb.DBMaker.extendShutdownHookBefore(org.mapdb.Engine)'}, {'UPD': 0, 'TOT': 1, 'DEL': 1, 'INS': 0, 'MOV': 0, 'spoonMethodName': 'org.mapdb.DBMaker.extendShutdownHookAfter(org.mapdb.Engine)'}, {'UPD': 0, 'TOT': 6, 'DEL': 5, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.DBMaker.makeEngine()'}], 'spoonFilePath': 'DBMaker.java'}], 'commitMessage': 'DBMaker: cleanup JVM shutdown code. See #272\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2014-02-10 14:07:45'}, {'commitUser': 'jankotek', 'commitDateTime': '2014-02-02 20:34:08', 'commitHash': 'a7c6b0158ee1eb90660a39ef2c0026ea83919fc8', 'commitParents': ['c52b02d9ce625c085555e82b7050a917efeb2a2d'], 'commitGHEventType': 'referenced', 'nameRev': 'a7c6b0158ee1eb90660a39ef2c0026ea83919fc8 tags/mapdb-0.9.10~30', 'commitGitStats': [{'insertions': 20, 'lines': 24, 'filePath': 'src/main/java/org/mapdb/DBMaker.java', 'deletions': 4}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.DBMaker.makeEngine().1.run()'}, {'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.DBMaker.makeTxMaker()'}, {'UPD': 0, 'TOT': 5, 'DEL': 0, 'INS': 4, 'MOV': 1, 'spoonMethodName': 'org.mapdb.DBMaker.makeEngine()'}], 'spoonFilePath': 'DBMaker.java'}], 'commitMessage': 'DBMaker: fix memory leak in shutdown hooks. WSee #272\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2014-02-02 20:34:08'}]",https://github.com/jankotek/mapdb/issues/272,19.00027777777778,['bug'],Memory leak when using closeOnJvmShutdown (eg. any tmp map),2.0,"['org.mapdb.EngineWrapper.CloseOnJVMShutdown', 'org.mapdb.DBMaker.extendShutdownHookAfter(org.mapdb.Engine)', 'org.mapdb.DBMaker.extendShutdownHookBefore(org.mapdb.Engine)', 'org.mapdb.DBMaker.makeEngine().1.run()', 'org.mapdb.DBMaker.makeTxMaker()', 'org.mapdb.DBMaker.makeEngine()']","['a7c6b0158ee1eb90660a39ef2c0026ea83919fc8', '2353ab68949d7bebf1854f0c1b730865d4a8694c']",,['src/main/java/org/mapdb'],60.0,33.0,93.0,2.0,0.0,6.0,16.0,1.0,8.0,7.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,MapDB
26369,2012-12-18 22:45:23,jankotek,"Transactional mode does not mark deleted physical records as free. It will not reuse space after release, but grow file instead.
",2013-02-07 23:58:43,"[{'commitUser': 'jankotek', 'commitDateTime': '2013-02-07 23:57:39', 'commitHash': '47c4f06186a05fdc9c66523857e7c54a87719ff5', 'commitParents': ['97d73671867b262f477802d46084e8bff59063bf'], 'commitGHEventType': 'referenced', 'nameRev': '47c4f06186a05fdc9c66523857e7c54a87719ff5 tags/mapdb-0.9.0~67', 'commitGitStats': [{'insertions': 1, 'lines': 2, 'filePath': 'src/main/java/org/mapdb/Storage.java', 'deletions': 1}, {'insertions': 3, 'lines': 6, 'filePath': 'src/main/java/org/mapdb/StorageDirect.java', 'deletions': 3}, {'insertions': 29, 'lines': 35, 'filePath': 'src/main/java/org/mapdb/StorageJournaled.java', 'deletions': 6}], 'commitSpoonAstDiffStats': [{'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.StorageJournaled.delete(long)'}, {'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.StorageJournaled'}, {'UPD': 0, 'TOT': 3, 'DEL': 0, 'INS': 2, 'MOV': 1, 'spoonMethodName': 'org.mapdb.StorageJournaled.update(long,java.lang.Object,org.mapdb.Serializer)'}, {'UPD': 0, 'TOT': 6, 'DEL': 0, 'INS': 6, 'MOV': 0, 'spoonMethodName': 'org.mapdb.StorageJournaled.unlinkPhysRecord(long,long)'}, {'UPD': 0, 'TOT': 3, 'DEL': 0, 'INS': 3, 'MOV': 0, 'spoonMethodName': 'org.mapdb.StorageJournaled.putLargeLinkedRecord(org.mapdb.DataOutput2,long)'}, {'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.StorageJournaled.reloadIndexFile()'}], 'spoonFilePath': 'StorageJournaled.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.Storage.unlinkPhysRecord(long,long)'}], 'spoonFilePath': 'Storage.java'}, {'spoonMethods': [{'UPD': 0, 'TOT': 1, 'DEL': 0, 'INS': 1, 'MOV': 0, 'spoonMethodName': 'org.mapdb.StorageDirect.delete(long)'}, {'UPD': 0, 'TOT': 2, 'DEL': 0, 'INS': 2, 'MOV': 0, 'spoonMethodName': 'org.mapdb.StorageDirect.update(long,java.lang.Object,org.mapdb.Serializer)'}], 'spoonFilePath': 'StorageDirect.java'}], 'commitMessage': 'Fixed Issue #36, disk leak in StorageJournaled\n', 'spoonStatsSkippedReason': '', 'authoredDateTime': '2013-02-07 23:55:48'}]",https://github.com/jankotek/mapdb/issues/36,51.000277777777775,['bug'],Disk leak in journaled (transactional mode) ,1.0,"['org.mapdb.StorageDirect.delete(long)', 'org.mapdb.StorageJournaled.delete(long)', 'org.mapdb.StorageJournaled.putLargeLinkedRecord(org.mapdb.DataOutput2,long)', 'org.mapdb.StorageJournaled.update(long,java.lang.Object,org.mapdb.Serializer)', 'org.mapdb.StorageJournaled.unlinkPhysRecord(long,long)', 'org.mapdb.Storage.unlinkPhysRecord(long,long)', 'org.mapdb.StorageJournaled', 'org.mapdb.StorageJournaled.reloadIndexFile()', 'org.mapdb.StorageDirect.update(long,java.lang.Object,org.mapdb.Serializer)']",['47c4f06186a05fdc9c66523857e7c54a87719ff5'],,['src/main/java/org/mapdb'],33.0,10.0,43.0,3.0,0.0,9.0,19.0,1.0,18.0,0.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,MapDB
26491,2017-09-20 07:15:48,uruuru,"The `GraphConfigurator` creates a new `EdgeRouterFactory` for every layout run:
```
algorithmAssembler.setPhase(LayeredPhases.P5_EDGE_ROUTING,
        EdgeRouterFactory.factoryFor(lgraph.getProperty(LayeredOptions.EDGE_ROUTING)));
```

The created edge router instance, say `SplineEdgeRouter`, is then cached within the `AlgorithmAssembler`. Since it's a new factory every time, caching is broken in `AlgorithmAssembler#retrieveProcessor`. 

```
if (enableCaching) {
            if (cache.containsKey(factory)) {
[...]
```",2017-10-03 12:19:09,"[{'commitHash': '1a888887d5d418ad898e7fc192ca5db2c88e83cf', 'commitGHEventType': 'referenced', 'commitUser': 'le-cds', 'commitParents': ['8d615c317edfd5bf972136092d39457002100090'], 'nameRev': '1a888887d5d418ad898e7fc192ca5db2c88e83cf tags/v0.4.0~93', 'commitMessage': 'Layered: Fix memory leak. #252\n\nSigned-off-by: Christoph Daniel Schulze <cds@informatik.uni-kiel.de>', 'commitDateTime': '2017-10-03 14:17:11', 'authoredDateTime': '2017-10-03 14:16:54', 'commitGitStats': [{'filePath': 'plugins/org.eclipse.elk.alg.layered/src/org/eclipse/elk/alg/layered/p5edges/EdgeRouterFactory.java', 'insertions': 11, 'deletions': 3, 'lines': 14}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'EdgeRouterFactory.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.elk.alg.layered.p5edges.EdgeRouterFactory.factoryFor(org.eclipse.elk.core.options.EdgeRouting)', 'TOT': 5, 'UPD': 0, 'INS': 2, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'org.eclipse.elk.alg.layered.p5edges.EdgeRouterFactory', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '938b6d7ecca482ded5beb9ce72208af428333b92', 'commitGHEventType': 'referenced', 'commitUser': 'le-cds', 'commitParents': ['adea914ddca69cd59667726afef8e3d9097ad1f4'], 'nameRev': '938b6d7ecca482ded5beb9ce72208af428333b92 tags/v0.3.0~3', 'commitMessage': 'Layered: Fix memory leak. #252\n\nSigned-off-by: Christoph Daniel Schulze <cds@informatik.uni-kiel.de>', 'commitDateTime': '2017-10-03 14:19:34', 'authoredDateTime': '2017-10-03 14:16:54', 'commitGitStats': [{'filePath': 'plugins/org.eclipse.elk.alg.layered/src/org/eclipse/elk/alg/layered/p5edges/EdgeRouterFactory.java', 'insertions': 11, 'deletions': 3, 'lines': 14}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'EdgeRouterFactory.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.elk.alg.layered.p5edges.EdgeRouterFactory.factoryFor(org.eclipse.elk.core.options.EdgeRouting)', 'TOT': 5, 'UPD': 0, 'INS': 2, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'org.eclipse.elk.alg.layered.p5edges.EdgeRouterFactory', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/eclipse/elk/issues/252,13.000277777777777,['bug'],EdgeRouterFactory yields memory leak,1.0,"['org.eclipse.elk.alg.layered.p5edges.EdgeRouterFactory.factoryFor(org.eclipse.elk.core.options.EdgeRouting)', 'org.eclipse.elk.alg.layered.p5edges.EdgeRouterFactory']",['1a888887d5d418ad898e7fc192ca5db2c88e83cf'],,['plugins/org.eclipse.elk.alg.layered/src/org/eclipse/elk/alg/layered/p5edges'],11.0,3.0,14.0,1.0,0.0,2.0,6.0,2.0,3.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,elk
26545,2016-07-18 09:10:18,le-cds,"The execution time view is notified by the layout kernel whenever a layout run has completed. It then adds the root progress monitor of that layout run to the list of executions to be shown. Sadly, the root progress monitor keeps references to a whole lot of things, among them the layout mapping. This keeps the layout graph and the original view model from being garbage collected.

The solution will probably be to traverse the progress monitor hierarchy, extract the information to be shown in the view, and keep those around in light-weight objects.

_This ticket originated from the KIELER ticket [KIPRA-1532](https://rtsys.informatik.uni-kiel.de/jira/browse/KIPRA-1532)._
",2016-07-18 11:23:19,"[{'commitHash': '7bad22f55453db7a222de14b2789b8b2e42ff9c5', 'commitGHEventType': 'referenced', 'commitUser': 'le-cds', 'commitParents': ['0c321ae040aa5b1cb609d59062a8faf65209c8a8'], 'nameRev': '7bad22f55453db7a222de14b2789b8b2e42ff9c5 tags/v0.2.0~133', 'commitMessage': 'Fixed memory leak in execution time view. #67\n\nSigned-off-by: Christoph Daniel Schulze <cds@informatik.uni-kiel.de>', 'commitDateTime': '2016-07-18 12:29:32', 'authoredDateTime': '2016-07-18 12:29:32', 'commitGitStats': [{'filePath': 'plugins/org.eclipse.elk.core.debug/src/org/eclipse/elk/core/debug/views/execution/Execution.java', 'insertions': 133, 'deletions': 0, 'lines': 133}, {'filePath': 'plugins/org.eclipse.elk.core.debug/src/org/eclipse/elk/core/debug/views/execution/ExecutionContentProvider.java', 'insertions': 9, 'deletions': 10, 'lines': 19}, {'filePath': 'plugins/org.eclipse.elk.core.debug/src/org/eclipse/elk/core/debug/views/execution/ExecutionLabelProvider.java', 'insertions': 23, 'deletions': 23, 'lines': 46}, {'filePath': 'plugins/org.eclipse.elk.core.debug/src/org/eclipse/elk/core/debug/views/execution/ExecutionView.java', 'insertions': 5, 'deletions': 3, 'lines': 8}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'Execution.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.elk.core.debug.views.execution.Execution', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ExecutionContentProvider.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.elk.core.debug.views.execution.ExecutionContentProvider', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.eclipse.elk.core.debug.views.execution.ExecutionContentProvider.getChildren(java.lang.Object)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.eclipse.elk.core.debug.views.execution.ExecutionContentProvider.getParent(java.lang.Object)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.eclipse.elk.core.debug.views.execution.ExecutionContentProvider.hasChildren(java.lang.Object)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ExecutionLabelProvider.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.elk.core.debug.views.execution.ExecutionLabelProvider.toString(double)', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.eclipse.elk.core.debug.views.execution.ExecutionLabelProvider', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.eclipse.elk.core.debug.views.execution.ExecutionLabelProvider.getImage(java.lang.Object)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.eclipse.elk.core.debug.views.execution.ExecutionLabelProvider.getText(java.lang.Object)', 'TOT': 26, 'UPD': 10, 'INS': 4, 'MOV': 8, 'DEL': 4}]}, {'spoonFilePath': 'ExecutionView.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.elk.core.debug.views.execution.ExecutionView', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.eclipse.elk.core.debug.views.execution.ExecutionView.addExecution(org.eclipse.elk.core.util.IElkProgressMonitor).1.run()', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/eclipse/elk/issues/67,0.0002777777777777778,['bug'],Memory leak in Execution Time View,1.0,"['org.eclipse.elk.core.debug.views.execution.ExecutionContentProvider', 'org.eclipse.elk.core.debug.views.execution.ExecutionView', 'org.eclipse.elk.core.debug.views.execution.Execution', 'org.eclipse.elk.core.debug.views.execution.ExecutionLabelProvider.getImage(java.lang.Object)', 'org.eclipse.elk.core.debug.views.execution.ExecutionLabelProvider.getText(java.lang.Object)', 'org.eclipse.elk.core.debug.views.execution.ExecutionView.addExecution(org.eclipse.elk.core.util.IElkProgressMonitor).1.run()', 'org.eclipse.elk.core.debug.views.execution.ExecutionLabelProvider.toString(double)', 'org.eclipse.elk.core.debug.views.execution.ExecutionContentProvider.getParent(java.lang.Object)', 'org.eclipse.elk.core.debug.views.execution.ExecutionContentProvider.hasChildren(java.lang.Object)', 'org.eclipse.elk.core.debug.views.execution.ExecutionContentProvider.getChildren(java.lang.Object)', 'org.eclipse.elk.core.debug.views.execution.ExecutionLabelProvider']",['7bad22f55453db7a222de14b2789b8b2e42ff9c5'],,['plugins/org.eclipse.elk.core.debug/src/org/eclipse/elk/core/debug/views/execution'],170.0,36.0,206.0,4.0,23.0,11.0,42.0,9.0,6.0,4.0,4.0,0.0,0.0,0.0,0.0,0.0,0.0,elk
29278,2020-03-23 10:05:58,juriad,"### What version of gRPC-Java are you using?

GRPC 1.25.0, but the problem can be found also in master
Netty 4.1.43.Final

### What is your environment?

Linux, OpenJDK 11

### What did you expect to see?

I expected GRPC server not to keep a bound port if the start fails due to interruption.

### What did you see instead?

When I interrupt the start of server during binding to a port (https://github.com/grpc/grpc-java/blob/74cde7e8b4d4b8e59d6b8383b1557dddbada9f67/netty/src/main/java/io/grpc/netty/NettyServer.java#L248), the server fails correctly but the port is still bound.

When the server is starting for the second time, the port is still bound which leads to a failure.

### Steps to reproduce the bug

A little background story: I have nothing to do with GRPC, I am trying to implement restarting Spring Application Context on a signal (HTTP REST call) due to reloading the whole app (the main reason is that the database structures have changed). The signal can come at any point when the web server is alive, which can be even before the application context is fully refreshed. If the signal comes and there is a thread creating an application context, we interrupt it, discard its result, and start a new context. I hope this explains the role of interruption in my use case.

One of the beans is a GRpcServerStarter which encloses Server (NettyServer). If the initialization of this bean is interrupted at the wrong stage (server is binding to a port), then the future.await() is interrupted, server crashes, bean is not created, application context is closed. This however still leads to the port being bound, and the binding leaking.

```
java.lang.RuntimeException: Interrupted waiting for bind
        at io.grpc.netty.NettyServer.start(NettyServer.java:244) ~[grpc-netty-1.25.0.jar:1.25.0]
        at io.grpc.internal.ServerImpl.start(ServerImpl.java:184) ~[grpc-core-1.25.0.jar:1.25.0]
        at io.grpc.internal.ServerImpl.start(ServerImpl.java:90) ~[grpc-core-1.25.0.jar:1.25.0]
        at com.ataccama.dpe.grpc.GRpcServerStarter.init(GRpcServerStarter.java:76) ~[grpc-0.2.1.jar:0.2.1]
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
        at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
        at org.springframework.context.event.ApplicationListenerMethodAdapter.doInvoke(ApplicationListenerMethodAdapter.java:300) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.event.ApplicationListenerMethodAdapter.processEvent(ApplicationListenerMethodAdapter.java:190) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.event.ApplicationListenerMethodAdapter.onApplicationEvent(ApplicationListenerMethodAdapter.java:153) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:403) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:360) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.boot.context.event.EventPublishingRunListener.started(EventPublishingRunListener.java:98) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
        at org.springframework.boot.SpringApplicationRunListeners.started(SpringApplicationRunListeners.java:71) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:321) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
        at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:140) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
        at com.ataccama.one.metadata.MetadataServerApplication.restartApplicationContext(MetadataServerApplication.java:78) ~[app-0.0.0-restart-app-context-SNAPSHOT.jar:0.0.0-restart-app-context-SNAPSHOT]
        at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
```

After this interruption, there is no way to create a new server as the port is used.

```
java.lang.reflect.UndeclaredThrowableException: Failed to invoke event listener method
HandlerMethod details: 
Bean [com.ataccama.dpe.grpc.GRpcServerStarter]
Method [public void com.ataccama.dpe.grpc.GRpcServerStarter.init() throws java.lang.Exception]
Resolved arguments: 

        at org.springframework.context.event.ApplicationListenerMethodAdapter.doInvoke(ApplicationListenerMethodAdapter.java:317) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.event.ApplicationListenerMethodAdapter.processEvent(ApplicationListenerMethodAdapter.java:190) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.event.ApplicationListenerMethodAdapter.onApplicationEvent(ApplicationListenerMethodAdapter.java:153) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:403) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:360) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        at org.springframework.boot.context.event.EventPublishingRunListener.started(EventPublishingRunListener.java:98) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
        at org.springframework.boot.SpringApplicationRunListeners.started(SpringApplicationRunListeners.java:71) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:321) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
        at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:140) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
        at com.ataccama.one.metadata.MetadataServerApplication.restartApplicationContext(MetadataServerApplication.java:78) ~[app-0.0.0-restart-app-context-SNAPSHOT.jar:0.0.0-restart-app-context-SNAPSHOT]
        at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
Caused by: java.io.IOException: Failed to bind
        at io.grpc.netty.NettyServer.start(NettyServer.java:247) ~[grpc-netty-1.25.0.jar:1.25.0]
        at io.grpc.internal.ServerImpl.start(ServerImpl.java:184) ~[grpc-core-1.25.0.jar:1.25.0]
        at io.grpc.internal.ServerImpl.start(ServerImpl.java:90) ~[grpc-core-1.25.0.jar:1.25.0]
        at com.ataccama.dpe.grpc.GRpcServerStarter.init(GRpcServerStarter.java:76) ~[grpc-0.2.1.jar:0.2.1]
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
        at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
        at org.springframework.context.event.ApplicationListenerMethodAdapter.doInvoke(ApplicationListenerMethodAdapter.java:300) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
        ... 13 common frames omitted
Caused by: java.net.BindException: Address already in use
        at java.base/sun.nio.ch.Net.bind0(Native Method) ~[na:na]
        at java.base/sun.nio.ch.Net.bind(Net.java:461) ~[na:na]
        at java.base/sun.nio.ch.Net.bind(Net.java:453) ~[na:na]
        at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227) ~[na:na]
        at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:134) ~[netty-transport-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:551) ~[netty-transport-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1346) ~[netty-transport-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:503) ~[netty-transport-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:488) ~[netty-transport-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:985) ~[netty-transport-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:247) ~[netty-transport-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:344) ~[netty-transport-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) ~[netty-common-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:510) ~[netty-common-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:518) ~[netty-transport-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050) ~[netty-common-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.43.Final.jar:4.1.43.Final]
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.43.Final.jar:4.1.43.Final]
        ... 1 common frames omitted
```

I assume that a fix should handle better the InterruptedException by trying to unbind the port. I guess that this bug could be fixed in Netty, however from theit point of view, the binding can still succeed; you were just not patient enough to wait for the result, and it is your problem that you crash.",2020-03-28 00:21:23,"[{'commitHash': '2c250ace523c7bf329b27dfb81099f936a7810a9', 'commitGHEventType': 'referenced', 'commitUser': 'ejona86', 'commitParents': ['0b4503e4b27833e0797f08db721414f4d07397f9'], 'nameRev': '2c250ace523c7bf329b27dfb81099f936a7810a9 tags/v1.29.0~29', 'commitMessage': 'netty: prevent interruption during bind from leaking channel\n\nFixes #6850\n', 'commitDateTime': '2020-03-27 17:21:22', 'authoredDateTime': '2020-03-27 12:35:56', 'commitGitStats': [{'filePath': 'core/src/test/java/io/grpc/internal/AbstractTransportTest.java', 'insertions': 30, 'deletions': 0, 'lines': 30}, {'filePath': 'netty/src/main/java/io/grpc/netty/NettyServer.java', 'insertions': 4, 'deletions': 6, 'lines': 10}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AbstractTransportTest.java', 'spoonMethods': [{'spoonMethodName': 'io.grpc.internal.AbstractTransportTest.serverStartInterrupted()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'NettyServer.java', 'spoonMethods': [{'spoonMethodName': 'io.grpc.netty.NettyServer.start(io.grpc.internal.ServerListener)', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/grpc/grpc-java/issues/6850,4.000277777777778,['bug'],Port is bound if start is Interrupted,1.0,['io.grpc.netty.NettyServer.start(io.grpc.internal.ServerListener)'],['2c250ace523c7bf329b27dfb81099f936a7810a9'],,['netty/src/main/java/io/grpc/netty'],4.0,6.0,10.0,1.0,0.0,1.0,3.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,grpc-java
29350,2018-03-09 04:52:39,srujann,"**gRPC Version used: 1.7.0
Netty Version used: 4.1.16.Final
Java version: 1.8.0_161**

Context:
Observed Netty leak detector complaining of bytebuf leaks on the gRPC server configured with Netty Epoll. This occurs more often, a few minutes after the service restarts on a prod machine. Here is the full trace of all 25 access for the bytebuf:
 [netty_buf_leak_trace.txt](https://github.com/grpc/grpc-java/files/1795622/netty_buf_leak_trace.txt)

The most recent access to the leaked bytebuf occurs at `io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:273)` but the bytebuf is actually released here.  Not sure what is causing the leak.

```
 ERROR [2018-03-09 02:25:49,034] io.netty.util.ResourceLeakDetector: LEAK: ByteBuf.release() was not called before it's garbage-collected. See http://netty.io/wiki/reference-counted-objects.html for more information.
 Recent access records: 25
 #25:
 	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:273)
 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
 	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
 	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
 	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
 	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
 	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
 	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
 	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
 	io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
 	java.lang.Thread.run(Thread.java:748)
```





",2018-04-03 23:11:20,"[{'commitHash': '8f01084bb3b4dd7bf39f3bf3b87e0ce09be22e74', 'commitGHEventType': 'referenced', 'commitUser': 'ejona86', 'commitParents': ['bace06fe9f027d67bc00a4a621346929a3267a51'], 'nameRev': '8f01084bb3b4dd7bf39f3bf3b87e0ce09be22e74 tags/v1.12.0~50', 'commitMessage': 'core: add a `close` to InputBufferStream\n\nBefore:\n`InputBufferStream.close()` does not close their buffer so the buffer will leak.\n\nAfter:\nResolves #4198.\nOverride the `close` for closing their buffer.\n', 'commitDateTime': '2018-04-03 16:11:19', 'authoredDateTime': '2018-04-04 00:18:01', 'commitGitStats': [{'filePath': 'core/src/main/java/io/grpc/internal/ReadableBuffers.java', 'insertions': 5, 'deletions': 0, 'lines': 5}, {'filePath': 'core/src/test/java/io/grpc/internal/ReadableBuffersTest.java', 'insertions': 9, 'deletions': 0, 'lines': 9}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ReadableBuffers.java', 'spoonMethods': [{'spoonMethodName': 'io.grpc.internal.ReadableBuffers.BufferInputStream.close()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ReadableBuffersTest.java', 'spoonMethods': [{'spoonMethodName': 'io.grpc.internal.ReadableBuffersTest.bufferInputStream_close_closesBuffer()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/grpc/grpc-java/issues/4198,25.00027777777778,"['bug', 'good first issue']",ReadableBuffers.BufferInputStream does not release buffer on close(),1.0,['io.grpc.internal.ReadableBuffers.BufferInputStream.close()'],['8f01084bb3b4dd7bf39f3bf3b87e0ce09be22e74'],,['core/src/main/java/io/grpc/internal'],5.0,0.0,5.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,grpc-java
29475,2015-07-03 18:23:10,ohad7,"We're experiencing a slow memory leak with 0.7.1 when using ALPN and TLS. The server is built and started with this code : 

```
NettyServerBuilder builder = NettyServerBuilder.forPort(port);
definitions.forEach(builder::addService);
SslContext context = SslContextBuilder.forServer(keyCertPathprivateKeyPath).build();
builder.sslContext(context);
ServerImpl server = builder.build();
server.start();
```

This is the alpn version that we're using.
-Xbootclasspath/p:/usr/lib/java/alpn-boot-8.1.3.v20150130.jar""

Running a heap dump, we're seeing a huge amount of SSLEngineImpl objects stored in a concurrent hash map : 

![image](https://cloud.githubusercontent.com/assets/9012046/8503526/2c2acda0-21c9-11e5-9dfe-ba599b324c12.png)

The server is running behind a Amazon ELB. This might be related since the Amazon load balancer would open connections every once in a while to the server and to ping and make sure the server is live. Unfortunately it takes a long time to replicate, the server would run out of memory after 36 hours or so, but it doesn't seem like the number of requests 
",2015-07-13 21:37:22,"[{'commitHash': '492128e23c559c50e884c4d2b557e0ed0e33ecc4', 'commitGHEventType': 'referenced', 'commitUser': 'nmittler', 'commitParents': ['4bf37b9397752822d3f6f491f0e5316577451b3e'], 'nameRev': '492128e23c559c50e884c4d2b557e0ed0e33ecc4 tags/v0.7.2~4', 'commitMessage': 'Fixing leak of SSLEngine for Jetty ALPN/NPN servers\n\nFixes #598\n', 'commitDateTime': '2015-07-07 07:34:58', 'authoredDateTime': '2015-07-06 14:32:50', 'commitGitStats': [{'filePath': 'netty/src/main/java/io/grpc/transport/netty/ProtocolNegotiators.java', 'insertions': 39, 'deletions': 5, 'lines': 44}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ProtocolNegotiators.java', 'spoonMethods': [{'spoonMethodName': 'io.grpc.transport.netty.ProtocolNegotiators.tls(io.netty.handler.ssl.SslContext,java.net.InetSocketAddress).1', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.grpc.transport.netty.ProtocolNegotiators.plaintextUpgrade().2', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.grpc.transport.netty.ProtocolNegotiators.plaintext().3', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.grpc.transport.netty.ProtocolNegotiators.installJettyTlsProtocolSelection(javax.net.ssl.SSLEngine,com.google.common.util.concurrent.SettableFuture,boolean)', 'TOT': 2, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.grpc.transport.netty.ProtocolNegotiators.installJettyTlsProtocolSelection(javax.net.ssl.SSLEngine,com.google.common.util.concurrent.SettableFuture,boolean).4', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.grpc.transport.netty.ProtocolNegotiators.tls(io.netty.handler.ssl.SslContext,java.net.InetSocketAddress).1.newHandler(io.netty.handler.codec.http2.Http2ConnectionHandler).1.handlerAdded(io.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.grpc.transport.netty.ProtocolNegotiators.serverTls(javax.net.ssl.SSLEngine)', 'TOT': 5, 'UPD': 0, 'INS': 3, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.grpc.transport.netty.ProtocolNegotiators.installJettyTlsProtocolSelection(javax.net.ssl.SSLEngine,com.google.common.util.concurrent.SettableFuture,boolean).4.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])', 'TOT': 3, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 2}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/grpc/grpc-java/issues/598,10.000277777777777,['bug'],Memory leaking when using ALPN,1.0,"['io.grpc.transport.netty.ProtocolNegotiators.tls(io.netty.handler.ssl.SslContext,java.net.InetSocketAddress).1', 'io.grpc.transport.netty.ProtocolNegotiators.installJettyTlsProtocolSelection(javax.net.ssl.SSLEngine,com.google.common.util.concurrent.SettableFuture,boolean).4', 'io.grpc.transport.netty.ProtocolNegotiators.installJettyTlsProtocolSelection(javax.net.ssl.SSLEngine,com.google.common.util.concurrent.SettableFuture,boolean)', 'io.grpc.transport.netty.ProtocolNegotiators.serverTls(javax.net.ssl.SSLEngine)', 'io.grpc.transport.netty.ProtocolNegotiators.installJettyTlsProtocolSelection(javax.net.ssl.SSLEngine,com.google.common.util.concurrent.SettableFuture,boolean).4.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])', 'io.grpc.transport.netty.ProtocolNegotiators.plaintext().3', 'io.grpc.transport.netty.ProtocolNegotiators.tls(io.netty.handler.ssl.SslContext,java.net.InetSocketAddress).1.newHandler(io.netty.handler.codec.http2.Http2ConnectionHandler).1.handlerAdded(io.netty.channel.ChannelHandlerContext)', 'io.grpc.transport.netty.ProtocolNegotiators.plaintextUpgrade().2']",['492128e23c559c50e884c4d2b557e0ed0e33ecc4'],,['netty/src/main/java/io/grpc/transport/netty'],39.0,5.0,44.0,1.0,6.0,8.0,15.0,2.0,4.0,3.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,grpc-java
30823,2020-01-14 14:54:39,kwart,"While investigating a Jet OOME, we've realized there can be issues related to `ClusterViewListenerService.clusterListeningEndpoints`.

First of all, there were cca 27000 `TcpIpConnection` instances, but just about 20 of them were alive. The size of `clusterListeningEndpoints` map was about 25000 entries. (@olukas can provide the original heapdump).

We didn't find the reason for this behavior, but we realized there can be a resource leak in `com.hazelcast.client.impl.ClientEndpointImpl.destroy()` E.g. when a `logout` throws a `LoginException` or another problem jumps in before removing endpoint from the map.

https://github.com/hazelcast/hazelcast/blob/fdc6a205b2b6f50e01d21a263c373a0894ad2e67/hazelcast/src/main/java/com/hazelcast/client/impl/ClientEndpointImpl.java#L214-L231",2020-01-24 20:53:27,"[{'commitHash': 'c0b263572698eab8eb3d7281a49653a411a4faa7', 'commitGHEventType': 'referenced', 'commitUser': 'sancar', 'commitParents': ['c6c8df11d6b7cbdd3687c30af782a9e6676b4414'], 'nameRev': 'c0b263572698eab8eb3d7281a49653a411a4faa7 tags/v4.0~34', 'commitMessage': 'Handle login exception when logging out\n\nMade logout last so that all steps are done even when an exception\nthrown form logout method.\n\nTests are on the enterprise repo.\n\nrelated to https://github.com/hazelcast/hazelcast/issues/16482\n', 'commitDateTime': '2020-01-22 10:55:16', 'authoredDateTime': '2020-01-20 11:53:56', 'commitGitStats': [{'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/ClientEndpointImpl.java', 'insertions': 9, 'deletions': 6, 'lines': 15}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ClientEndpointImpl.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.destroy()', 'TOT': 4, 'UPD': 0, 'INS': 1, 'MOV': 3, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'ebb435321a369b30775f2181f9ade956181e24a2', 'commitGHEventType': 'referenced', 'commitUser': 'sancar', 'commitParents': ['7e284d474a2a742f3a02bb5191ebad011c110a22'], 'nameRev': 'ebb435321a369b30775f2181f9ade956181e24a2 tags/v3.12.6~6', 'commitMessage': 'Handle login exception when logging out\n\nMade logout last so that all steps are done even when an exception\nthrown form logout method.\n\nrelated to https://github.com/hazelcast/hazelcast/issues/16482\n', 'commitDateTime': '2020-01-22 12:47:00', 'authoredDateTime': '2020-01-22 11:07:26', 'commitGitStats': [{'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/ClientEndpointImpl.java', 'insertions': 9, 'deletions': 6, 'lines': 15}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ClientEndpointImpl.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.destroy()', 'TOT': 4, 'UPD': 0, 'INS': 1, 'MOV': 3, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '62eb0813d92c84b5ea77fdcac1d8c8a88b594a0e', 'commitGHEventType': 'referenced', 'commitUser': 'sancar', 'commitParents': ['f826a4dcce379314fc2721711578164da44fdf4e'], 'nameRev': '62eb0813d92c84b5ea77fdcac1d8c8a88b594a0e tags/v4.0~10', 'commitMessage': 'Fix clusterViewListener Leak\n\nIf connection closes while registering listener, we can get\nCancelledKeyException from initial push operation. Since we can\nnot add the necessary DestroyAction it was causing the leak.\n\nAdded catch and ignore for CancelledKeyException to avoid the problem.\n\nfixes https://github.com/hazelcast/hazelcast/issues/16482\n', 'commitDateTime': '2020-01-24 23:53:26', 'authoredDateTime': '2020-01-24 17:11:12', 'commitGitStats': [{'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/ClusterViewListenerService.java', 'insertions': 14, 'deletions': 2, 'lines': 16}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ClusterViewListenerService.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.impl.ClusterViewListenerService.write(com.hazelcast.client.impl.protocol.ClientMessage,com.hazelcast.internal.nio.Connection)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.impl.ClusterViewListenerService.sendToListeningEndpoints(com.hazelcast.client.impl.protocol.ClientMessage)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.impl.ClusterViewListenerService.registerListener(com.hazelcast.client.impl.ClientEndpoint,long)', 'TOT': 4, 'UPD': 0, 'INS': 2, 'MOV': 2, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/hazelcast/hazelcast/issues/16482,10.000277777777777,"['Source: Internal', 'Team: Client', 'Team: Core', 'Type: Defect']",Resource leaks related to ClusterViewListenerService.clusterListeningEndpoints,2.0,"['com.hazelcast.client.impl.ClusterViewListenerService.sendToListeningEndpoints(com.hazelcast.client.impl.protocol.ClientMessage)', 'com.hazelcast.client.impl.ClusterViewListenerService.write(com.hazelcast.client.impl.protocol.ClientMessage,com.hazelcast.internal.nio.Connection)', 'com.hazelcast.client.impl.ClusterViewListenerService.registerListener(com.hazelcast.client.impl.ClientEndpoint,long)', 'com.hazelcast.client.impl.ClientEndpointImpl.destroy()']","['c0b263572698eab8eb3d7281a49653a411a4faa7', '62eb0813d92c84b5ea77fdcac1d8c8a88b594a0e']",,['hazelcast/src/main/java/com/hazelcast/client/impl'],23.0,8.0,31.0,2.0,0.0,4.0,11.0,6.0,5.0,0.0,2.0,0.0,0.0,0.0,1.0,0.0,0.0,hazelcast
30828,2020-01-08 02:55:46,Danny-Hazelcast,"
http://jenkins.hazelcast.com/view/stable/job/stable-client-connection/49/console

/disk1/jenkins/workspace/stable-client-connection/4.0-SNAPSHOT/2020_01_08-01_28_06/client-connection 

Failed

HzClient14HZ client-ConnectGetShutdown hzcmd.client.ConnectGetPutShutdown threadId=6 com.hazelcast.spi.exception.TargetDisconnectedException: The client has closed the connection to this member, after receiving a member left event from the cluster. ClientConnection{alive=true, connectionId=3, channel=NioChannel{/10.0.0.216:43985->/10.0.0.216:5701}, remoteEndpoint=[10.0.0.216]:5701, lastReadTime=2020-01-08 02:23:54.193, lastWriteTime=2020-01-08 02:24:22.203, closedTime=never, connected server version=4.0-SNAPSHOT}


Hazelcast Enterprise 4.0-SNAPSHOT (20200106 - 04d69c5, 33fc094)

./client-connection/output/HZ/HzMember2HZ/HzMember2HZ.hprof

http://54.147.27.51/~jenkins/workspace/stable-client-connection/4.0-SNAPSHOT/2020_01_08-01_28_06/client-connection/gc.html

http://54.147.27.51/~jenkins/workspace/stable-client-connection/4.0-SNAPSHOT/2020_01_08-01_28_06/client-connection/output/HZ/HzMember2HZ/


<img width=""944"" alt=""Screen Shot 2020-01-08 at 10 54 57"" src=""https://user-images.githubusercontent.com/5988678/71946647-60e3f980-3205-11ea-9657-ed86cd2d281a.png"">


",2020-01-10 10:55:35,"[{'commitHash': '40a956bbacac7de6ec727fdd2658286c08956c0b', 'commitGHEventType': 'referenced', 'commitUser': 'sancar', 'commitParents': ['83c9a3db1ff3220607be4fa9bd54c0ca83e00d4b'], 'nameRev': '40a956bbacac7de6ec727fdd2658286c08956c0b tags/v4.0~56', 'commitMessage': 'Fix client listener registry leaks\n\nBackground:\nWhen a listener is added from an endpoint, we also register a\ndestroyAction. A destroyAction is a function to deregister the listener.\nIt is used when endpoint is removed. When endpoint is removed, we call\n all the registered destroy actions.\n\nRacy scenario is as follows:\n1. A listener is added, but not registered the destroy action.\n2. Endpoint is removed because the client is disconnected.\nAll the destroy actions currently registered are called.\n3. DestroyAction is registered to endpoint after it is destroyed.\n4. After this point, there is no one to call the last destroyAction,\nhence the leak.\n\nAs fix, we have added a second check if endpoint is destroyed after\na destroy action is put.\n\nfixes https://github.com/hazelcast/hazelcast/issues/16429\n', 'commitDateTime': '2020-01-10 13:55:34', 'authoredDateTime': '2020-01-09 15:25:52', 'commitGitStats': [{'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/ClientEndpoint.java', 'insertions': 0, 'deletions': 2, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/ClientEndpointImpl.java', 'insertions': 43, 'deletions': 26, 'lines': 69}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/ClusterViewListenerService.java', 'insertions': 4, 'deletions': 0, 'lines': 4}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/client/listeners/leak/ListenerLeakTest.java', 'insertions': 13, 'deletions': 0, 'lines': 13}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ClientEndpoint.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.impl.clearAllListeners()', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'ClientEndpointImpl.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.clearAllListeners()', 'TOT': 9, 'UPD': 5, 'INS': 0, 'MOV': 4, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.destroy()', 'TOT': 14, 'UPD': 2, 'INS': 1, 'MOV': 10, 'DEL': 1}, {'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl', 'TOT': 2, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.setTransactionContext(com.hazelcast.transaction.TransactionContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.addDestroyAction(java.util.UUID,java.util.concurrent.Callable)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.removedAndRollbackTransactionContext(java.util.UUID)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ClusterViewListenerService.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.impl.ClusterViewListenerService.getClusterListeningEndpoints()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ListenerLeakTest.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.listeners.leak.ListenerLeakTest.testListenerLeakOnMember_whenClientDestroyed()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '342b8c8b57218b5b22bade5e0177ff174c3a5066', 'commitGHEventType': 'referenced', 'commitUser': 'sancar', 'commitParents': ['5f064360b79fde227bb85269e86a7ff7654c5988'], 'nameRev': '342b8c8b57218b5b22bade5e0177ff174c3a5066 tags/v3.12.6~12', 'commitMessage': 'Fix client listener registry leaks\n\nBackground:\nWhen a listener is added from an endpoint, we also register a\ndestroyAction. A destroyAction is a function to deregister the listener.\nIt is used when endpoint is removed. When endpoint is removed, we call\n all the registered destroy actions.\n\nRacy scenario is as follows:\n1. A listener is added, but not registered the destroy action.\n2. Endpoint is removed because the client is disconnected.\nAll the destroy actions currently registered are called.\n3. DestroyAction is registered to endpoint after it is destroyed.\n4. After this point, there is no one to call the last destroyAction,\nhence the leak.\n\nAs fix, we have added a second check if endpoint is destroyed after\na destroy action is put.\n\nfixes https://github.com/hazelcast/hazelcast/issues/16429\n\n(cherry picked from commit 600502cd5ed258ca4f44a9a7a796e2ebe806990f)\n', 'commitDateTime': '2020-01-10 14:58:43', 'authoredDateTime': '2020-01-09 15:25:52', 'commitGitStats': [{'filePath': 'checkstyle/suppressions.xml', 'insertions': 1, 'deletions': 0, 'lines': 1}, {'filePath': 'hazelcast-client/src/test/java/com/hazelcast/client/listeners/leak/ListenerLeakTest.java', 'insertions': 13, 'deletions': 0, 'lines': 13}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/ClientEndpointImpl.java', 'insertions': 36, 'deletions': 12, 'lines': 48}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/ClientPartitionListenerService.java', 'insertions': 5, 'deletions': 0, 'lines': 5}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ListenerLeakTest.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.listeners.leak.ListenerLeakTest.testListenerLeakOnMember_whenClientDestroyed()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ClientEndpointImpl.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl', 'TOT': 2, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.clearAllListeners()', 'TOT': 9, 'UPD': 5, 'INS': 1, 'MOV': 3, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.destroy()', 'TOT': 17, 'UPD': 1, 'INS': 1, 'MOV': 13, 'DEL': 2}, {'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.removeAndCallRemoveAction(java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.removedAndRollbackTransactionContext(java.lang.String)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.setTransactionContext(com.hazelcast.transaction.TransactionContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.impl.ClientEndpointImpl.addDestroyAction(java.lang.String,java.util.concurrent.Callable)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ClientPartitionListenerService.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.impl.ClientPartitionListenerService.getPartitionListeningEndpoints()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/hazelcast/hazelcast/issues/16429,2.000277777777778,"['Module: Cluster', 'Source: Internal', 'Team: Client', 'Team: Core', 'Type: Defect']","Member OOME hprof, clients connect put get disconnect",1.0,"['com.hazelcast.client.impl.ClientEndpointImpl.addDestroyAction(java.util.UUID,java.util.concurrent.Callable)', 'com.hazelcast.client.impl.ClientEndpointImpl.removedAndRollbackTransactionContext(java.util.UUID)', 'com.hazelcast.client.impl.ClientEndpointImpl', 'com.hazelcast.client.impl.ClientEndpointImpl.setTransactionContext(com.hazelcast.transaction.TransactionContext)', 'com.hazelcast.client.impl.clearAllListeners()', 'com.hazelcast.client.impl.ClientEndpointImpl.clearAllListeners()', 'com.hazelcast.client.impl.ClientEndpointImpl.destroy()', 'com.hazelcast.client.impl.ClusterViewListenerService.getClusterListeningEndpoints()']",['40a956bbacac7de6ec727fdd2658286c08956c0b'],,['hazelcast/src/main/java/com/hazelcast/client/impl'],47.0,28.0,75.0,3.0,8.0,8.0,30.0,14.0,6.0,2.0,3.0,0.0,0.0,0.0,1.0,0.0,0.0,hazelcast
30984,2018-11-08 13:39:21,alparslanavci,"When destroying a `DurableExecutorService`, the `DurableExecutorPartitionContainer` instances are not cleared. This makes some of the resources such as `TaskRingBuffer` still left in the heap even the service itself is destroyed. ",2019-03-27 12:33:14,"[{'commitHash': 'b7ca00c021b37e90a5a95deb9b78299b8d1f1972', 'commitGHEventType': 'referenced', 'commitUser': 'mustafaiman', 'commitParents': ['336bd4dd3daf67f9bb98130939dd097c4b048c2c'], 'nameRev': 'b7ca00c021b37e90a5a95deb9b78299b8d1f1972 tags/v3.12~36', 'commitMessage': 'Clears lefotver durable executor containers after destroy\n\nDistributedDurableExecutorService did not clean containers removed via DurableExecutorService#destroy() call. This caused a leak.\n\nfixes https://github.com/hazelcast/hazelcast/issues/14087\n', 'commitDateTime': '2019-03-27 08:33:13', 'authoredDateTime': '2019-03-26 17:22:22', 'commitGitStats': [{'filePath': 'hazelcast/src/main/java/com/hazelcast/durableexecutor/impl/DistributedDurableExecutorService.java', 'insertions': 6, 'deletions': 0, 'lines': 6}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/durableexecutor/impl/DurableExecutorPartitionContainer.java', 'insertions': 9, 'deletions': 0, 'lines': 9}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/durableexecutor/DurableExecutorServiceTest.java', 'insertions': 41, 'deletions': 0, 'lines': 41}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/durableexecutor/impl/DurableExecutorServiceHelper.java', 'insertions': 24, 'deletions': 0, 'lines': 24}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/executor/ExecutorServiceTestSupport.java', 'insertions': 8, 'deletions': 0, 'lines': 8}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'DistributedDurableExecutorService.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.removeAllContainers(java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.destroyDistributedObject(java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'DurableExecutorPartitionContainer.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.durableexecutor.impl.DurableExecutorPartitionContainer.removeContainer(java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.durableexecutor.impl.DurableExecutorPartitionContainer.getExistingExecutorContainer(java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'DurableExecutorServiceTest.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.durableexecutor.DurableExecutorServiceTest.testManagedContextAndLocal().1', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.durableexecutor.DurableExecutorServiceTest.testSubmitToKeyOwnerRunnable().2', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.durableexecutor.DurableExecutorServiceTest.testDestroyCleansAllContainers()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'DurableExecutorServiceHelper.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.durableexecutor.impl.DurableExecutorServiceHelper', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ExecutorServiceTestSupport.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.executor.ExecutorServiceTestSupport.DummyCallable', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/hazelcast/hazelcast/issues/14087,138.00027777777777,"['Module: IExecutor', 'Priority: Medium', 'Source: Internal', 'Team: Core', 'Type: Defect']",Not all of the resources are cleared when destroying DurableExecutorService,1.0,"['com.hazelcast.durableexecutor.impl.DurableExecutorServiceHelper', 'com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.destroyDistributedObject(java.lang.String)', 'com.hazelcast.durableexecutor.impl.DurableExecutorPartitionContainer.removeContainer(java.lang.String)', 'com.hazelcast.durableexecutor.impl.DurableExecutorPartitionContainer.getExistingExecutorContainer(java.lang.String)', 'com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.removeAllContainers(java.lang.String)']",['b7ca00c021b37e90a5a95deb9b78299b8d1f1972'],,['hazelcast/src/main/java/com/hazelcast/durableexecutor/impl'],15.0,0.0,15.0,2.0,0.0,5.0,5.0,0.0,5.0,0.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,hazelcast
31087,2018-03-22 05:53:37,Danny-Hazelcast,"
/disk1/jenkins/workspace/shutdown-All/3.10-SNAPSHOT/2018_03_20-18_17_05/stable/destroy/create-use-dist-destroy Failed

```
fail HzClient1HZ _create-use-dist-destroy_createUseDistDestroy_id hzcmd.id.generator.CreateUse threadId=0 java.lang.Exception: java.lang.OutOfMemoryError: GC overhead limit exceeded 
```

http://54.82.84.143/~jenkins/workspace/shutdown-All/3.10-SNAPSHOT/2018_03_20-18_17_05/stable/destroy/create-use-dist-destroy

GC
http://54.82.84.143/~jenkins/workspace/shutdown-All/3.10-SNAPSHOT/2018_03_20-18_17_05/stable/destroy/create-use-dist-destroy/gc.html

```
output/HZ/HzMember4HZ/HzMember4HZ.hprof
output/HZ/HzClient2HZ/exception.txt
output/HZ/HzClient2HZ/HzClient2HZ.hprof
output/HZ/HzClient1HZ/exception.txt
output/HZ/HzClient1HZ/HzClient1HZ.oome
output/HZ/HzClient1HZ/HzClient1HZ.hprof
```

http://54.82.84.143/~jenkins/workspace/shutdown-All/3.10-SNAPSHOT/2018_03_20-18_17_05/stable/destroy/create-use-dist-destroy/output/HZ/HzMember4HZ/

http://54.82.84.143/~jenkins/workspace/shutdown-All/3.10-SNAPSHOT/2018_03_20-18_17_05/stable/destroy/create-use-dist-destroy/output/HZ/HzClient1HZ/",2018-04-12 12:26:01,"[{'commitHash': 'd9b653e516d9a55ef408830b9fcea63e6dd1889c', 'commitGHEventType': 'referenced', 'commitUser': 'taburet', 'commitParents': ['6a2e584594c6a9203398a49a2d18acf6f7e21f00'], 'nameRev': 'd9b653e516d9a55ef408830b9fcea63e6dd1889c tags/v3.10~58', 'commitMessage': 'Fix resource leakage in getDistributedObjects\n\ngetDistributedObjects syncs the contents of the local and remote\r\ndistributed object registries on each invocation. That involves the\r\nremoval of the stale local proxies from the local registry, but the\r\nlocal resources associated with the proxies were not cleaned up\r\nproperly.\r\n\r\nFixes: https://github.com/hazelcast/hazelcast/issues/12679\r\nRelated: https://github.com/hazelcast/hazelcast/issues/9423', 'commitDateTime': '2018-04-10 18:07:43', 'authoredDateTime': '2018-04-10 18:07:43', 'commitGitStats': [{'filePath': 'hazelcast-client/src/main/java/com/hazelcast/client/impl/HazelcastClientInstanceImpl.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast-client/src/main/java/com/hazelcast/client/spi/ClientProxy.java', 'insertions': 20, 'deletions': 0, 'lines': 20}, {'filePath': 'hazelcast-client/src/main/java/com/hazelcast/client/spi/ProxyManager.java', 'insertions': 19, 'deletions': 0, 'lines': 19}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'HazelcastClientInstanceImpl.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.impl.HazelcastClientInstanceImpl.getDistributedObjects()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ClientProxy.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.spi.ClientProxy.destroyLocally()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ProxyManager.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.destroyProxyLocally(java.lang.String,java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '79546494b1c8df9323552a057aa94afbec1f89aa', 'commitGHEventType': 'referenced', 'commitUser': 'taburet', 'commitParents': ['6c5c6302734849c9e164ac8fdd8bc58d9b678d65'], 'nameRev': '79546494b1c8df9323552a057aa94afbec1f89aa tags/v3.10~31', 'commitMessage': 'Fix a race condition while destroying proxies\n\nBefore this change there was a race condition while destroying proxies\r\nin a cluster-wide way. Multiple threads were performing destruction of\r\nthe same proxy instance simultaneously and sometimes none of them\r\nwere able to succeed at the local resources cleanup.\r\n\r\nThe idea of the fix is to unify the proxy destruction logic in\r\nProxyManager to make sure the cluster-wide destruction for a certain\r\nproxy instance is done only once.\r\n\r\nFixes: https://github.com/hazelcast/hazelcast/issues/12679', 'commitDateTime': '2018-04-12 19:26:00', 'authoredDateTime': '2018-04-12 19:26:00', 'commitGitStats': [{'filePath': 'hazelcast-client/src/main/java/com/hazelcast/client/spi/ClientProxy.java', 'insertions': 14, 'deletions': 13, 'lines': 27}, {'filePath': 'hazelcast-client/src/main/java/com/hazelcast/client/spi/ProxyManager.java', 'insertions': 40, 'deletions': 7, 'lines': 47}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ClientProxy.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.spi.ClientProxy.destroy()', 'TOT': 10, 'UPD': 0, 'INS': 2, 'MOV': 7, 'DEL': 1}, {'spoonMethodName': 'com.hazelcast.client.spi.ClientProxy.destroyLocally()', 'TOT': 4, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 4}, {'spoonMethodName': 'com.hazelcast.client.spi.ClientProxy.destroyRemotely()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ProxyManager.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.removeProxy(java.lang.String,java.lang.String)', 'TOT': 9, 'UPD': 6, 'INS': 0, 'MOV': 3, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/hazelcast/hazelcast/issues/12679,21.00027777777778,"['Source: Community', 'Team: Core', 'Type: Critical', 'Type: Defect']","Member / Client OOME GC overhead limit, create-use-distributed-obj-destroy",2.0,"['com.hazelcast.client.spi.ClientProxy.destroyLocally()', 'com.hazelcast.client.spi.ClientProxy.destroy()', 'com.hazelcast.client.impl.HazelcastClientInstanceImpl.getDistributedObjects()', 'com.hazelcast.client.spi.ProxyManager.destroyProxyLocally(java.lang.String,java.lang.String)', 'com.hazelcast.client.spi.ClientProxy.destroyRemotely()', 'com.hazelcast.client.spi.ProxyManager.removeProxy(java.lang.String,java.lang.String)']","['d9b653e516d9a55ef408830b9fcea63e6dd1889c', '79546494b1c8df9323552a057aa94afbec1f89aa']",,"['hazelcast-client/src/main/java/com/hazelcast/client/spi', 'hazelcast-client/src/main/java/com/hazelcast/client/impl']",94.0,21.0,115.0,3.0,7.0,6.0,27.0,10.0,5.0,5.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,hazelcast
31100,2018-03-02 08:51:46,ghqian,"This seems to be a bug.

ProxyManager won't remove Proxy even after original distributed object destroyed.
This caused memory leak after long time such as 1 month.

The only removing event happens when hazelcast client instance call the getDistributedObjects function.
https://github.com/hazelcast/hazelcast/blob/e0ea8ed98b3c30d4e8a03d38fc6fd9c6bca57574/hazelcast-client/src/main/java/com/hazelcast/client/impl/HazelcastClientInstanceImpl.java#L661

To avoid memory leak we had to call getDistributedObjects function in distributedObjectDestroyed event in our program.
",2019-12-30 06:34:14,"[{'commitHash': '4d7712e5e0206078b91cdca7840f1351a782a74c', 'commitGHEventType': 'closed', 'commitUser': 'Holmistr', 'commitParents': ['b03a0c1e24e4431c4634d0d77424e79862015f4c'], 'nameRev': '4d7712e5e0206078b91cdca7840f1351a782a74c tags/v3.10.6~11^2', 'commitMessage': 'Proxy creation and deletion on remote delegated to client\n\nClients does not listen proxies by default, because listening every\nproxy event could create unncessary load on the cluster, especially\nwhen number of clients are high.\nTo avoid leak on the clients, a periodic poll based method is\nintroduced with this pr.\n\nfixes https://github.com/hazelcast/hazelcast/issues/12470\n\n(cherry picked from commit 5dc3e4afdea36529ba2e929a8461d5329b2f5eac)\n', 'commitDateTime': '2018-09-20 15:47:25', 'authoredDateTime': '2018-08-13 16:08:13', 'commitGitStats': [{'filePath': 'hazelcast-client/src/main/java/com/hazelcast/client/impl/HazelcastClientInstanceImpl.java', 'insertions': 0, 'deletions': 27, 'lines': 27}, {'filePath': 'hazelcast-client/src/main/java/com/hazelcast/client/spi/ClientContext.java', 'insertions': 3, 'deletions': 1, 'lines': 4}, {'filePath': 'hazelcast-client/src/main/java/com/hazelcast/client/spi/ProxyManager.java', 'insertions': 76, 'deletions': 18, 'lines': 94}, {'filePath': 'hazelcast-client/src/main/java/com/hazelcast/client/spi/impl/listener/LazyDistributedObjectEvent.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast-client/src/test/java/com/hazelcast/client/map/impl/querycache/ClientQueryCacheMemoryLeakTest.java', 'insertions': 1, 'deletions': 3, 'lines': 4}, {'filePath': 'hazelcast-client/src/test/java/com/hazelcast/client/spi/ClientProxyDestroyTest.java', 'insertions': 39, 'deletions': 3, 'lines': 42}, {'filePath': 'hazelcast-client/src/test/java/com/hazelcast/client/spi/ProxyFactoryTest.java', 'insertions': 1, 'deletions': 1, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'HazelcastClientInstanceImpl.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.impl.HazelcastClientInstanceImpl.getDistributedObjects()', 'TOT': 10, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 10}]}, {'spoonFilePath': 'ClientContext.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.spi.ClientContext.getHazelcastInstance()', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'com.hazelcast.client.spi.ClientContext', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ProxyManager.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.getContext()', 'TOT': 5, 'UPD': 2, 'INS': 0, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.getHazelcastInstance()', 'TOT': 5, 'UPD': 2, 'INS': 0, 'MOV': 3, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.getDistributedObjects()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.isRetryable(java.lang.Throwable)', 'TOT': 11, 'UPD': 4, 'INS': 0, 'MOV': 5, 'DEL': 2}, {'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.init(com.hazelcast.client.config.ClientConfig,com.hazelcast.client.spi.ClientContext)', 'TOT': 6, 'UPD': 1, 'INS': 2, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.initializeWithRetry(com.hazelcast.client.spi.ClientProxy)', 'TOT': 4, 'UPD': 4, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.SyncDistributedObjectsTask', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.processDistributedObjectInfos(com.hazelcast.client.impl.protocol.ClientMessage)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.getOrCreateProxy(java.lang.String,java.lang.String,boolean)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.getOrCreateProxy(java.lang.String,java.lang.String)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'LazyDistributedObjectEvent.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.spi.impl.listener.LazyDistributedObjectEvent.getDistributedObject()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ClientQueryCacheMemoryLeakTest.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.map.impl.querycache.ClientQueryCacheMemoryLeakTest.assertNoUserListenerLeft(java.lang.String,com.hazelcast.core.HazelcastInstance)', 'TOT': 4, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 2}]}, {'spoonFilePath': 'ClientProxyDestroyTest.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.spi.ClientProxyDestroyTest', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.spi.ClientProxyDestroyTest.testRemoteProxyCreationDelegatesToClientEventually()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.spi.ClientProxyDestroyTest.testRemoteProxyDeletionDelegatesToClientEventually()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'com.hazelcast.client.spi.ClientProxyDestroyTest.setup()', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'ProxyFactoryTest.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.spi.ProxyFactoryTest.testProxyCreation(java.lang.String,com.hazelcast.client.config.ClientConfig)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'a4f2b76dbfb45d1f81ed6b2bd33db5f0de570270', 'commitGHEventType': 'referenced', 'commitUser': 'ihsandemir', 'commitParents': ['21c690b2b3d31803d02b6c9381a1b75b138086dc'], 'nameRev': 'a4f2b76dbfb45d1f81ed6b2bd33db5f0de570270 tags/v4.0~120', 'commitMessage': 'Make client destroy proxies when other client/members do destroy proxy (#16347)\n\n* Added source field to `DistributedObjectEvent`.\r\n\r\nClient `ProxyManager` registers to distributed object events and processes the destroy events only. It skips the destroy events which were originally initiated by destroy proxy request from the same client.\r\n\r\nfixes https://github.com/hazelcast/hazelcast/issues/12470\r\n', 'commitDateTime': '2019-12-30 09:34:13', 'authoredDateTime': '2019-12-30 09:34:13', 'commitGitStats': [{'filePath': 'hazelcast/src/main/java/com/hazelcast/cache/impl/AbstractCacheService.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/cardinality/impl/CardinalityEstimatorService.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/protocol/codec/ClientAddDistributedObjectListenerCodec.java', 'insertions': 9, 'deletions': 7, 'lines': 16}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/AbstractMultiTargetMessageTask.java', 'insertions': 1, 'deletions': 0, 'lines': 1}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/AddDistributedObjectListenerMessageTask.java', 'insertions': 6, 'deletions': 1, 'lines': 7}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/CreateProxiesMessageTask.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/map/MapFlushMessageTask.java', 'insertions': 3, 'deletions': 1, 'lines': 4}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/map/MapLoadAllMessageTask.java', 'insertions': 3, 'deletions': 1, 'lines': 4}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/spi/ProxyManager.java', 'insertions': 27, 'deletions': 3, 'lines': 30}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/client/impl/spi/impl/listener/LazyDistributedObjectEvent.java', 'insertions': 9, 'deletions': 6, 'lines': 15}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/collection/impl/list/ListService.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/collection/impl/queue/QueueContainer.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/collection/impl/queue/QueueService.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/collection/impl/queue/operations/CheckAndEvictOperation.java', 'insertions': 7, 'deletions': 2, 'lines': 9}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/collection/impl/set/SetService.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/core/DistributedObjectEvent.java', 'insertions': 14, 'deletions': 12, 'lines': 26}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/durableexecutor/impl/DistributedDurableExecutorService.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/executor/impl/DistributedExecutorService.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/flakeidgen/impl/FlakeIdGeneratorProxy.java', 'insertions': 4, 'deletions': 1, 'lines': 5}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/flakeidgen/impl/FlakeIdGeneratorService.java', 'insertions': 3, 'deletions': 2, 'lines': 5}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/flakeidgen/impl/NewIdBatchOperation.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/flakeidgen/impl/client/NewIdBatchMessageTask.java', 'insertions': 4, 'deletions': 1, 'lines': 5}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/instance/impl/HazelcastInstanceImpl.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/internal/crdt/pncounter/PNCounterService.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/internal/longregister/LongRegisterService.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/internal/services/RemoteService.java', 'insertions': 7, 'deletions': 3, 'lines': 10}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/map/impl/MapRemoteService.java', 'insertions': 3, 'deletions': 1, 'lines': 4}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/map/impl/MapService.java', 'insertions': 2, 'deletions': 2, 'lines': 4}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/multimap/impl/MultiMapService.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/replicatedmap/impl/ReplicatedMapService.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/ringbuffer/impl/RingbufferService.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/scheduledexecutor/impl/DistributedScheduledExecutorService.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/spi/impl/AbstractDistributedObject.java', 'insertions': 6, 'deletions': 1, 'lines': 7}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice/InternalProxyService.java', 'insertions': 3, 'deletions': 1, 'lines': 4}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice/ProxyService.java', 'insertions': 3, 'deletions': 3, 'lines': 6}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice/impl/DistributedObjectEventPacket.java', 'insertions': 12, 'deletions': 1, 'lines': 13}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice/impl/DistributedObjectFuture.java', 'insertions': 12, 'deletions': 0, 'lines': 12}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice/impl/ProxyEventProcessor.java', 'insertions': 5, 'deletions': 2, 'lines': 7}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice/impl/ProxyInfo.java', 'insertions': 11, 'deletions': 2, 'lines': 13}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice/impl/ProxyRegistry.java', 'insertions': 25, 'deletions': 22, 'lines': 47}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice/impl/ProxyServiceImpl.java', 'insertions': 11, 'deletions': 10, 'lines': 21}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice/impl/operations/DistributedObjectDestroyOperation.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice/impl/operations/InitializeDistributedObjectOperation.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice/impl/operations/PostJoinProxyOperation.java', 'insertions': 4, 'deletions': 2, 'lines': 6}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/topic/impl/TopicService.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/topic/impl/reliable/ReliableTopicService.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/transaction/impl/TransactionContextImpl.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/transaction/impl/xa/XAService.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/main/java/com/hazelcast/transaction/impl/xa/XATransactionContextImpl.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/client/impl/proxy/ClientDistributedObjectListenerTest.java', 'insertions': 91, 'deletions': 0, 'lines': 91}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/client/impl/proxy/DistributedObjectListenerTest.java', 'insertions': 0, 'deletions': 190, 'lines': 190}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/client/impl/spi/ProxyFactoryTest.java', 'insertions': 3, 'deletions': 1, 'lines': 4}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/client/map/impl/querycache/ClientQueryCacheDestroyResourcesTest.java', 'insertions': 9, 'deletions': 5, 'lines': 14}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/client/protocol/compatibility/ClientCompatibilityNullTest_2_0.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/client/protocol/compatibility/ClientCompatibilityTest_2_0.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/client/protocol/compatibility/MemberCompatibilityNullTest_2_0.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/client/protocol/compatibility/MemberCompatibilityTest_2_0.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/core/DistributedObjectListenerTest.java', 'insertions': 155, 'deletions': 19, 'lines': 174}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/core/DistributedObjectTest.java', 'insertions': 10, 'deletions': 4, 'lines': 14}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/flakeidgen/impl/FlakeIdGeneratorProxyTest.java', 'insertions': 14, 'deletions': 1, 'lines': 15}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/map/impl/tx/MapTransactionStressTest.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/serviceprovider/TestRemoteService.java', 'insertions': 3, 'deletions': 1, 'lines': 4}, {'filePath': 'hazelcast/src/test/java/com/hazelcast/spi/impl/proxyservice/impl/DistributedObjectFutureTest.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'hazelcast/src/test/resources/2.0.protocol.compatibility.binary', 'insertions': 0, 'deletions': 0, 'lines': 0}, {'filePath': 'hazelcast/src/test/resources/2.0.protocol.compatibility.null.binary', 'insertions': 0, 'deletions': 0, 'lines': 0}], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': 'tooManyFiles'}]",https://github.com/hazelcast/hazelcast/issues/12470,667.0002777777778,"['Source: Community', 'Team: Client', 'Type: Defect']",ProxyManager won't remove Proxy even after original distributed object destroyed.,2.0,"['com.hazelcast.client.spi.ProxyManager.getHazelcastInstance()', 'com.hazelcast.client.spi.ProxyManager.getOrCreateProxy(java.lang.String,java.lang.String,boolean)', 'com.hazelcast.client.spi.ClientContext', 'com.hazelcast.client.spi.ProxyManager.getContext()', 'com.hazelcast.client.impl.HazelcastClientInstanceImpl.getDistributedObjects()', 'com.hazelcast.client.spi.ProxyManager.SyncDistributedObjectsTask', 'com.hazelcast.client.spi.ProxyManager.isRetryable(java.lang.Throwable)', 'com.hazelcast.client.spi.ProxyManager.initializeWithRetry(com.hazelcast.client.spi.ClientProxy)', 'com.hazelcast.client.spi.ProxyManager.init(com.hazelcast.client.config.ClientConfig,com.hazelcast.client.spi.ClientContext)', 'com.hazelcast.client.spi.ProxyManager.processDistributedObjectInfos(com.hazelcast.client.impl.protocol.ClientMessage)', 'com.hazelcast.client.spi.ProxyManager.getOrCreateProxy(java.lang.String,java.lang.String)', 'com.hazelcast.client.spi.ProxyManager', 'com.hazelcast.client.spi.ProxyManager.getDistributedObjects()', 'com.hazelcast.client.spi.impl.listener.LazyDistributedObjectEvent.getDistributedObject()', 'com.hazelcast.client.spi.ClientContext.getHazelcastInstance()']","['4d7712e5e0206078b91cdca7840f1351a782a74c', 'a4f2b76dbfb45d1f81ed6b2bd33db5f0de570270']",,"['hazelcast/src/main/java/com/hazelcast/collection/impl/queue', 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice/impl', 'hazelcast/src/main/java/com/hazelcast/internal/services', 'hazelcast/src/main/java/com/hazelcast/cardinality/impl', 'hazelcast/src/main/java/com/hazelcast/topic/impl/reliable', 'hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task', 'hazelcast/src/main/java/com/hazelcast/flakeidgen/impl', 'hazelcast-client/src/main/java/com/hazelcast/client/spi', 'hazelcast/src/main/java/com/hazelcast/internal/longregister', 'hazelcast/src/main/java/com/hazelcast/flakeidgen/impl/client', 'hazelcast/src/main/java/com/hazelcast/spi/impl', 'hazelcast/src/main/java/com/hazelcast/instance/impl', 'hazelcast/src/main/java/com/hazelcast/topic/impl', 'hazelcast/src/main/java/com/hazelcast/transaction/impl/xa', 'hazelcast/src/main/java/com/hazelcast/client/impl/spi', 'hazelcast/src/main/java/com/hazelcast/scheduledexecutor/impl', 'hazelcast/src/main/java/com/hazelcast/map/impl', 'hazelcast/src/main/java/com/hazelcast/collection/impl/queue/operations', 'hazelcast/src/main/java/com/hazelcast/client/impl/protocol/codec', 'hazelcast/src/main/java/com/hazelcast/client/impl/spi/impl', 'hazelcast/src/main/java/com/hazelcast/collection/impl/set', 'hazelcast/src/main/java/com/hazelcast/collection/impl/list', 'hazelcast/src/main/java/com/hazelcast/spi/impl/proxyservice', 'hazelcast/src/main/java/com/hazelcast/executor/impl', 'hazelcast/src/main/java/com/hazelcast/core', 'hazelcast/src/main/java/com/hazelcast/transaction/impl', 'hazelcast/src/main/java/com/hazelcast/durableexecutor/impl', 'hazelcast/src/main/java/com/hazelcast/multimap/impl', 'hazelcast-client/src/main/java/com/hazelcast/client/impl', 'hazelcast/src/main/java/com/hazelcast/internal/crdt/pncounter', 'hazelcast-client/src/main/java/com/hazelcast/client/spi/impl/listener', 'hazelcast/src/main/java/com/hazelcast/replicatedmap/impl', 'hazelcast/src/main/java/com/hazelcast/ringbuffer/impl', 'hazelcast/src/main/java/com/hazelcast/cache/impl']",309.0,158.0,467.0,53.0,14.0,15.0,55.0,14.0,12.0,15.0,4.0,0.0,0.0,0.0,0.0,0.0,0.0,hazelcast
31471,2016-12-12 08:45:09,alparslanavci,"HazelcastClient.getDistributedObjects() returns the proxies already created. But the proxy list is not updated after a distributed object removal from other instance. Below is the reproducer test for the issue: 

```    
    @Test
    public void testGetDistributedObjectsAfterRemove(){
        HazelcastInstance server = hazelcastFactory.newHazelcastInstance();
        IMap<Object, Object> firstMap = server.getMap(""firstMap"");
        server.getMap(""secondMap"");

        HazelcastInstance client = hazelcastFactory.newHazelcastClient();
        assertEquals(2, client.getDistributedObjects().size());

        firstMap.destroy();

        assertEquals(1, client.getDistributedObjects().size());
    }
```

",2016-12-16 18:36:59,"[{'commitHash': 'd9b653e516d9a55ef408830b9fcea63e6dd1889c', 'commitGHEventType': 'referenced', 'commitUser': 'taburet', 'commitParents': ['6a2e584594c6a9203398a49a2d18acf6f7e21f00'], 'nameRev': 'd9b653e516d9a55ef408830b9fcea63e6dd1889c tags/v3.10~58', 'commitMessage': 'Fix resource leakage in getDistributedObjects\n\ngetDistributedObjects syncs the contents of the local and remote\r\ndistributed object registries on each invocation. That involves the\r\nremoval of the stale local proxies from the local registry, but the\r\nlocal resources associated with the proxies were not cleaned up\r\nproperly.\r\n\r\nFixes: https://github.com/hazelcast/hazelcast/issues/12679\r\nRelated: https://github.com/hazelcast/hazelcast/issues/9423', 'commitDateTime': '2018-04-10 18:07:43', 'authoredDateTime': '2018-04-10 18:07:43', 'commitGitStats': [{'filePath': 'hazelcast-client/src/main/java/com/hazelcast/client/impl/HazelcastClientInstanceImpl.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'hazelcast-client/src/main/java/com/hazelcast/client/spi/ClientProxy.java', 'insertions': 20, 'deletions': 0, 'lines': 20}, {'filePath': 'hazelcast-client/src/main/java/com/hazelcast/client/spi/ProxyManager.java', 'insertions': 19, 'deletions': 0, 'lines': 19}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'HazelcastClientInstanceImpl.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.impl.HazelcastClientInstanceImpl.getDistributedObjects()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ClientProxy.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.spi.ClientProxy.destroyLocally()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ProxyManager.java', 'spoonMethods': [{'spoonMethodName': 'com.hazelcast.client.spi.ProxyManager.destroyProxyLocally(java.lang.String,java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/hazelcast/hazelcast/issues/9423,4.000277777777778,"['Source: Internal', 'Team: Client', 'Type: Defect']",HazelcastClient.getDistributedObjects is not updated after distributed object removal from other instance,1.0,"['com.hazelcast.client.spi.ProxyManager.destroyProxyLocally(java.lang.String,java.lang.String)', 'com.hazelcast.client.impl.HazelcastClientInstanceImpl.getDistributedObjects()', 'com.hazelcast.client.spi.ClientProxy.destroyLocally()']",['d9b653e516d9a55ef408830b9fcea63e6dd1889c'],,"['hazelcast-client/src/main/java/com/hazelcast/client/impl', 'hazelcast-client/src/main/java/com/hazelcast/client/spi']",40.0,1.0,41.0,3.0,1.0,3.0,3.0,0.0,2.0,0.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,hazelcast
32915,2018-01-22 15:29:38,ctron,"While testing Hono I stumbled over the situation that the Hono HTTP adapter runs into memory issues. Peeking at the heap I can see a high number of instances of the `TelemetrySenderImpl`:

~~~
sh-4.2$ jmap -histo 1  | head -n 30

 num     #instances         #bytes  class name
----------------------------------------------
   1:        306888       31552608  [B
   2:        273952       26299392  org.apache.qpid.proton.engine.impl.DeliveryImpl
   3:        343058       25441536  [C
   4:        273952        8766464  org.apache.qpid.proton.engine.impl.TransportDelivery
   5:        330609        7934616  java.lang.String
   6:        273952        6574848  io.vertx.proton.impl.ProtonDeliveryImpl
   7:        273309        6559416  org.eclipse.hono.client.impl.TelemetrySenderImpl$$Lambda$180/1997786804
   8:        284584        4553344  org.apache.qpid.proton.amqp.UnsignedInteger
   9:         16953        3474568  [I
  10:         14247        1534456  [Ljava.lang.Object;
  11:          7507         834672  java.lang.Class
  12:         19613         627616  java.util.concurrent.ConcurrentHashMap$Node
  13:          8313         532032  java.nio.DirectByteBuffer
  14:         10630         510240  java.nio.HeapByteBuffer
  15:          5433         378288  [Ljava.util.HashMap$Node;
  16:         10935         349920  java.util.HashMap$Node
  17:          7718         308720  java.util.LinkedHashMap$Entry
  18:         17963         287408  java.lang.Object
  19:           386         212272  [Ljava.nio.channels.SelectionKey;
  20:          4170         200160  io.netty.buffer.UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf
  21:          2186         192368  java.lang.reflect.Method
  22:          3421         191576  java.util.LinkedHashMap
  23:           133         177968  [Ljava.util.concurrent.ConcurrentHashMap$Node;
  24:          3654         175392  java.util.HashMap
  25:          4221         168840  io.netty.handler.codec.DefaultHeaders$HeaderEntry
  26:           234         153504  io.netty.util.internal.shaded.org.jctools.queues.MpscArrayQueue
  27:          4769         152608  java.lang.ref.WeakReference
~~~

Looking at the code I spotted the following in `org.eclipse.hono.client.impl.HonoClientImpl.getOrCreateSender(String, Consumer<Handler<AsyncResult<MessageSender>>>, Handler<AsyncResult<MessageSender>>)`:

~~~java
…
} else if (!creationLocks.computeIfAbsent(key, k -> Boolean.FALSE)) {

  // register a handler to be notified if the underlying connection to the server fails
  // so that we can fail the result handler passed in
  final Handler<Void> connectionFailureHandler = connectionLost -> {
  // remove lock so that next attempt to open a sender doesn't fail
  creationLocks.remove(key);
  resultHandler.handle(Future.failedFuture(
    new ServerErrorException(HttpURLConnection.HTTP_UNAVAILABLE, ""connection to server lost"")));
  };
  creationRequests.add(connectionFailureHandler);
  creationLocks.put(key, Boolean.TRUE);
  LOG.debug(""creating new message sender for {}"", key);
…
~~~

To me it looks like as if this method gets called un-synchronized from various threads. So between the ""computeIfAbsent"" (which will always return false) and the ""put"", it might be that multiple callers might have triggered a new connection.

Changing it to `creationLocks.putIfAbsent(key, k -> Boolean.TRUE) == null` should fix this issue as only the first caller will pass. After that the result will be non-null until the key is removed by the call to `remove`. Of course that would change the meaning of the value carried by the map. So maybe switching this to `Map<String,Object>` would be more appropriate then.",2018-01-24 09:17:43,"[{'commitHash': '1f2d56ed5e33dceec00235a9b0bdc45702004e09', 'commitGHEventType': 'referenced', 'commitUser': 'sophokles73', 'commitParents': ['a469c6e835b29cb955f8a81ca4c9649bfed7e4b6'], 'nameRev': '1f2d56ed5e33dceec00235a9b0bdc45702004e09 tags/0.5~78', 'commitMessage': '[#454] Fix memory leak in message sender using handlers\n\nThis change fixes a memory leak by locally settling messages in:\n* EventSenderImpl\n* ForwardingEventDownstreamAdapter\n* TelemetrySenderImp\n\nSigned-off-by: Jens Reimann <jreimann@redhat.com>', 'commitDateTime': '2018-01-23 16:56:33', 'authoredDateTime': '2018-01-22 16:58:28', 'commitGitStats': [{'filePath': 'client/src/main/java/org/eclipse/hono/client/impl/EventSenderImpl.java', 'insertions': 4, 'deletions': 1, 'lines': 5}, {'filePath': 'client/src/main/java/org/eclipse/hono/client/impl/TelemetrySenderImpl.java', 'insertions': 4, 'deletions': 1, 'lines': 5}, {'filePath': 'services/messaging/src/main/java/org/eclipse/hono/event/impl/ForwardingEventDownstreamAdapter.java', 'insertions': 12, 'deletions': 2, 'lines': 14}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'EventSenderImpl.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.hono.client.impl.EventSenderImpl.sendMessage(org.apache.qpid.proton.message.Message)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'TelemetrySenderImpl.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.hono.client.impl.TelemetrySenderImpl.sendMessage(org.apache.qpid.proton.message.Message)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ForwardingEventDownstreamAdapter.java', 'spoonMethods': [{'spoonMethodName': 'org.eclipse.hono.event.impl.ForwardingEventDownstreamAdapter.forwardMessage(io.vertx.proton.ProtonSender,org.apache.qpid.proton.message.Message,io.vertx.proton.ProtonDelivery)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/eclipse/hono/issues/454,1.0002777777777778,"['Client', 'bug']",Possible memory leak with `TelemetrySenderImpl`,1.0,"['org.eclipse.hono.event.impl.ForwardingEventDownstreamAdapter.forwardMessage(io.vertx.proton.ProtonSender,org.apache.qpid.proton.message.Message,io.vertx.proton.ProtonDelivery)', 'org.eclipse.hono.client.impl.EventSenderImpl.sendMessage(org.apache.qpid.proton.message.Message)', 'org.eclipse.hono.client.impl.TelemetrySenderImpl.sendMessage(org.apache.qpid.proton.message.Message)']",['1f2d56ed5e33dceec00235a9b0bdc45702004e09'],,"['client/src/main/java/org/eclipse/hono/client/impl', 'services/messaging/src/main/java/org/eclipse/hono/event/impl']",20.0,4.0,24.0,3.0,0.0,3.0,3.0,0.0,3.0,0.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,hono
33081,2017-06-15 20:31:48,zolotov,"A lot of following exceptions we get in JetBrains:

```
Editor of class com.intellij.openapi.editor.impl.EditorImpl hasn't been released:

com.intellij.openapi.util.TraceableDisposable.ObjectNotDisposedException: See stack trace responsible for creation of unreleased object below 
	at com.intellij.openapi.editor.impl.EditorImpl.<init>(EditorImpl.java:156)
	at com.intellij.openapi.editor.impl.EditorFactoryImpl.createEditor(EditorFactoryImpl.java:220)
	at com.intellij.openapi.editor.impl.EditorFactoryImpl.createEditor(EditorFactoryImpl.java:195)
	at mobi.hsz.idea.gitignore.util.Utils.createPreviewEditor(Utils.java:369)
	at mobi.hsz.idea.gitignore.ui.untrackFiles.UntrackFilesDialog.createCenterPanel(UntrackFilesDialog.java:197)
	at com.intellij.openapi.ui.DialogWrapper.init(DialogWrapper.java:1308)
	at mobi.hsz.idea.gitignore.ui.untrackFiles.UntrackFilesDialog.<init>(UntrackFilesDialog.java:139)
	at mobi.hsz.idea.gitignore.TrackedIgnoredFilesComponent$1.hyperlinkUpdate(TrackedIgnoredFilesComponent.java:125)
	at com.intellij.notification.impl.ui.NotificationsUtil$1.hyperlinkUpdate(NotificationsUtil.java:155)
	at javax.swing.JEditorPane.fireHyperlinkUpdate(JEditorPane.java:342)
	at javax.swing.text.html.HTMLEditorKit$LinkController.activateLink(HTMLEditorKit.java:875)
	at javax.swing.text.html.HTMLEditorKit$LinkController.mouseClicked(HTMLEditorKit.java:674)
	at java.awt.AWTEventMulticaster.mouseClicked(AWTEventMulticaster.java:270)
	at java.awt.Component.processMouseEvent(Component.java:6544)
	at javax.swing.JComponent.processMouseEvent(JComponent.java:3324)
	at java.awt.Component.processEvent(Component.java:6306)
	at java.awt.Container.processEvent(Container.java:2237)
	at java.awt.Component.dispatchEventImpl(Component.java:4897)
	at java.awt.Container.dispatchEventImpl(Container.java:2295)
	at java.awt.Component.dispatchEvent(Component.java:4719)
	at java.awt.LightweightDispatcher.retargetMouseEvent(Container.java:4889)
	at java.awt.LightweightDispatcher.processMouseEvent(Container.java:4535)
	at java.awt.LightweightDispatcher.dispatchEvent(Container.java:4467)
	at java.awt.Container.dispatchEventImpl(Container.java:2281)
	at java.awt.Window.dispatchEventImpl(Window.java:2746)
	at java.awt.Component.dispatchEvent(Component.java:4719)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:764)
	at java.awt.EventQueue.access$500(EventQueue.java:98)
	at java.awt.EventQueue$3.run(EventQueue.java:715)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:80)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:90)
	at java.awt.EventQueue$4.run(EventQueue.java:737)
	at java.awt.EventQueue$4.run(EventQueue.java:735)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:80)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:734)
	at com.intellij.ide.IdeEventQueue.defaultDispatchEvent(IdeEventQueue.java:821)
	at com.intellij.ide.IdeEventQueue._dispatchEvent(IdeEventQueue.java:645)
	at com.intellij.ide.IdeEventQueue.dispatchEvent(IdeEventQueue.java:365)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:201)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:105)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:101)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:93)
	at java.awt.EventDispatchThread.run(EventDispatchThread.java:82)

```",2017-07-29 23:14:19,"[{'commitHash': '94b697ca8614222075774e1bf68c6a7d29b44c81', 'commitGHEventType': 'referenced', 'commitUser': 'hsz', 'commitParents': ['c67699a1a8be415cad8ee2d08dca5387ced01eb1'], 'nameRev': '94b697ca8614222075774e1bf68c6a7d29b44c81 tags/v2.0.0~19', 'commitMessage': '#373 Fixed unreleased editor - memory leak\n', 'commitDateTime': '2017-06-19 22:55:08', 'authoredDateTime': '2017-06-19 22:55:08', 'commitGitStats': [{'filePath': 'src/mobi/hsz/idea/gitignore/ui/untrackFiles/UntrackFilesDialog.java', 'insertions': 8, 'deletions': 0, 'lines': 8}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'UntrackFilesDialog.java', 'spoonMethods': [{'spoonMethodName': 'mobi.hsz.idea.gitignore.ui.untrackFiles.UntrackFilesDialog.dispose()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/JetBrains/idea-gitignore/issues/373,44.000277777777775,"['bug', 'ready for release']",Memory leak,1.0,['mobi.hsz.idea.gitignore.ui.untrackFiles.UntrackFilesDialog.dispose()'],['94b697ca8614222075774e1bf68c6a7d29b44c81'],,['src/mobi/hsz/idea/gitignore/ui/untrackFiles'],8.0,0.0,8.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,idea-gitignore
34997,2019-05-17 17:26:38,ericdriggs,"Failing test case here:

https://github.com/ericdriggs/karate-callonce-bug/blob/master/src/test/java/callonce-bug.feature

Expected:
* variables created by previous scenario remain undefined when another scenario starts

Actual
* variables still have previous values when start new scenario

Manually verified the following work correctly: karate.callSingle, callonce for a function variable",2019-06-10 01:43:01,"[{'commitHash': '2c7d58e478767a4a5632df0fb31935c20edd1b37', 'commitGHEventType': 'referenced', 'commitUser': 'ptrthomas', 'commitParents': ['d20356af65be34b1946a5e7d437027934d5ea8c0'], 'nameRev': '2c7d58e478767a4a5632df0fb31935c20edd1b37 tags/v0.9.3~46', 'commitMessage': 'callonce leaks scenario variables #779\n', 'commitDateTime': '2019-05-17 23:34:18', 'authoredDateTime': '2019-05-17 23:34:18', 'commitGitStats': [{'filePath': 'README.md', 'insertions': 4, 'deletions': 2, 'lines': 6}, {'filePath': 'karate-core/src/main/java/com/intuit/karate/Script.java', 'insertions': 4, 'deletions': 2, 'lines': 6}, {'filePath': 'karate-core/src/main/java/com/intuit/karate/ScriptValue.java', 'insertions': 15, 'deletions': 4, 'lines': 19}, {'filePath': 'karate-core/src/main/java/com/intuit/karate/ScriptValueMap.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'karate-core/src/main/java/com/intuit/karate/http/HttpRequestBuilder.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'karate-junit4/src/test/java/com/intuit/karate/junit4/demos/CallonceGlobalRunner.java', 'insertions': 11, 'deletions': 0, 'lines': 11}, {'filePath': 'karate-junit4/src/test/java/com/intuit/karate/junit4/demos/{CallOnceHelper.java => CallonceHelper.java}', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'karate-junit4/src/test/java/com/intuit/karate/junit4/demos/{CallOnceRunner.java => CallonceRunner.java}', 'insertions': 2, 'deletions': 2, 'lines': 4}, {'filePath': 'karate-junit4/src/test/java/com/intuit/karate/junit4/demos/called-noop.feature', 'insertions': 4, 'deletions': 0, 'lines': 4}, {'filePath': 'karate-junit4/src/test/java/com/intuit/karate/junit4/demos/callonce-global.feature', 'insertions': 12, 'deletions': 0, 'lines': 12}, {'filePath': 'karate-junit4/src/test/java/com/intuit/karate/junit4/demos/{call-once.feature => callonce.feature}', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'karate-junit4/src/test/java/com/intuit/karate/junit4/demos/scenario-variable-scope.feature', 'insertions': 3, 'deletions': 1, 'lines': 4}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'Script.java', 'spoonMethods': [{'spoonMethodName': 'com.intuit.karate.Script.callWithCache(java.lang.String,java.lang.String,com.intuit.karate.core.ScenarioContext,boolean)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'com.intuit.karate.Script.assign(com.intuit.karate.AssignType,java.lang.String,java.lang.String,com.intuit.karate.core.ScenarioContext,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ScriptValue.java', 'spoonMethods': [{'spoonMethodName': 'com.intuit.karate.ScriptValue.copy()', 'TOT': 5, 'UPD': 2, 'INS': 0, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'com.intuit.karate.ScriptValue.copy(boolean)', 'TOT': 3, 'UPD': 0, 'INS': 3, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ScriptValueMap.java', 'spoonMethods': [{'spoonMethodName': 'com.intuit.karate.ScriptValueMap.copy(boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'HttpRequestBuilder.java', 'spoonMethods': [{'spoonMethodName': 'com.intuit.karate.http.HttpRequestBuilder.copy()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'CallonceGlobalRunner.java', 'spoonMethods': [{'spoonMethodName': 'com.intuit.karate.junit4.demos.CallonceGlobalRunner', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'CallonceHelper.java', 'spoonMethods': [{'spoonMethodName': 'com.intuit.karate.junit4.demos.CallOnceHelper', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'CallonceRunner.java', 'spoonMethods': [{'spoonMethodName': 'com.intuit.karate.junit4.demos.CallOnceRunner', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '8382e115b7ba45b2fd9d274482c727bce52abcae', 'commitGHEventType': 'referenced', 'commitUser': 'ptrthomas', 'commitParents': ['2c7d58e478767a4a5632df0fb31935c20edd1b37'], 'nameRev': '8382e115b7ba45b2fd9d274482c727bce52abcae tags/v0.9.3~45', 'commitMessage': 'adjusting / more safe for #779\n', 'commitDateTime': '2019-05-18 07:05:03', 'authoredDateTime': '2019-05-18 07:05:03', 'commitGitStats': [{'filePath': 'karate-core/src/main/java/com/intuit/karate/Script.java', 'insertions': 15, 'deletions': 16, 'lines': 31}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'Script.java', 'spoonMethods': [{'spoonMethodName': 'com.intuit.karate.Script.callWithCache(java.lang.String,java.lang.String,com.intuit.karate.core.ScenarioContext,boolean)', 'TOT': 8, 'UPD': 0, 'INS': 2, 'MOV': 4, 'DEL': 2}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '1ec60aa418b5aeeca69f70f4015ae0e0ef47692d', 'commitGHEventType': 'referenced', 'commitUser': 'ptrthomas', 'commitParents': ['b6d10c40d8da9a194c115930e39209ffd455fec8'], 'nameRev': '1ec60aa418b5aeeca69f70f4015ae0e0ef47692d tags/v0.9.3~42', 'commitMessage': 'fixing build because of not thinking through #779\n', 'commitDateTime': '2019-05-18 13:47:52', 'authoredDateTime': '2019-05-18 13:47:52', 'commitGitStats': [{'filePath': 'karate-core/src/main/java/com/intuit/karate/Script.java', 'insertions': 14, 'deletions': 10, 'lines': 24}, {'filePath': 'karate-demo/src/test/java/demo/headers/call-updates-config.feature', 'insertions': 0, 'deletions': 1, 'lines': 1}, {'filePath': 'karate-demo/src/test/java/demo/outline/dynamic-csv.feature', 'insertions': 0, 'deletions': 1, 'lines': 1}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'Script.java', 'spoonMethods': [{'spoonMethodName': 'com.intuit.karate.Script.callWithCache(java.lang.String,java.lang.String,com.intuit.karate.core.ScenarioContext,boolean)', 'TOT': 4, 'UPD': 0, 'INS': 2, 'MOV': 2, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/intuit/karate/issues/779,23.00027777777778,"['bug', 'fixed']",background callonce read causes scenarios to share variables,3.0,"['com.intuit.karate.Script.callWithCache(java.lang.String,java.lang.String,com.intuit.karate.core.ScenarioContext,boolean)', 'com.intuit.karate.ScriptValueMap.copy(boolean)', 'com.intuit.karate.http.HttpRequestBuilder.copy()', 'com.intuit.karate.junit4.demos.CallonceGlobalRunner', 'com.intuit.karate.ScriptValue.copy(boolean)', 'com.intuit.karate.junit4.demos.CallOnceHelper', 'com.intuit.karate.ScriptValue.copy()', 'com.intuit.karate.Script.assign(com.intuit.karate.AssignType,java.lang.String,java.lang.String,com.intuit.karate.core.ScenarioContext,boolean)', 'com.intuit.karate.junit4.demos.CallOnceRunner']","['2c7d58e478767a4a5632df0fb31935c20edd1b37', '8382e115b7ba45b2fd9d274482c727bce52abcae', '1ec60aa418b5aeeca69f70f4015ae0e0ef47692d']",,"['karate-core/src/main/java/com/intuit/karate', 'karate-core/src/main/java/com/intuit/karate/http']",50.0,34.0,84.0,4.0,5.0,9.0,29.0,8.0,12.0,4.0,7.0,0.0,0.0,0.0,0.0,0.0,0.0,karate
35076,2017-09-28 00:49:42,ptrthomas,"This  was just reported.

```
java.lang.OutOfMemoryError: Java heap space
    at java.util.Arrays.copyOf(Arrays.java:3332)
    at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:137)
    at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:121)
    at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:421)
    at java.lang.StringBuilder.append(StringBuilder.java:136)
    at ch.qos.logback.core.pattern.FormattingConverter.write(FormattingConverter.java:39)
    at ch.qos.logback.core.pattern.PatternLayoutBase.writeLoopOnConverters(PatternLayoutBase.java:115)
    at ch.qos.logback.classic.PatternLayout.doLayout(PatternLayout.java:141)
    at ch.qos.logback.classic.PatternLayout.doLayout(PatternLayout.java:39)
    at ch.qos.logback.core.encoder.LayoutWrappingEncoder.encode(LayoutWrappingEncoder.java:115)
    at com.intuit.karate.cucumber.ReporterLogAppender.append(ReporterLogAppender.java:72)
    at com.intuit.karate.cucumber.ReporterLogAppender.append(ReporterLogAppender.java:38)
    at ch.qos.logback.core.AppenderBase.doAppend(AppenderBase.java:82)
    at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:51)
    at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:270)
    at ch.qos.logback.classic.Logger.callAppenders(Logger.java:257)
    at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:421)
    at ch.qos.logback.classic.Logger.filterAndLog_0_Or3Plus(Logger.java:383)
    at ch.qos.logback.classic.Logger.error(Logger.java:534)
    at com.intuit.karate.cucumber.CucumberUtils.afterStep(CucumberUtils.java:152)
    at com.intuit.karate.cucumber.CucumberUtils.runStep(CucumberUtils.java:126)
    at com.intuit.karate.cucumber.CucumberUtils.runStep(CucumberUtils.java:106)
    at com.intuit.karate.cucumber.CucumberUtils.call(CucumberUtils.java:96)
    at com.intuit.karate.cucumber.CucumberUtils.call(CucumberUtils.java:88)
```",2017-10-08 16:49:04,"[{'commitHash': 'ceed9e69cfa046df642aa339430343d071054769', 'commitGHEventType': 'closed', 'commitUser': 'ptrthomas', 'commitParents': ['f800155a1ef29b37ab2fd5d0d413ecbad9fc642d'], 'nameRev': 'ceed9e69cfa046df642aa339430343d071054769 tags/v0.6.1~24', 'commitMessage': 'stop variable state dump which fixes #198\nthis was more trouble for people with complaints that log was getting hard to read even though in parallel runner\nand then finding that it blows up with oom in cases where called features have bloated variable state\nif people really need the variable state dump to show up in the parallel report, they have to set log level to TRACE\n', 'commitDateTime': '2017-09-28 07:51:23', 'authoredDateTime': '2017-09-28 07:51:23', 'commitGitStats': [{'filePath': 'karate-core/src/main/java/com/intuit/karate/cucumber/CucumberUtils.java', 'insertions': 10, 'deletions': 5, 'lines': 15}, {'filePath': 'karate-core/src/main/java/com/intuit/karate/cucumber/KarateStats.java', 'insertions': 3, 'deletions': 0, 'lines': 3}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'CucumberUtils.java', 'spoonMethods': [{'spoonMethodName': 'com.intuit.karate.cucumber.CucumberUtils.afterStep(gherkin.formatter.Reporter,gherkin.formatter.model.Step,gherkin.formatter.model.Match,gherkin.formatter.model.Result,java.lang.Throwable,java.lang.String,com.intuit.karate.cucumber.KarateBackend,boolean)', 'TOT': 14, 'UPD': 6, 'INS': 3, 'MOV': 5, 'DEL': 0}]}, {'spoonFilePath': 'KarateStats.java', 'spoonMethods': [{'spoonMethodName': 'com.intuit.karate.cucumber.KarateStats.printStats(int)', 'TOT': 7, 'UPD': 0, 'INS': 2, 'MOV': 4, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/intuit/karate/issues/198,10.000277777777777,"['bug', 'fixed']",Parallel runner logger - java.lang.OutOfMemoryError: Java heap space,1.0,"['com.intuit.karate.cucumber.KarateStats.printStats(int)', 'com.intuit.karate.cucumber.CucumberUtils.afterStep(gherkin.formatter.Reporter,gherkin.formatter.model.Step,gherkin.formatter.model.Match,gherkin.formatter.model.Result,java.lang.Throwable,java.lang.String,com.intuit.karate.cucumber.KarateBackend,boolean)']",['ceed9e69cfa046df642aa339430343d071054769'],,['karate-core/src/main/java/com/intuit/karate/cucumber'],13.0,5.0,18.0,2.0,6.0,2.0,21.0,9.0,5.0,1.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,karate
36769,2018-02-13 17:55:50,simonbasle,"### Expected behavior
The internal `all` queue should be impacted by TTL eviction.

### Actual behavior
The `all` queue retains references to every single `ExecutorService` created by the scheduler.

### Fix
Remove from both `cache` and `all` during eviction.",2018-02-14 09:21:31,"[{'commitHash': '5625eea66a0eb066f608962acdced4ee933a039d', 'commitGHEventType': 'referenced', 'commitUser': 'simonbasle', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'a6a2630f7a90d064ed13df6b3c37324d87f40ec9', 'commitGHEventType': 'referenced', 'commitUser': 'simonbasle', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '3c891298e172ccaf435b70c871150152a973e9a1', 'commitGHEventType': 'referenced', 'commitUser': 'simonbasle', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '1a34ef34ea035da282fed2abffc3e8ce4468850c', 'commitGHEventType': 'closed', 'commitUser': 'simonbasle', 'commitParents': ['dcc36e52230b5c2b6fab87d4ab7d0fb72d9dff7c'], 'nameRev': '1a34ef34ea035da282fed2abffc3e8ce4468850c tags/v3.1.4.RELEASE~4', 'commitMessage': ""fix #1070 Don't retain ref to executor during ElasticScheduler eviction\n\nThis commit fixes a retaining issue where `all` elastic workers ever\ncreated would be retained by the `all` collection rather than being\nevicted along their cache-expiry wrapper.\n"", 'commitDateTime': '2018-02-14 10:21:29', 'authoredDateTime': '2018-02-13 19:38:42', 'commitGitStats': [{'filePath': 'reactor-core/src/main/java/reactor/core/scheduler/ElasticScheduler.java', 'insertions': 1, 'deletions': 1, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ElasticScheduler.java', 'spoonMethods': [{'spoonMethodName': 'reactor.core.scheduler.ElasticScheduler.eviction()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/reactor/reactor-core/issues/1070,0.0002777777777777778,['type/bug'],ElasticScheduler retains references to evicted executors,1.0,['reactor.core.scheduler.ElasticScheduler.eviction()'],['1a34ef34ea035da282fed2abffc3e8ce4468850c'],,['reactor-core/src/main/java/reactor/core/scheduler'],1.0,1.0,2.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,3.0,0.0,0.0,reactor-core
36817,2017-05-02 13:38:20,fvlad,"When running the following test:
```
@Test
    public void test() throws Exception {
        AtomicLong counter = new AtomicLong(0L);
        Scheduler scheduler = Schedulers.newParallel(""scheduler"", 10);
        Flux
            .<Long>generate(sink -> sink.next(counter.getAndIncrement()))
            .concatMap(i -> {
                return Mono.just(i)
                    .publishOn(scheduler)
                    .map(number -> number * 2L);
            })
            .subscribeOn(Schedulers.newSingle(""subscriber""))
            .subscribe(new BaseSubscriber<Long>() {
                @Override
                protected void hookOnSubscribe(Subscription subscription) {
                    subscription.request(10);
                }

                @Override
                protected void hookOnNext(Long value) {
                    upstream().request(1);
                }
            });

        Thread.sleep(100000000);
    }
```
Memory starts to leak.
Thanks to @dfeist the leak seems to be here `reactor.core.scheduler.SingleScheduler.SingleWorker#tasks` and as a workaround scheduler can be replaced with
`.subscribeOn(Schedulers.fromExecutorService(Executors.newSingleThreadExecutor()))`.",2017-05-04 12:18:24,"[{'commitHash': 'ae54548c922c87574b711d86cec3a754b9e7e859', 'commitGHEventType': 'closed', 'commitUser': 'simonbasle', 'commitParents': ['515b3aae8ae06f484a3d564ca20eb7dcdacb101c'], 'nameRev': 'ae54548c922c87574b711d86cec3a754b9e7e859 tags/v3.1.0.M2~38', 'commitMessage': 'fix #578 Address memory leak in SingleScheduler.schedule\n\n', 'commitDateTime': '2017-05-04 14:18:23', 'authoredDateTime': '2017-05-04 14:18:23', 'commitGitStats': [{'filePath': 'src/main/java/reactor/core/scheduler/SingleScheduler.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'src/test/java/reactor/core/scheduler/SingleSchedulerTest.java', 'insertions': 39, 'deletions': 6, 'lines': 45}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'SingleScheduler.java', 'spoonMethods': [{'spoonMethodName': 'reactor.core.scheduler.SingleScheduler.SingleWorker.schedule(java.lang.Runnable,long,java.util.concurrent.TimeUnit)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'SingleSchedulerTest.java', 'spoonMethods': [{'spoonMethodName': 'reactor.core.scheduler.SingleSchedulerTest.smokeTestDelay()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'reactor.core.scheduler.SingleSchedulerTest.smokeTestInterval()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'reactor.core.scheduler.SingleSchedulerTest.lotsOfTasks()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/reactor/reactor-core/issues/578,1.0002777777777778,['type/bug'],Memory leaks when using concatMap and subscribeOn Schedulers.newSingle,1.0,"['reactor.core.scheduler.SingleScheduler.SingleWorker.schedule(java.lang.Runnable,long,java.util.concurrent.TimeUnit)']",['ae54548c922c87574b711d86cec3a754b9e7e859'],,['src/main/java/reactor/core/scheduler'],1.0,1.0,2.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,reactor-core
37551,2019-01-30 15:09:18,johnou,"### Expected behavior

Memory footprint is more or less consistent.

### Actual behavior

Substantial memory footprint increase after updating from 4.1.30.Final to 4.1.32.Final.

### Steps to reproduce

Working on it..

### Minimal yet complete reproducer code (or URL to code)

Working on it..

### Netty version

4.1.32.Final and 4.1.33.Final show a large memory footprint increase compared to 4.1.30.Final.

### JVM version (e.g. `java -version`)

java version ""1.8.0_172""
Java(TM) SE Runtime Environment (build 1.8.0_172-b11)
Java HotSpot(TM) 64-Bit Server VM (build 25.172-b11, mixed mode)

### OS version (e.g. `uname -a`)

Linux 4.14.77-70.82.amzn1.x86_64 #1 SMP Mon Dec 3 20:01:27 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux",2019-02-02 06:10:02,"[{'commitHash': 'b909447842855363be112a4b561d3df741db1baf', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '7f61055cbdcd8ac1226d3572c2f38667c978f856', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['154d6e87f6befe1d8bbb71cb58a6f844a8d4f051'], 'nameRev': '7f61055cbdcd8ac1226d3572c2f38667c978f856 tags/netty-4.1.34.Final~35', 'commitMessage': 'Reduce direct memory overhead per EpollEventLoop when using EpollDatagramChannel (#8825)\n\nMotivation:\r\n\r\nWhen using a linux distribution that supports sendmmsg(...) we allocated enough direct memory per EpollEventLoop to be able to write IOV_MAX number of iovecs per message that can be written per sendmmsg.\r\nThe number of messages that can be written per sendmmsg(...) call is limited by UIO_MAX_IOV.\r\n\r\nIn practice this resulted in an allocation of 16MB direct memory per EpollEventLoop instance that stayed allocated until the EpollEventLoop was shutdown which happens as part of the shutdown of the enclosing EpollEVentLoopGroup.\r\n\r\nThis resulted in quite some heavy direct memory usage in practice even when in practice we have very slim changes to ever need all of the memory.\r\n\r\nModification:\r\n\r\nAdjust NativeDatagramPacketArray to share one IovArray instance across all NativeDatagramPacket instances it holds. This limits the max number of iovecs we can write across all messages to IOV_MAX per sendmmsg(...) call.\r\nThis in practice will still be enough to allow us to write multiple messages with one syscall while keep the memory overhead to a minimum.\r\n\r\nResult:\r\n\r\nSmaller direct memory footprint per EpollEventLoop when using EpollDatagramChannel on distributions that support sendmmsg(...).\r\nFixes https://github.com/netty/netty/issues/8814', 'commitDateTime': '2019-02-02 07:10:02', 'authoredDateTime': '2019-02-02 07:10:02', 'commitGitStats': [{'filePath': 'transport-native-epoll/src/main/java/io/netty/channel/epoll/NativeDatagramPacketArray.java', 'insertions': 16, 'deletions': 25, 'lines': 41}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'NativeDatagramPacketArray.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.release()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.NativeDatagramPacket.release()', 'TOT': 4, 'UPD': 2, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.NativeDatagramPacket.init(io.netty.buffer.ByteBuf,java.net.InetSocketAddress)', 'TOT': 11, 'UPD': 3, 'INS': 0, 'MOV': 1, 'DEL': 7}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.add(io.netty.channel.socket.DatagramPacket)', 'TOT': 9, 'UPD': 1, 'INS': 3, 'MOV': 4, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.clear()', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.NativeDatagramPacket', 'TOT': 10, 'UPD': 0, 'INS': 1, 'MOV': 8, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.NativeDatagramPacket.init(long,int,java.net.InetSocketAddress)', 'TOT': 5, 'UPD': 0, 'INS': 5, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'd96c02fc68c1f785452eae9417940f5085ef0e95', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['3ac9363ef9e835fc5adb41bcc084d80c64be208a'], 'nameRev': 'd96c02fc68c1f785452eae9417940f5085ef0e95 remotes/origin/drop-npn~2', 'commitMessage': 'Reduce direct memory overhead per EpollEventLoop when using EpollDatagramChannel (#8825)\n\nMotivation:\n\nWhen using a linux distribution that supports sendmmsg(...) we allocated enough direct memory per EpollEventLoop to be able to write IOV_MAX number of iovecs per message that can be written per sendmmsg.\nThe number of messages that can be written per sendmmsg(...) call is limited by UIO_MAX_IOV.\n\nIn practice this resulted in an allocation of 16MB direct memory per EpollEventLoop instance that stayed allocated until the EpollEventLoop was shutdown which happens as part of the shutdown of the enclosing EpollEVentLoopGroup.\n\nThis resulted in quite some heavy direct memory usage in practice even when in practice we have very slim changes to ever need all of the memory.\n\nModification:\n\nAdjust NativeDatagramPacketArray to share one IovArray instance across all NativeDatagramPacket instances it holds. This limits the max number of iovecs we can write across all messages to IOV_MAX per sendmmsg(...) call.\nThis in practice will still be enough to allow us to write multiple messages with one syscall while keep the memory overhead to a minimum.\n\nResult:\n\nSmaller direct memory footprint per EpollEventLoop when using EpollDatagramChannel on distributions that support sendmmsg(...).\nFixes https://github.com/netty/netty/issues/8814\n', 'commitDateTime': '2019-02-02 07:14:53', 'authoredDateTime': '2019-02-02 07:10:02', 'commitGitStats': [{'filePath': 'transport-native-epoll/src/main/java/io/netty/channel/epoll/NativeDatagramPacketArray.java', 'insertions': 16, 'deletions': 25, 'lines': 41}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'NativeDatagramPacketArray.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.release()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.NativeDatagramPacket.release()', 'TOT': 4, 'UPD': 2, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.NativeDatagramPacket.init(io.netty.buffer.ByteBuf,java.net.InetSocketAddress)', 'TOT': 11, 'UPD': 3, 'INS': 0, 'MOV': 1, 'DEL': 7}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.add(io.netty.channel.socket.DatagramPacket)', 'TOT': 9, 'UPD': 1, 'INS': 3, 'MOV': 4, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.clear()', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.NativeDatagramPacket', 'TOT': 10, 'UPD': 0, 'INS': 1, 'MOV': 8, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.epoll.NativeDatagramPacketArray.NativeDatagramPacket.init(long,int,java.net.InetSocketAddress)', 'TOT': 5, 'UPD': 0, 'INS': 5, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/8814,2.000277777777778,"['defect', 'improvement']",Memory footprint increase after upgrading to 4.1.32.Final,1.0,"['io.netty.channel.epoll.NativeDatagramPacketArray.add(io.netty.channel.socket.DatagramPacket)', 'io.netty.channel.epoll.NativeDatagramPacketArray.clear()', 'io.netty.channel.epoll.NativeDatagramPacketArray.NativeDatagramPacket.release()', 'io.netty.channel.epoll.NativeDatagramPacketArray.NativeDatagramPacket', 'io.netty.channel.epoll.NativeDatagramPacketArray.NativeDatagramPacket.init(long,int,java.net.InetSocketAddress)', 'io.netty.channel.epoll.NativeDatagramPacketArray', 'io.netty.channel.epoll.NativeDatagramPacketArray.NativeDatagramPacket.init(io.netty.buffer.ByteBuf,java.net.InetSocketAddress)', 'io.netty.channel.epoll.NativeDatagramPacketArray.release()']",['7f61055cbdcd8ac1226d3572c2f38667c978f856'],,['transport-native-epoll/src/main/java/io/netty/channel/epoll'],16.0,25.0,41.0,1.0,7.0,8.0,43.0,15.0,10.0,11.0,1.0,0.0,0.0,0.0,2.0,0.0,0.0,netty
37615,2018-01-23 00:07:55,bryce-anderson,"### Expected behavior

The payload of a PingFrame would be released or passed somewhere into the application for consumption.

### Actual behavior

It appears that `Http2PingFrame`s are dropped on the floor in the [`Http2MultiplexCodec.onHttp2Frame`](https://github.com/netty/netty/blob/4.1/codec-http2/src/main/java/io/netty/handler/codec/http2/Http2MultiplexCodec.java#L219) method.

### Steps to reproduce

Start HTTP/2 server and send it ping frames with advanced leak detection yields logs as follows:
```
2018-01-22 22:46:25,178 ERR i.n.u.ResourceLeakDetector |  LEAK: ByteBuf.release() was not called before it's garbage-collected. See http://netty.io/wiki/reference-counted-objects.html for more information.
Recent access records: 16
#16:
	io.netty.util.ReferenceCountUtil.release(ReferenceCountUtil.java:84)
	io.netty.util.ReferenceCountUtil.safeRelease(ReferenceCountUtil.java:109)
	io.netty.channel.ChannelOutboundBuffer.remove(ChannelOutboundBuffer.java:256)
	io.netty.channel.ChannelOutboundBuffer.removeBytes(ChannelOutboundBuffer.java:337)
	io.netty.channel.epoll.AbstractEpollStreamChannel.writeBytesMultiple(AbstractEpollStreamChannel.java:302)
	io.netty.channel.epoll.AbstractEpollStreamChannel.doWriteMultiple(AbstractEpollStreamChannel.java:505)
	io.netty.channel.epoll.AbstractEpollStreamChannel.doWrite(AbstractEpollStreamChannel.java:442)
	io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:934)
	io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.flush0(AbstractEpollChannel.java:543)
	io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:901)
	io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1321)
	io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776)
	io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768)
	io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749)
	io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:117)
	io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776)
	io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768)
	io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749)
	io.netty.handler.codec.http2.Http2ConnectionHandler.flush(Http2ConnectionHandler.java:201)
	io.netty.handler.codec.http2.Http2MultiplexCodec.flush(Http2MultiplexCodec.java:373)
	io.netty.handler.codec.http2.Http2MultiplexCodec.flush0(Http2MultiplexCodec.java:378)
	io.netty.handler.codec.http2.Http2MultiplexCodec.onChannelReadComplete(Http2MultiplexCodec.java:366)
	io.netty.handler.codec.http2.Http2MultiplexCodec.channelReadComplete(Http2MultiplexCodec.java:340)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelReadComplete(AbstractChannelHandlerContext.java:398)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelReadComplete(AbstractChannelHandlerContext.java:380)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelReadComplete(AbstractChannelHandlerContext.java:373)
	io.netty.channel.ChannelInboundHandlerAdapter.channelReadComplete(ChannelInboundHandlerAdapter.java:97)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelReadComplete(AbstractChannelHandlerContext.java:398)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelReadComplete(AbstractChannelHandlerContext.java:380)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelReadComplete(AbstractChannelHandlerContext.java:373)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelReadComplete(DefaultChannelPipeline.java:1364)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelReadComplete(AbstractChannelHandlerContext.java:398)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelReadComplete(AbstractChannelHandlerContext.java:380)
	io.netty.channel.DefaultChannelPipeline.fireChannelReadComplete(DefaultChannelPipeline.java:941)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:817)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#15:
	io.netty.buffer.AdvancedLeakAwareByteBuf.nioBufferCount(AdvancedLeakAwareByteBuf.java:702)
	io.netty.channel.unix.IovArray.add(IovArray.java:79)
	io.netty.channel.unix.IovArray.processMessage(IovArray.java:209)
	io.netty.channel.ChannelOutboundBuffer.forEachFlushedMessage(ChannelOutboundBuffer.java:738)
	io.netty.channel.epoll.AbstractEpollStreamChannel.doWriteMultiple(AbstractEpollStreamChannel.java:500)
	io.netty.channel.epoll.AbstractEpollStreamChannel.doWrite(AbstractEpollStreamChannel.java:442)
	io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:934)
	io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.flush0(AbstractEpollChannel.java:543)
	io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:901)
	io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1321)
	io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776)
	io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768)
	io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749)
	io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:117)
	io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776)
	io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768)
	io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749)
	io.netty.handler.codec.http2.Http2ConnectionHandler.flush(Http2ConnectionHandler.java:201)
	io.netty.handler.codec.http2.Http2MultiplexCodec.flush(Http2MultiplexCodec.java:373)
	io.netty.handler.codec.http2.Http2MultiplexCodec.flush0(Http2MultiplexCodec.java:378)
	io.netty.handler.codec.http2.Http2MultiplexCodec.onChannelReadComplete(Http2MultiplexCodec.java:366)
	io.netty.handler.codec.http2.Http2MultiplexCodec.channelReadComplete(Http2MultiplexCodec.java:340)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelReadComplete(AbstractChannelHandlerContext.java:398)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelReadComplete(AbstractChannelHandlerContext.java:380)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelReadComplete(AbstractChannelHandlerContext.java:373)
	io.netty.channel.ChannelInboundHandlerAdapter.channelReadComplete(ChannelInboundHandlerAdapter.java:97)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelReadComplete(AbstractChannelHandlerContext.java:398)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelReadComplete(AbstractChannelHandlerContext.java:380)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelReadComplete(AbstractChannelHandlerContext.java:373)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelReadComplete(DefaultChannelPipeline.java:1364)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelReadComplete(AbstractChannelHandlerContext.java:398)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelReadComplete(AbstractChannelHandlerContext.java:380)
	io.netty.channel.DefaultChannelPipeline.fireChannelReadComplete(DefaultChannelPipeline.java:941)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:817)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#14:
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:273)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelRead(ChannelStatsHandler.scala:108)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#13:
	io.netty.buffer.DefaultByteBufHolder.retain(DefaultByteBufHolder.java:93)
	io.netty.handler.codec.http2.DefaultHttp2PingFrame.retain(DefaultHttp2PingFrame.java:76)
	io.netty.handler.codec.http2.Http2FrameCodec$FrameListener.onPingRead(Http2FrameCodec.java:488)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.onPingRead(DefaultHttp2ConnectionDecoder.java:432)
	io.netty.handler.codec.http2.Http2InboundFrameLogger$1.onPingRead(Http2InboundFrameLogger.java:99)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readPingFrame(DefaultHttp2FrameReader.java:583)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.processPayloadState(DefaultHttp2FrameReader.java:269)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:160)
	io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:118)
	io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:383)
	io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:443)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelRead(ChannelStatsHandler.scala:108)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#12:
	Hint: 'DefaultChannelPipeline$HeadContext#0' will handle the message from this point.
	io.netty.channel.DefaultChannelPipeline.touch(DefaultChannelPipeline.java:116)
	io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:810)
	io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:723)
	io.netty.channel.ChannelDuplexHandler.write(ChannelDuplexHandler.java:106)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.write(ChannelStatsHandler.scala:96)
	io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:816)
	io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:723)
	io.netty.handler.codec.http2.DefaultHttp2FrameWriter.writePing(DefaultHttp2FrameWriter.java:281)
	io.netty.handler.codec.http2.Http2OutboundFrameLogger.writePing(Http2OutboundFrameLogger.java:99)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionEncoder.writePing(DefaultHttp2ConnectionEncoder.java:269)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.onPingRead(DefaultHttp2ConnectionDecoder.java:430)
	io.netty.handler.codec.http2.Http2InboundFrameLogger$1.onPingRead(Http2InboundFrameLogger.java:99)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readPingFrame(DefaultHttp2FrameReader.java:583)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.processPayloadState(DefaultHttp2FrameReader.java:269)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:160)
	io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:118)
	io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:383)
	io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:443)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelRead(ChannelStatsHandler.scala:108)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#11:
	Hint: 'channelStats' will handle the message from this point.
	io.netty.channel.DefaultChannelPipeline.touch(DefaultChannelPipeline.java:116)
	io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:810)
	io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:723)
	io.netty.handler.codec.http2.DefaultHttp2FrameWriter.writePing(DefaultHttp2FrameWriter.java:281)
	io.netty.handler.codec.http2.Http2OutboundFrameLogger.writePing(Http2OutboundFrameLogger.java:99)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionEncoder.writePing(DefaultHttp2ConnectionEncoder.java:269)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.onPingRead(DefaultHttp2ConnectionDecoder.java:430)
	io.netty.handler.codec.http2.Http2InboundFrameLogger$1.onPingRead(Http2InboundFrameLogger.java:99)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readPingFrame(DefaultHttp2FrameReader.java:583)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.processPayloadState(DefaultHttp2FrameReader.java:269)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:160)
	io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:118)
	io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:383)
	io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:443)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelRead(ChannelStatsHandler.scala:108)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#10:
	io.netty.buffer.AdvancedLeakAwareByteBuf.retainedSlice(AdvancedLeakAwareByteBuf.java:84)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.onPingRead(DefaultHttp2ConnectionDecoder.java:430)
	io.netty.handler.codec.http2.Http2InboundFrameLogger$1.onPingRead(Http2InboundFrameLogger.java:99)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readPingFrame(DefaultHttp2FrameReader.java:583)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.processPayloadState(DefaultHttp2FrameReader.java:269)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:160)
	io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:118)
	io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:383)
	io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:443)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelRead(ChannelStatsHandler.scala:108)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#9:
	io.netty.buffer.AdvancedLeakAwareByteBuf.readSlice(AdvancedLeakAwareByteBuf.java:114)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readPingFrame(DefaultHttp2FrameReader.java:579)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.processPayloadState(DefaultHttp2FrameReader.java:269)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:160)
	io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:118)
	io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:383)
	io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:443)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelRead(ChannelStatsHandler.scala:108)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#8:
	io.netty.buffer.AdvancedLeakAwareByteBuf.readSlice(AdvancedLeakAwareByteBuf.java:114)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.processPayloadState(DefaultHttp2FrameReader.java:243)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:160)
	io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:118)
	io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:383)
	io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:443)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelRead(ChannelStatsHandler.scala:108)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#7:
	io.netty.buffer.AdvancedLeakAwareByteBuf.readInt(AdvancedLeakAwareByteBuf.java:432)
	io.netty.handler.codec.http2.Http2CodecUtil.readUnsignedInt(Http2CodecUtil.java:210)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.processHeaderState(DefaultHttp2FrameReader.java:192)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:148)
	io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:118)
	io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:383)
	io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:443)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelRead(ChannelStatsHandler.scala:108)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#6:
	io.netty.buffer.AdvancedLeakAwareByteBuf.readUnsignedByte(AdvancedLeakAwareByteBuf.java:402)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.processHeaderState(DefaultHttp2FrameReader.java:191)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:148)
	io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:118)
	io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:383)
	io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:443)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelRead(ChannelStatsHandler.scala:108)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#5:
	io.netty.buffer.AdvancedLeakAwareByteBuf.readByte(AdvancedLeakAwareByteBuf.java:396)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.processHeaderState(DefaultHttp2FrameReader.java:190)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:148)
	io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:118)
	io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:383)
	io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:443)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelRead(ChannelStatsHandler.scala:108)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#4:
	io.netty.buffer.AdvancedLeakAwareByteBuf.readUnsignedMedium(AdvancedLeakAwareByteBuf.java:426)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.processHeaderState(DefaultHttp2FrameReader.java:185)
	io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:148)
	io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
	io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:118)
	io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:383)
	io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:443)
	io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)
	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelRead(ChannelStatsHandler.scala:108)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#3:
	Hint: 'UpgradeMultiplexCodecBuilder$$anon$1#0' will handle the message from this point.
	io.netty.channel.DefaultChannelPipeline.touch(DefaultChannelPipeline.java:116)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelRead(ChannelStatsHandler.scala:108)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#2:
	Hint: 'channelStats' will handle the message from this point.
	io.netty.channel.DefaultChannelPipeline.touch(DefaultChannelPipeline.java:116)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
#1:
	Hint: 'DefaultChannelPipeline$HeadContext#0' will handle the message from this point.
	io.netty.channel.DefaultChannelPipeline.touch(DefaultChannelPipeline.java:116)
	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:797)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
Created at:
	io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:331)
	io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:181)
	io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:172)
	io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:133)
	io.netty.channel.DefaultMaxMessagesRecvByteBufAllocator$MaxMessageHandle.allocate(DefaultMaxMessagesRecvByteBufAllocator.java:80)
	io.netty.channel.epoll.EpollRecvByteAllocatorHandle.allocate(EpollRecvByteAllocatorHandle.java:71)
	io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:786)
	io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23)
	java.lang.Thread.run(Thread.java:748)
```

### Netty version
4.1.16, though a scan of the GitHub repo suggests it's still an issue.

### JVM version (e.g. `java -version`)
openjdk version ""1.8.0_152""

### OS version (e.g. `uname -a`)
Centos 7
",2018-01-25 21:26:46,"[{'commitHash': '8a095d0244da237f6eb76c4c24be49a1833b3988', 'commitGHEventType': 'referenced', 'commitUser': 'Scottmitch', 'commitParents': ['f0c76cacc3f6eb3a7df3fdc06059d5ddaac3c442'], 'nameRev': '8a095d0244da237f6eb76c4c24be49a1833b3988 tags/netty-4.1.21.Final~36', 'commitMessage': 'Http2MultiplexCodec should propagate unhandled Http2Frames down the pipeline\n\nMotivation:\r\n\r\nHttp2MultiplexCodec swallows Http2PingFrames without releasing the payload, resulting in a memory leak.\r\n\r\nModification:\r\n\r\nSend unhandled frames down the pipeline for consumption/disposal by another InboundChannelHandler.\r\n\r\nResult:\r\n\r\nFixes #7607.', 'commitDateTime': '2018-01-25 13:26:45', 'authoredDateTime': '2018-01-25 14:26:45', 'commitGitStats': [{'filePath': 'codec-http2/src/main/java/io/netty/handler/codec/http2/Http2MultiplexCodec.java', 'insertions': 3, 'deletions': 0, 'lines': 3}, {'filePath': 'codec-http2/src/test/java/io/netty/handler/codec/http2/Http2MultiplexCodecTest.java', 'insertions': 11, 'deletions': 0, 'lines': 11}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'Http2MultiplexCodec.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http2.Http2MultiplexCodec.onHttp2Frame(io.netty.channel.ChannelHandlerContext,io.netty.handler.codec.http2.Http2Frame)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'Http2MultiplexCodecTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http2.Http2MultiplexCodecTest.unhandledHttp2FramesShouldBePropagated()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/7607,2.000277777777778,['defect'],Http2MultiplexCodec leaks ping payloads,1.0,"['io.netty.handler.codec.http2.Http2MultiplexCodec.onHttp2Frame(io.netty.channel.ChannelHandlerContext,io.netty.handler.codec.http2.Http2Frame)']",['8a095d0244da237f6eb76c4c24be49a1833b3988'],,['codec-http2/src/main/java/io/netty/handler/codec/http2'],3.0,0.0,3.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,netty
37626,2017-11-18 22:03:49,pkolaczk,"### Expected behavior
Writing `DefaultLastContent` object with trailing headers sends an empty chunk with trailing headers.

### Actual behavior
Writing `DefaultLastContent` with trailing headers causes EncoderException:
```
io.netty.handler.codec.EncoderException: HttpServerCodec$HttpServerResponseEncoder must produce at least one message.
        at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:98) ~[netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.channel.CombinedChannelDuplexHandler.write(CombinedChannelDuplexHandler.java:348) ~[netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:732) ~[netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:724) ~[netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:809) ~[netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:717) ~[netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.handler.logging.LoggingHandler.write(LoggingHandler.java:254) ~[netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:732) ~[netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:795) ~[netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:807) ~[netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:788) ~[netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:824) ~[netty-all-4.0.52.Final.jar:4.0.52.Final]
        at com.datastax.bdp.fs.rest.util.NettyHttpUtil$.writeAndFlush(NettyHttpUtil.scala:77) ~[dse-dsefs-common-5.0.12-cbbffcf.jar:5.0.12-cbbffcf]
        at com.datastax.bdp.fs.rest.server.RestServerHandler$$anonfun$sendResponseBody$2.apply(RestServerHandler.scala:163) [dse-dsefs-common-5.0.12-cbbffcf.jar:5.0.12-cbbffcf]
        at com.datastax.bdp.fs.rest.server.RestServerHandler$$anonfun$sendResponseBody$2.apply(RestServerHandler.scala:143) [dse-dsefs-common-5.0.12-cbbffcf.jar:5.0.12-cbbffcf]
        at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [scala-library-2.10.6.jar:na]
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:399) [netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:464) [netty-all-4.0.52.Final.jar:4.0.52.Final]
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131) [netty-all-4.0.52.Final.jar:4.0.52.Final]
        at java.lang.Thread.run(Thread.java:748) [na:1.8.0_144]

```
Writing `DefaultLastContent` with no trailing headers in the same place of code, works as expected - sends an empty last chunk and no exception is thrown.

### Steps to reproduce
1. Setup a simple HttpServer using HttpServerCodec (without HttpMessageAggregator)
2. When sending a response, enable chunked transfer encoding.
3. writeAndFlush a DefaultLastContent object with trailers:
```
   val lastContent = new DefaultLastHttpContent()
   lastContent.trailingHeaders().add(...., ....)
   context.writeAndFlush(lastContent)
```

### Minimal yet complete reproducer code (or URL to code)

### Netty version
We found the problem after upgrading to 4.0.52.Final
Error was not present in 4.0.34.Final.

### JVM version (e.g. `java -version`)
java version ""1.8.0_144""
Java(TM) SE Runtime Environment (build 1.8.0_144-b01)
Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)

### OS version (e.g. `uname -a`)
Linux p5520 4.14.0-041400rc8-generic #201711052313 SMP Sun Nov 5 23:14:08 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
",2017-11-21 06:48:16,"[{'commitHash': '7530473107d671472100dc2f6a9dc1fbcedc315b', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'a8951ec6045498027b689becdec01f901fe5532d', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'e5e4c18c1be1d32c5bcb9e6aa0ee300e9c89c18d', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['a3e41ba6eb118dde7657af9a95d6ce34424f76da'], 'nameRev': 'e5e4c18c1be1d32c5bcb9e6aa0ee300e9c89c18d tags/netty-4.1.18.Final~32', 'commitMessage': 'Add testcase for writing empty last content with headers.\n\nMotivation:\n\nhttps://github.com/netty/netty/issues/7418 reported an issue with writing a LastHttpContent with trailers set.\n\nModifications:\n\nAdd unit test to ensure this issue is fixed in latest netty release.\n\nResult:\n\nEnsure code is correct.\n', 'commitDateTime': '2017-11-21 07:45:58', 'authoredDateTime': '2017-11-19 09:19:07', 'commitGitStats': [{'filePath': 'codec-http/src/test/java/io/netty/handler/codec/http/HttpRequestEncoderTest.java', 'insertions': 20, 'deletions': 6, 'lines': 26}, {'filePath': 'codec-http/src/test/java/io/netty/handler/codec/http/HttpResponseEncoderTest.java', 'insertions': 51, 'deletions': 0, 'lines': 51}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'HttpRequestEncoderTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.HttpRequestEncoderTest.testEmptyContentChunked()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpRequestEncoderTest.testEmptyContentNotChunked()', 'TOT': 3, 'UPD': 2, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpRequestEncoderTest.testEmptyContent(boolean)', 'TOT': 2, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpRequestEncoderTest.testEmptyContentsChunkedWithTrailers()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpRequestEncoderTest.testEmptyContentNotsChunkedWithTrailers()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpRequestEncoderTest.testEmptyContents(boolean,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'HttpResponseEncoderTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.HttpResponseEncoderTest.testEmptyContentsChunked()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpResponseEncoderTest.testEmptyContentsChunkedWithTrailers()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpResponseEncoderTest.testEmptyContentsNotChunked()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpResponseEncoderTest.testEmptyContentNotsChunkedWithTrailers()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpResponseEncoderTest.testEmptyContents(boolean,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '8009c4c8a0514dc63b2cc6c437f9a8ebc2176579', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['5ca273814ffde676083751352f9c957a912387b9'], 'nameRev': '8009c4c8a0514dc63b2cc6c437f9a8ebc2176579 tags/netty-4.0.54.Final~16', 'commitMessage': 'Fix writing of empty LastHttpContent with trailers\n\nMotivation:\n\n4732fabb1664acae0a545b6496066acb8d39ecb7 introduced a regression in HttpObjectEncoder which will lead to buffer leak and IllegalStateException when a LastHttpContent with trailers is written.\n\nModifications:\n\n- Correctly add the buffer to the encoded list.\n- Add testcases\n\nResult:\n\nFixes [#7418]\n', 'commitDateTime': '2017-11-21 07:47:16', 'authoredDateTime': '2017-11-19 09:19:07', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/HttpObjectEncoder.java', 'insertions': 1, 'deletions': 0, 'lines': 1}, {'filePath': 'codec-http/src/test/java/io/netty/handler/codec/http/HttpRequestEncoderTest.java', 'insertions': 20, 'deletions': 6, 'lines': 26}, {'filePath': 'codec-http/src/test/java/io/netty/handler/codec/http/HttpResponseEncoderTest.java', 'insertions': 51, 'deletions': 0, 'lines': 51}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'HttpObjectEncoder.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.HttpObjectEncoder.encodeChunkedContent(io.netty.channel.ChannelHandlerContext,java.lang.Object,long,java.util.List)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'HttpRequestEncoderTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.HttpRequestEncoderTest.testEmptyContentChunked()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpRequestEncoderTest.testEmptyContentNotChunked()', 'TOT': 3, 'UPD': 2, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpRequestEncoderTest.testEmptyContent(boolean)', 'TOT': 2, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpRequestEncoderTest.testEmptyContentsChunkedWithTrailers()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpRequestEncoderTest.testEmptyContentNotsChunkedWithTrailers()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpRequestEncoderTest.testEmptyContents(boolean,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'HttpResponseEncoderTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.HttpResponseEncoderTest.testEmptyContentsChunked()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpResponseEncoderTest.testEmptyContentsChunkedWithTrailers()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpResponseEncoderTest.testEmptyContentsNotChunked()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpResponseEncoderTest.testEmptyContentNotsChunkedWithTrailers()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpResponseEncoderTest.testEmptyContents(boolean,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/7418,2.000277777777778,['defect'],"Sending DefaultLastContent with trailers causes ""io.netty.handler.codec.EncoderException: HttpServerCodec$HttpServerResponseEncoder must produce at least one message.""",1.0,"['io.netty.handler.codec.http.HttpObjectEncoder.encodeChunkedContent(io.netty.channel.ChannelHandlerContext,java.lang.Object,long,java.util.List)']","['e5e4c18c1be1d32c5bcb9e6aa0ee300e9c89c18d', '8009c4c8a0514dc63b2cc6c437f9a8ebc2176579']",,['codec-http/src/main/java/io/netty/handler/codec/http'],1.0,0.0,1.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,2.0,0.0,0.0,netty
37629,2017-11-08 03:52:57,Scottmitch,"AbstractChannel attempts to ""filter"" messages which are written [1]. A goal of this process is to copy from heap to direct if necessary. However implementations of this method [2][3] may translate a buffer with 0 readable bytes to EMPTY_BUFFER. This may mask a user error where an empty buffer is written but already released.

[1] https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/AbstractChannel.java#L877
[2] https://github.com/netty/netty/blob/4.1/transport-native-kqueue/src/main/java/io/netty/channel/kqueue/AbstractKQueueChannel.java#L252
[3] https://github.com/netty/netty/blob/4.1/transport-native-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollChannel.java#L306",2017-12-04 19:40:12,"[{'commitHash': '1ac94454240d204fc23fb2fc254f7e80bfbe25fb', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '251bb1a73961f785ad12dbb3ae92830eca70b8cd', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['95b02e49ac914972ac27c35bcb3272f8ca3956a4'], 'nameRev': '251bb1a73961f785ad12dbb3ae92830eca70b8cd tags/netty-4.1.18.Final~10', 'commitMessage': 'Not use safeRelease(...) but release(...) to release non-readable holders to ensure we not mask errors.\n\nMotivation:\n\nAbstractChannel attempts to ""filter"" messages which are written [1]. A goal of this process is to copy from heap to direct if necessary. However implementations of this method [2][3] may translate a buffer with 0 readable bytes to EMPTY_BUFFER. This may mask a user error where an empty buffer is written but already released.\n\nModifications:\n\nReplace safeRelease(...) with release(...) to ensure we propagate reference count issues.\n\nResult:\n\nFixes [#7383]\n', 'commitDateTime': '2017-12-04 20:38:35', 'authoredDateTime': '2017-11-25 21:10:29', 'commitGitStats': [{'filePath': 'transport-native-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollChannel.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'transport-native-kqueue/src/main/java/io/netty/channel/kqueue/AbstractKQueueChannel.java', 'insertions': 1, 'deletions': 1, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AbstractEpollChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollChannel.newDirectBuffer(java.lang.Object,io.netty.buffer.ByteBuf)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'AbstractKQueueChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.kqueue.AbstractKQueueChannel.newDirectBuffer(java.lang.Object,io.netty.buffer.ByteBuf)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'ea8ff3b4f6a629a8f36f16bae97ee8ec3029991d', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['6583b5271c4898db2fc7240e7702e4b9cec23783'], 'nameRev': 'ea8ff3b4f6a629a8f36f16bae97ee8ec3029991d tags/netty-4.0.54.Final~7', 'commitMessage': 'Not use safeRelease(...) but release(...) to release non-readable holders to ensure we not mask errors.\n\nMotivation:\n\nAbstractChannel attempts to ""filter"" messages which are written [1]. A goal of this process is to copy from heap to direct if necessary. However implementations of this method [2][3] may translate a buffer with 0 readable bytes to EMPTY_BUFFER. This may mask a user error where an empty buffer is written but already released.\n\nModifications:\n\nReplace safeRelease(...) with release(...) to ensure we propagate reference count issues.\n\nResult:\n\nFixes [#7383]\n', 'commitDateTime': '2017-12-04 20:39:19', 'authoredDateTime': '2017-11-25 21:10:29', 'commitGitStats': [{'filePath': 'transport-native-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollChannel.java', 'insertions': 1, 'deletions': 1, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AbstractEpollChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollChannel.newDirectBuffer(java.lang.Object,io.netty.buffer.ByteBuf)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/7383,26.00027777777778,['defect'],AbstractChannel#filterOutboundMessage may mask writing a released empty buffer,1.0,"['io.netty.channel.kqueue.AbstractKQueueChannel.newDirectBuffer(java.lang.Object,io.netty.buffer.ByteBuf)', 'io.netty.channel.epoll.AbstractEpollChannel.newDirectBuffer(java.lang.Object,io.netty.buffer.ByteBuf)']",['251bb1a73961f785ad12dbb3ae92830eca70b8cd'],,"['transport-native-epoll/src/main/java/io/netty/channel/epoll', 'transport-native-kqueue/src/main/java/io/netty/channel/kqueue']",2.0,2.0,4.0,2.0,2.0,2.0,2.0,0.0,0.0,0.0,2.0,0.0,0.0,0.0,2.0,0.0,0.0,netty
37635,2017-10-24 12:04:30,Anon43590,"Excuse me if I'm missing something obvious, but it seems to me that in SslHandler.java, ""buf"" removed from ""pendingUnencryptedWrites"" on line 751 may leak if ""wrap(alloc, engine, buf, out)"" called on line 762 throws. The wrap function on line 912 is marked as ""throws SSLException"", which I assume is something that could possibly happen and not be a fatal error for the entire server. So it seems like the aforementioned buffer had ought to be released if such an exception occurs, perhaps in the finally block on line 803.

I only noticed this randomly while helping a coworker to track down an unrelated issue, so it's not like I've actually seen this leak happen.",2017-10-24 13:12:34,"[{'commitHash': 'd8802b90c3019ae7425efb02efaf7d2d2b24a808', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '56eb62c52babf1924464c2ef4b243611c0fb2691', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '92b786e2f33a44f16be224305fe4fb716422b14a', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['dcbbae7f9006f5b995d055702dd1c9f55f0e0c9d'], 'nameRev': '92b786e2f33a44f16be224305fe4fb716422b14a tags/netty-4.1.17.Final~25', 'commitMessage': 'Fix possible leak in SslHandler if wrap(...) throws.\n\nMotivation:\n\nWe can end up with a buffer leak if SSLEngine.wrap(...) throws.\n\nModifications:\n\nCorrectly release the ByteBuf if SSLEngine.wrap(...) throws.\n\nResult:\n\nFixes [#7337].\n', 'commitDateTime': '2017-10-24 18:52:20', 'authoredDateTime': '2017-10-24 14:19:32', 'commitGitStats': [{'filePath': 'handler/src/main/java/io/netty/handler/ssl/SslHandler.java', 'insertions': 8, 'deletions': 1, 'lines': 9}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'SslHandler.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.SslHandler.wrap(io.netty.channel.ChannelHandlerContext,boolean)', 'TOT': 7, 'UPD': 0, 'INS': 5, 'MOV': 1, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/7337,0.0002777777777777778,['defect'],Possible buffer leak in SslHandler?,1.0,"['io.netty.handler.ssl.SslHandler.wrap(io.netty.channel.ChannelHandlerContext,boolean)']",['92b786e2f33a44f16be224305fe4fb716422b14a'],,['handler/src/main/java/io/netty/handler/ssl'],8.0,1.0,9.0,1.0,0.0,1.0,7.0,1.0,5.0,1.0,1.0,0.0,0.0,0.0,2.0,0.0,0.0,netty
37638,2017-10-10 04:13:01,juebanlin,"### Expected behavior

### Actual behavior

### Steps to reproduce
`package net.jueb.redAlert.script.game.serverScript.sys;

import io.netty.buffer.ByteBufAllocator;
import net.jueb.redAlert.core.base.message.AppByteMessage;
import net.jueb.redAlert.core.base.message.MsgCode;
import net.jueb.redAlert.game.ServerConfig;
import net.jueb.redAlert.game.ServerMain;
import net.jueb.redAlert.game.factory.ScriptFactory;
import net.jueb.util4j.hotSwap.annationScriptFactory.annations.AnnationScript;

/**
 * 调试脚本
 * @author Administrator
 */
@AnnationScript(id = MsgCode.Game_Sys_Debug)
public class DebugScript extends AbstractSysScript{

	@Override
	public void action() {
		ClassLoader customLoader=ServerConfig.classProvider.getClassLoader();
		if(getClass().getClassLoader()==customLoader)
		{//this is hotswap script
			//test1 
			ByteBufAllocator.DEFAULT.ioBuffer();// init ThreadDeathWatcher watcher thread
			//or test2 ,use netty client write msg to init ThreadDeathWatcher
			ServerMain.getInstance().getLogClient().sendMessage(new AppByteMessage(AppByteMessage.Heart_Req));
			//so ,this script started netty thread
		}
	}
	public static void main(String[] args) {
		//run DebugScript action method
		ScriptFactory.getInstance().buildAction(MsgCode.Game_Sys_Debug).run();
	}
}`
### Minimal yet complete reproducer code (or URL to code)
![default](https://user-images.githubusercontent.com/5427272/31369054-5110b35e-adb4-11e7-9796-a4bb6b2a5b88.png)

### Netty version
4.1.6
### JVM version (e.g. `java -version`)

### OS version (e.g. `uname -a`)
",2017-12-12 08:08:23,"[{'commitHash': 'b7337f7872d3749f2ea5e0bfc9443e1cc5fd52c5', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '63bae0956aeb42e875ad303a2281989ad92acbf2', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['b2bc6407ab6ff6e9be65ada56e4a4058e2c6a293'], 'nameRev': '63bae0956aeb42e875ad303a2281989ad92acbf2 tags/netty-4.1.19.Final~7', 'commitMessage': 'Ensure ThreadDeathWatcher and GlobalEventExecutor will not cause classloader leaks.\n\nMotivation:\n\nThreadDeathWatcher and GlobalEventExecutor may create and start a new thread from various other threads and so inherit the classloader. We need to ensure we not inherit to allow recycling the classloader.\n\nModifications:\n\nUse Thread.setContextClassLoader(null) to ensure we not hold a strong reference to the classloader and so not leak it.\n\nResult:\n\nFixes [#7290].\n', 'commitDateTime': '2017-12-12 09:06:54', 'authoredDateTime': '2017-12-11 15:18:34', 'commitGitStats': [{'filePath': 'common/src/main/java/io/netty/util/ThreadDeathWatcher.java', 'insertions': 7, 'deletions': 0, 'lines': 7}, {'filePath': 'common/src/main/java/io/netty/util/concurrent/GlobalEventExecutor.java', 'insertions': 7, 'deletions': 0, 'lines': 7}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ThreadDeathWatcher.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.ThreadDeathWatcher.schedule(java.lang.Thread,java.lang.Runnable,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'GlobalEventExecutor.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.concurrent.GlobalEventExecutor.startThread()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '11cfda3bbb8379ab5973b35b17e85f3423b8bad1', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['692ce0c288f7c36dca730cdd5d6bf8b68932a638'], 'nameRev': '11cfda3bbb8379ab5973b35b17e85f3423b8bad1 tags/netty-4.0.55.Final~18', 'commitMessage': 'Ensure ThreadDeathWatcher and GlobalEventExecutor will not cause classloader leaks.\n\nMotivation:\n\nThreadDeathWatcher and GlobalEventExecutor may create and start a new thread from various other threads and so inherit the classloader. We need to ensure we not inherit to allow recycling the classloader.\n\nModifications:\n\nUse Thread.setContextClassLoader(null) to ensure we not hold a strong reference to the classloader and so not leak it.\n\nResult:\n\nFixes [#7290].\n', 'commitDateTime': '2017-12-12 09:07:52', 'authoredDateTime': '2017-12-11 15:18:34', 'commitGitStats': [{'filePath': 'common/src/main/java/io/netty/util/ThreadDeathWatcher.java', 'insertions': 7, 'deletions': 0, 'lines': 7}, {'filePath': 'common/src/main/java/io/netty/util/concurrent/GlobalEventExecutor.java', 'insertions': 7, 'deletions': 0, 'lines': 7}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ThreadDeathWatcher.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.ThreadDeathWatcher.schedule(java.lang.Thread,java.lang.Runnable,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'GlobalEventExecutor.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.concurrent.GlobalEventExecutor.startThread()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/7290,63.000277777777775,['defect'],ThreadDeathWatcher causes custom classLoader script memory leaks,1.0,"['io.netty.util.ThreadDeathWatcher.schedule(java.lang.Thread,java.lang.Runnable,boolean)', 'io.netty.util.concurrent.GlobalEventExecutor.startThread()']",['63bae0956aeb42e875ad303a2281989ad92acbf2'],,"['common/src/main/java/io/netty/util', 'common/src/main/java/io/netty/util/concurrent']",14.0,0.0,14.0,2.0,0.0,2.0,2.0,0.0,2.0,0.0,2.0,0.0,0.0,0.0,2.0,0.0,0.0,netty
37663,2017-08-15 07:14:31,MKudo,"I faced the huge direct memory usage in my application (using Netty). I research it and found this ReadOnlyByteBufferBuf copy method.


https://github.com/netty/netty/blob/eb7f751ba519cbcab47d640cd18757f09d077b55/buffer/src/main/java/io/netty/buffer/ReadOnlyByteBufferBuf.java#L419


It seams to create DirectByteBuffer and put it to UnpooledDirectByteBuf constructor. In this constructor, 'doNotFree field' will set to true. Then this DirectByteBuffer seams be not freed (by code. But GC will free this memory).


I hope Netty free this memory.",2017-08-16 05:36:15,"[{'commitHash': 'c223abafbef4af4d5f890c075c69461a99c02c30', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'e487db783673c9c153a011c8156083bbd86bf8e6', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['bbcab32874711f856040a47ee8e45cfbf4b29846'], 'nameRev': 'e487db783673c9c153a011c8156083bbd86bf8e6 tags/netty-4.1.15.Final~25', 'commitMessage': 'Use the ByteBufAllocator when copy a ReadOnlyByteBufferBuf and so also be able to release it without the GC when the Cleaner is present.\n\nMotivation:\n\nIn ReadOnlyByteBufferBuf.copy(...) we just allocated a ByteBuffer directly and wrapped it. This way it was not possible for us to free the direct memory that was used by the copy without the GC.\n\nModifications:\n\n- Ensure we use the allocator when create the copy and so be able to release direct memory in a timely manner\n- Add unit test\n- Depending on if the to be copied buffer is direct or heap based we also allocate the same type on copy.\n\nResult:\n\nFixes [#7103].\n', 'commitDateTime': '2017-08-16 07:33:10', 'authoredDateTime': '2017-08-15 13:33:21', 'commitGitStats': [{'filePath': 'buffer/src/main/java/io/netty/buffer/ReadOnlyByteBufferBuf.java', 'insertions': 3, 'deletions': 5, 'lines': 8}, {'filePath': 'buffer/src/test/java/io/netty/buffer/ReadOnlyByteBufferBufTest.java', 'insertions': 33, 'deletions': 0, 'lines': 33}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ReadOnlyByteBufferBuf.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.ReadOnlyByteBufferBuf.copy(int,int)', 'TOT': 12, 'UPD': 3, 'INS': 2, 'MOV': 3, 'DEL': 4}]}, {'spoonFilePath': 'ReadOnlyByteBufferBufTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.ReadOnlyByteBufferBufTest.testCopyDirect()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.ReadOnlyByteBufferBufTest.testCopyHeap()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.ReadOnlyByteBufferBufTest.testCopy(boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '1b357872a30c46873162b2d825669a01f2474e23', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['040ef7e3b534f0720d87a75e9ef2e019a1c40359'], 'nameRev': '1b357872a30c46873162b2d825669a01f2474e23 tags/netty-4.0.51.Final~18', 'commitMessage': 'Use the ByteBufAllocator when copy a ReadOnlyByteBufferBuf and so also be able to release it without the GC when the Cleaner is present.\n\nMotivation:\n\nIn ReadOnlyByteBufferBuf.copy(...) we just allocated a ByteBuffer directly and wrapped it. This way it was not possible for us to free the direct memory that was used by the copy without the GC.\n\nModifications:\n\n- Ensure we use the allocator when create the copy and so be able to release direct memory in a timely manner\n- Add unit test\n- Depending on if the to be copied buffer is direct or heap based we also allocate the same type on copy.\n\nResult:\n\nFixes [#7103].\n', 'commitDateTime': '2017-08-16 07:33:30', 'authoredDateTime': '2017-08-15 13:33:21', 'commitGitStats': [{'filePath': 'buffer/src/main/java/io/netty/buffer/ReadOnlyByteBufferBuf.java', 'insertions': 3, 'deletions': 5, 'lines': 8}, {'filePath': 'buffer/src/test/java/io/netty/buffer/ReadOnlyByteBufferBufTest.java', 'insertions': 33, 'deletions': 0, 'lines': 33}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ReadOnlyByteBufferBuf.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.ReadOnlyByteBufferBuf.copy(int,int)', 'TOT': 12, 'UPD': 3, 'INS': 2, 'MOV': 3, 'DEL': 4}]}, {'spoonFilePath': 'ReadOnlyByteBufferBufTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.ReadOnlyByteBufferBufTest.testCopyDirect()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.ReadOnlyByteBufferBufTest.testCopyHeap()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.ReadOnlyByteBufferBufTest.testCopy(boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/7103,0.0002777777777777778,"['defect', 'improvement']",This DirectMemory should be released,1.0,"['io.netty.buffer.ReadOnlyByteBufferBuf.copy(int,int)']",['e487db783673c9c153a011c8156083bbd86bf8e6'],,['buffer/src/main/java/io/netty/buffer'],3.0,5.0,8.0,1.0,3.0,1.0,12.0,3.0,2.0,4.0,1.0,0.0,0.0,0.0,2.0,0.0,0.0,netty
37714,2017-04-11 12:22:01,trollheim,"for byte buffers larger than 715827882 bytes this code 
ByteBuf bb = Unpooled.buffer(size);
Base64.decode(bb, 0, size);
throws exception
Exception in thread ""main"" java.lang.IllegalArgumentException: initialCapacity: -536870911 (expectd: 0+)
 
It is happening  because line 120 in  io.netty.handler.codec.base64.Base64 class, `int len43 = len * 4 / 3;` can cause integer overflow for values larger than Integer.MAX_VALUE/3.
changing order of operations to be division followed by multiplication should solve this issue.
Problem was spotted in version 4.1.8.Final.
",2017-04-21 06:21:31,"[{'commitHash': '166d67f99445acd7ddc159f89bcce756c89b54fc', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '8eff709864ba6d506b85c4c23d1e660524ec025a', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '34ff9cf5f246efddec9da2994d039cd40e896c5e', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['c663a94359b70069b67b8d7f7bc9d0c43dca7674'], 'nameRev': '34ff9cf5f246efddec9da2994d039cd40e896c5e tags/netty-4.1.10.Final~23', 'commitMessage': 'Fix possible overflow when calculate in the size of the out buffer in Base64\n\nMotivation:\n\nWe not correctly guarded against overflow and so call Base64.encode(...) with a big buffer may lead to an overflow when calculate the size of the out buffer.\n\nModifications:\n\nCorrectly guard against overflow.\n\nResult:\n\nFixes [#6620].\n', 'commitDateTime': '2017-04-21 08:11:17', 'authoredDateTime': '2017-04-19 14:16:06', 'commitGitStats': [{'filePath': 'codec/src/main/java/io/netty/handler/codec/base64/Base64.java', 'insertions': 22, 'deletions': 7, 'lines': 29}, {'filePath': 'codec/src/test/java/io/netty/handler/codec/base64/Base64Test.java', 'insertions': 11, 'deletions': 0, 'lines': 11}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'Base64.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.base64.Base64.encode(io.netty.buffer.ByteBuf,int,int,boolean,io.netty.handler.codec.base64.Base64Dialect,io.netty.buffer.ByteBufAllocator)', 'TOT': 5, 'UPD': 1, 'INS': 1, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.codec.base64.Base64.Decoder.decode(io.netty.buffer.ByteBuf,int,int,io.netty.buffer.ByteBufAllocator,io.netty.handler.codec.base64.Base64Dialect)', 'TOT': 4, 'UPD': 1, 'INS': 1, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.codec.base64.Base64.encodedBufferSize(int,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.base64.Base64.decodedBufferSize(int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'Base64Test.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.base64.Base64Test.testOverflowEncodedBufferSize()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.base64.Base64Test.testOverflowDecodedBufferSize()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'ae5dba53932e629acf86f1c6a1b455ed61a1312c', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['a20d1c930d33fa9a74afd25d0b75a4fb3336e0dd'], 'nameRev': 'ae5dba53932e629acf86f1c6a1b455ed61a1312c tags/netty-4.0.46.Final~15', 'commitMessage': 'Fix possible overflow when calculate in the size of the out buffer in Base64\n\nMotivation:\n\nWe not correctly guarded against overflow and so call Base64.encode(...) with a big buffer may lead to an overflow when calculate the size of the out buffer.\n\nModifications:\n\nCorrectly guard against overflow.\n\nResult:\n\nFixes [#6620].\n', 'commitDateTime': '2017-04-21 08:19:47', 'authoredDateTime': '2017-04-19 14:16:06', 'commitGitStats': [{'filePath': 'codec/src/main/java/io/netty/handler/codec/base64/Base64.java', 'insertions': 23, 'deletions': 7, 'lines': 30}, {'filePath': 'codec/src/test/java/io/netty/handler/codec/base64/Base64Test.java', 'insertions': 11, 'deletions': 0, 'lines': 11}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'Base64.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.base64.Base64.encode(io.netty.buffer.ByteBuf,int,int,boolean,io.netty.handler.codec.base64.Base64Dialect,io.netty.buffer.ByteBufAllocator)', 'TOT': 5, 'UPD': 1, 'INS': 1, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.codec.base64.Base64.Decoder.decode(io.netty.buffer.ByteBuf,int,int,io.netty.buffer.ByteBufAllocator,io.netty.handler.codec.base64.Base64Dialect)', 'TOT': 4, 'UPD': 1, 'INS': 1, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.codec.base64.Base64.encodedBufferSize(int,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.base64.Base64.decodedBufferSize(int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'Base64Test.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.base64.Base64Test.testOverflowEncodedBufferSize()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.base64.Base64Test.testOverflowDecodedBufferSize()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/6620,9.000277777777777,['defect'],Base64 decoder can handle buffers larger or equal to 715827883 bytes,1.0,"['io.netty.handler.codec.base64.Base64.encodedBufferSize(int,boolean)', 'io.netty.handler.codec.base64.Base64.decodedBufferSize(int)', 'io.netty.handler.codec.base64.Base64.encode(io.netty.buffer.ByteBuf,int,int,boolean,io.netty.handler.codec.base64.Base64Dialect,io.netty.buffer.ByteBufAllocator)', 'io.netty.handler.codec.base64.Base64.Decoder.decode(io.netty.buffer.ByteBuf,int,int,io.netty.buffer.ByteBufAllocator,io.netty.handler.codec.base64.Base64Dialect)']",['34ff9cf5f246efddec9da2994d039cd40e896c5e'],,['codec/src/main/java/io/netty/handler/codec/base64'],22.0,7.0,29.0,1.0,2.0,4.0,11.0,3.0,4.0,2.0,1.0,0.0,0.0,0.0,3.0,0.0,0.0,netty
37720,2017-03-27 18:59:17,ghost,"### Observed behavior

Running any Apache Spark job results in an IllegalArgumentException.

```
java.lang.IllegalArgumentException: address: -2251768783175664 (expected: >= 0)
	at io.netty.util.internal.ObjectUtil.checkPositiveOrZero(ObjectUtil.java:75)
	at io.netty.util.internal.PlatformDependent0.newDirectBuffer(PlatformDependent0.java:280)
	at io.netty.util.internal.PlatformDependent0.allocateDirectNoCleaner(PlatformDependent0.java:276)
	at io.netty.util.internal.PlatformDependent.allocateDirectNoCleaner(PlatformDependent.java:486)
	at io.netty.buffer.PoolArena$DirectArena.allocateDirect(PoolArena.java:711)
	at io.netty.buffer.PoolArena$DirectArena.newChunk(PoolArena.java:700)
	at io.netty.buffer.PoolArena.allocateNormal(PoolArena.java:237)
	at io.netty.buffer.PoolArena.allocate(PoolArena.java:213)
	at io.netty.buffer.PoolArena.allocate(PoolArena.java:141)
	at io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:296)
	at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:177)
	at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:168)
	at io.netty.channel.nio.AbstractNioChannel.newDirectBuffer(AbstractNioChannel.java:404)
	at io.netty.channel.nio.AbstractNioByteChannel.filterOutboundMessage(AbstractNioByteChannel.java:275)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:746)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:733)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:725)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:810)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:718)
	at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:111)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:733)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:725)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:810)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:718)
	at io.netty.handler.timeout.IdleStateHandler.write(IdleStateHandler.java:305)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:733)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:725)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:35)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1062)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1116)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1051)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:399)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:446)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
```

### Steps to reproduce

The crash can be reproduced by running the Apache Spark SparkPi example:

`$ $SPARK_HOME/bin/run-example SparkPi`

### Netty version
4.0.43.Final

### JVM version (e.g. `java -version`)
java version ""1.8.0_121""
Java(TM) SE Runtime Environment (build 1.8.0_121-b13)
Java HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode)

### OS version (e.g. `uname -a`)
Linux localhost 4.1.12-80.el6uek.sparc64 #1 SMP Wed Nov 30 03:09:10 PST 2016 sparc64 sparc64 sparc64 GNU/Linux

### Analysis

It appears that UNSAFE.allocateMemory is returning an **address** whose high bit is set. When **address** is tested in ObjectUtil.checkPositiveOrZero, **address** appears negative and an exception is raised. 

### Proposed Fix

I propose to add two methods to ObjectUtil:

```
public static int checkNotZero(int i, String name)
public static long checkNotZero(long i, String name)
```

and replace the call to ObjectUtil.checkPositiveOrZero() in PlatformDependent0.newDirectBuffer() with ObjectUtil.checkNotZero() instead:

```
    static ByteBuffer newDirectBuffer(long address, int capacity) {
        ObjectUtil.checkNotZero(address, ""address"");
        ObjectUtil.checkPositiveOrZero(capacity, ""capacity"");

        try {
            return (ByteBuffer) DIRECT_BUFFER_CONSTRUCTOR.newInstance(address, capacity);
        } catch (Throwable cause) {
            // Not expected to ever throw!
            if (cause instanceof Error) {
                throw (Error) cause;
            }
            throw new Error(cause);
        }
    }
```",2017-03-29 20:36:25,"[{'commitHash': '5a51464890c184cefd05e19c8b8748c4f0a48ee0', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'd64c321c3808a640304ff6cd0535b0892f28d62a', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '5c1c14286d29d57acddf32b227722f7b2e113ed4', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['016629fe3b65b3797e7e9de39a661bac196c41e0'], 'nameRev': '5c1c14286d29d57acddf32b227722f7b2e113ed4 tags/netty-4.1.10.Final~66', 'commitMessage': 'Allow negative memoryAddress when calling PlatformDependent0.newDirectBuffer(...)\n\nMotivation:\n\nWhen UNSAFE.allocateMemory is returning an address whose high bit is set we currently throw an IllegalArgumentException. This is not correct as it may return a negative number on at least sparc.\n\nModifications:\n\n- Allow to pass in negative memoryAddress\n- Add unit tests\n\nResult:\n\nCorrectly validate the memoryAddress and so also work on sparc as expected. Fixes [#6574].\n', 'commitDateTime': '2017-03-29 22:33:34', 'authoredDateTime': '2017-03-28 08:24:40', 'commitGitStats': [{'filePath': 'common/src/main/java/io/netty/util/internal/PlatformDependent0.java', 'insertions': 0, 'deletions': 1, 'lines': 1}, {'filePath': 'common/src/test/java/io/netty/util/internal/PlatformDependent0Test.java', 'insertions': 56, 'deletions': 0, 'lines': 56}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'PlatformDependent0.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.internal.PlatformDependent0.newDirectBuffer(long,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'PlatformDependent0Test.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.internal.PlatformDependent0Test', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'd05e20dcbe7519eeed5856d4819193b5e2c0243e', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['1bbe4893ec666cf0036f57004e897e6917c96f09'], 'nameRev': 'd05e20dcbe7519eeed5856d4819193b5e2c0243e tags/netty-4.0.46.Final~42', 'commitMessage': 'Allow negative memoryAddress when calling PlatformDependent0.newDirectBuffer(...)\n\nMotivation:\n\nWhen UNSAFE.allocateMemory is returning an address whose high bit is set we currently throw an IllegalArgumentException. This is not correct as it may return a negative number on at least sparc.\n\nModifications:\n\n- Allow to pass in negative memoryAddress\n- Add unit tests\n\nResult:\n\nCorrectly validate the memoryAddress and so also work on sparc as expected. Fixes [#6574].\n', 'commitDateTime': '2017-03-29 22:35:19', 'authoredDateTime': '2017-03-28 08:24:40', 'commitGitStats': [{'filePath': 'common/src/main/java/io/netty/util/internal/PlatformDependent0.java', 'insertions': 0, 'deletions': 1, 'lines': 1}, {'filePath': 'common/src/test/java/io/netty/util/internal/PlatformDependent0Test.java', 'insertions': 56, 'deletions': 0, 'lines': 56}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'PlatformDependent0.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.internal.PlatformDependent0.newDirectBuffer(long,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'PlatformDependent0Test.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.internal.PlatformDependent0Test', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/6574,2.000277777777778,['defect'],"IllegalArgumentException for ""address"" in newDirectBuffer",1.0,"['io.netty.util.internal.PlatformDependent0.newDirectBuffer(long,int)']",['5c1c14286d29d57acddf32b227722f7b2e113ed4'],,['common/src/main/java/io/netty/util/internal'],0.0,1.0,1.0,1.0,0.0,1.0,1.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,3.0,0.0,0.0,netty
37723,2017-03-24 09:33:28,trustin,"### Expected behavior

When a user attempts to write a large buffer (e.g. 1GB) via SslHandler, SslHandler should not attempt to allocate an outNet buffer that's as large as the buffer given by the user, because

- We may not be able to flush fast enough to deallocate it soon.
- A user may get an OOME when under backpressure due to double memory allocation.
- It's inefficient to allocate a direct buffer that's bigger than 16MiB (pooled allocator's chunk size)

### Actual behavior

When a user attempts to write a large buffer, SslHandler should not allocate a huge buffer upfront but only allocate up to certain threshold. e.g. Always keep the number of pending outNet bytes low even if `SslHandler.pendingUnencryptedWrites.bytes` is high.

### Steps to reproduce

- Give JVM relatively small amount of heap and direct memory (e.g. 128m)
- On an SSL connection, attempt to send a buffer that's slightly larger than half of the available direct memory. 
- SslHandler will attempt to allocate a buffer that's as large as the buffer being sent and end up with an OOME.

### Minimal yet complete reproducer code (or URL to code)

I reproduced the problem by running `./gradlew core:check` for [Armeria](https://github.com/line/armeria), but it's not a minimal reproducer obviously. You get the idea though, right? ;-)

### Netty version

4.1.9.Final. No problem with 4.1.8.Final.

### JVM version (e.g. `java -version`)

```
java version ""1.8.0_112""
Java(TM) SE Runtime Environment (build 1.8.0_112-b15)
Java HotSpot(TM) 64-Bit Server VM (build 25.112-b15, mixed mode)
```

### OS version (e.g. `uname -a`)

`Linux porori 4.9.0-0.bpo.2-amd64 #1 SMP Debian 4.9.13-1~bpo8+1 (2017-02-27) x86_64 GNU/Linux`",2017-03-31 05:55:08,"[{'commitHash': '896046bfe500dc9db7287de0b6b79f1608b73d34', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'ed749122cc61ee874e98604c59a674c0ff7e988b', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '094a4d92d2b37a017a061b96521783f359899e58', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '91d532aaf352340f80568c8f02c2e8564135059a', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'ed1071d327cdd77bf520befda7f62081374e77bc', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['40bead56c4d57b33e751ef243c7fb3cfe861bfac'], 'nameRev': 'ed1071d327cdd77bf520befda7f62081374e77bc tags/netty-4.1.10.Final~62', 'commitMessage': 'Limit the maximum size of the allocated outbound buffer to MAX_ENCRYPTED_PACKET_LENGTH\n\nMotivation:\n\nWe should limit the size of the allocated outbound buffer to MAX_ENCRYPTED_PACKET_LENGTH to ensure we not cause an OOME when the user tries to encrypt a very big buffer.\n\nModifications:\n\nLimit the size of the allocated outbound buffer to MAX_ENCRYPTED_PACKET_LENGTH\n\nResult:\n\nFixes [#6564]\n', 'commitDateTime': '2017-03-31 07:53:50', 'authoredDateTime': '2017-03-25 17:14:53', 'commitGitStats': [{'filePath': 'handler/src/main/java/io/netty/handler/ssl/ReferenceCountedOpenSslEngine.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'handler/src/test/java/io/netty/handler/ssl/OpenSslEngineTest.java', 'insertions': 7, 'deletions': 1, 'lines': 8}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ReferenceCountedOpenSslEngine.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.calculateOutNetBufSize(int,int)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'OpenSslEngineTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testCalculateOutNetBufSizeOverflow()', 'TOT': 6, 'UPD': 1, 'INS': 1, 'MOV': 3, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testCalculateOutNetBufSizeMaxEncryptedPacketLength()', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '29a83e7df9dc70c12502226b176f9549dd1af508', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['99c2d1e303305273c115474dcd863065a83c6ffc'], 'nameRev': '29a83e7df9dc70c12502226b176f9549dd1af508 tags/netty-4.0.46.Final~39', 'commitMessage': 'Limit the maximum size of the allocated outbound buffer to MAX_ENCRYPTED_PACKET_LENGTH\n\nMotivation:\n\nWe should limit the size of the allocated outbound buffer to MAX_ENCRYPTED_PACKET_LENGTH to ensure we not cause an OOME when the user tries to encrypt a very big buffer.\n\nModifications:\n\nLimit the size of the allocated outbound buffer to MAX_ENCRYPTED_PACKET_LENGTH\n\nResult:\n\nFixes [#6564]\n', 'commitDateTime': '2017-03-31 07:54:13', 'authoredDateTime': '2017-03-25 17:14:53', 'commitGitStats': [{'filePath': 'handler/src/main/java/io/netty/handler/ssl/ReferenceCountedOpenSslEngine.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'handler/src/test/java/io/netty/handler/ssl/OpenSslEngineTest.java', 'insertions': 7, 'deletions': 1, 'lines': 8}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ReferenceCountedOpenSslEngine.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.calculateOutNetBufSize(int,int)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'OpenSslEngineTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testCalculateOutNetBufSizeOverflow()', 'TOT': 6, 'UPD': 1, 'INS': 1, 'MOV': 3, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testCalculateOutNetBufSizeMaxEncryptedPacketLength()', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/6564,6.000277777777778,['defect'],"When the number of pending unencrypted bytes is high, SslHandler tries to allocate a huge outNet buffer.",1.0,"['io.netty.handler.ssl.ReferenceCountedOpenSslEngine.calculateOutNetBufSize(int,int)']",['ed1071d327cdd77bf520befda7f62081374e77bc'],,['handler/src/main/java/io/netty/handler/ssl'],2.0,1.0,3.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,5.0,0.0,0.0,netty
37730,2017-03-01 23:13:57,rkapsi,"Netty 4.1.9-SNAPSHOT with netty-tcnative 2.0.0.Beta6

I'll try to provide a repro but I'm seeing the following error in our application when I upgrade to Netty 4.1.9-SNAPSHOT and netty-tcnative 2.0.0.Beta6.

From what I can tell, the SSL hanshake completes, I receive the HTTP request, I respond with `ctx.writeAndFlush(FullHttpResponse)`, I see the response data in curl but it cuts off randomly and both ends report the following errors:

```
// Server: Netty w/ OpenSSL on port 8443
ReferenceCountedOpenSslEngine DEBUG: SSL_read failed: OpenSSL error: error:1409442E:SSL routines:ssl3_read_bytes:tlsv1 alert protocol version
```

```
// Client: curl -k https://localhost:8443
curl: (56) SSL read: error:1408F10B:SSL routines:SSL3_GET_RECORD:wrong version number, errno 0
```

An another observation is that curl seems to be a bit more stable. Some requests do succeed but Browsers (I tested Chrome and FF) on the other hand fail pretty reliably (every time). The problem goes away as soon as I switch back to Netty 4.1.8.

This resembles what we observed in the #6466 ticket (minus the Exception).",2017-03-06 16:15:29,"[{'commitHash': '53fc69390130f7a5a33d454a59ad214f6b4176f5', 'commitGHEventType': 'closed', 'commitUser': 'Scottmitch', 'commitParents': ['f343de8fb178103d6dd966a9e81e09f67c201aac'], 'nameRev': '53fc69390130f7a5a33d454a59ad214f6b4176f5 tags/netty-4.1.9.Final~22', 'commitMessage': ""SslHandler and OpenSslEngine miscalculation of wrap destination buffer size\n\nMotivation:\nWhen we do a wrap operation we calculate the maximum size of the destination buffer ahead of time, and return a BUFFER_OVERFLOW exception if the destination buffer is not big enough. However if there is a CompositeByteBuf the wrap operation may consist of multiple ByteBuffers and each incurs its own overhead during the encryption. We currently don't account for the overhead required for encryption if there are multiple ByteBuffers and we assume the overhead will only apply once to the entire input size. If there is not enough room to write an entire encrypted packed into the BIO SSL_write will return -1 despite having actually written content to the BIO. We then attempt to retry the write with a bigger buffer, but because SSL_write is stateful the remaining bytes from the previous operation are put into the BIO. This results in sending the second half of the encrypted data being sent to the peer which is not of proper format and the peer will be confused and ultimately not get the expected data (which may result in a fatal error). In this case because SSL_write returns -1 we have no way to know how many bytes were actually consumed and so the best we can do is ensure that we always allocate a destination buffer with enough space so we are guaranteed to complete the write operation synchronously.\n\nModifications:\n- SslHandler#allocateNetBuf should take into account how many ByteBuffers will be wrapped and apply the encryption overhead for each\n- Include the TLS header length in the overhead computation\n\nResult:\nFixes https://github.com/netty/netty/issues/6481\n"", 'commitDateTime': '2017-03-06 08:15:13', 'authoredDateTime': '2017-03-03 09:22:26', 'commitGitStats': [{'filePath': 'handler/src/main/java/io/netty/handler/ssl/ReferenceCountedOpenSslEngine.java', 'insertions': 10, 'deletions': 11, 'lines': 21}, {'filePath': 'handler/src/main/java/io/netty/handler/ssl/SslHandler.java', 'insertions': 10, 'deletions': 13, 'lines': 23}, {'filePath': 'handler/src/test/java/io/netty/handler/ssl/OpenSslEngineTest.java', 'insertions': 18, 'deletions': 14, 'lines': 32}, {'filePath': 'handler/src/test/java/io/netty/handler/ssl/SslHandlerTest.java', 'insertions': 130, 'deletions': 0, 'lines': 130}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ReferenceCountedOpenSslEngine.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine', 'TOT': 8, 'UPD': 4, 'INS': 1, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.calculateOutNetBufSize(int)', 'TOT': 4, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 2}, {'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.unwrap(java.nio.ByteBuffer[],int,int,java.nio.ByteBuffer[],int,int)', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.calculateOutNetBufSize(int,int)', 'TOT': 3, 'UPD': 0, 'INS': 3, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(java.nio.ByteBuffer[],int,int,java.nio.ByteBuffer)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'SslHandler.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.SslHandler.SslEngineType.forEngine(javax.net.ssl.SSLEngine)', 'TOT': 6, 'UPD': 1, 'INS': 1, 'MOV': 2, 'DEL': 2}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.SslEngineType.1.unwrap(io.netty.handler.ssl.SslHandler,io.netty.buffer.ByteBuf,int,int,io.netty.buffer.ByteBuf)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.allocateOutNetBuf(io.netty.channel.ChannelHandlerContext,int,int)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.SslEngineType.calculateOutNetBufSize(io.netty.handler.ssl.SslHandler,int,int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.SslEngineType.1.calculateOutNetBufSize(io.netty.handler.ssl.SslHandler,int,int)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.SslEngineType.2.calculateOutNetBufSize(io.netty.handler.ssl.SslHandler,int,int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.wrap(io.netty.channel.ChannelHandlerContext,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.wrapNonAppData(io.netty.channel.ChannelHandlerContext,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'OpenSslEngineTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testCalculateOutNetBufSize0()', 'TOT': 2, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testWrapWithDifferentSizes(java.lang.String,java.lang.String)', 'TOT': 2, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testWrapDstBigEnough(javax.net.ssl.SSLEngine,int)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testOnlySmallBufferNeededForWrap()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testNeededDstCapacityIsCorrectlyCalculated()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testSrcsLenOverFlowCorrectlyHandled()', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testCalculateOutNetBufSizeOverflow()', 'TOT': 4, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 2}]}, {'spoonFilePath': 'SslHandlerTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.SslHandlerTest.testCompositeBufSizeEstimationGuaranteesSynchronousWrite()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandlerTest.compositeBufSizeEstimationGuaranteesSynchronousWrite(io.netty.handler.ssl.SslProvider,io.netty.handler.ssl.SslProvider)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'ccd609863ecf02dcc4039cee13ccec4ffe603813', 'commitGHEventType': 'referenced', 'commitUser': 'Scottmitch', 'commitParents': ['5bbfd08057ef87ea6610b1cc17a72ec368de61a1'], 'nameRev': 'ccd609863ecf02dcc4039cee13ccec4ffe603813 tags/netty-4.0.45.Final~21', 'commitMessage': ""SslHandler and OpenSslEngine miscalculation of wrap destination buffer size\n\nMotivation:\nWhen we do a wrap operation we calculate the maximum size of the destination buffer ahead of time, and return a BUFFER_OVERFLOW exception if the destination buffer is not big enough. However if there is a CompositeByteBuf the wrap operation may consist of multiple ByteBuffers and each incurs its own overhead during the encryption. We currently don't account for the overhead required for encryption if there are multiple ByteBuffers and we assume the overhead will only apply once to the entire input size. If there is not enough room to write an entire encrypted packed into the BIO SSL_write will return -1 despite having actually written content to the BIO. We then attempt to retry the write with a bigger buffer, but because SSL_write is stateful the remaining bytes from the previous operation are put into the BIO. This results in sending the second half of the encrypted data being sent to the peer which is not of proper format and the peer will be confused and ultimately not get the expected data (which may result in a fatal error). In this case because SSL_write returns -1 we have no way to know how many bytes were actually consumed and so the best we can do is ensure that we always allocate a destination buffer with enough space so we are guaranteed to complete the write operation synchronously.\n\nModifications:\n- SslHandler#allocateNetBuf should take into account how many ByteBuffers will be wrapped and apply the encryption overhead for each\n- Include the TLS header length in the overhead computation\n\nResult:\nFixes https://github.com/netty/netty/issues/6481\n"", 'commitDateTime': '2017-03-06 08:15:36', 'authoredDateTime': '2017-03-03 09:22:26', 'commitGitStats': [{'filePath': 'handler/src/main/java/io/netty/handler/ssl/ReferenceCountedOpenSslEngine.java', 'insertions': 10, 'deletions': 11, 'lines': 21}, {'filePath': 'handler/src/main/java/io/netty/handler/ssl/SslHandler.java', 'insertions': 10, 'deletions': 13, 'lines': 23}, {'filePath': 'handler/src/test/java/io/netty/handler/ssl/OpenSslEngineTest.java', 'insertions': 18, 'deletions': 14, 'lines': 32}, {'filePath': 'handler/src/test/java/io/netty/handler/ssl/SslHandlerTest.java', 'insertions': 130, 'deletions': 0, 'lines': 130}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ReferenceCountedOpenSslEngine.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine', 'TOT': 8, 'UPD': 4, 'INS': 1, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.calculateOutNetBufSize(int)', 'TOT': 4, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 2}, {'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.unwrap(java.nio.ByteBuffer[],int,int,java.nio.ByteBuffer[],int,int)', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.calculateOutNetBufSize(int,int)', 'TOT': 3, 'UPD': 0, 'INS': 3, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(java.nio.ByteBuffer[],int,int,java.nio.ByteBuffer)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'SslHandler.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.SslHandler.SslEngineType.forEngine(javax.net.ssl.SSLEngine)', 'TOT': 6, 'UPD': 1, 'INS': 1, 'MOV': 2, 'DEL': 2}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.SslEngineType.1.unwrap(io.netty.handler.ssl.SslHandler,io.netty.buffer.ByteBuf,int,int,io.netty.buffer.ByteBuf)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.allocateOutNetBuf(io.netty.channel.ChannelHandlerContext,int,int)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.SslEngineType.calculateOutNetBufSize(io.netty.handler.ssl.SslHandler,int,int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.SslEngineType.1.calculateOutNetBufSize(io.netty.handler.ssl.SslHandler,int,int)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.SslEngineType.2.calculateOutNetBufSize(io.netty.handler.ssl.SslHandler,int,int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.wrap(io.netty.channel.ChannelHandlerContext,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandler.wrapNonAppData(io.netty.channel.ChannelHandlerContext,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'OpenSslEngineTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testCalculateOutNetBufSize0()', 'TOT': 2, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testWrapWithDifferentSizes(java.lang.String,java.lang.String)', 'TOT': 2, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testWrapDstBigEnough(javax.net.ssl.SSLEngine,int)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testOnlySmallBufferNeededForWrap()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testNeededDstCapacityIsCorrectlyCalculated()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testSrcsLenOverFlowCorrectlyHandled()', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslEngineTest.testCalculateOutNetBufSizeOverflow()', 'TOT': 4, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 2}]}, {'spoonFilePath': 'SslHandlerTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.SslHandlerTest.testCompositeBufSizeEstimationGuaranteesSynchronousWrite()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SslHandlerTest.compositeBufSizeEstimationGuaranteesSynchronousWrite(io.netty.handler.ssl.SslProvider,io.netty.handler.ssl.SslProvider)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/6481,4.000277777777778,['defect'],SSL_read failed: OpenSSL error,1.0,"['io.netty.handler.ssl.SslHandler.SslEngineType.calculateOutNetBufSize(io.netty.handler.ssl.SslHandler,int,int)', 'io.netty.handler.ssl.SslHandler.wrapNonAppData(io.netty.channel.ChannelHandlerContext,boolean)', 'io.netty.handler.ssl.SslHandler.SslEngineType.1.unwrap(io.netty.handler.ssl.SslHandler,io.netty.buffer.ByteBuf,int,int,io.netty.buffer.ByteBuf)', 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.calculateOutNetBufSize(int)', 'io.netty.handler.ssl.SslHandler.allocateOutNetBuf(io.netty.channel.ChannelHandlerContext,int,int)', 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine', 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.unwrap(java.nio.ByteBuffer[],int,int,java.nio.ByteBuffer[],int,int)', 'io.netty.handler.ssl.SslHandler.wrap(io.netty.channel.ChannelHandlerContext,boolean)', 'io.netty.handler.ssl.SslHandler.SslEngineType.forEngine(javax.net.ssl.SSLEngine)', 'io.netty.handler.ssl.SslHandler.SslEngineType.2.calculateOutNetBufSize(io.netty.handler.ssl.SslHandler,int,int)', 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.calculateOutNetBufSize(int,int)', 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(java.nio.ByteBuffer[],int,int,java.nio.ByteBuffer)', 'io.netty.handler.ssl.SslHandler.SslEngineType.1.calculateOutNetBufSize(io.netty.handler.ssl.SslHandler,int,int)']",['53fc69390130f7a5a33d454a59ad214f6b4176f5'],,['handler/src/main/java/io/netty/handler/ssl'],20.0,24.0,44.0,2.0,7.0,13.0,33.0,5.0,14.0,7.0,2.0,0.0,0.0,0.0,1.0,0.0,0.0,netty
37788,2016-11-03 17:11:11,jrudolph,"It seems OpenSSLEngine needs more package buffer space than the JDK one. Both JDK and Openssl report for `session.getPacketBufferSize` 18713 bytes (16665 + 2048) but the OpenSSLEngine will in some cases only succeed with buffers of size 16665 + 2048 + 58 (I bisected the exact amount, 1 byte less will still fail) and will otherwise return a BUFFER_OVERFLOW. 

This isn't a fatal problem as you can just provide more buffer space and call again. However, 
we relied on the invariant that a call to `wrap` can never result with BUFFER_OVERFLOW if the destination buffer was at least of size `session.getPacketBufferSize`. This allows us not to care for BUFFER_OVERFLOWs at all using the JDK SSLEngine. Not sure if that invariant really exists, though, so, one could say that this is just another degree of freedom the SSLEngine might leave to implementors.",2016-11-15 08:44:41,"[{'commitHash': '248871bcd55fa053a0aeb568e47432667431c278', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'c8575c42d0964812c0d2617f98efa7cb64c46be8', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['c4e96d010e3d16810d7130c93169817b3d72b421'], 'nameRev': 'c8575c42d0964812c0d2617f98efa7cb64c46be8 tags/netty-4.1.7.Final~92', 'commitMessage': '[#5976] Ensure we only consume as much data on wrap(...) as we can handle.\n\nMotiviation:\n\nWe need to ensure we only consume as much da as we can maximal put in one ssl record to not produce a BUFFER_OVERFLOW when calling wrap(...).\n\nModification:\n\n- Limit the amount of data that we consume based on the maximal plain text size that can be put in one ssl record\n- Add testcase to verify the fix\n- Tighten up testcases to ensure the amount of produced and consumed data in SslEngineResult matches the buffers. If not the tests will fail now.\n\nResult:\n\nCorrect and conform behavior of OpenSslEngine.wrap(...) and better test coverage during handshaking in general.\n', 'commitDateTime': '2016-11-15 09:39:03', 'authoredDateTime': '2016-11-10 11:53:59', 'commitGitStats': [{'filePath': 'handler/src/main/java/io/netty/handler/ssl/ReferenceCountedOpenSslEngine.java', 'insertions': 11, 'deletions': 4, 'lines': 15}, {'filePath': 'handler/src/test/java/io/netty/handler/ssl/SSLEngineTest.java', 'insertions': 92, 'deletions': 4, 'lines': 96}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ReferenceCountedOpenSslEngine.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.writePlaintextData(java.nio.ByteBuffer)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.writePlaintextData(java.nio.ByteBuffer,int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(java.nio.ByteBuffer[],int,int,java.nio.ByteBuffer)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'SSLEngineTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.SSLEngineTest.isHandshaking(javax.net.ssl.SSLEngineResult)', 'TOT': 10, 'UPD': 3, 'INS': 0, 'MOV': 6, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.ssl.SSLEngineTest.handshake(javax.net.ssl.SSLEngine,javax.net.ssl.SSLEngine)', 'TOT': 24, 'UPD': 0, 'INS': 21, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.ssl.SSLEngineTest.isHandshakeFinished(javax.net.ssl.SSLEngineResult)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SSLEngineTest.testPacketBufferSizeLimit()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '595b2676be9fae5ead92263d0a8396929b3f88b5', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['2ec06e2c344539a9d73b14953ddf6f088667f8d2'], 'nameRev': '595b2676be9fae5ead92263d0a8396929b3f88b5 tags/netty-4.0.43.Final~65', 'commitMessage': '[#5976] Ensure we only consume as much data on wrap(...) as we can handle.\n\nMotiviation:\n\nWe need to ensure we only consume as much da as we can maximal put in one ssl record to not produce a BUFFER_OVERFLOW when calling wrap(...).\n\nModification:\n\n- Limit the amount of data that we consume based on the maximal plain text size that can be put in one ssl record\n- Add testcase to verify the fix\n- Tighten up testcases to ensure the amount of produced and consumed data in SslEngineResult matches the buffers. If not the tests will fail now.\n\nResult:\n\nCorrect and conform behavior of OpenSslEngine.wrap(...) and better test coverage during handshaking in general.\n', 'commitDateTime': '2016-11-15 09:39:38', 'authoredDateTime': '2016-11-10 11:53:59', 'commitGitStats': [{'filePath': 'handler/src/main/java/io/netty/handler/ssl/ReferenceCountedOpenSslEngine.java', 'insertions': 11, 'deletions': 4, 'lines': 15}, {'filePath': 'handler/src/test/java/io/netty/handler/ssl/SSLEngineTest.java', 'insertions': 92, 'deletions': 4, 'lines': 96}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ReferenceCountedOpenSslEngine.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.writePlaintextData(java.nio.ByteBuffer)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.writePlaintextData(java.nio.ByteBuffer,int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(java.nio.ByteBuffer[],int,int,java.nio.ByteBuffer)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'SSLEngineTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.SSLEngineTest.isHandshaking(javax.net.ssl.SSLEngineResult)', 'TOT': 10, 'UPD': 3, 'INS': 0, 'MOV': 6, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.ssl.SSLEngineTest.handshake(javax.net.ssl.SSLEngine,javax.net.ssl.SSLEngine)', 'TOT': 24, 'UPD': 0, 'INS': 21, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.ssl.SSLEngineTest.isHandshakeFinished(javax.net.ssl.SSLEngineResult)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.SSLEngineTest.testPacketBufferSizeLimit()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/5976,11.000277777777777,['defect'],Openssl SSLEngine reports too little size in session.getPacketBufferSize,1.0,"['io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(java.nio.ByteBuffer[],int,int,java.nio.ByteBuffer)', 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.writePlaintextData(java.nio.ByteBuffer)', 'io.netty.handler.ssl.ReferenceCountedOpenSslEngine.writePlaintextData(java.nio.ByteBuffer,int)']",['c8575c42d0964812c0d2617f98efa7cb64c46be8'],,['handler/src/main/java/io/netty/handler/ssl'],11.0,4.0,15.0,1.0,0.0,3.0,4.0,0.0,3.0,1.0,1.0,0.0,0.0,0.0,2.0,0.0,0.0,netty
37806,2016-09-16 17:31:33,zsxwing,"Right now there is no way to release pooled `DirectByteBuffer`s in `PooledByteBufAllocator`. However, Netty uses no cleaner DirectByteBuffer by default since 4.0.37. Hence, if I create a client using `PooledByteBufAllocator`, then send some messages and shutdown the client, there will be some DirectByteBuffers still in `PooledByteBufAllocator` (they are just put back into the PoolChunkList) and I don't find any way to release them, but no cleaner DirectByteBuffers require being released manually.

Running the following test will see `OutOfDirectMemoryError` quickly.

``` Java
    @Test
    public void testNoCleanerDirectByteBuffer() throws InterruptedException {
        // System.setProperty(""io.netty.maxDirectMemory"", ""0"");
        for(;;) {
            PooledByteBufAllocator allocator = new PooledByteBufAllocator(true);
            allocator.buffer(8000).release();
            allocator.freeThreadLocalCache();
        }
    }
```

Right now we just use `System.setProperty(""io.netty.maxDirectMemory"", ""0"");` to disable it to pass our thousands of unit tests.

It would be better that Netty provides an API to release them so that we can try the no cleaner DirectByteBuffers.
",2016-09-23 22:21:51,"[{'commitHash': 'bf6f7dce4df05022e3e05e692e45a54411001dd1', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'b790b9e6c1995984f7e6b52d742f9c892e0883e4', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'aa72fc4c9392b7cea162dd19de1500df21f062cf', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '5986c229c463f064e7b787a4547c0689d2302a03', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['0d2baaf6aeb1ffdb9b9a9e2bb26f4c21c5e949b0'], 'nameRev': '5986c229c463f064e7b787a4547c0689d2302a03 tags/netty-4.1.6.Final~30', 'commitMessage': '[#5833] Ensure direct memory is released when DirectPoolArena is collected\n\nMotivation:\n\nWe need to ensure we release all direct memory once the DirectPoolArena is collected. Otherwise we may never reclaim the memory and so leak memory.\n\nModifications:\n\nEnsure we destroy all PoolChunk memory when DirectPoolArena is collected.\n\nResult:\n\nFree up unreleased memory when DirectPoolArena is collected.\n', 'commitDateTime': '2016-09-23 15:20:59', 'authoredDateTime': '2016-09-16 19:43:51', 'commitGitStats': [{'filePath': 'buffer/src/main/java/io/netty/buffer/PoolArena.java', 'insertions': 23, 'deletions': 0, 'lines': 23}, {'filePath': 'buffer/src/main/java/io/netty/buffer/PoolChunk.java', 'insertions': 4, 'deletions': 0, 'lines': 4}, {'filePath': 'buffer/src/main/java/io/netty/buffer/PoolChunkList.java', 'insertions': 9, 'deletions': 1, 'lines': 10}, {'filePath': 'buffer/src/main/java/io/netty/buffer/PoolSubpage.java', 'insertions': 6, 'deletions': 0, 'lines': 6}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'PoolArena.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolArena.finalize()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PoolArena.destroyPoolSubPages(io.netty.buffer.PoolSubpage[])', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PoolArena.destroyPoolChunkLists(io.netty.buffer.PoolChunkList[])', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'PoolChunk.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolChunk.destroy()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'PoolChunkList.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolChunkList.destroy(io.netty.buffer.PoolArena)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'PoolSubpage.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolSubpage.destroy()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'b861961e60bc599c87cecaf82d2ca96831336bd8', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['bb81496076e7398d28bdc2b4ef9487aa78538f68'], 'nameRev': 'b861961e60bc599c87cecaf82d2ca96831336bd8 tags/netty-4.0.42.Final~19', 'commitMessage': '[#5833] Ensure direct memory is released when DirectPoolArena is collected\n\nMotivation:\n\nWe need to ensure we release all direct memory once the DirectPoolArena is collected. Otherwise we may never reclaim the memory and so leak memory.\n\nModifications:\n\nEnsure we destroy all PoolChunk memory when DirectPoolArena is collected.\n\nResult:\n\nFree up unreleased memory when DirectPoolArena is collected.\n', 'commitDateTime': '2016-09-23 15:21:14', 'authoredDateTime': '2016-09-16 19:43:51', 'commitGitStats': [{'filePath': 'buffer/src/main/java/io/netty/buffer/PoolArena.java', 'insertions': 23, 'deletions': 0, 'lines': 23}, {'filePath': 'buffer/src/main/java/io/netty/buffer/PoolChunk.java', 'insertions': 4, 'deletions': 0, 'lines': 4}, {'filePath': 'buffer/src/main/java/io/netty/buffer/PoolChunkList.java', 'insertions': 9, 'deletions': 1, 'lines': 10}, {'filePath': 'buffer/src/main/java/io/netty/buffer/PoolSubpage.java', 'insertions': 6, 'deletions': 0, 'lines': 6}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'PoolArena.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolArena.finalize()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PoolArena.destroyPoolSubPages(io.netty.buffer.PoolSubpage[])', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PoolArena.destroyPoolChunkLists(io.netty.buffer.PoolChunkList[])', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'PoolChunk.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolChunk.destroy()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'PoolChunkList.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolChunkList.destroy(io.netty.buffer.PoolArena)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'PoolSubpage.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolSubpage.destroy()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/5833,7.000277777777778,['defect'],Feature request: API to release pooled direct buffers in PooledByteBufAllocator,1.0,"['io.netty.buffer.PoolChunk.destroy()', 'io.netty.buffer.PoolChunkList.destroy(io.netty.buffer.PoolArena)', 'io.netty.buffer.PoolArena.finalize()', 'io.netty.buffer.PoolArena.destroyPoolSubPages(io.netty.buffer.PoolSubpage[])', 'io.netty.buffer.PoolSubpage.destroy()', 'io.netty.buffer.PoolArena.destroyPoolChunkLists(io.netty.buffer.PoolChunkList[])']",['5986c229c463f064e7b787a4547c0689d2302a03'],,['buffer/src/main/java/io/netty/buffer'],42.0,1.0,43.0,4.0,0.0,6.0,6.0,0.0,6.0,0.0,4.0,0.0,0.0,0.0,4.0,0.0,0.0,netty
37819,2016-08-10 22:40:39,rkapsi,"The SniHandler#select()/AsyncMapper#map() methods execute asynchronously and by the time the returned Future completes the client is possibly no longer connected.

The #selection field will be set but probably after #channelInactive() (i.e. can't really do anything with it) and the #replace() call on the ChannelPipeline will probably throw a NoSuchElementException.

I have no good suggestion how to fix it. There is an opportunity to cancel the future and it could try to decrement the refCnt if the Future completes successfully but the client has disconnected in the meantime. 

Given SniHandler is a one-shot handler maybe something along the lines of this?!

``` java
class SniHandler {
  private Promsie<SslContext> promise;

  void handlerAdded(ChannelHandlerContext ctx) {
    promsie = ctx.newPromise();
  }

  void channelInactive(ChannelHandlerContext ctx) {
    promsie.cancel(true);
    promsie.addFutureListener(... release() on success ...);
    ctx.fireChannelInactive();
  }

  void select(...) {
    mapping.map(hostname, promsie).addFutureListener(... replaceHandler() ...);
  }
}
```
",2016-08-25 20:09:21,"[{'commitHash': 'acb40a87c31c524e9f7fe9a06a9c1ac7ee96c2aa', 'commitGHEventType': 'closed', 'commitUser': 'Scottmitch', 'commitParents': ['208893aac98ecb94ec190f1834db928e2e7908a0'], 'nameRev': 'acb40a87c31c524e9f7fe9a06a9c1ac7ee96c2aa tags/netty-4.1.5.Final~7', 'commitMessage': 'SniHandler reference count leak if pipeline replace fails\n\nMotivation:\nThe SniHandler attempts to generate a new SslHandler from the selected SslContext in a and insert that SslHandler into the pipeline. However if the underlying channel has been closed or the pipeline has been modified the pipeline.replace(..) operation may fail. Creating the SslHandler may also create a SSLEngine which is of type ReferenceCounted. The SslHandler states that if it is not inserted into a pipeline that it will not take reference count ownership of the SSLEngine. Under these conditions we will leak the SSLEngine if it is reference counted.\n\nModifications:\n- If the pipeline.replace(..) operation fails we should release the SSLEngine object.\n\nResult:\nFixes https://github.com/netty/netty/issues/5678\n', 'commitDateTime': '2016-08-25 13:08:59', 'authoredDateTime': '2016-08-10 18:17:17', 'commitGitStats': [{'filePath': 'handler/src/main/java/io/netty/handler/ssl/SniHandler.java', 'insertions': 15, 'deletions': 2, 'lines': 17}, {'filePath': 'handler/src/main/java/io/netty/handler/ssl/SslContext.java', 'insertions': 1, 'deletions': 1, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'SniHandler.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.SniHandler.replaceHandler(io.netty.channel.ChannelHandlerContext,io.netty.handler.ssl.SniHandler$Selection)', 'TOT': 12, 'UPD': 4, 'INS': 1, 'MOV': 6, 'DEL': 1}]}, {'spoonFilePath': 'SslContext.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.SslContext.newHandler(javax.net.ssl.SSLEngine)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'aef16549efdde282a4bdcd6576596521316eb3c3', 'commitGHEventType': 'referenced', 'commitUser': 'Scottmitch', 'commitParents': ['1e4f5f2cc830052707a9a414bfa6a173bd2287e5'], 'nameRev': 'aef16549efdde282a4bdcd6576596521316eb3c3 tags/netty-4.0.41.Final~7', 'commitMessage': 'SniHandler reference count leak if pipeline replace fails\n\nMotivation:\nThe SniHandler attempts to generate a new SslHandler from the selected SslContext in a and insert that SslHandler into the pipeline. However if the underlying channel has been closed or the pipeline has been modified the pipeline.replace(..) operation may fail. Creating the SslHandler may also create a SSLEngine which is of type ReferenceCounted. The SslHandler states that if it is not inserted into a pipeline that it will not take reference count ownership of the SSLEngine. Under these conditions we will leak the SSLEngine if it is reference counted.\n\nModifications:\n- If the pipeline.replace(..) operation fails we should release the SSLEngine object.\n\nResult:\nFixes https://github.com/netty/netty/issues/5678\n', 'commitDateTime': '2016-08-25 13:13:43', 'authoredDateTime': '2016-08-10 18:17:17', 'commitGitStats': [{'filePath': 'handler/src/main/java/io/netty/handler/ssl/SniHandler.java', 'insertions': 15, 'deletions': 2, 'lines': 17}, {'filePath': 'handler/src/main/java/io/netty/handler/ssl/SslContext.java', 'insertions': 1, 'deletions': 1, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'SniHandler.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.SniHandler.select(io.netty.channel.ChannelHandlerContext,java.lang.String)', 'TOT': 14, 'UPD': 3, 'INS': 2, 'MOV': 7, 'DEL': 2}]}, {'spoonFilePath': 'SslContext.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.SslContext.newHandler(javax.net.ssl.SSLEngine)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/5678,14.000277777777777,['defect'],SniHandler#replaceHandler() may leak (reference counted) SslContexts,1.0,"['io.netty.handler.ssl.SniHandler.replaceHandler(io.netty.channel.ChannelHandlerContext,io.netty.handler.ssl.SniHandler$Selection)', 'io.netty.handler.ssl.SslContext.newHandler(javax.net.ssl.SSLEngine)']",['acb40a87c31c524e9f7fe9a06a9c1ac7ee96c2aa'],,['handler/src/main/java/io/netty/handler/ssl'],16.0,3.0,19.0,2.0,4.0,2.0,13.0,6.0,1.0,2.0,2.0,0.0,0.0,0.0,1.0,0.0,0.0,netty
37834,2016-07-19 18:26:02,rkapsi,"Hey,

I just stumbled onto this one. The `SimpleChannelPool#notifyConnect()` method will leak Channels if the user cancelled the Promise. 

``` java
private static void notifyConnect(ChannelFuture future, Promise<Channel> promise) {
        if (future.isSuccess()) {
            // This will leak the Channel if the Promise is complete
            promise.setSuccess(future.channel());
        } else {
            promise.setFailure(future.cause());
        }
    }
```

``` java
private static void notifyConnect(ChannelFuture future, Promise<Channel> promise) {
        if (future.isSuccess()) {
            // Possible fix
            Channel channel = future.channel();
            if (!promise.trySuccess(channel)) {
                release(channel);
            }
        } else {
            promise.setFailure(future.cause());
        }
    }
```

``` java
2016-07-19 14:14:48:400 EDT [32647,NIO-ConnectorThread-0,] WARN DefaultPromise - An exception was thrown by io.netty.channel.pool.SimpleChannelPool$2.operationComplete()
java.lang.IllegalStateException: complete already: DefaultPromise@78ba125f(failure: java.util.concurrent.CancellationException)
    at io.netty.util.concurrent.DefaultPromise.setSuccess(DefaultPromise.java:105)
    at io.netty.channel.pool.SimpleChannelPool.notifyConnect(SimpleChannelPool.java:159)
    at io.netty.channel.pool.SimpleChannelPool.access$000(SimpleChannelPool.java:42)
    at io.netty.channel.pool.SimpleChannelPool$2.operationComplete(SimpleChannelPool.java:134)
    at io.netty.channel.pool.SimpleChannelPool$2.operationComplete(SimpleChannelPool.java:131)
    at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:514)
    at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:507)
    at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:486)
    at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:427)
    at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:111)
    at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:82)
    at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:300)
    at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:335)
    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:588)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:512)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:426)
    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:398)
    at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:877)
    at java.lang.Thread.run(Thread.java:745)
```
",2016-07-20 18:20:52,"[{'commitHash': '647566d8418aabaf06f567e40b4195232986467c', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'b8400f96283fec0b1f60232aab52da06a9921ad6', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['d262f7c1892d1cc93eaffe77144419174ea6e3e7'], 'nameRev': 'b8400f96283fec0b1f60232aab52da06a9921ad6 tags/netty-4.1.4.Final~22', 'commitMessage': '[#5553] SimpleChannelPool#notifyConnect() may leak Channels\n\nMotivation:\n\nThe SimpleChannelPool#notifyConnect() method will leak Channels if the user cancelled the Promise in between.\n\nModifications:\n\nRelease the channel if the Promise was complete before.\n\nResult:\n\nNo more channel leaks.\n', 'commitDateTime': '2016-07-20 20:17:19', 'authoredDateTime': '2016-07-19 20:55:44', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/pool/SimpleChannelPool.java', 'insertions': 6, 'deletions': 2, 'lines': 8}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'SimpleChannelPool.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.pool.SimpleChannelPool.notifyConnect(io.netty.channel.ChannelFuture,io.netty.util.concurrent.Promise)', 'TOT': 6, 'UPD': 0, 'INS': 2, 'MOV': 2, 'DEL': 2}, {'spoonMethodName': 'io.netty.channel.pool.SimpleChannelPool.acquireHealthyFromPoolOrNew(io.netty.util.concurrent.Promise)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.pool.SimpleChannelPool.acquireHealthyFromPoolOrNew(io.netty.util.concurrent.Promise).2.operationComplete(io.netty.channel.ChannelFuture)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '1f3bae78c5823d2e3c43ba0666f889e3850df34a', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['42de9d446ff61524ce37084f33a188eaa69e4f3f'], 'nameRev': '1f3bae78c5823d2e3c43ba0666f889e3850df34a tags/netty-4.0.40.Final~13', 'commitMessage': '[#5553] SimpleChannelPool#notifyConnect() may leak Channels\n\nMotivation:\n\nThe SimpleChannelPool#notifyConnect() method will leak Channels if the user cancelled the Promise in between.\n\nModifications:\n\nRelease the channel if the Promise was complete before.\n\nResult:\n\nNo more channel leaks.\n', 'commitDateTime': '2016-07-20 20:17:46', 'authoredDateTime': '2016-07-19 20:55:44', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/pool/SimpleChannelPool.java', 'insertions': 6, 'deletions': 2, 'lines': 8}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'SimpleChannelPool.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.pool.SimpleChannelPool.notifyConnect(io.netty.channel.ChannelFuture,io.netty.util.concurrent.Promise)', 'TOT': 6, 'UPD': 0, 'INS': 2, 'MOV': 2, 'DEL': 2}, {'spoonMethodName': 'io.netty.channel.pool.SimpleChannelPool.acquireHealthyFromPoolOrNew(io.netty.util.concurrent.Promise)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.pool.SimpleChannelPool.acquireHealthyFromPoolOrNew(io.netty.util.concurrent.Promise).2.operationComplete(io.netty.channel.ChannelFuture)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/5553,0.0002777777777777778,['defect'],SimpleChannelPool#notifyConnect() may leak Channels,1.0,"['io.netty.channel.pool.SimpleChannelPool.acquireHealthyFromPoolOrNew(io.netty.util.concurrent.Promise)', 'io.netty.channel.pool.SimpleChannelPool.acquireHealthyFromPoolOrNew(io.netty.util.concurrent.Promise).2.operationComplete(io.netty.channel.ChannelFuture)', 'io.netty.channel.pool.SimpleChannelPool.notifyConnect(io.netty.channel.ChannelFuture,io.netty.util.concurrent.Promise)']",['b8400f96283fec0b1f60232aab52da06a9921ad6'],,['transport/src/main/java/io/netty/channel/pool'],6.0,2.0,8.0,1.0,0.0,3.0,8.0,2.0,4.0,2.0,1.0,0.0,0.0,0.0,2.0,0.0,0.0,netty
37855,2016-06-08 13:37:13,ylgrgyq,"[OpenSslContext](https://github.com/netty/netty/blob/4.1/handler/src/main/java/io/netty/handler/ssl/OpenSslContext.java) (I mean OpenSslClientContext or OpenSslServerContext exactly) object hold some resources (like custom verification callback to verify ssl certificate) which need to be released when this OpenSslContext object is GC. This is done by JVM calling [`finalize`](https://github.com/netty/netty/blob/4.1/handler/src/main/java/io/netty/handler/ssl/OpenSslContext.java#L352) in OpenSslContext.

But I found that OpenSslContext will never be GC so all the resources possessed by it will never be released. Take [OpenSslClientContext](https://github.com/netty/netty/blob/4.1/handler/src/main/java/io/netty/handler/ssl/OpenSslClientContext.java) as example but the same bug exists in [OpenSslServerContext](https://github.com/netty/netty/blob/4.1/handler/src/main/java/io/netty/handler/ssl/OpenSslServerContext.java) too. In the constructor of OpenSslClientContext, there's [an anonymous class object](https://github.com/netty/netty/blob/4.1/handler/src/main/java/io/netty/handler/ssl/OpenSslClientContext.java#L253) which is used as a custom verification callback to verify certificate and is set into [SSLContext](https://github.com/netty/netty-tcnative/blob/1.1.33/openssl-dynamic/src/main/java/org/apache/tomcat/jni/SSLContext.java) by calling [SSLContext.setCertVerifyCallback](https://github.com/netty/netty-tcnative/blob/1.1.33/openssl-dynamic/src/main/java/org/apache/tomcat/jni/SSLContext.java#L437). This SSLContext.setCertVerifyCallback is a native function in which [a global reference](https://github.com/netty/netty-tcnative/blob/1.1.33/openssl-dynamic/src/main/c/sslcontext.c#L1619) is created and ref to the custom verification callback passed to SSLContext.setCertVerifyCallback. 

So the custom verification callback used to verify certificate will be released only when OpenSslClientContext object is GC. And the OpenSslClientContext object will be GC only when the custom verification callback is removed from JNI global reference.
",2016-06-09 20:40:33,"[{'commitHash': 'fc1fb755f36f38f4ae18ae6c5725c76f20128d04', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '717478713675c1f9c91bfbdaa01492875662e4a1', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '88dbd96376b7878bf4eec217da158419692fae17', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['52bbfd3310aaa45996673749c66b3137893c5849'], 'nameRev': '88dbd96376b7878bf4eec217da158419692fae17 tags/netty-4.1.2.Final~65', 'commitMessage': '[#5372] Ensure OpenSslClientContext / OpenSslServerContext can be garbage collected\n\nMotivation:\n\nOpenSslClientContext / OpenSslServerContext can never be garbage collected as both are part of a reference to a callback that is stored as global reference in jni code.\n\nModifications:\n\nEnsure the callbacks are static and so not hold the reference.\n\nResult:\n\nNo more leak due not collectable OpenSslClientContext / OpenSslServerContext\n', 'commitDateTime': '2016-06-09 22:37:13', 'authoredDateTime': '2016-06-08 15:57:47', 'commitGitStats': [{'filePath': 'handler/src/main/java/io/netty/handler/ssl/OpenSslClientContext.java', 'insertions': 39, 'deletions': 15, 'lines': 54}, {'filePath': 'handler/src/main/java/io/netty/handler/ssl/OpenSslContext.java', 'insertions': 8, 'deletions': 2, 'lines': 10}, {'filePath': 'handler/src/main/java/io/netty/handler/ssl/OpenSslServerContext.java', 'insertions': 39, 'deletions': 15, 'lines': 54}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'OpenSslClientContext.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext', 'TOT': 5, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 3}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext.TrustManagerVerifyCallback', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext.ExtendedTrustManagerVerifyCallback', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext.2', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext.1', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext.2.verify(io.netty.handler.ssl.OpenSslEngine,java.security.cert.X509Certificate[],java.lang.String)', 'TOT': 3, 'UPD': 0, 'INS': 0, 'MOV': 3, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext.1.verify(io.netty.handler.ssl.OpenSslEngine,java.security.cert.X509Certificate[],java.lang.String)', 'TOT': 3, 'UPD': 0, 'INS': 0, 'MOV': 3, 'DEL': 0}]}, {'spoonFilePath': 'OpenSslContext.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.OpenSslContext.AbstractCertificateVerifier.verify(long,byte[][],java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslContext', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslContext.AbstractCertificateVerifier', 'TOT': 3, 'UPD': 0, 'INS': 3, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'OpenSslServerContext.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext', 'TOT': 5, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 3}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext.TrustManagerVerifyCallback', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext.ExtendedTrustManagerVerifyCallback', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext.2', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext.1', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext.2.verify(io.netty.handler.ssl.OpenSslEngine,java.security.cert.X509Certificate[],java.lang.String)', 'TOT': 3, 'UPD': 0, 'INS': 0, 'MOV': 3, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext.1.verify(io.netty.handler.ssl.OpenSslEngine,java.security.cert.X509Certificate[],java.lang.String)', 'TOT': 3, 'UPD': 0, 'INS': 0, 'MOV': 3, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'c5d70ec7dc790d2910130a25984d4db0e56c2480', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['ed7c05f7c52289ac66796bf987f606f0301750df'], 'nameRev': 'c5d70ec7dc790d2910130a25984d4db0e56c2480 tags/netty-4.0.38.Final~49', 'commitMessage': '[#5372] Ensure OpenSslClientContext / OpenSslServerContext can be garbage collected\n\nMotivation:\n\nOpenSslClientContext / OpenSslServerContext can never be garbage collected as both are part of a reference to a callback that is stored as global reference in jni code.\n\nModifications:\n\nEnsure the callbacks are static and so not hold the reference.\n\nResult:\n\nNo more leak due not collectable OpenSslClientContext / OpenSslServerContext\n', 'commitDateTime': '2016-06-09 22:39:33', 'authoredDateTime': '2016-06-08 15:57:47', 'commitGitStats': [{'filePath': 'handler/src/main/java/io/netty/handler/ssl/OpenSslClientContext.java', 'insertions': 39, 'deletions': 15, 'lines': 54}, {'filePath': 'handler/src/main/java/io/netty/handler/ssl/OpenSslContext.java', 'insertions': 8, 'deletions': 2, 'lines': 10}, {'filePath': 'handler/src/main/java/io/netty/handler/ssl/OpenSslServerContext.java', 'insertions': 39, 'deletions': 15, 'lines': 54}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'OpenSslClientContext.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext', 'TOT': 5, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 3}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext.TrustManagerVerifyCallback', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext.ExtendedTrustManagerVerifyCallback', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext.2', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext.1', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext.2.verify(io.netty.handler.ssl.OpenSslEngine,java.security.cert.X509Certificate[],java.lang.String)', 'TOT': 3, 'UPD': 0, 'INS': 0, 'MOV': 3, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslClientContext.1.verify(io.netty.handler.ssl.OpenSslEngine,java.security.cert.X509Certificate[],java.lang.String)', 'TOT': 3, 'UPD': 0, 'INS': 0, 'MOV': 3, 'DEL': 0}]}, {'spoonFilePath': 'OpenSslContext.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.OpenSslContext.AbstractCertificateVerifier.verify(long,byte[][],java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslContext', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslContext.AbstractCertificateVerifier', 'TOT': 3, 'UPD': 0, 'INS': 3, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'OpenSslServerContext.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext', 'TOT': 5, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 3}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext.TrustManagerVerifyCallback', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext.ExtendedTrustManagerVerifyCallback', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext.2', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext.1', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext.2.verify(io.netty.handler.ssl.OpenSslEngine,java.security.cert.X509Certificate[],java.lang.String)', 'TOT': 3, 'UPD': 0, 'INS': 0, 'MOV': 3, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.ssl.OpenSslServerContext.1.verify(io.netty.handler.ssl.OpenSslEngine,java.security.cert.X509Certificate[],java.lang.String)', 'TOT': 3, 'UPD': 0, 'INS': 0, 'MOV': 3, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/5372,1.0002777777777778,['defect'],Leak in OpenSslContext,1.0,"['io.netty.handler.ssl.OpenSslServerContext.2', 'io.netty.handler.ssl.OpenSslContext', 'io.netty.handler.ssl.OpenSslContext.AbstractCertificateVerifier', 'io.netty.handler.ssl.OpenSslContext.AbstractCertificateVerifier.verify(long,byte[][],java.lang.String)', 'io.netty.handler.ssl.OpenSslClientContext.2.verify(io.netty.handler.ssl.OpenSslEngine,java.security.cert.X509Certificate[],java.lang.String)', 'io.netty.handler.ssl.OpenSslServerContext.ExtendedTrustManagerVerifyCallback', 'io.netty.handler.ssl.OpenSslServerContext.1', 'io.netty.handler.ssl.OpenSslClientContext.1', 'io.netty.handler.ssl.OpenSslServerContext.TrustManagerVerifyCallback', 'io.netty.handler.ssl.OpenSslClientContext.2', 'io.netty.handler.ssl.OpenSslClientContext.TrustManagerVerifyCallback', 'io.netty.handler.ssl.OpenSslServerContext.2.verify(io.netty.handler.ssl.OpenSslEngine,java.security.cert.X509Certificate[],java.lang.String)', 'io.netty.handler.ssl.OpenSslClientContext', 'io.netty.handler.ssl.OpenSslServerContext', 'io.netty.handler.ssl.OpenSslClientContext.1.verify(io.netty.handler.ssl.OpenSslEngine,java.security.cert.X509Certificate[],java.lang.String)', 'io.netty.handler.ssl.OpenSslClientContext.ExtendedTrustManagerVerifyCallback', 'io.netty.handler.ssl.OpenSslServerContext.1.verify(io.netty.handler.ssl.OpenSslEngine,java.security.cert.X509Certificate[],java.lang.String)']",['88dbd96376b7878bf4eec217da158419692fae17'],,['handler/src/main/java/io/netty/handler/ssl'],86.0,32.0,118.0,3.0,1.0,17.0,37.0,18.0,12.0,6.0,3.0,0.0,0.0,0.0,3.0,0.0,0.0,netty
37871,2016-04-30 00:46:46,Scottmitch,"RedisDecoder calls `ByteBuf.retain()` and the next line may throw an exception, but the buffer is never released [1]. More investigation is needed in this class whenever retain is called to ensure it is either written or released.

[1] https://github.com/netty/netty/blob/4.1/codec-redis/src/main/java/io/netty/handler/codec/redis/RedisDecoder.java#L208
",2016-05-06 05:46:40,"[{'commitHash': 'f224d82509418e080d6b725132c34dbdd6ca06d8', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '06436efaa1b118eac3526d8f77d9e159d0292959', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['ef13d19b8b5d876463d4365b76d3046410a7811a'], 'nameRev': '06436efaa1b118eac3526d8f77d9e159d0292959 tags/netty-4.1.0.Final~65', 'commitMessage': '[#5190] Ensure memory is not leaked when readEndOfLine(...) throws an exception.\n\nMotivation:\n\nWe need to ensure we not retain the buffer until readEndOfLine(...) completes as otherwise we may leak memory in the case of an exception.\n\nModifications:\n\nOnly call retain after readEndOfLine(...) returns.\n\nResult:\n\nNo more leak in case of exception while decoding redis messages.\n', 'commitDateTime': '2016-05-06 07:45:44', 'authoredDateTime': '2016-05-03 10:32:25', 'commitGitStats': [{'filePath': 'codec-redis/src/main/java/io/netty/handler/codec/redis/RedisDecoder.java', 'insertions': 3, 'deletions': 2, 'lines': 5}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'RedisDecoder.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.redis.RedisDecoder.decodeBulkStringContent(io.netty.buffer.ByteBuf,java.util.List)', 'TOT': 4, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 2}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/5190,6.000277777777778,['defect'],Redis Buffer Leak,1.0,"['io.netty.handler.codec.redis.RedisDecoder.decodeBulkStringContent(io.netty.buffer.ByteBuf,java.util.List)']",['06436efaa1b118eac3526d8f77d9e159d0292959'],,['codec-redis/src/main/java/io/netty/handler/codec/redis'],3.0,2.0,5.0,1.0,0.0,1.0,4.0,1.0,1.0,2.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,netty
37991,2015-09-14 15:55:42,jfarcand,"The Atmosphere Framework bundles the [ForkJoinPool](https://github.com/netty/netty/blob/master/common/src/main/java/io/netty/util/internal/chmv8/ForkJoinPool.java) implementation of Netty. It seems there is a Thread Local leak as reported [here](https://github.com/Atmosphere/atmosphere/issues/2048)

``` java
SEVERE: The web application [/atmosphere-chat] created a ThreadLocal with key of type [java.lang.ThreadLocal] (value [java.lang.ThreadLocal@41a80e5a]) and a value of type [org.atmosphere.util.chmv8.ForkJoinPool.Submitter]
 (value [org.atmosphere.util.chmv8.ForkJoinPool$Submitter@450ae3fb]) but failed to remove it when the web application was stopped. This is very likely to create a memory leak.
```

When using the JDK7/8 implementation the leak doesn't occurs (no error message) so I suspect the current implementation leaks.
",2016-05-18 08:54:58,"[{'commitHash': '55dd7d035fad00ef8681b0007eade6232f832e3a', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['2b340df452d5ec282b7cefd15f887f31604b9425'], 'nameRev': '55dd7d035fad00ef8681b0007eade6232f832e3a tags/netty-4.1.0.Final~23', 'commitMessage': ""Fix a class loader leak in ForkJoinPool\n\nMotivation:\n\nAs reported in #4211, when using Netty in Tomcat (or other container based deployment), ForkJoinPool leaks an instance of `Submitter` so that the class loader of `Submitter` won't be GCed. However, since `Submitter` is just a wrapper of `int`, we can replace it with `int[1]`.\n\nModifications:\n\nReplace `Submitter` with `int[1]`.\n\nResult:\n\nNo class loader leak in ForkJoinPool when using in a container.\n"", 'commitDateTime': '2016-05-18 10:53:33', 'authoredDateTime': '2016-05-17 19:05:29', 'commitGitStats': [{'filePath': 'common/src/main/java/io/netty/util/internal/chmv8/ForkJoinPool.java', 'insertions': 23, 'deletions': 18, 'lines': 41}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ForkJoinPool.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.internal.chmv8.ForkJoinPool.externalPush(io.netty.util.internal.chmv8.ForkJoinTask)', 'TOT': 3, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.util.internal.chmv8.ForkJoinPool.commonSubmitterQueue()', 'TOT': 3, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.util.internal.chmv8.ForkJoinPool.tryExternalUnpush(io.netty.util.internal.chmv8.ForkJoinTask)', 'TOT': 3, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.util.internal.chmv8.ForkJoinPool.externalHelpComplete(io.netty.util.internal.chmv8.CountedCompleter)', 'TOT': 3, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.util.internal.chmv8.ForkJoinPool.fullExternalPush(io.netty.util.internal.chmv8.ForkJoinTask)', 'TOT': 7, 'UPD': 1, 'INS': 3, 'MOV': 0, 'DEL': 3}, {'spoonMethodName': 'io.netty.util.internal.chmv8.ForkJoinPool.Submitter', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '28bc1070e7f89021fc6afa96b0c79c33353810cf', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['f984870ccca133d6056e8b0df0b2352f8f90b0fe'], 'nameRev': '28bc1070e7f89021fc6afa96b0c79c33353810cf tags/netty-4.0.37.Final~39', 'commitMessage': ""Fix a class loader leak in ForkJoinPool\n\nMotivation:\n\nAs reported in #4211, when using Netty in Tomcat (or other container based deployment), ForkJoinPool leaks an instance of `Submitter` so that the class loader of `Submitter` won't be GCed. However, since `Submitter` is just a wrapper of `int`, we can replace it with `int[1]`.\n\nModifications:\n\nReplace `Submitter` with `int[1]`.\n\nResult:\n\nNo class loader leak in ForkJoinPool when using in a container.\n"", 'commitDateTime': '2016-05-18 10:53:49', 'authoredDateTime': '2016-05-17 19:05:29', 'commitGitStats': [{'filePath': 'common/src/main/java/io/netty/util/internal/chmv8/ForkJoinPool.java', 'insertions': 23, 'deletions': 18, 'lines': 41}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ForkJoinPool.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.internal.chmv8.ForkJoinPool.externalPush(io.netty.util.internal.chmv8.ForkJoinTask)', 'TOT': 3, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.util.internal.chmv8.ForkJoinPool.commonSubmitterQueue()', 'TOT': 3, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.util.internal.chmv8.ForkJoinPool.tryExternalUnpush(io.netty.util.internal.chmv8.ForkJoinTask)', 'TOT': 3, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.util.internal.chmv8.ForkJoinPool.externalHelpComplete(io.netty.util.internal.chmv8.CountedCompleter)', 'TOT': 3, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.util.internal.chmv8.ForkJoinPool.fullExternalPush(io.netty.util.internal.chmv8.ForkJoinTask)', 'TOT': 7, 'UPD': 1, 'INS': 3, 'MOV': 0, 'DEL': 3}, {'spoonMethodName': 'io.netty.util.internal.chmv8.ForkJoinPool.Submitter', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/4211,246.00027777777777,['defect'],[ForkJoinPool] Thread Local Leak detected,1.0,"['io.netty.util.internal.chmv8.ForkJoinPool.externalPush(io.netty.util.internal.chmv8.ForkJoinTask)', 'io.netty.util.internal.chmv8.ForkJoinPool.tryExternalUnpush(io.netty.util.internal.chmv8.ForkJoinTask)', 'io.netty.util.internal.chmv8.ForkJoinPool.fullExternalPush(io.netty.util.internal.chmv8.ForkJoinTask)', 'io.netty.util.internal.chmv8.ForkJoinPool.commonSubmitterQueue()', 'io.netty.util.internal.chmv8.ForkJoinPool.Submitter', 'io.netty.util.internal.chmv8.ForkJoinPool.externalHelpComplete(io.netty.util.internal.chmv8.CountedCompleter)']",['55dd7d035fad00ef8681b0007eade6232f832e3a'],,['common/src/main/java/io/netty/util/internal/chmv8'],23.0,18.0,41.0,1.0,5.0,6.0,20.0,0.0,7.0,8.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,netty
37992,2015-09-10 18:09:15,ninja-,"Scenario:
netty 4.1
user calls writeAndFlush(packet)

Expected behaviour:

the packet is ALWAYS written and flushed...
(want a unit test in the future? stress writeAndFlush() + check that outbound buffer is empty)

What can happen:

the explict flush can be ignored because of improrer use of the OP_WRITE/EPOLLOUT flag.......
(it only gets called later on by the event loop)
it's a pretty serious bug because it increases used resources(5 million ChannelOutboundBuffer$Entrys anyone?)
please note that channel.isWritable() etc. etc. is NOT involved in this

the flag is not always turned on when there's work to do, it's the same problem on epoll and nio backends.

example(confirmed working) patch:

```
Index: transport-native-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollStreamChannel.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- transport-native-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollStreamChannel.java (revision 250a09df635d70853e1576a9e522c846e918938e)
+++ transport-native-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollStreamChannel.java (revision )
@@ -389,6 +389,8 @@
                 // Wrote all messages.
                 clearFlag(Native.EPOLLOUT);
                 break;
+            } else {
+                setFlag(Native.EPOLLOUT);
             }
```

nio has the same behaviour and this line at NIO can be blamed
https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/socket/nio/NioSocketChannel.java#L271
or more like https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/socket/nio/NioSocketChannel.java#L283 should also set opwrite

I hope this gives you an idea of what is wrong and you guys can think of a ""better"" way to fix it(but I will also look for a such a way in the meantime)
",2015-09-16 09:01:10,"[{'commitHash': '3b89472a401cca177f1453596d1f5eb398078047', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '2290eb2def531b1d892d8e8cfdba66c4013105d7', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '211bb100463f35a49d759e0e1af7db48e65859cc', 'commitGHEventType': 'referenced', 'commitUser': 'ninja-', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '7961138f5278380da0397df5efb2863dad0b2333', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['0915b1b215ffe8dda34575f874761ca57a30f286'], 'nameRev': '7961138f5278380da0397df5efb2863dad0b2333 tags/netty-4.0.32.Final~18', 'commitMessage': '[#4205] Correctly set EPOLLOUT flag whe writeBytes(...) was not able to write everything\n\nMotivation:\n\nwriteBytes(...) missed to set EPOLLOUT flag when not all bytes were written. This could lead to have the EpollEventLoop not try to flush the remaining bytes once the socket becomes writable again.\n\nModifications:\n\n- Move setting EPOLLOUT flag logic to one point so we are sure we always do it.\n- Move OP_WRITE flag logic to one point as well.\n\nResult:\n\nCorrectly try to write pending data if socket becomes writable again.\n', 'commitDateTime': '2015-09-16 07:28:28', 'authoredDateTime': '2015-09-10 21:23:23', 'commitGitStats': [{'filePath': 'transport-native-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollStreamChannel.java', 'insertions': 7, 'deletions': 10, 'lines': 17}, {'filePath': 'transport/src/main/java/io/netty/channel/nio/AbstractNioByteChannel.java', 'insertions': 6, 'deletions': 5, 'lines': 11}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AbstractEpollStreamChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollStreamChannel.writeBytesMultiple(io.netty.channel.ChannelOutboundBuffer,io.netty.channel.epoll.IovArray,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollStreamChannel.writeBytesMultiple(io.netty.channel.ChannelOutboundBuffer,java.nio.ByteBuffer[],int,long,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollStreamChannel.writeFileRegion(io.netty.channel.ChannelOutboundBuffer,io.netty.channel.DefaultFileRegion,int)', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollStreamChannel.doWrite(io.netty.channel.ChannelOutboundBuffer)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'AbstractNioByteChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.nio.AbstractNioByteChannel.doWrite(io.netty.channel.ChannelOutboundBuffer)', 'TOT': 6, 'UPD': 0, 'INS': 1, 'MOV': 2, 'DEL': 3}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '076d4ed5147f186b5e5a25945b77bce63c0d0165', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['cac51ab8d68412a3db6b6c3310e5ed0f842865c2'], 'nameRev': '076d4ed5147f186b5e5a25945b77bce63c0d0165 tags/netty-4.1.0.Beta7~43', 'commitMessage': '[#4205] Correctly set EPOLLOUT flag whe writeBytes(...) was not able to write everything\n\nMotivation:\n\nwriteBytes(...) missed to set EPOLLOUT flag when not all bytes were written. This could lead to have the EpollEventLoop not try to flush the remaining bytes once the socket becomes writable again.\n\nModifications:\n\n- Move setting EPOLLOUT flag logic to one point so we are sure we always do it.\n- Move OP_WRITE flag logic to one point as well.\n\nResult:\n\nCorrectly try to write pending data if socket becomes writable again.\n', 'commitDateTime': '2015-09-16 07:30:17', 'authoredDateTime': '2015-09-10 21:23:23', 'commitGitStats': [{'filePath': 'transport-native-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollStreamChannel.java', 'insertions': 7, 'deletions': 10, 'lines': 17}, {'filePath': 'transport/src/main/java/io/netty/channel/nio/AbstractNioByteChannel.java', 'insertions': 6, 'deletions': 5, 'lines': 11}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AbstractEpollStreamChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollStreamChannel.writeBytesMultiple(io.netty.channel.ChannelOutboundBuffer,io.netty.channel.epoll.IovArray,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollStreamChannel.writeBytesMultiple(io.netty.channel.ChannelOutboundBuffer,java.nio.ByteBuffer[],int,long,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollStreamChannel.writeFileRegion(io.netty.channel.ChannelOutboundBuffer,io.netty.channel.DefaultFileRegion,int)', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollStreamChannel.doWrite(io.netty.channel.ChannelOutboundBuffer)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'AbstractNioByteChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.nio.AbstractNioByteChannel.doWrite(io.netty.channel.ChannelOutboundBuffer)', 'TOT': 6, 'UPD': 0, 'INS': 1, 'MOV': 2, 'DEL': 3}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '943db1cea0b96208c060a675bc19b4031bfdd6b6', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['82f6a079f6790881f2265f14966878856506f78a'], 'nameRev': '943db1cea0b96208c060a675bc19b4031bfdd6b6 remotes/origin/master_deprecated~164', 'commitMessage': '[#4205] Correctly set EPOLLOUT flag whe writeBytes(...) was not able to write everything\n\nMotivation:\n\nwriteBytes(...) missed to set EPOLLOUT flag when not all bytes were written. This could lead to have the EpollEventLoop not try to flush the remaining bytes once the socket becomes writable again.\n\nModifications:\n\n- Move setting EPOLLOUT flag logic to one point so we are sure we always do it.\n- Move OP_WRITE flag logic to one point as well.\n\nResult:\n\nCorrectly try to write pending data if socket becomes writable again.\n', 'commitDateTime': '2015-09-16 10:45:48', 'authoredDateTime': '2015-09-10 21:23:23', 'commitGitStats': [{'filePath': 'transport-native-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollStreamChannel.java', 'insertions': 7, 'deletions': 10, 'lines': 17}, {'filePath': 'transport/src/main/java/io/netty/channel/nio/AbstractNioByteChannel.java', 'insertions': 6, 'deletions': 5, 'lines': 11}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AbstractEpollStreamChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollStreamChannel.writeBytesMultiple(io.netty.channel.ChannelOutboundBuffer,io.netty.channel.epoll.IovArray,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollStreamChannel.writeBytesMultiple(io.netty.channel.ChannelOutboundBuffer,java.nio.ByteBuffer[],int,long,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollStreamChannel.writeFileRegion(io.netty.channel.ChannelOutboundBuffer,io.netty.channel.DefaultFileRegion,int)', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.netty.channel.epoll.AbstractEpollStreamChannel.doWrite(io.netty.channel.ChannelOutboundBuffer)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'AbstractNioByteChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.nio.AbstractNioByteChannel.doWrite(io.netty.channel.ChannelOutboundBuffer)', 'TOT': 6, 'UPD': 0, 'INS': 1, 'MOV': 2, 'DEL': 3}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/4205,5.000277777777778,['defect'],"[FIX INCLUDED] Improrer use of the ""write"" flag causes flush() to be ignored, increasing used resources",1.0,"['io.netty.channel.epoll.AbstractEpollStreamChannel.writeBytesMultiple(io.netty.channel.ChannelOutboundBuffer,io.netty.channel.epoll.IovArray,int)', 'io.netty.channel.epoll.AbstractEpollStreamChannel.writeBytesMultiple(io.netty.channel.ChannelOutboundBuffer,java.nio.ByteBuffer[],int,long,int)', 'io.netty.channel.epoll.AbstractEpollStreamChannel.doWrite(io.netty.channel.ChannelOutboundBuffer)', 'io.netty.channel.epoll.AbstractEpollStreamChannel.writeFileRegion(io.netty.channel.ChannelOutboundBuffer,io.netty.channel.DefaultFileRegion,int)', 'io.netty.channel.nio.AbstractNioByteChannel.doWrite(io.netty.channel.ChannelOutboundBuffer)']",['7961138f5278380da0397df5efb2863dad0b2333'],,"['transport-native-epoll/src/main/java/io/netty/channel/epoll', 'transport/src/main/java/io/netty/channel/nio']",13.0,15.0,28.0,2.0,0.0,5.0,12.0,3.0,2.0,7.0,2.0,0.0,0.0,0.0,5.0,0.0,0.0,netty
38042,2015-05-28 08:39:01,suyanNone,"I found DirectBufferR is reference by ThreadLocal in the sender side even the message is already received by the receiver for a long time.
this problem is occurs in SPARK, which use netty to send block.
I not familiar with netty, or there have other solution to resolve that problem
",2015-06-04 10:35:08,"[{'commitHash': 'c2db485e29db509a22c2f71793ed4fd856babcef', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '5d4e34b021229b988d41742e0c85dba0d940260e', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['a1afaf4c3558242f017b38f20ea144e327dfef9f'], 'nameRev': '5d4e34b021229b988d41742e0c85dba0d940260e tags/netty-4.0.29.Final~21', 'commitMessage': '[#3837] Null out ByteBuffer[] array once done\n\nMotivation:\n\nthe ByteBuffer[] that we keep in the ThreadLocal are never nulled out which can lead to have ByteBuffer instances sit there forever.\nThis is even a bigger problem if nioBuffer() of ByteBuffer returns a new ByteBuffer that can not be destroyed by ByteBuffer.release().\n\nModifications:\n\nNull out ByteBuffer array after processing.\n\nResult:\n\nNo more dangling references after done.\n', 'commitDateTime': '2015-06-04 12:33:13', 'authoredDateTime': '2015-05-29 08:04:34', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/ChannelOutboundBuffer.java', 'insertions': 15, 'deletions': 0, 'lines': 15}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ChannelOutboundBuffer.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.clearNioBuffers()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.removeBytes(long)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.close(java.nio.channels.ClosedChannelException)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.remove()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.remove0(java.lang.Throwable,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'ed3d26cf7d2ab0ddd4a7c5729a0a6ced60240780', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['5d11be58ea28c8832a2572acdbef7f467ccc19c0'], 'nameRev': 'ed3d26cf7d2ab0ddd4a7c5729a0a6ced60240780 tags/netty-4.1.0.Beta6~167', 'commitMessage': '[#3837] Null out ByteBuffer[] array once done\n\nMotivation:\n\nthe ByteBuffer[] that we keep in the ThreadLocal are never nulled out which can lead to have ByteBuffer instances sit there forever.\nThis is even a bigger problem if nioBuffer() of ByteBuffer returns a new ByteBuffer that can not be destroyed by ByteBuffer.release().\n\nModifications:\n\nNull out ByteBuffer array after processing.\n\nResult:\n\nNo more dangling references after done.\n', 'commitDateTime': '2015-06-04 12:33:25', 'authoredDateTime': '2015-05-29 08:04:34', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/ChannelOutboundBuffer.java', 'insertions': 15, 'deletions': 0, 'lines': 15}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ChannelOutboundBuffer.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.clearNioBuffers()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.removeBytes(long)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.close(java.nio.channels.ClosedChannelException)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.remove()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.remove0(java.lang.Throwable,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'c999dc6f20d7ac1c81a06933550648ddfc38878e', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['86a7c6d9ee3beb7a1d28f6bf077536f847f66d4e'], 'nameRev': 'c999dc6f20d7ac1c81a06933550648ddfc38878e remotes/origin/master_deprecated~346', 'commitMessage': '[#3837] Null out ByteBuffer[] array once done\n\nMotivation:\n\nthe ByteBuffer[] that we keep in the ThreadLocal are never nulled out which can lead to have ByteBuffer instances sit there forever.\nThis is even a bigger problem if nioBuffer() of ByteBuffer returns a new ByteBuffer that can not be destroyed by ByteBuffer.release().\n\nModifications:\n\nNull out ByteBuffer array after processing.\n\nResult:\n\nNo more dangling references after done.\n', 'commitDateTime': '2015-06-04 12:33:34', 'authoredDateTime': '2015-05-29 08:04:34', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/ChannelOutboundBuffer.java', 'insertions': 15, 'deletions': 0, 'lines': 15}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ChannelOutboundBuffer.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.clearNioBuffers()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.removeBytes(long)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.close(java.nio.channels.ClosedChannelException)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.remove()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.ChannelOutboundBuffer.remove0(java.lang.Throwable,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/3837,7.000277777777778,['defect'],Did ChannelOutBoundBuffer need to remove NIOBUFFER threadLocal while the message is done,1.0,"['io.netty.channel.ChannelOutboundBuffer.close(java.nio.channels.ClosedChannelException)', 'io.netty.channel.ChannelOutboundBuffer.remove0(java.lang.Throwable,boolean)', 'io.netty.channel.ChannelOutboundBuffer.remove()', 'io.netty.channel.ChannelOutboundBuffer.removeBytes(long)', 'io.netty.channel.ChannelOutboundBuffer.clearNioBuffers()']",['5d4e34b021229b988d41742e0c85dba0d940260e'],,['transport/src/main/java/io/netty/channel'],15.0,0.0,15.0,1.0,0.0,5.0,5.0,0.0,5.0,0.0,1.0,0.0,0.0,0.0,3.0,0.0,0.0,netty
38136,2014-11-21 02:42:46,ylgrgyq,"In Netty.4.0.24.final.

In class io.netty.util.Recycler, there's a DEFAULT_MAX_CAPACITY variable to constrain the size of the stack in Recycler. From INITIAL_CAPACITY, whenever the stack is full, it's size doubled until hitting the DEFAULT_MAX_CAPACITY limit(Line 341 in Netty.4.0.24.final). 
![image](https://cloud.githubusercontent.com/assets/1115061/5156597/45b7fa9a-730a-11e4-89aa-bb1f87c47428.png)
As you can see in the image above, stack size is constrained by maxCapacity. And if the size > maxCapacity, this check will fail forever, beacuse the check use ""if (size == maxCapacity)"" rather than ""if (size > maxCapacity)"".  And there's a way to set size bigger than maxCapacity.

In class WeakOrderQueue which is an inner class in Recycler, there's a method called ""transfer"" which can also double the stack size in Recycler, but there's no check to ensure the stack size not exceed DEFAULT_MAX_CAPACITY limit(Line 218 in Netty.4.0.24.final) like the one mentioned before. 
![image](https://cloud.githubusercontent.com/assets/1115061/5156598/5a17c01a-730a-11e4-873b-1e65ee539db3.png)
In the image above, variable ""to"" is a stack in Recycler and count is resources's quantity recycled by other thread rather than the Recycler's owner. If there's no enough space for those resources to be recycled, the stack's size will be doubled. I think there should have a check for the stack size here. And whenever the stack size greater than maxCapacity, it can grow infinitely.
",2016-11-02 07:51:20,"[{'commitHash': '77ec337e475660cb12a83dc05a968eabc81f6725', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '989cbbeab97f27edb7b3374d469478674f7753eb', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'a9fda3c8e0b20a1a3da0353c033cb57be7ad49b2', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['66834bc818013aa5923207226e29a0b47ff2d113'], 'nameRev': 'a9fda3c8e0b20a1a3da0353c033cb57be7ad49b2 tags/netty-4.0.25.Final~69', 'commitMessage': ""Fix a bug where Recycler's capacity can increase beyond its maximum\n\nRelated: #3166\n\nMotivation:\n\nWhen the recyclable object created at one thread is returned at the\nother thread, it is stored in a WeakOrderedQueue.\n\nThe objects stored in the WeakOrderedQueue is added back to the stack by\nWeakOrderedQueue.transfer() when the owner thread ran out of recyclable\nobjects.\n\nHowever, WeakOrderedQueue.transfer() does not have any mechanism that\nprevents the stack from growing beyond its maximum capacity.\n\nModifications:\n\n- Make WeakOrderedQueue.transfer() increase the capacity of the stack\n  only up to its maximum\n- Add tests for the cases where the recyclable object is returned at the\n  non-owner thread\n- Fix a bug where Stack.scavengeSome() does not scavenge the objects\n  when it's the first time it ran out of objects and thus its cursor is\n  null.\n- Overall clean-up of scavengeSome() and transfer()\n\nResult:\n\nThe capacity of Stack never increases beyond its maximum.\n"", 'commitDateTime': '2014-12-06 17:56:10', 'authoredDateTime': '2014-12-05 21:09:28', 'commitGitStats': [{'filePath': 'common/src/main/java/io/netty/util/Recycler.java', 'insertions': 77, 'deletions': 35, 'lines': 112}, {'filePath': 'common/src/test/java/io/netty/util/RecyclerTest.java', 'insertions': 73, 'deletions': 4, 'lines': 77}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'Recycler.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.Recycler.WeakOrderQueue.transfer(io.netty.util.Recycler$Stack)', 'TOT': 70, 'UPD': 26, 'INS': 9, 'MOV': 23, 'DEL': 12}, {'spoonMethodName': 'io.netty.util.Recycler.Stack.push(io.netty.util.Recycler$DefaultHandle)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.Recycler.Stack', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.util.Recycler.Stack.scavengeSome()', 'TOT': 16, 'UPD': 0, 'INS': 4, 'MOV': 9, 'DEL': 3}, {'spoonMethodName': 'io.netty.util.Recycler.threadLocalSize()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.Recycler.Stack.increaseCapacity(int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RecyclerTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.RecyclerTest.testRecycle()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.RecyclerTest.testMaxCapacity(int)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.RecyclerTest.testRecycleAtDifferentThread()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.RecyclerTest.testMaxCapacityWithRecycleAtDifferentThread()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '7f92771496ef59eaf6fe86b516f5a8abdb38b9c0', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['a79466769fe359fbfc5cbca8d55e64197e049176'], 'nameRev': '7f92771496ef59eaf6fe86b516f5a8abdb38b9c0 tags/netty-4.1.0.Beta4~164', 'commitMessage': ""Fix a bug where Recycler's capacity can increase beyond its maximum\n\nRelated: #3166\n\nMotivation:\n\nWhen the recyclable object created at one thread is returned at the\nother thread, it is stored in a WeakOrderedQueue.\n\nThe objects stored in the WeakOrderedQueue is added back to the stack by\nWeakOrderedQueue.transfer() when the owner thread ran out of recyclable\nobjects.\n\nHowever, WeakOrderedQueue.transfer() does not have any mechanism that\nprevents the stack from growing beyond its maximum capacity.\n\nModifications:\n\n- Make WeakOrderedQueue.transfer() increase the capacity of the stack\n  only up to its maximum\n- Add tests for the cases where the recyclable object is returned at the\n  non-owner thread\n- Fix a bug where Stack.scavengeSome() does not scavenge the objects\n  when it's the first time it ran out of objects and thus its cursor is\n  null.\n- Overall clean-up of scavengeSome() and transfer()\n\nResult:\n\nThe capacity of Stack never increases beyond its maximum.\n"", 'commitDateTime': '2014-12-06 17:58:31', 'authoredDateTime': '2014-12-05 21:09:28', 'commitGitStats': [{'filePath': 'common/src/main/java/io/netty/util/Recycler.java', 'insertions': 77, 'deletions': 35, 'lines': 112}, {'filePath': 'common/src/test/java/io/netty/util/RecyclerTest.java', 'insertions': 73, 'deletions': 4, 'lines': 77}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'Recycler.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.Recycler.WeakOrderQueue.transfer(io.netty.util.Recycler$Stack)', 'TOT': 70, 'UPD': 26, 'INS': 9, 'MOV': 23, 'DEL': 12}, {'spoonMethodName': 'io.netty.util.Recycler.Stack.push(io.netty.util.Recycler$DefaultHandle)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.Recycler.Stack', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.util.Recycler.Stack.scavengeSome()', 'TOT': 16, 'UPD': 0, 'INS': 4, 'MOV': 9, 'DEL': 3}, {'spoonMethodName': 'io.netty.util.Recycler.threadLocalSize()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.Recycler.Stack.increaseCapacity(int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RecyclerTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.RecyclerTest.testRecycle()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.RecyclerTest.testMaxCapacity(int)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.RecyclerTest.testRecycleAtDifferentThread()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.RecyclerTest.testMaxCapacityWithRecycleAtDifferentThread()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '13ad58aed7006fae8a87696fdf0b37295632bdc3', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['47319d3cfca84c9fcd5eebea8d401c5ddc00113d'], 'nameRev': '13ad58aed7006fae8a87696fdf0b37295632bdc3 tags/netty-5.0.0.Alpha2~175', 'commitMessage': ""Fix a bug where Recycler's capacity can increase beyond its maximum\n\nRelated: #3166\n\nMotivation:\n\nWhen the recyclable object created at one thread is returned at the\nother thread, it is stored in a WeakOrderedQueue.\n\nThe objects stored in the WeakOrderedQueue is added back to the stack by\nWeakOrderedQueue.transfer() when the owner thread ran out of recyclable\nobjects.\n\nHowever, WeakOrderedQueue.transfer() does not have any mechanism that\nprevents the stack from growing beyond its maximum capacity.\n\nModifications:\n\n- Make WeakOrderedQueue.transfer() increase the capacity of the stack\n  only up to its maximum\n- Add tests for the cases where the recyclable object is returned at the\n  non-owner thread\n- Fix a bug where Stack.scavengeSome() does not scavenge the objects\n  when it's the first time it ran out of objects and thus its cursor is\n  null.\n- Overall clean-up of scavengeSome() and transfer()\n\nResult:\n\nThe capacity of Stack never increases beyond its maximum.\n"", 'commitDateTime': '2014-12-06 17:58:53', 'authoredDateTime': '2014-12-05 21:09:28', 'commitGitStats': [{'filePath': 'common/src/main/java/io/netty/util/Recycler.java', 'insertions': 77, 'deletions': 35, 'lines': 112}, {'filePath': 'common/src/test/java/io/netty/util/RecyclerTest.java', 'insertions': 73, 'deletions': 4, 'lines': 77}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'Recycler.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.Recycler.WeakOrderQueue.transfer(io.netty.util.Recycler$Stack)', 'TOT': 70, 'UPD': 26, 'INS': 9, 'MOV': 23, 'DEL': 12}, {'spoonMethodName': 'io.netty.util.Recycler.Stack.push(io.netty.util.Recycler$DefaultHandle)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.Recycler.Stack', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.util.Recycler.Stack.scavengeSome()', 'TOT': 16, 'UPD': 0, 'INS': 4, 'MOV': 9, 'DEL': 3}, {'spoonMethodName': 'io.netty.util.Recycler.threadLocalSize()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.Recycler.Stack.increaseCapacity(int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RecyclerTest.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.util.RecyclerTest.testRecycle()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.RecyclerTest.testMaxCapacity(int)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.RecyclerTest.testRecycleAtDifferentThread()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.util.RecyclerTest.testMaxCapacityWithRecycleAtDifferentThread()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/3166,712.0002777777778,['defect'],Recycler could cache infinite resources,1.0,"['io.netty.util.Recycler.Stack.increaseCapacity(int)', 'io.netty.util.Recycler.Stack', 'io.netty.util.Recycler.threadLocalSize()', 'io.netty.util.Recycler.Stack.scavengeSome()', 'io.netty.util.Recycler.Stack.push(io.netty.util.Recycler$DefaultHandle)', 'io.netty.util.Recycler.WeakOrderQueue.transfer(io.netty.util.Recycler$Stack)']",['a9fda3c8e0b20a1a3da0353c033cb57be7ad49b2'],,['common/src/main/java/io/netty/util'],77.0,35.0,112.0,1.0,27.0,6.0,91.0,32.0,16.0,16.0,1.0,0.0,0.0,0.0,4.0,0.0,0.0,netty
38175,2014-09-22 04:45:05,garretwu,"When MeoryRegionCache's trim() is triggered, some unused cache entries will be freed(Start from head). However, in MeoryRegionCache.trim() the head is not updated, which make entry list's head point to an entry whose chunk is null(freed in trim()) and following allocate of MeoryRegionCache will return false immediately.

In other word, cache is no longer usable once trim happen.
",2014-09-22 09:05:08,"[{'commitHash': '687d3d3b5c5ab67f7a8521d0995da51a0f326097', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['9479cdd0d4e70e94493109fd50d3572e3e8dcd13'], 'nameRev': '687d3d3b5c5ab67f7a8521d0995da51a0f326097 tags/netty-4.0.24.Final~36', 'commitMessage': ""[#2924] Correctly update head in MemoryRegionCache.trim()\n\nMotivation:\nWhen MemoryRegionCache.trim() is called, some unused cache entries will be freed (started from head). However, in MeoryRegionCache.trim() the head is not updated, which make entry list's head point to an entry whose chunk is null now and following allocate of MeoryRegionCache will return false immediately.\n\nIn other word, cache is no longer usable once trim happen.\n\nModifications:\n\nUpdate head to correct idx after free entries in trim().\n\nResult:\n\nMemoryRegionCache behaves correctly even after calling trim().\n"", 'commitDateTime': '2014-09-22 10:56:17', 'authoredDateTime': '2014-09-22 10:56:17', 'commitGitStats': [{'filePath': 'buffer/src/main/java/io/netty/buffer/PoolThreadCache.java', 'insertions': 5, 'deletions': 1, 'lines': 6}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'PoolThreadCache.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolThreadCache.MemoryRegionCache.trim()', 'TOT': 3, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '858de5699baacfa0de0810cf8da631f83d6f3e87', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['a25c585f39aefc9cfd45d8190239f3443e729c03'], 'nameRev': '858de5699baacfa0de0810cf8da631f83d6f3e87 tags/netty-4.1.0.Beta4~259', 'commitMessage': ""[#2924] Correctly update head in MemoryRegionCache.trim()\n\nMotivation:\nWhen MemoryRegionCache.trim() is called, some unused cache entries will be freed (started from head). However, in MeoryRegionCache.trim() the head is not updated, which make entry list's head point to an entry whose chunk is null now and following allocate of MeoryRegionCache will return false immediately.\n\nIn other word, cache is no longer usable once trim happen.\n\nModifications:\n\nUpdate head to correct idx after free entries in trim().\n\nResult:\n\nMemoryRegionCache behaves correctly even after calling trim().\n"", 'commitDateTime': '2014-09-22 11:04:21', 'authoredDateTime': '2014-09-22 10:56:17', 'commitGitStats': [{'filePath': 'buffer/src/main/java/io/netty/buffer/PoolThreadCache.java', 'insertions': 5, 'deletions': 1, 'lines': 6}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'PoolThreadCache.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolThreadCache.MemoryRegionCache.trim()', 'TOT': 3, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '4131e1dfd31679294a5200b82d1c177c21ddab76', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['764e6c3bb719b3542c3ae20db61cccec8122e0cb'], 'nameRev': '4131e1dfd31679294a5200b82d1c177c21ddab76 tags/netty-5.0.0.Alpha2~327', 'commitMessage': ""[#2924] Correctly update head in MemoryRegionCache.trim()\n\nMotivation:\nWhen MemoryRegionCache.trim() is called, some unused cache entries will be freed (started from head). However, in MeoryRegionCache.trim() the head is not updated, which make entry list's head point to an entry whose chunk is null now and following allocate of MeoryRegionCache will return false immediately.\n\nIn other word, cache is no longer usable once trim happen.\n\nModifications:\n\nUpdate head to correct idx after free entries in trim().\n\nResult:\n\nMemoryRegionCache behaves correctly even after calling trim().\n"", 'commitDateTime': '2014-09-22 11:04:50', 'authoredDateTime': '2014-09-22 10:56:17', 'commitGitStats': [{'filePath': 'buffer/src/main/java/io/netty/buffer/PoolThreadCache.java', 'insertions': 5, 'deletions': 1, 'lines': 6}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'PoolThreadCache.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolThreadCache.MemoryRegionCache.trim()', 'TOT': 3, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/2924,0.0002777777777777778,['defect'],head is not updated when trim MemoryRegionCache,1.0,['io.netty.buffer.PoolThreadCache.MemoryRegionCache.trim()'],['687d3d3b5c5ab67f7a8521d0995da51a0f326097'],,['buffer/src/main/java/io/netty/buffer'],5.0,1.0,6.0,1.0,0.0,1.0,3.0,0.0,2.0,1.0,1.0,0.0,0.0,0.0,2.0,0.0,0.0,netty
38234,2014-07-08 16:27:40,frouleau,"Using Netty 4.0.21.Final.

While debuging my code in paranoid mode, a temporary problem on my DNS leads to IOException. Then the leak detector triggers that the ByteBuf allocated in io.netty.channel.socket.nio.NioDatagramChannel.doWriteMessage(NioDatagramChannel.java:298) was not released before being GC.

While looking at the code, it seems obvious than if an exception is triggered during the call of DatagramChannel.send() or write(), the ByteBuf allocated when needsCopy var is true will be lost.

This problem was resolved in 4.1 branch while solving issue #2239.
",2014-07-08 18:19:46,"[{'commitHash': '21aa3d899762f741de57f762783e75452bd312eb', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['26c20c91bd009e0dfbdbe7320c9774f78573b7e9'], 'nameRev': '21aa3d899762f741de57f762783e75452bd312eb tags/netty-4.0.22.Final~71', 'commitMessage': '[#2644] Correctly release buffer when exception happens during send DatagramPacket or SctpMessage\n\nMotivation:\n\nWhen an exception is thrown during try to send DatagramPacket or SctpMessage a buffer may leak.\n\nModification:\n\nCorrectly handle allocated buffers in case of exception\n\nResult:\n\nNo more leaks\n', 'commitDateTime': '2014-07-08 20:15:33', 'authoredDateTime': '2014-07-08 20:15:33', 'commitGitStats': [{'filePath': 'transport-sctp/src/main/java/io/netty/channel/sctp/nio/NioSctpChannel.java', 'insertions': 14, 'deletions': 10, 'lines': 24}, {'filePath': 'transport/src/main/java/io/netty/channel/socket/nio/NioDatagramChannel.java', 'insertions': 25, 'deletions': 20, 'lines': 45}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'NioSctpChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.sctp.nio.NioSctpChannel.doWriteMessage(java.lang.Object,io.netty.channel.ChannelOutboundBuffer)', 'TOT': 6, 'UPD': 0, 'INS': 2, 'MOV': 4, 'DEL': 0}]}, {'spoonFilePath': 'NioDatagramChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.socket.nio.NioDatagramChannel.doWriteMessage(java.lang.Object,io.netty.channel.ChannelOutboundBuffer)', 'TOT': 7, 'UPD': 0, 'INS': 2, 'MOV': 5, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/2644,0.0002777777777777778,['defect'],ByteBuf leak in NioDatagramChannel when IOException occure,1.0,"['io.netty.channel.socket.nio.NioDatagramChannel.doWriteMessage(java.lang.Object,io.netty.channel.ChannelOutboundBuffer)', 'io.netty.channel.sctp.nio.NioSctpChannel.doWriteMessage(java.lang.Object,io.netty.channel.ChannelOutboundBuffer)']",['21aa3d899762f741de57f762783e75452bd312eb'],,"['transport/src/main/java/io/netty/channel/socket/nio', 'transport-sctp/src/main/java/io/netty/channel/sctp/nio']",39.0,30.0,69.0,2.0,0.0,2.0,13.0,9.0,4.0,0.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,netty
38270,2014-04-05 17:13:12,normanmaurer,"Because we not null out the array entry in the `SelectionKey[]` which is produced by `SelectedSelectionKeySet.flip()` we may end up with a few `SelectionKey`references still hanging around here even after the `Channel` was closed. As these entries may be present at the end of the `SelectionKey[]` which is never updated for a long time as not enough `SelectionKeys` are ready.
",2014-04-05 17:31:31,"[{'commitHash': 'cd579f75d2b5f236f35bc47f454cc07e50ae8037', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['22c13271d142dee6a218c5e7742cfba2fcc128c4'], 'nameRev': 'cd579f75d2b5f236f35bc47f454cc07e50ae8037 tags/netty-5.0.0.Alpha2~776', 'commitMessage': ""[#2363] SelectedSelectionKeySet may hold strong reference to SelectionKey after Channel is closed\n\nMotivation:\nBecause we not null out the array entry in the SelectionKey[] which is produced by SelectedSelectionKeySet.flip() we may end up with a few SelectionKeyreferences still hanging around here even after the Channel was closed. As these entries may be present at the end of the SelectionKey[] which is never updated for a long time as not enough SelectionKeys are ready.\n\nModifications:\nOnce we access the SelectionKey out of the SelectionKey[] we directly null it out.\n\nResult:\nReference can be GC'ed right away once the Channel was closed.\n"", 'commitDateTime': '2014-04-05 19:27:09', 'authoredDateTime': '2014-04-05 19:27:09', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/nio/NioEventLoop.java', 'insertions': 13, 'deletions': 0, 'lines': 13}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'NioEventLoop.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(java.nio.channels.SelectionKey[])', 'TOT': 9, 'UPD': 0, 'INS': 4, 'MOV': 5, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '2aa35922b47f6c65a5f6114965d33cdd8078e197', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['a4c80211ea256771ead493e67365ea1264f362a3'], 'nameRev': '2aa35922b47f6c65a5f6114965d33cdd8078e197 tags/netty-4.0.19.Final~39', 'commitMessage': ""[#2363] SelectedSelectionKeySet may hold strong reference to SelectionKey after Channel is closed\n\nMotivation:\nBecause we not null out the array entry in the SelectionKey[] which is produced by SelectedSelectionKeySet.flip() we may end up with a few SelectionKeyreferences still hanging around here even after the Channel was closed. As these entries may be present at the end of the SelectionKey[] which is never updated for a long time as not enough SelectionKeys are ready.\n\nModifications:\nOnce we access the SelectionKey out of the SelectionKey[] we directly null it out.\n\nResult:\nReference can be GC'ed right away once the Channel was closed.\n"", 'commitDateTime': '2014-04-05 19:29:58', 'authoredDateTime': '2014-04-05 19:27:09', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/nio/NioEventLoop.java', 'insertions': 13, 'deletions': 0, 'lines': 13}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'NioEventLoop.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(java.nio.channels.SelectionKey[])', 'TOT': 9, 'UPD': 0, 'INS': 4, 'MOV': 5, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '1087160fa7fa024991d8944dfe2823429773bc5c', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['791c38befe1885cad549460a4de6d9d0b5d5cc68'], 'nameRev': '1087160fa7fa024991d8944dfe2823429773bc5c tags/netty-4.1.0.Beta1~221', 'commitMessage': ""[#2363] SelectedSelectionKeySet may hold strong reference to SelectionKey after Channel is closed\n\nMotivation:\nBecause we not null out the array entry in the SelectionKey[] which is produced by SelectedSelectionKeySet.flip() we may end up with a few SelectionKeyreferences still hanging around here even after the Channel was closed. As these entries may be present at the end of the SelectionKey[] which is never updated for a long time as not enough SelectionKeys are ready.\n\nModifications:\nOnce we access the SelectionKey out of the SelectionKey[] we directly null it out.\n\nResult:\nReference can be GC'ed right away once the Channel was closed.\n"", 'commitDateTime': '2014-04-05 19:31:12', 'authoredDateTime': '2014-04-05 19:27:09', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/nio/NioEventLoop.java', 'insertions': 13, 'deletions': 0, 'lines': 13}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'NioEventLoop.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(java.nio.channels.SelectionKey[])', 'TOT': 9, 'UPD': 0, 'INS': 4, 'MOV': 5, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'c2c0d01ddb1c0e5301d58973ab3f2f3b3e805614', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['b95dbb391f7b23c21893f4b9b69f5b9abcd22977'], 'nameRev': 'c2c0d01ddb1c0e5301d58973ab3f2f3b3e805614 tags/netty-4.0.34.Final~28', 'commitMessage': ""[#2363] Correctly null out SelectionKey[] when selectAgain\n\nMotivation:\n\nThe prefix fix of #2363 did not correctly handle the case when selectAgain is true and so missed to null out entries.\n\nModifications:\n\nMove the i++ from end of loop to beginning of loop\n\nResult:\n\nEntries in the array will be null out so allow to have these GC'ed once the Channel close\n"", 'commitDateTime': '2016-01-08 09:01:53', 'authoredDateTime': '2016-01-08 14:11:58', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/nio/NioEventLoop.java', 'insertions': 1, 'deletions': 1, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'NioEventLoop.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(java.nio.channels.SelectionKey[])', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '0c733e14256715e64003a47aa75083c47c781208', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['1bee71fb1c2066035a6afcba151a1515338d0db9'], 'nameRev': '0c733e14256715e64003a47aa75083c47c781208 tags/netty-4.1.0.CR1~34', 'commitMessage': ""[#2363] Correctly null out SelectionKey[] when selectAgain\n\nMotivation:\n\nThe prefix fix of #2363 did not correctly handle the case when selectAgain is true and so missed to null out entries.\n\nModifications:\n\nMove the i++ from end of loop to beginning of loop\n\nResult:\n\nEntries in the array will be null out so allow to have these GC'ed once the Channel close\n"", 'commitDateTime': '2016-01-08 09:04:10', 'authoredDateTime': '2016-01-08 14:11:58', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/nio/NioEventLoop.java', 'insertions': 1, 'deletions': 1, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'NioEventLoop.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(java.nio.channels.SelectionKey[])', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/2363,0.0002777777777777778,['defect'],SelectedSelectionKeySet may hold strong reference to SelectionKey after Channel is closed,2.0,['io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(java.nio.channels.SelectionKey[])'],"['cd579f75d2b5f236f35bc47f454cc07e50ae8037', 'c2c0d01ddb1c0e5301d58973ab3f2f3b3e805614']",,['transport/src/main/java/io/netty/channel/nio'],14.0,1.0,15.0,1.0,0.0,1.0,10.0,6.0,4.0,0.0,1.0,0.0,0.0,0.0,3.0,0.0,0.0,netty
38350,2013-10-01 05:12:09,normanmaurer,,2013-10-01 05:18:50,"[{'commitHash': 'aaafdf909ddefe7844eb3b1c8f1b6c2adf31fa10', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['328f67fdfec9686df1e0f39cb0675719ac032743'], 'nameRev': 'aaafdf909ddefe7844eb3b1c8f1b6c2adf31fa10 tags/netty-5.0.0.Alpha1~200', 'commitMessage': '[#1878] Fix leak of ByteBuf when masked payload is used\n', 'commitDateTime': '2013-10-01 07:18:16', 'authoredDateTime': '2013-10-01 07:18:16', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/websocketx/WebSocket08FrameDecoder.java', 'insertions': 6, 'deletions': 3, 'lines': 9}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebSocket08FrameDecoder.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,java.util.List)', 'TOT': 6, 'UPD': 0, 'INS': 2, 'MOV': 2, 'DEL': 2}, {'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.unmask(io.netty.buffer.ByteBuf)', 'TOT': 4, 'UPD': 0, 'INS': 1, 'MOV': 2, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'f70ceeab58772ec99d12f65ddcd137d54b42dd9e', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['be126395e3ee5c51b3e4d24900d398bfe05dc89e'], 'nameRev': 'f70ceeab58772ec99d12f65ddcd137d54b42dd9e tags/netty-4.0.10.Final~4', 'commitMessage': '[#1878] Fix leak of ByteBuf when masked payload is used\n', 'commitDateTime': '2013-10-01 07:18:41', 'authoredDateTime': '2013-10-01 07:18:16', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/websocketx/WebSocket08FrameDecoder.java', 'insertions': 6, 'deletions': 3, 'lines': 9}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebSocket08FrameDecoder.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,java.util.List)', 'TOT': 6, 'UPD': 0, 'INS': 2, 'MOV': 2, 'DEL': 2}, {'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.unmask(io.netty.buffer.ByteBuf)', 'TOT': 4, 'UPD': 0, 'INS': 1, 'MOV': 2, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/1878,0.0002777777777777778,['defect'],WebSocket08FrameDecoder leaks ByteBuf when payload is masked,1.0,"['io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,java.util.List)', 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.unmask(io.netty.buffer.ByteBuf)', 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder']",['aaafdf909ddefe7844eb3b1c8f1b6c2adf31fa10'],,['codec-http/src/main/java/io/netty/handler/codec/http/websocketx'],6.0,3.0,9.0,1.0,1.0,3.0,11.0,4.0,3.0,3.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,netty
38352,2013-09-29 11:28:31,fbettag,"Morning, i was looking through logfiles from our application and found this (after running without exceptions for days):

```
22:48:33.120 WARN  io.netty.util.ResourceLeakDetector - LEAK: ByteBuf was GC'd before being released correctly.  The following stack trace shows where the leaked object was created, rather than where you failed to release it.
io.netty.util.ResourceLeakException: io.netty.buffer.UnpooledUnsafeDirectByteBuf@201e42a1
at io.netty.util.ResourceLeakDetector$DefaultResourceLeak.<init>(ResourceLeakDetector.java:174) ~[thruput-0.6.2.jar:na]
at io.netty.util.ResourceLeakDetector.open(ResourceLeakDetector.java:116) ~[thruput-0.6.2.jar:na]
at io.netty.buffer.UnpooledUnsafeDirectByteBuf.<init>(UnpooledUnsafeDirectByteBuf.java:72) ~[thruput-0.6.2.jar:na]
at io.netty.buffer.UnpooledByteBufAllocator.newDirectBuffer(UnpooledByteBufAllocator.java:49) ~[thruput-0.6.2.jar:na]
at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:132) ~[thruput-0.6.2.jar:na]
at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:123) ~[thruput-0.6.2.jar:na]
at io.netty.buffer.AbstractByteBufAllocator.buffer(AbstractByteBufAllocator.java:60) ~[thruput-0.6.2.jar:na]
at io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.decode(WebSocket08FrameDecoder.java:268) ~[thruput-0.6.2.jar:na]
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:362) ~[thruput-0.6.2.jar:na]
at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:131) [thruput-0.6.2.jar:na]
at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:337) [thruput-0.6.2.jar:na]
at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:323) [thruput-0.6.2.jar:na]
at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:253) [thruput-0.6.2.jar:na]
at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:337) [thruput-0.6.2.jar:na]
at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:323) [thruput-0.6.2.jar:na]
at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:785) [thruput-0.6.2.jar:na]
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:100) [thruput-0.6.2.jar:na]
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:478) [thruput-0.6.2.jar:na]
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:447) [thruput-0.6.2.jar:na]
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:341) [thruput-0.6.2.jar:na]
at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101) [thruput-0.6.2.jar:na]
at java.lang.Thread.run(Thread.java:724) [na:1.7.0_40]
```

I do not have any more information than this :(
",2013-09-30 18:45:22,"[{'commitHash': '328f67fdfec9686df1e0f39cb0675719ac032743', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['20d5361403c36e74ccc11dba5fb35b10de7e8f55'], 'nameRev': '328f67fdfec9686df1e0f39cb0675719ac032743 tags/netty-5.0.0.Alpha1~201', 'commitMessage': '[#1874] WebSocket08FrameDecoder may leak memory if channel is closed before the full frame was received\n', 'commitDateTime': '2013-09-30 20:43:30', 'authoredDateTime': '2013-09-30 20:43:30', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/websocketx/WebSocket08FrameDecoder.java', 'insertions': 22, 'deletions': 0, 'lines': 22}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebSocket08FrameDecoder.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.channelInactive(io.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,java.util.List)', 'TOT': 10, 'UPD': 0, 'INS': 8, 'MOV': 2, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'be126395e3ee5c51b3e4d24900d398bfe05dc89e', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['013ac44d3a64d53ab9e131cb43124fcbc0873caf'], 'nameRev': 'be126395e3ee5c51b3e4d24900d398bfe05dc89e tags/netty-4.0.10.Final~5', 'commitMessage': '[#1874] WebSocket08FrameDecoder may leak memory if channel is closed before the full frame was received\n', 'commitDateTime': '2013-09-30 20:44:55', 'authoredDateTime': '2013-09-30 20:43:30', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/websocketx/WebSocket08FrameDecoder.java', 'insertions': 22, 'deletions': 0, 'lines': 22}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebSocket08FrameDecoder.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.channelInactive(io.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,java.util.List)', 'TOT': 10, 'UPD': 0, 'INS': 8, 'MOV': 2, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/1874,1.0002777777777778,['defect'],WebSocket08FrameDecoder may leak memory if channel is closed before the full frame was received,1.0,"['io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.channelInactive(io.netty.channel.ChannelHandlerContext)', 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,java.util.List)']",['328f67fdfec9686df1e0f39cb0675719ac032743'],,['codec-http/src/main/java/io/netty/handler/codec/http/websocketx'],22.0,0.0,22.0,1.0,0.0,2.0,11.0,2.0,9.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,netty
38409,2013-07-20 20:47:13,aaronriekenberg,"I have a server using ProtobufEncoder and ProtobufDecoder to encode and decode messages with Netty 4.0.2 (Linux, OpenJDK 7 64-bit).

I'm finding when I have 50 client connections each sending 1000 messages/second and all connections are closed simultaneously, I often (but not always) see this error message in the server.  This error message only occurs when many client connections are shutdown quickly, not during normal steady state operation.

```
15:37:45,221 {nioEventLoopGroup-3-8} WARN  ResourceLeakDetector - LEAK: ByteBuf was GC'd before being released correctly.  The following stack trace shows where the leaked object was created, rather than who failed to release it where.
io.netty.util.ResourceLeakException: io.netty.buffer.UnpooledUnsafeDirectByteBuf@286d15b6
    at io.netty.util.ResourceLeakDetector$DefaultResourceLeak.<init>(ResourceLeakDetector.java:161)
    at io.netty.util.ResourceLeakDetector.open(ResourceLeakDetector.java:103)
    at io.netty.buffer.UnpooledUnsafeDirectByteBuf.<init>(UnpooledUnsafeDirectByteBuf.java:72)
    at io.netty.buffer.UnpooledByteBufAllocator.newDirectBuffer(UnpooledByteBufAllocator.java:49)
    at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:130)
    at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:121)
    at io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:74)
    at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
    at io.netty.channel.DefaultChannelHandlerContext.invokeWrite0(DefaultChannelHandlerContext.java:698)
    at io.netty.channel.DefaultChannelHandlerContext.invokeWrite(DefaultChannelHandlerContext.java:684)
    at io.netty.channel.DefaultChannelHandlerContext.write(DefaultChannelHandlerContext.java:677)
    at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:114)
    at io.netty.channel.DefaultChannelHandlerContext.invokeWrite0(DefaultChannelHandlerContext.java:698)
    at io.netty.channel.DefaultChannelHandlerContext.access$1700(DefaultChannelHandlerContext.java:27)
    at io.netty.channel.DefaultChannelHandlerContext$18.run(DefaultChannelHandlerContext.java:689)
    at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:353)
    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:366)
    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101)
    at java.lang.Thread.run(Thread.java:724)
```

My server code is here: https://github.com/aaronriekenberg/Simple-Message-Service/blob/master/sms-broker/src/main/java/org/aaron/sms/broker/SMSBrokerTCPServer.java

The ChannelInitializer in the server is below.  ServerHandler extends SimpleChannelInboundHandler, so I believe all pooling/reference counting should be handled automatically.  The only writes I'm doing in the server use instances of protobuf objects.

``` java
    private class ServerChannelInitializer extends ChannelInitializer<Channel> {

        @Override
        protected void initChannel(Channel ch) throws Exception {
            final ChannelPipeline p = ch.pipeline();
            p.addLast(""logger"", new LoggingHandler(LogLevel.DEBUG));

            p.addLast(""frameEncoder"", new LengthFieldPrepender(
                    SMSProtocolConstants.MESSAGE_HEADER_LENGTH_BYTES));

            p.addLast(""frameDecoder"", new LengthFieldBasedFrameDecoder(
                    SMSProtocolConstants.MAX_MESSAGE_LENGTH_BYTES, 0,
                    SMSProtocolConstants.MESSAGE_HEADER_LENGTH_BYTES, 0,
                    SMSProtocolConstants.MESSAGE_HEADER_LENGTH_BYTES));

            p.addLast(""protobufEncoder"", new ProtobufEncoder());

            p.addLast(""protobufDecoder"", new ProtobufDecoder(
                    SMSProtocol.ClientToBrokerMessage.getDefaultInstance()));

            p.addLast(""serverHandler"", new ServerHandler());
        }
    }
```
",2013-07-22 09:12:29,"[{'commitHash': '81612f8e9bc02bdb1bac6f1d6bd4d221668bb559', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['0f6cc0cc7bcc546c124ed875d197f0333bca2da9'], 'nameRev': '81612f8e9bc02bdb1bac6f1d6bd4d221668bb559 tags/netty-4.0.4.Final~15', 'commitMessage': '[#1624] Fix resource leak when writing to a closed / not-open channel\n', 'commitDateTime': '2013-07-22 10:59:06', 'authoredDateTime': '2013-07-22 10:59:06', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/AbstractChannel.java', 'insertions': 3, 'deletions': 0, 'lines': 3}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AbstractChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.AbstractChannel.AbstractUnsafe.write(java.lang.Object,io.netty.channel.ChannelPromise)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/1624,1.0002777777777778,['defect'],"Spurious ""LEAK: ByteBuf was GC'd before being released correctly"" message?",1.0,"['io.netty.channel.AbstractChannel.AbstractUnsafe.write(java.lang.Object,io.netty.channel.ChannelPromise)']",['81612f8e9bc02bdb1bac6f1d6bd4d221668bb559'],,['transport/src/main/java/io/netty/channel'],3.0,0.0,3.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,netty
38426,2013-07-15 17:08:57,normanmaurer,"org.vertx.java.tests.core.http.GroovyHttpTest > testPUTChunked STANDARD_OUT
    17:43:22.682 WARN  [vert.x-eventloop-thread-1][io.netty.util.ResourceLeakDetector] LEAK: ByteBuf was GC'd before being released correctly.
    io.netty.util.ResourceLeakException: io.netty.buffer.UnpooledUnsafeDirectByteBuf@46f8fbdb
        at io.netty.util.ResourceLeakDetector$DefaultResourceLeak.<init>(ResourceLeakDetector.java:158)
        at io.netty.util.ResourceLeakDetector.open(ResourceLeakDetector.java:103)
        at io.netty.buffer.UnpooledUnsafeDirectByteBuf.<init>(UnpooledUnsafeDirectByteBuf.java:72)
        at io.netty.buffer.UnpooledByteBufAllocator.newDirectBuffer(UnpooledByteBufAllocator.java:49)
        at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:130)
        at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:121)
        at io.netty.buffer.AbstractByteBufAllocator.buffer(AbstractByteBufAllocator.java:58)
        at io.netty.handler.codec.base64.Base64.encode(Base64.java:115)
        at io.netty.handler.codec.base64.Base64.encode(Base64.java:86)
        at io.netty.handler.codec.base64.Base64.encode(Base64.java:73)
        at io.netty.handler.codec.base64.Base64.encode(Base64.java:69)
        at io.netty.handler.codec.http.websocketx.WebSocketUtil.base64(WebSocketUtil.java:74)
        at io.netty.handler.codec.http.websocketx.WebSocketClientHandshaker13.newHandshakeRequest(WebSocketClientHandshaker13.java:106)
        at io.netty.handler.codec.http.websocketx.WebSocketClientHandshaker.handshake(WebSocketClientHandshaker.java:149)
        at io.netty.handler.codec.http.websocketx.WebSocketClientHandshaker.handshake(WebSocketClientHandshaker.java:137)
        at org.vertx.java.core.http.impl.ClientConnection.toWebSocket(ClientConnection.java:115)
        at org.vertx.java.core.http.impl.DefaultHttpClient$3.handle(DefaultHttpClient.java:153)
        at org.vertx.java.core.http.impl.DefaultHttpClient$3.handle(DefaultHttpClient.java:150)
        at org.vertx.java.core.http.impl.DefaultHttpClient.createConn(DefaultHttpClient.java:540)
        at org.vertx.java.core.http.impl.DefaultHttpClient.access$600(DefaultHttpClient.java:47)
        at org.vertx.java.core.http.impl.DefaultHttpClient$6.run(DefaultHttpClient.java:526)
        at org.vertx.java.core.impl.DefaultContext$3.run(DefaultContext.java:171)
        at org.vertx.java.core.impl.DefaultContext.execute(DefaultContext.java:129)
        at org.vertx.java.core.http.impl.DefaultHttpClient.connected(DefaultHttpClient.java:524)
        at org.vertx.java.core.http.impl.DefaultHttpClient.access$400(DefaultHttpClient.java:47)
        at org.vertx.java.core.http.impl.DefaultHttpClient$5.operationComplete(DefaultHttpClient.java:508)
        at org.vertx.java.core.http.impl.DefaultHttpClient$5.operationComplete(DefaultHttpClient.java:487)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:612)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:577)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:539)
        at io.netty.util.concurrent.DefaultPromise.setSuccess(DefaultPromise.java:380)
        at io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:76)
        at io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:71)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:232)
        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:513)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:465)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:359)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101)
        at java.lang.Thread.run(Thread.java:722)
",2013-07-15 17:13:34,"[{'commitHash': 'e879848056a5f53c1055ebbf4f9971b5ab2282d6', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['5297eba280555a7b785e7f57975546a2af07e045'], 'nameRev': 'e879848056a5f53c1055ebbf4f9971b5ab2282d6 tags/netty-4.0.1.Final~5', 'commitMessage': '[#1579] Fix resource leakage in WebSocketUtil.base64(...)\n', 'commitDateTime': '2013-07-15 19:12:24', 'authoredDateTime': '2013-07-15 19:12:24', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/websocketx/WebSocketUtil.java', 'insertions': 4, 'deletions': 1, 'lines': 5}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebSocketUtil.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocketUtil.base64(byte[])', 'TOT': 7, 'UPD': 0, 'INS': 4, 'MOV': 2, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/1579,0.0002777777777777778,['defect'],WebSocketUtil.base64(..) leaks resources,1.0,['io.netty.handler.codec.http.websocketx.WebSocketUtil.base64(byte[])'],['e879848056a5f53c1055ebbf4f9971b5ab2282d6'],,['codec-http/src/main/java/io/netty/handler/codec/http/websocketx'],4.0,1.0,5.0,1.0,0.0,1.0,7.0,2.0,4.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,netty
38444,2013-07-04 14:15:33,planerist,"17:47:24,585  WARN ResourceLeakDetector:151    - LEAK: ByteBuf was GC'd before being released correctly.
io.netty.util.ResourceLeakException: io.netty.buffer.PooledHeapByteBuf@6dde8fae
    at io.netty.util.ResourceLeakDetector$DefaultResourceLeak.<init>(ResourceLeakDetector.java:158)
    at io.netty.util.ResourceLeakDetector.open(ResourceLeakDetector.java:103)
    at io.netty.buffer.PooledByteBuf.<init>(PooledByteBuf.java:42)
    at io.netty.buffer.PooledHeapByteBuf.<init>(PooledHeapByteBuf.java:44)
    at io.netty.buffer.PooledHeapByteBuf.<init>(PooledHeapByteBuf.java:28)
    at io.netty.buffer.PooledHeapByteBuf$1.newObject(PooledHeapByteBuf.java:33)
    at io.netty.buffer.PooledHeapByteBuf$1.newObject(PooledHeapByteBuf.java:30)
    at io.netty.util.Recycler.get(Recycler.java:40)
    at io.netty.buffer.PooledHeapByteBuf.newInstance(PooledHeapByteBuf.java:38)
    at io.netty.buffer.PoolArena$HeapArena.newByteBuf(PoolArena.java:357)
    at io.netty.buffer.PoolArena.allocate(PoolArena.java:93)
    at io.netty.buffer.PooledByteBufAllocator.newHeapBuffer(PooledByteBufAllocator.java:222)
    at io.netty.buffer.AbstractByteBufAllocator.heapBuffer(AbstractByteBufAllocator.java:111)
    at io.netty.buffer.AbstractByteBufAllocator.heapBuffer(AbstractByteBufAllocator.java:97)
    at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:96)
    at io.netty.channel.DefaultChannelHandlerContext.invokeWrite0(DefaultChannelHandlerContext.java:719)
    at io.netty.channel.DefaultChannelHandlerContext.invokeWrite(DefaultChannelHandlerContext.java:703)
    at io.netty.channel.DefaultChannelHandlerContext.write(DefaultChannelHandlerContext.java:697)
    at io.netty.channel.DefaultChannelHandlerContext.write(DefaultChannelHandlerContext.java:480)
    at io.netty.channel.DefaultChannelPipeline.write(DefaultChannelPipeline.java:842)
    at io.netty.channel.AbstractChannel.write(AbstractChannel.java:251)
    at io.netty.channel.embedded.EmbeddedChannel.writeOutbound(EmbeddedChannel.java:169)
    at io.netty.handler.codec.http.HttpContentEncoder.encode(HttpContentEncoder.java:265)
    at io.netty.handler.codec.http.HttpContentEncoder.encodeContent(HttpContentEncoder.java:205)
    at io.netty.handler.codec.http.HttpContentEncoder.encode(HttpContentEncoder.java:166)
    at io.netty.handler.codec.http.HttpContentEncoder.encode(HttpContentEncoder.java:54)
    at io.netty.handler.codec.MessageToMessageCodec$1.encode(MessageToMessageCodec.java:66)
    at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:80)
    at io.netty.handler.codec.MessageToMessageCodec.write(MessageToMessageCodec.java:105)
    at io.netty.channel.DefaultChannelHandlerContext.invokeWrite0(DefaultChannelHandlerContext.java:719)
    at io.netty.channel.DefaultChannelHandlerContext.invokeWrite(DefaultChannelHandlerContext.java:703)
    at io.netty.channel.DefaultChannelHandlerContext.write(DefaultChannelHandlerContext.java:697)
    at io.netty.channel.DefaultChannelHandlerContext.write(DefaultChannelHandlerContext.java:687)
    at io.netty.channel.DefaultChannelHandlerContext.write(DefaultChannelHandlerContext.java:475)
",2013-07-05 04:40:09,"[{'commitHash': 'd900f8c21d2c8205eff3fb392f1b6f134dc447a1', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['2bda1b530adad4e92039c3e16fc08044634f0cd8'], 'nameRev': 'd900f8c21d2c8205eff3fb392f1b6f134dc447a1 tags/netty-4.0.0.Final~111', 'commitMessage': '[#1524] Fix resource leak in HttpContentEncoder\n', 'commitDateTime': '2013-07-05 06:27:25', 'authoredDateTime': '2013-07-05 06:27:25', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/HttpContentEncoder.java', 'insertions': 16, 'deletions': 1, 'lines': 17}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'HttpContentEncoder.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.HttpContentEncoder.cleanup()', 'TOT': 3, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpContentEncoder.fetchEncoderOutput(io.netty.buffer.ByteBuf)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/1524,0.0002777777777777778,['defect'],HttpContentEncoder leaks resources,1.0,"['io.netty.handler.codec.http.HttpContentEncoder.cleanup()', 'io.netty.handler.codec.http.HttpContentEncoder.fetchEncoderOutput(io.netty.buffer.ByteBuf)']",['d900f8c21d2c8205eff3fb392f1b6f134dc447a1'],,['codec-http/src/main/java/io/netty/handler/codec/http'],16.0,1.0,17.0,1.0,0.0,2.0,4.0,0.0,3.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,netty
38450,2013-07-04 06:43:35,ghost,"4 Jul, 2013 12:06:47 PM io.netty.util.ResourceLeakDetector reportLeak
WARNING: LEAK: ByteBuf was GC'd before being released correctly.
io.netty.util.ResourceLeakException: io.netty.buffer.DefaultCompositeByteBuf@b82368
    at io.netty.util.ResourceLeakDetector$DefaultResourceLeak.<init>(ResourceLeakDetector.java:158)
    at io.netty.util.ResourceLeakDetector.open(ResourceLeakDetector.java:103)
    at io.netty.buffer.DefaultCompositeByteBuf.<init>(DefaultCompositeByteBuf.java:80)
    at io.netty.buffer.Unpooled.wrappedBuffer(Unpooled.java:301)
    at io.netty.buffer.Unpooled.wrappedBuffer(Unpooled.java:238)
    at io.netty.handler.codec.http.multipart.HttpPostRequestDecoder.offer(HttpPostRequestDecoder.java:363)
    at io.netty.example.http.upload.HttpUploadServerHandler.messageReceived(HttpUploadServerHandler.java:185)
    at io.netty.example.http.upload.HttpUploadServerHandler.messageReceived(HttpUploadServerHandler.java:1)
    at io.netty.channel.SimpleChannelInboundHandler.messageReceived(SimpleChannelInboundHandler.java:84)
    at io.netty.channel.DefaultChannelHandlerContext.invokeMessageReceived(DefaultChannelHandlerContext.java:379)
    at io.netty.channel.DefaultChannelHandlerContext.fireMessageReceived(DefaultChannelHandlerContext.java:364)
    at io.netty.handler.codec.ByteToMessageDecoder.messageReceived(ByteToMessageDecoder.java:178)
    at io.netty.channel.DefaultChannelHandlerContext.invokeMessageReceived(DefaultChannelHandlerContext.java:379)
    at io.netty.channel.DefaultChannelHandlerContext.fireMessageReceived(DefaultChannelHandlerContext.java:364)
    at io.netty.channel.DefaultChannelHandlerContext.fireMessageReceived(DefaultChannelHandlerContext.java:347)
    at io.netty.channel.DefaultChannelPipeline.fireMessageReceived(DefaultChannelPipeline.java:780)
    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:92)
    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:489)
    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:464)
    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:358)
    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101)
    at java.lang.Thread.run(Unknown Source)

I forgot to mention one more result that i got with the same example.
I configured the HttpDataFectory to useDisk = false;
I didn't get any exception but received file have size less than the actual file size(in case of media file but worked correctly with text file with size of around 7MB).
",2013-07-04 08:59:56,"[{'commitHash': '45d20d5c9faf51a506d4d2a9fdb04b9cfd876876', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['08b75e594cbe4f16ec73c3840a3981af7871066f'], 'nameRev': '45d20d5c9faf51a506d4d2a9fdb04b9cfd876876 tags/netty-4.0.0.Final~115', 'commitMessage': '[#1516] Fix resource leakage which was caused by the AbstractDiskHttpData which did not release the buffer after copy to disk\n', 'commitDateTime': '2013-07-04 10:41:49', 'authoredDateTime': '2013-07-04 10:41:49', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/multipart/AbstractDiskHttpData.java', 'insertions': 53, 'deletions': 41, 'lines': 94}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AbstractDiskHttpData.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.multipart.AbstractDiskHttpData.setContent(io.netty.buffer.ByteBuf)', 'TOT': 15, 'UPD': 0, 'INS': 1, 'MOV': 14, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.multipart.AbstractDiskHttpData.addContent(io.netty.buffer.ByteBuf,boolean)', 'TOT': 10, 'UPD': 0, 'INS': 1, 'MOV': 9, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/1516,0.0002777777777777778,['defect'],Got following exception when i try upload large file(25MB) using netty HttpUpload example. ,1.0,"['io.netty.handler.codec.http.multipart.AbstractDiskHttpData.setContent(io.netty.buffer.ByteBuf)', 'io.netty.handler.codec.http.multipart.AbstractDiskHttpData.addContent(io.netty.buffer.ByteBuf,boolean)']",['45d20d5c9faf51a506d4d2a9fdb04b9cfd876876'],,['codec-http/src/main/java/io/netty/handler/codec/http/multipart'],53.0,41.0,94.0,1.0,0.0,2.0,25.0,23.0,2.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,netty
38455,2013-07-02 11:44:50,normanmaurer,"tim@tim-laptop ~/projects/vert-x/vertx-examples/src/raw/java $ vertx run wsperf/PerfClient.java
Starting perf client
Received data on all conns
LEAK: ByteBuf was GC'd before being released correctly. 
io.netty.util.ResourceLeakException: io.netty.buffer.UnpooledUnsafeDirectByteBuf@6f83405
at io.netty.util.ResourceLeakDetector$DefaultResourceLeak.(ResourceLeakDetector.java:158)
at io.netty.util.ResourceLeakDetector.open(ResourceLeakDetector.java:103)
at io.netty.buffer.UnpooledUnsafeDirectByteBuf.(UnpooledUnsafeDirectByteBuf.java:72)
at io.netty.buffer.UnpooledByteBufAllocator.newDirectBuffer(UnpooledByteBufAllocator.java:49)
at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:130)
at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:121)
at io.netty.buffer.AbstractByteBufAllocator.buffer(AbstractByteBufAllocator.java:58)
at io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.decode(WebSocket08FrameDecoder.java:259)
at io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:356)
at io.netty.handler.codec.ByteToMessageDecoder.messageReceived(ByteToMessageDecoder.java:138)
at io.netty.channel.DefaultChannelHandlerContext.invokeMessageReceived(DefaultChannelHandlerContext.java:379)
at io.netty.channel.DefaultChannelHandlerContext.fireMessageReceived(DefaultChannelHandlerContext.java:364)
at io.netty.channel.DefaultChannelPipeline.fireMessageReceived(DefaultChannelPipeline.java:786)
at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:120)
at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:489)
at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:464)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:358)
at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101)
at java.lang.Thread.run(Thread.java:722)

See also:
https://github.com/vert-x/vert.x/issues/667
",2013-07-02 11:46:31,"[{'commitHash': 'a4ee2841be0be8e69d624f0543ab9d0ebb4b9567', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['ec5e793a2fd244e334c2b1f2c22d55389a3452f7'], 'nameRev': 'a4ee2841be0be8e69d624f0543ab9d0ebb4b9567 tags/netty-4.0.0.Final~124', 'commitMessage': '[#1507] Fix buffer leak in WebSocket08FrameDecoder\n', 'commitDateTime': '2013-07-02 13:46:09', 'authoredDateTime': '2013-07-02 13:46:09', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/websocketx/WebSocket08FrameDecoder.java', 'insertions': 1, 'deletions': 0, 'lines': 1}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebSocket08FrameDecoder.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,io.netty.channel.MessageList)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/1507,0.0002777777777777778,['defect'],Resource leak in WebSocket08FrameDecoder,1.0,"['io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,io.netty.channel.MessageList)']",['a4ee2841be0be8e69d624f0543ab9d0ebb4b9567'],,['codec-http/src/main/java/io/netty/handler/codec/http/websocketx'],1.0,0.0,1.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,netty
38484,2013-05-21 14:48:55,sprek,"I get a StackOverFlow exception when trying to make a simple program that uses the SnappyFrameEncoder / Decoder. I posted the problem here: http://stackoverflow.com/questions/16659555/stackoverflow-exception-when-using-nettys-snappyframedecoder/16663160#16663160

I get the same error when I use JZlibDecoder and JZlibEncoder instead of Snappy.

Here is my full example:

``` java
import io.netty.bootstrap.Bootstrap;
import io.netty.bootstrap.ServerBootstrap;
import io.netty.channel.Channel;
import io.netty.channel.ChannelFuture;
import io.netty.channel.ChannelHandlerContext;
import io.netty.channel.ChannelInboundMessageHandlerAdapter;
import io.netty.channel.ChannelInitializer;
import io.netty.channel.EventLoopGroup;
import io.netty.channel.local.LocalAddress;
import io.netty.channel.local.LocalChannel;
import io.netty.channel.local.LocalEventLoopGroup;
import io.netty.channel.local.LocalServerChannel;
import io.netty.handler.codec.compression.SnappyFramedDecoder;
import io.netty.handler.codec.compression.SnappyFramedEncoder;
import io.netty.handler.codec.string.StringDecoder;
import io.netty.handler.codec.string.StringEncoder;
import io.netty.handler.logging.LogLevel;
import io.netty.handler.logging.LoggingHandler;

public class LocalNettyTest {
  private static String LOCAL_ID = ""localtest"";
  private static String TEST_STRING = ""Test message longer than 18 bytes"";

  public void run() throws Exception {
    final LocalAddress addr = new LocalAddress(LOCAL_ID);
    Bootstrap cb = new Bootstrap();
    ServerBootstrap sb = new ServerBootstrap();
    EventLoopGroup serverGroup = new LocalEventLoopGroup();
    EventLoopGroup clientGroup = new LocalEventLoopGroup();
    try {
      sb.group(serverGroup)
      .channel(LocalServerChannel.class)
      .handler(new ChannelInitializer<LocalServerChannel>(){
        @Override
        public void initChannel(LocalServerChannel ch) throws Exception {
          ch.pipeline().addLast(new LoggingHandler(LogLevel.INFO));
        }
      })
      .childHandler(new ChannelInitializer<LocalChannel>() {
        @Override
        public void initChannel(LocalChannel ch) throws Exception {
          // comment the next line out for it to work
          ch.pipeline().addLast(new SnappyFramedDecoder());
          ch.pipeline().addLast(new StringDecoder());
          ch.pipeline().addLast(new ChannelInboundMessageHandlerAdapter<String>() {
            @Override
            public void messageReceived(ChannelHandlerContext ctx,
                String msg) throws Exception {
              System.out.println (""RECEIVED: "" + msg);
            }
          });
        }
      });

      cb.group(clientGroup)
      .channel(LocalChannel.class)
      .handler(new ChannelInitializer<LocalChannel>() {
        @Override
        public void initChannel(LocalChannel ch) throws Exception {
          ch.pipeline().addLast(new StringEncoder ());
          // comment the next line out for it to work
          ch.pipeline().addLast(new SnappyFramedEncoder ());
        }
      });
      // Start the server.
      sb.bind(addr).sync();

      // Start the client.
      Channel ch = cb.connect(addr).sync().channel();

      ChannelFuture lastWriteFuture = ch.write(TEST_STRING);

      // Wait until all messages are flushed before closing the channel.
      if (lastWriteFuture != null) {
        System.out.println (""Waiting"");
        lastWriteFuture.awaitUninterruptibly();
      }
    } catch (Exception e) {
      e.printStackTrace();
    } finally {
      serverGroup.shutdownGracefully();
      clientGroup.shutdownGracefully();
    }
    System.out.println (""Done"");
  }

  public static void main(String[] args) throws Exception {
    new LocalNettyTest().run();
  }
}
```

The exception that I get is very long (longer than GitHub lets me post in a single message). Here is the first part of my console output, before the exception:

```
 INFO [main] [io.netty.util.internal.logging.Slf4JLogger] 10:25:29,948 You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
 INFO [localEventLoopGroup-1-1] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,025 [id: 0xe9ece3a1] REGISTERED
 INFO [localEventLoopGroup-1-1] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,026 [id: 0xe9ece3a1] BIND(local:localtest)
 INFO [localEventLoopGroup-1-1] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,028 [id: 0xe9ece3a1, local:localtest] ACTIVE
Waiting
Done
 INFO [localEventLoopGroup-1-1] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,080 [id: 0xe9ece3a1, local:localtest] INACTIVE
 INFO [localEventLoopGroup-1-1] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,081 [id: 0xe9ece3a1, local:localtest] UNREGISTERED
 WARN [localEventLoopGroup-1-2] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,117 An exception was thrown by a user handler's exceptionCaught() method while handling the following exception:
 WARN [localEventLoopGroup-1-2] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,119 An exception was thrown by a user handler's exceptionCaught() method while handling the following exception:
 WARN [localEventLoopGroup-1-2] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,122 An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
 WARN [localEventLoopGroup-1-2] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,124 An exception was thrown by a user handler's exceptionCaught() method while handling the following exception:
 WARN [localEventLoopGroup-1-2] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,126 An exception was thrown by a user handler's exceptionCaught() method while handling the following exception:
 WARN [localEventLoopGroup-1-2] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,128 An exception was thrown by a user handler's exceptionCaught() method while handling the following exception:
 WARN [localEventLoopGroup-1-2] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,130 An exception was thrown by a user handler's exceptionCaught() method while handling the following exception:
 WARN [localEventLoopGroup-1-2] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,132 An exception was thrown by a user handler's exceptionCaught() method while handling the following exception:
 WARN [localEventLoopGroup-1-2] [io.netty.util.internal.logging.Slf4JLogger] 10:25:30,135 An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
```

The previous 7 lines repeats about 20 times, then here is part of my exception.

```
java.lang.StackOverflowError
  at java.lang.ThreadLocal$ThreadLocalMap.getEntry(ThreadLocal.java:376)
  at java.lang.ThreadLocal$ThreadLocalMap.access$000(ThreadLocal.java:261)
  at java.lang.ThreadLocal.get(ThreadLocal.java:146)
  at java.lang.StringCoding.deref(StringCoding.java:63)
  at java.lang.StringCoding.encode(StringCoding.java:330)
  at java.lang.String.getBytes(String.java:916)
  at java.io.UnixFileSystem.getBooleanAttributes0(Native Method)
  at java.io.UnixFileSystem.getBooleanAttributes(UnixFileSystem.java:242)
  at java.io.File.exists(File.java:772)
  at sun.misc.URLClassPath$FileLoader.getResource(URLClassPath.java:1057)
  at sun.misc.URLClassPath.getResource(URLClassPath.java:195)
  at java.net.URLClassLoader$1.run(URLClassLoader.java:358)
  at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
  at java.security.AccessController.doPrivileged(Native Method)
  at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
  at java.lang.ClassLoader.loadClass(ClassLoader.java:423)
  at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
  at java.lang.ClassLoader.loadClass(ClassLoader.java:356)
  at java.lang.ClassLoader.defineClass1(Native Method)
  at java.lang.ClassLoader.defineClass(ClassLoader.java:791)
  at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
  at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)
  at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
  at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
  at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
  at java.security.AccessController.doPrivileged(Native Method)
  at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
  at java.lang.ClassLoader.loadClass(ClassLoader.java:423)
  at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
  at java.lang.ClassLoader.loadClass(ClassLoader.java:356)
  at org.apache.log4j.spi.ThrowableInformation.getThrowableStrRep(ThrowableInformation.java:87)
  at org.apache.log4j.spi.LoggingEvent.getThrowableStrRep(LoggingEvent.java:413)
  at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:313)
  at org.apache.log4j.WriterAppender.append(WriterAppender.java:162)
  at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
  at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
  at org.apache.log4j.Category.callAppenders(Category.java:206)
  at org.apache.log4j.Category.forcedLog(Category.java:391)
  at org.apache.log4j.Category.log(Category.java:856)
  at org.slf4j.impl.Log4jLoggerAdapter.warn(Log4jLoggerAdapter.java:478)
  at io.netty.util.internal.logging.Slf4JLogger.warn(Slf4JLogger.java:151)
  at io.netty.channel.DefaultChannelHandlerContext.invokeExceptionCaught0(DefaultChannelHandlerContext.java:846)
  at io.netty.channel.DefaultChannelHandlerContext.invokeExceptionCaught(DefaultChannelHandlerContext.java:822)
  at io.netty.channel.DefaultChannelHandlerContext.notifyHandlerException(DefaultChannelHandlerContext.java:1546)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1247)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
```

These are the last lines of the exception:

```
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
  at io.netty.channel.DefaultChannelPipeline.fireChannelReadSuspended(DefaultChannelPipeline.java:834)
  at io.netty.channel.local.LocalChannel.doBeginRead(LocalChannel.java:229)
  at io.netty.channel.AbstractChannel$AbstractUnsafe.beginRead(AbstractChannel.java:806)
  at io.netty.channel.DefaultChannelPipeline$HeadHandler.read(DefaultChannelPipeline.java:1108)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead0(DefaultChannelHandlerContext.java:1245)
  at io.netty.channel.DefaultChannelHandlerContext.invokeRead(DefaultChannelHandlerContext.java:1228)
  at io.netty.channel.DefaultChannelHandlerContext.read(DefaultChannelHandlerContext.java:1222)
  at io.netty.channel.DefaultChannelPipeline.read(DefaultChannelPipeline.java:911)
```
",2013-05-24 02:55:31,"[{'commitHash': 'a3b4cdd614d0ecd20c1b23758df969df0ca410a4', 'commitGHEventType': 'closed', 'commitUser': 'trustin', 'commitParents': ['5398792ffa19829bfdc7e9ac02ebdb8952c84032'], 'nameRev': 'a3b4cdd614d0ecd20c1b23758df969df0ca410a4 tags/netty-4.0.0.CR4~75', 'commitMessage': 'Fix StackOverflowError in LocalEcho.doBeginRead() when the peer channel keeps writing data\n\n- Fixes #1380\n', 'commitDateTime': '2013-05-24 11:55:21', 'authoredDateTime': '2013-05-24 11:54:44', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/local/LocalChannel.java', 'insertions': 29, 'deletions': 2, 'lines': 31}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'LocalChannel.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.channel.local.LocalChannel', 'TOT': 6, 'UPD': 1, 'INS': 4, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.local.LocalChannel.1', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.local.LocalChannel.doRegister()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.local.LocalChannel.doFlushMessageBuffer(io.netty.buffer.MessageBuf)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.local.LocalChannel.doRegister().2', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.local.LocalChannel.doFlushMessageBuffer(io.netty.buffer.MessageBuf).3', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.local.LocalChannel.1.run()', 'TOT': 3, 'UPD': 2, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.local.LocalChannel.doRegister().2.run()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.local.LocalChannel.doBeginRead()', 'TOT': 4, 'UPD': 0, 'INS': 2, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'io.netty.channel.local.LocalChannel.3.run()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/1380,2.000277777777778,['defect'],StackOverFlow exception with SnappyFrameDecoder / Encoder - 4.0.0.CR2,1.0,"['io.netty.channel.local.LocalChannel.doBeginRead()', 'io.netty.channel.local.LocalChannel.doFlushMessageBuffer(io.netty.buffer.MessageBuf)', 'io.netty.channel.local.LocalChannel.1', 'io.netty.channel.local.LocalChannel.3.run()', 'io.netty.channel.local.LocalChannel.doRegister().2', 'io.netty.channel.local.LocalChannel.doRegister().2.run()', 'io.netty.channel.local.LocalChannel.doRegister()', 'io.netty.channel.local.LocalChannel.doFlushMessageBuffer(io.netty.buffer.MessageBuf).3', 'io.netty.channel.local.LocalChannel.1.run()', 'io.netty.channel.local.LocalChannel']",['a3b4cdd614d0ecd20c1b23758df969df0ca410a4'],,['transport/src/main/java/io/netty/channel/local'],29.0,2.0,31.0,1.0,9.0,10.0,20.0,4.0,7.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,netty
38570,2013-03-04 05:38:19,trustin,"`SslHandler.closeOutboundAndChannel(...)`, does not send the specified event downstream at all if `SslEngine.isInboundDone()` returns `true`.  If a user relies on the future of the specified event, the user will never be notified.  Also, if the peer does not close the connection after sending `close_notify`, the connection will never be closed, although all well-behaving peers will do.

This issue was introduced by beadadecf7489dbcc43d7939f796cc4017340a49.
",2013-03-07 06:33:14,"[{'commitHash': 'e15ca4947e7376d63471b864318a5711fb588ba6', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['c4f372b1115d1efa284145b1f85ad3468ed438c8'], 'nameRev': 'e15ca4947e7376d63471b864318a5711fb588ba6 tags/netty-3.6.4.Final~27', 'commitMessage': 'Fix potential resource leak in SslHandler\n\n- Fixes: #1116\n', 'commitDateTime': '2013-03-04 14:41:27', 'authoredDateTime': '2013-03-04 14:40:45', 'commitGitStats': [{'filePath': 'src/main/java/org/jboss/netty/handler/ssl/SslHandler.java', 'insertions': 3, 'deletions': 5, 'lines': 8}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'SslHandler.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.handler.ssl.SslHandler.closeOutboundAndChannel(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.ChannelStateEvent)', 'TOT': 7, 'UPD': 4, 'INS': 1, 'MOV': 0, 'DEL': 2}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '822223ede0a53212db33de5c9c03e807b8bf109f', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['f54cfa9dd52be5aa671281266b4014d2287cf026'], 'nameRev': '822223ede0a53212db33de5c9c03e807b8bf109f tags/netty-3.5.12.Final~9', 'commitMessage': 'Fix potential resource leak in SslHandler\n\n- Fixes: #1116\n', 'commitDateTime': '2013-03-04 14:55:42', 'authoredDateTime': '2013-03-04 14:40:45', 'commitGitStats': [{'filePath': 'src/main/java/org/jboss/netty/handler/ssl/SslHandler.java', 'insertions': 3, 'deletions': 5, 'lines': 8}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'SslHandler.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.handler.ssl.SslHandler.closeOutboundAndChannel(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.ChannelStateEvent)', 'TOT': 7, 'UPD': 4, 'INS': 1, 'MOV': 0, 'DEL': 2}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/1116,3.000277777777778,['defect'],Potential resource leak in SslHandler,1.0,"['org.jboss.netty.handler.ssl.SslHandler.closeOutboundAndChannel(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.ChannelStateEvent)']",['e15ca4947e7376d63471b864318a5711fb588ba6'],,['src/main/java/org/jboss/netty/handler/ssl'],3.0,5.0,8.0,1.0,4.0,1.0,7.0,0.0,1.0,2.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,netty
38634,2012-12-19 01:36:33,zcourts,"The MessageToByteEncoder's ByteBuf passed into the encode method quickly runs out of space when a lot (about 100K) of messages are sent in short bursts. See below:

![netty runs out runs out of space](https://f.cloud.github.com/assets/692396/21046/f8820a72-497b-11e2-99d7-950bf066e06b.png)

It is also not possible to increase the buffer's capacity since the capacity(int) method throws an ""IllegalArgumentException"" if this is attempted.

Before I was simply doing out.writeBytes(...), I started using out.writebytes() followed by ctx.flush() but this only delayed it as the buffer still got backed up.

This only started happening recently after pulling all the latest changes from master
",2012-12-19 08:35:43,"[{'commitHash': '67da6e4bf945f771607454dff40334990396ce7b', 'commitGHEventType': 'closed', 'commitUser': 'trustin', 'commitParents': ['35c01660da784a5ae12829589ad86ea15b56cedb'], 'nameRev': '67da6e4bf945f771607454dff40334990396ce7b tags/netty-4.0.0.Beta1~379', 'commitMessage': 'Remove the notion of ByteBufAllocator.bufferMaxCapacity()\n\n- Allocate the unpooled memory if the requested capacity is greater then the chunkSize\n- Fixes #834\n', 'commitDateTime': '2012-12-19 17:35:32', 'authoredDateTime': '2012-12-19 17:35:32', 'commitGitStats': [{'filePath': 'buffer/src/main/java/io/netty/buffer/AbstractByteBufAllocator.java', 'insertions': 10, 'deletions': 21, 'lines': 31}, {'filePath': 'buffer/src/main/java/io/netty/buffer/ByteBufAllocator.java', 'insertions': 0, 'deletions': 2, 'lines': 2}, {'filePath': 'buffer/src/main/java/io/netty/buffer/PoolArena.java', 'insertions': 28, 'deletions': 3, 'lines': 31}, {'filePath': 'buffer/src/main/java/io/netty/buffer/PoolChunk.java', 'insertions': 18, 'deletions': 2, 'lines': 20}, {'filePath': 'buffer/src/main/java/io/netty/buffer/PooledByteBuf.java', 'insertions': 35, 'deletions': 17, 'lines': 52}, {'filePath': 'buffer/src/main/java/io/netty/buffer/PooledByteBufAllocator.java', 'insertions': 11, 'deletions': 3, 'lines': 14}, {'filePath': 'buffer/src/main/java/io/netty/buffer/UnpooledByteBufAllocator.java', 'insertions': 1, 'deletions': 1, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AbstractByteBufAllocator.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.AbstractByteBufAllocator.validate(int,int)', 'TOT': 10, 'UPD': 5, 'INS': 2, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'io.netty.buffer.AbstractByteBufAllocator', 'TOT': 6, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 6}, {'spoonMethodName': 'io.netty.buffer.AbstractByteBufAllocator.bufferMaxCapacity()', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.netty.buffer.AbstractByteBufAllocator.heapBuffer()', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.netty.buffer.AbstractByteBufAllocator.heapBuffer(int)', 'TOT': 4, 'UPD': 0, 'INS': 1, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'io.netty.buffer.AbstractByteBufAllocator.heapBuffer(int,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.buffer.AbstractByteBufAllocator.directBuffer()', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'io.netty.buffer.AbstractByteBufAllocator.directBuffer(int)', 'TOT': 4, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 2}, {'spoonMethodName': 'io.netty.buffer.AbstractByteBufAllocator.directBuffer(int,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'ByteBufAllocator.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.bufferMaxCapacity()', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'PoolArena.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolArena.normalizeCapacity(int)', 'TOT': 10, 'UPD': 1, 'INS': 3, 'MOV': 4, 'DEL': 2}, {'spoonMethodName': 'io.netty.buffer.PoolArena.allocateHuge(io.netty.buffer.PooledByteBuf,int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PoolArena.newUnpooledChunk(int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PoolArena.free(io.netty.buffer.PoolChunk,long)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PoolArena.HeapArena.newUnpooledChunk(int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PoolArena.DirectArena.newUnpooledChunk(int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PoolArena.allocate(io.netty.buffer.PoolThreadCache,io.netty.buffer.PooledByteBuf,int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'PoolChunk.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PoolChunk.initBuf(io.netty.buffer.PooledByteBuf,long,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.buffer.PoolChunk.initBufWithSubpage(io.netty.buffer.PooledByteBuf,long,int,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.buffer.PoolChunk', 'TOT': 3, 'UPD': 0, 'INS': 3, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'PooledByteBuf.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PooledByteBuf.init(io.netty.buffer.PoolChunk,long,java.lang.Object,int,int,int)', 'TOT': 5, 'UPD': 2, 'INS': 0, 'MOV': 1, 'DEL': 2}, {'spoonMethodName': 'io.netty.buffer.PooledByteBuf.initUnpooled(io.netty.buffer.PoolChunk,int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PooledByteBuf.capacity(int)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PooledByteBuf.init(io.netty.buffer.PoolChunk,long,int,int,int)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PooledByteBuf.resumeIntermediaryDeallocations()', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'PooledByteBufAllocator.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.PooledByteBufAllocator.toString()', 'TOT': 5, 'UPD': 1, 'INS': 4, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.buffer.PooledByteBufAllocator', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 1}]}, {'spoonFilePath': 'UnpooledByteBufAllocator.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.buffer.UnpooledByteBufAllocator', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/834,0.0002777777777777778,['defect'],MessageToByteEncoder's output ByteBuf runs out of space,1.0,"['io.netty.buffer.PoolArena.newUnpooledChunk(int)', 'io.netty.buffer.PoolArena.normalizeCapacity(int)', 'io.netty.buffer.PooledByteBufAllocator', 'io.netty.buffer.AbstractByteBufAllocator', 'io.netty.buffer.PooledByteBuf.capacity(int)', 'io.netty.buffer.PoolArena.free(io.netty.buffer.PoolChunk,long)', 'io.netty.buffer.PooledByteBuf.init(io.netty.buffer.PoolChunk,long,java.lang.Object,int,int,int)', 'io.netty.buffer.PoolArena.allocate(io.netty.buffer.PoolThreadCache,io.netty.buffer.PooledByteBuf,int)', 'io.netty.buffer.PoolChunk', 'io.netty.buffer.AbstractByteBufAllocator.directBuffer(int,int)', 'io.netty.buffer.AbstractByteBufAllocator.directBuffer(int)', 'io.netty.buffer.AbstractByteBufAllocator.heapBuffer(int)', 'io.netty.buffer.AbstractByteBufAllocator.heapBuffer()', 'io.netty.buffer.PoolArena.HeapArena.newUnpooledChunk(int)', 'io.netty.buffer.PooledByteBuf.initUnpooled(io.netty.buffer.PoolChunk,int)', 'io.netty.buffer.PoolArena.allocateHuge(io.netty.buffer.PooledByteBuf,int)', 'io.netty.buffer.PooledByteBuf.resumeIntermediaryDeallocations()', 'io.netty.buffer.PoolChunk.initBufWithSubpage(io.netty.buffer.PooledByteBuf,long,int,int)', 'io.netty.buffer.PoolChunk.initBuf(io.netty.buffer.PooledByteBuf,long,int)', 'io.netty.buffer.AbstractByteBufAllocator.validate(int,int)', 'io.netty.buffer.PooledByteBuf.init(io.netty.buffer.PoolChunk,long,int,int,int)', 'io.netty.buffer.AbstractByteBufAllocator.heapBuffer(int,int)', 'io.netty.buffer.AbstractByteBufAllocator.bufferMaxCapacity()', 'io.netty.buffer.AbstractByteBufAllocator.directBuffer()', 'io.netty.buffer.PoolArena.DirectArena.newUnpooledChunk(int)', 'io.netty.buffer.UnpooledByteBufAllocator', 'io.netty.buffer.bufferMaxCapacity()', 'io.netty.buffer.PooledByteBufAllocator.toString()']",['67da6e4bf945f771607454dff40334990396ce7b'],,['buffer/src/main/java/io/netty/buffer'],103.0,49.0,152.0,7.0,9.0,28.0,78.0,17.0,28.0,24.0,7.0,0.0,0.0,0.0,0.0,0.0,0.0,netty
38691,2012-09-12 10:54:09,ghost,"On Java 1.6.0_u35, Windows 7 64-bit with 3.5.7.Final I see lots of garbage being generated (~17MB/minute with 16 workers) and churning from idle workers, immediately after startup before framework is actively used.

I don't observe this with 3.5.6.Final or 3.5.2.Final.

We're starting Netty as a client with a pretty standard setup like

```
        ChannelFactory factory = new NioClientSocketChannelFactory(
            Executors.newCachedThreadPool(),
            Executors.newCachedThreadPool());
    bootstrap = new ClientBootstrap(factory);
```

Any idea what's going on here?

Sorry for the formatting here, but here's an excerpt of a Yourkit allocation trace

```
Name            Recorded Objects  Size (bytes)
java.util.concurrent.ThreadPoolExecutor$Worker.run()    338335  12852080
  java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Runnable)  337818  12835328
    org.jboss.netty.util.internal.DeadLockProofWorker$1.run()   337725  12823856
      sun.nio.ch.SelectorImpl.select(long)  253434  9452216
        sun.nio.ch.SelectorImpl.lockAndDoSelect(long)   253434  9452216
          sun.nio.ch.WindowsSelectorImpl.doSelect(long) 253434  9452216
            sun.nio.ch.SelectorImpl.processDeregisterQueue()    167796  6711816
              java.util.HashMap$KeySet.iterator()   167795  6711800
              java.util.HashMap.keySet()    1   16
            sun.nio.ch.WindowsSelectorImpl.updateSelectedKeys() 85637   2740384
              java.util.AbstractList.iterator() 85637   2740384
            java.nio.channels.spi.AbstractSelector.begin()  1   16
      sun.nio.ch.Util$2.iterator()  84286   3371440
        java.util.HashSet.iterator()    84286   3371440
          java.util.HashMap$KeySet.iterator()   84286   3371440
            java.util.HashMap.newKeyIterator()  84286   3371440
```
",2012-09-13 10:38:46,"[{'commitHash': 'f1e00947a65bab840ef8e7cec3f9c11943dc0d3f', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['79c33bdfc4cfe20c421b5725c45bc3ddf7209397'], 'nameRev': 'f1e00947a65bab840ef8e7cec3f9c11943dc0d3f tags/netty-3.5.8.Final~20', 'commitMessage': 'Make sure we only create an Iterator during processSelectedKeys(..) if there is really something key to process. This cut down unneeded garbage that needs to get handled by the GC later. See #597\n', 'commitDateTime': '2012-09-13 09:45:55', 'authoredDateTime': '2012-09-13 09:45:55', 'commitGitStats': [{'filePath': 'src/main/java/org/jboss/netty/channel/socket/nio/AbstractNioWorker.java', 'insertions': 6, 'deletions': 0, 'lines': 6}, {'filePath': 'src/main/java/org/jboss/netty/channel/socket/nio/NioClientSocketPipelineSink.java', 'insertions': 6, 'deletions': 0, 'lines': 6}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AbstractNioWorker.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.channel.socket.nio.AbstractNioWorker.processSelectedKeys(java.util.Set)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'NioClientSocketPipelineSink.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.Boss.processSelectedKeys(java.util.Set)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '058dfd0a78214c794cfaad39f25a5c43f7587b78', 'commitGHEventType': 'referenced', 'commitUser': 'normanmaurer', 'commitParents': ['ded98ddaf9952770a366b90ccae1fdbacf59d514'], 'nameRev': '058dfd0a78214c794cfaad39f25a5c43f7587b78 tags/netty-4.0.0.Alpha4~1', 'commitMessage': 'Just add a comment to show that the code is related to #597\n', 'commitDateTime': '2012-09-13 10:25:59', 'authoredDateTime': '2012-09-13 10:25:59', 'commitGitStats': [{'filePath': 'transport/src/main/java/io/netty/channel/socket/nio/NioEventLoop.java', 'insertions': 3, 'deletions': 0, 'lines': 3}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'NioEventLoop.java', 'spoonMethods': []}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/597,0.0002777777777777778,"['defect', 'improvement']",Garbage being created from idle workers on 3.5.7.Final,2.0,"['org.jboss.netty.channel.socket.nio.AbstractNioWorker.processSelectedKeys(java.util.Set)', 'org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.Boss.processSelectedKeys(java.util.Set)']","['f1e00947a65bab840ef8e7cec3f9c11943dc0d3f', '058dfd0a78214c794cfaad39f25a5c43f7587b78']",,"['src/main/java/org/jboss/netty/channel/socket/nio', 'transport/src/main/java/io/netty/channel/socket/nio']",15.0,0.0,15.0,3.0,0.0,2.0,2.0,0.0,2.0,0.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,netty
38700,2012-08-20 03:14:23,trustin,"If `HttpContentEncoder` or `HttpContentDecoder` encodes or decodes a new `HttpMessage` before handling the previous message's last chunk, zlib's native memory is not freed, causing direct memory leak.
",2012-08-20 03:21:01,"[{'commitHash': '513fc4f78b29d06eef2532dc526f6c801cda2127', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['ebbcfbc1853fb8114eb8486096773633e919d6d1'], 'nameRev': '513fc4f78b29d06eef2532dc526f6c801cda2127 tags/netty-3.5.5.Final~8', 'commitMessage': '[#539] Fix potential direct memory leak in HttpContentEn/Decoder\n', 'commitDateTime': '2012-08-20 12:14:38', 'authoredDateTime': '2012-08-20 12:14:38', 'commitGitStats': [{'filePath': 'src/main/java/org/jboss/netty/handler/codec/http/HttpContentDecoder.java', 'insertions': 6, 'deletions': 1, 'lines': 7}, {'filePath': 'src/main/java/org/jboss/netty/handler/codec/http/HttpContentEncoder.java', 'insertions': 6, 'deletions': 1, 'lines': 7}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'HttpContentDecoder.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentDecoder.messageReceived(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.MessageEvent)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentDecoder.finishDecode()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'HttpContentEncoder.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentEncoder.writeRequested(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.MessageEvent)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentEncoder.finishEncode()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '10f26f3205e74050caddb11f525a7f6cbe501cd8', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['7f3f792017da8728e65d2756225c779f9a1c5e45'], 'nameRev': '10f26f3205e74050caddb11f525a7f6cbe501cd8 tags/netty-4.0.0.Alpha2~16', 'commitMessage': '[#539] Potential direct memory leak in HttpContentEn/Decoder', 'commitDateTime': '2012-08-20 12:18:39', 'authoredDateTime': '2012-08-20 12:18:39', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/HttpContentDecoder.java', 'insertions': 4, 'deletions': 1, 'lines': 5}, {'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/HttpContentEncoder.java', 'insertions': 4, 'deletions': 1, 'lines': 5}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'HttpContentDecoder.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.HttpContentDecoder.decode(io.netty.channel.ChannelHandlerContext,java.lang.Object)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'HttpContentEncoder.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.HttpContentEncoder.encode(io.netty.channel.ChannelHandlerContext,java.lang.Object)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'bf74b16774c7c0434df732784078a1ac450ad4a4', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['88c3fd306b4db580c1a05b9a91a8d4be4532ae9f'], 'nameRev': 'bf74b16774c7c0434df732784078a1ac450ad4a4 tags/netty-3.5.5.Final~6', 'commitMessage': '[#539] Potential direct memory leak in HttpContentEn/Decoder', 'commitDateTime': '2012-08-20 13:35:12', 'authoredDateTime': '2012-08-20 13:35:12', 'commitGitStats': [{'filePath': 'src/main/java/org/jboss/netty/handler/codec/http/HttpContentDecoder.java', 'insertions': 9, 'deletions': 0, 'lines': 9}, {'filePath': 'src/main/java/org/jboss/netty/handler/codec/http/HttpContentEncoder.java', 'insertions': 9, 'deletions': 0, 'lines': 9}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'HttpContentDecoder.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentDecoder.channelClosed(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.ChannelStateEvent)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'HttpContentEncoder.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentEncoder.channelClosed(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.ChannelStateEvent)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'a93ada203131b22fdc93945147e231566b87d7a6', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['bf74b16774c7c0434df732784078a1ac450ad4a4'], 'nameRev': 'a93ada203131b22fdc93945147e231566b87d7a6 tags/netty-3.5.5.Final~5', 'commitMessage': '[#539] Potential direct memory leak in HttpContentEn/Decoder', 'commitDateTime': '2012-08-20 13:40:58', 'authoredDateTime': '2012-08-20 13:40:58', 'commitGitStats': [{'filePath': 'src/main/java/org/jboss/netty/handler/codec/http/HttpContentDecoder.java', 'insertions': 19, 'deletions': 1, 'lines': 20}, {'filePath': 'src/main/java/org/jboss/netty/handler/codec/http/HttpContentEncoder.java', 'insertions': 19, 'deletions': 1, 'lines': 20}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'HttpContentDecoder.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentDecoder.beforeAdd(org.jboss.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentDecoder.afterAdd(org.jboss.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentDecoder.beforeRemove(org.jboss.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentDecoder.afterRemove(org.jboss.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'HttpContentEncoder.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentEncoder.beforeAdd(org.jboss.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentEncoder.afterAdd(org.jboss.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentEncoder.beforeRemove(org.jboss.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.jboss.netty.handler.codec.http.HttpContentEncoder.afterRemove(org.jboss.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'ec2b29f0b6ab3c57fe0e75b2951f1136c8db8ed0', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['df0aee22cbb77591e2c8ce7f71ea4b3727b7b133'], 'nameRev': 'ec2b29f0b6ab3c57fe0e75b2951f1136c8db8ed0 tags/netty-4.0.0.Alpha2~13', 'commitMessage': '[#539] Potential direct memory leak in HttpContentEn/Decoder', 'commitDateTime': '2012-08-20 13:38:14', 'authoredDateTime': '2012-08-20 13:38:14', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/HttpContentDecoder.java', 'insertions': 20, 'deletions': 4, 'lines': 24}, {'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/HttpContentEncoder.java', 'insertions': 21, 'deletions': 4, 'lines': 25}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'HttpContentDecoder.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.HttpContentDecoder.afterRemove(io.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpContentDecoder.channelInactive(io.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpContentDecoder.cleanup()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpContentDecoder.decode(io.netty.channel.ChannelHandlerContext,java.lang.Object)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'HttpContentEncoder.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.HttpContentEncoder.afterRemove(io.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpContentEncoder.channelInactive(io.netty.channel.ChannelHandlerContext)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpContentEncoder.cleanup()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.HttpContentEncoder.encode(io.netty.channel.ChannelHandlerContext,java.lang.Object)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/539,0.0002777777777777778,['defect'],Potential direct memory leak in HttpContentEn/Decoder,2.0,"['org.jboss.netty.handler.codec.http.HttpContentDecoder.finishDecode()', 'io.netty.handler.codec.http.HttpContentDecoder.decode(io.netty.channel.ChannelHandlerContext,java.lang.Object)', 'io.netty.handler.codec.http.HttpContentEncoder.encode(io.netty.channel.ChannelHandlerContext,java.lang.Object)', 'org.jboss.netty.handler.codec.http.HttpContentDecoder.messageReceived(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.MessageEvent)', 'org.jboss.netty.handler.codec.http.HttpContentEncoder.writeRequested(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.MessageEvent)', 'org.jboss.netty.handler.codec.http.HttpContentEncoder.finishEncode()']","['513fc4f78b29d06eef2532dc526f6c801cda2127', '10f26f3205e74050caddb11f525a7f6cbe501cd8']",,"['codec-http/src/main/java/io/netty/handler/codec/http', 'src/main/java/org/jboss/netty/handler/codec/http']",20.0,4.0,24.0,4.0,0.0,6.0,10.0,0.0,6.0,4.0,2.0,0.0,0.0,0.0,3.0,0.0,0.0,netty
38794,2011-12-15 07:34:25,trustin,,2011-12-15 07:39:29,"[{'commitHash': '414b18e70488153b3454b09233d23e0976cebb73', 'commitGHEventType': 'closed', 'commitUser': 'trustin', 'commitParents': ['c6ef712503412752968a0715be64864c795adc6e'], 'nameRev': '414b18e70488153b3454b09233d23e0976cebb73 tags/netty-3.3.0.Final~19', 'commitMessage': 'Fix #129: Memory leak when setOptions() fails while accepting a new connection.\n', 'commitDateTime': '2011-12-15 16:39:10', 'authoredDateTime': '2011-12-15 16:39:10', 'commitGitStats': [{'filePath': 'src/main/java/org/jboss/netty/bootstrap/ClientBootstrap.java', 'insertions': 9, 'deletions': 1, 'lines': 10}, {'filePath': 'src/main/java/org/jboss/netty/bootstrap/ConnectionlessBootstrap.java', 'insertions': 20, 'deletions': 3, 'lines': 23}, {'filePath': 'src/main/java/org/jboss/netty/bootstrap/ServerBootstrap.java', 'insertions': 5, 'deletions': 1, 'lines': 6}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ClientBootstrap.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.bootstrap.ClientBootstrap.connect(java.net.SocketAddress,java.net.SocketAddress)', 'TOT': 3, 'UPD': 0, 'INS': 2, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'ConnectionlessBootstrap.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.bootstrap.ConnectionlessBootstrap.bind(java.net.SocketAddress)', 'TOT': 4, 'UPD': 0, 'INS': 2, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'org.jboss.netty.bootstrap.ConnectionlessBootstrap.connect(java.net.SocketAddress,java.net.SocketAddress)', 'TOT': 3, 'UPD': 0, 'INS': 2, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'ServerBootstrap.java', 'spoonMethods': [{'spoonMethodName': 'org.jboss.netty.bootstrap.ServerBootstrap.Binder.childChannelOpen(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.ChildChannelStateEvent)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/129,0.0002777777777777778,['defect'],Memory leak when setOptions() fails while accepting a new connection.,1.0,"['org.jboss.netty.bootstrap.ConnectionlessBootstrap.connect(java.net.SocketAddress,java.net.SocketAddress)', 'org.jboss.netty.bootstrap.ConnectionlessBootstrap.bind(java.net.SocketAddress)', 'org.jboss.netty.bootstrap.ServerBootstrap.Binder.childChannelOpen(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.ChildChannelStateEvent)', 'org.jboss.netty.bootstrap.ClientBootstrap.connect(java.net.SocketAddress,java.net.SocketAddress)']",['414b18e70488153b3454b09233d23e0976cebb73'],,['src/main/java/org/jboss/netty/bootstrap'],34.0,5.0,39.0,3.0,0.0,4.0,12.0,5.0,7.0,0.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,netty
38952,2013-11-08 23:40:49,timboudreau,"I'm running into a subtle problem, where buffer leaks are logged, but very rarely, and it appears to be entirely code within the HTTP codec, and identical requests will sometimes produce the problem and sometimes not.

[Here is a simple fileserver maven project](http://timboudreau.com/files/simple-fileserver.tar.bz2) which demonstrates it.  Try the following:
- Run it. The index page loads 10 symlinked copies of the CSS file to generate 11 requests per load.
- Load [localhost:8732/index.html](http://localhost:8732/index.html) - I used Chrome
- Click refresh in your browser many, many times, occasionally shift-reloading to get a full reload
  - The first item in each line of logging is the request number - get it up to around 1000
- Switch away from the browser and do something else for a few minutes
- Come back and refresh again.   The following is logged:
  
  ```
  1003    0.002   /0:0:0:0:0:0:0:1:41829  304 Not Modified    /default-8.css  http://localhost:8732/index.html
  Nov 08, 2013 6:17:31 PM io.netty.util.ResourceLeakDetector reportLeak
  WARNING: LEAK: ByteBuf was GC'd before being released correctly.  The following stack trace shows where the leaked object was created, rather than where you failed to release it.
  io.netty.util.ResourceLeakException: io.netty.buffer.CompositeByteBuf@2c84c504
      at io.netty.util.ResourceLeakDetector$DefaultResourceLeak.<init>(ResourceLeakDetector.java:175)
      at io.netty.util.ResourceLeakDetector.open(ResourceLeakDetector.java:117)
      at io.netty.buffer.CompositeByteBuf.<init>(CompositeByteBuf.java:59)
      at io.netty.buffer.Unpooled.compositeBuffer(Unpooled.java:353)
      at io.netty.handler.codec.http.HttpObjectAggregator.decode(HttpObjectAggregator.java:138)
      at io.netty.handler.codec.http.HttpObjectAggregator.decode(HttpObjectAggregator.java:50)
      at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:89)
      at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:307)
      at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:293)
      at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:153)
      at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:307)
      at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:293)
      at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:775)
      at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)
      at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:485)
      at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:452)
      at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:346)
      at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:801)
      at java.lang.Thread.run(Thread.java:744)
  
  1004    0.002   /0:0:0:0:0:0:0:1:41830  304 Not Modified    /default-9.css  http://localhost:8732/index.html
  ```

This seems like some kind of interplay between whatever the default garbage collector is doing when the application is completely idle, and reference counting on buffers - but there is no information in the stack trace to diagnose what.  Any ideas?
### System info

``````
    Gentoo Linux kernel 3.10.17, i7 4-core, 8Gb RAM

```java version ""1.7.0_45""
Java(TM) SE Runtime Environment (build 1.7.0_45-b18)
Java HotSpot(TM) 64-Bit Server VM (build 24.45-b08, mixed mode)```
``````
",2014-02-07 08:30:44,"[{'commitHash': 'c01f08d3061f465ca1decba9d48f1e7e1ad347d5', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['50f8cc98d1f8462bcbf346edfc96c1155ae432a4'], 'nameRev': 'c01f08d3061f465ca1decba9d48f1e7e1ad347d5 tags/netty-5.0.0.Alpha2~922', 'commitMessage': 'Fix a leak in WebSocketServerProtocolHandshakeHandler\n\n- Related: #1975\n', 'commitDateTime': '2014-02-06 20:57:55', 'authoredDateTime': '2014-02-06 20:57:55', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/websocketx/WebSocketServerProtocolHandshakeHandler.java', 'insertions': 29, 'deletions': 25, 'lines': 54}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebSocketServerProtocolHandshakeHandler.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandshakeHandler', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandshakeHandler.channelRead(io.netty.channel.ChannelHandlerContext,java.lang.Object)', 'TOT': 5, 'UPD': 0, 'INS': 1, 'MOV': 4, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '2598223d0ecb31508de2a02d7310a7eeef864466', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['c4c71e6d289b034e6415e3b04ea8e56c0fd11b99'], 'nameRev': '2598223d0ecb31508de2a02d7310a7eeef864466 tags/netty-4.0.16.Final~56', 'commitMessage': 'Fix resource leaks in WebSocketServerProtocol(Handshake)Handler\n\n- Related: #1975\n', 'commitDateTime': '2014-02-06 21:22:01', 'authoredDateTime': '2014-02-06 21:22:01', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/websocketx/WebSocketServerProtocolHandler.java', 'insertions': 7, 'deletions': 2, 'lines': 9}, {'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/websocketx/WebSocketServerProtocolHandshakeHandler.java', 'insertions': 29, 'deletions': 25, 'lines': 54}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebSocketServerProtocolHandler.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandler.decode(io.netty.channel.ChannelHandlerContext,io.netty.handler.codec.http.websocketx.WebSocketFrame,java.util.List)', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandler.forbiddenHttpRequestResponder().1.channelRead(io.netty.channel.ChannelHandlerContext,java.lang.Object)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'WebSocketServerProtocolHandshakeHandler.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandshakeHandler', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandshakeHandler.channelRead(io.netty.channel.ChannelHandlerContext,java.lang.Object)', 'TOT': 5, 'UPD': 0, 'INS': 1, 'MOV': 4, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '2b769c6daf075183d82f96b78960cfaf6fe2d347', 'commitGHEventType': 'referenced', 'commitUser': 'trustin', 'commitParents': ['8738bc4ae7608fdbcfa7b59dc7207e4203aab66b'], 'nameRev': '2b769c6daf075183d82f96b78960cfaf6fe2d347 tags/netty-5.0.0.Alpha2~919', 'commitMessage': 'Fix resource leaks in WebSocketServerProtocolHandler\n\n- Related: #1975\n', 'commitDateTime': '2014-02-06 21:23:10', 'authoredDateTime': '2014-02-06 21:23:10', 'commitGitStats': [{'filePath': 'codec-http/src/main/java/io/netty/handler/codec/http/websocketx/WebSocketServerProtocolHandler.java', 'insertions': 6, 'deletions': 2, 'lines': 8}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebSocketServerProtocolHandler.java', 'spoonMethods': [{'spoonMethodName': 'io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandler.decode(io.netty.channel.ChannelHandlerContext,io.netty.handler.codec.http.websocketx.WebSocketFrame,java.util.List)', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 2, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/netty/netty/issues/1975,90.00027777777778,['not a bug'],Subtle buffer leak,3.0,"['io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandler.decode(io.netty.channel.ChannelHandlerContext,io.netty.handler.codec.http.websocketx.WebSocketFrame,java.util.List)', 'io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandshakeHandler', 'io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandshakeHandler.channelRead(io.netty.channel.ChannelHandlerContext,java.lang.Object)', 'io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandler.forbiddenHttpRequestResponder().1.channelRead(io.netty.channel.ChannelHandlerContext,java.lang.Object)']","['c01f08d3061f465ca1decba9d48f1e7e1ad347d5', '2598223d0ecb31508de2a02d7310a7eeef864466', '2b769c6daf075183d82f96b78960cfaf6fe2d347']",,['codec-http/src/main/java/io/netty/handler/codec/http/websocketx'],71.0,54.0,125.0,2.0,0.0,4.0,19.0,12.0,5.0,2.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,netty
39401,2019-02-25 05:05:42,amirlivneh,"This is a recent regression bisected to dd70407455f09f3eda7288f0bb9610f8943af03e.

It may be the cause for the recent increase in test flakiness.

To reproduce, run this modified test:
```
  @Test public void missingConnectionHeader() throws IOException {
    webServer.enqueue(new MockResponse()
        .setResponseCode(101)
        .setHeader(""Upgrade"", ""websocket"")
        .setHeader(""Sec-WebSocket-Accept"", ""ujmZX4KXZqjwy6vi1aQFH5p4Ygk=""));
    newWebSocket();

    clientListener.assertFailure(101, null, ProtocolException.class,
        ""Expected 'Connection' header value 'Upgrade' but was 'null'"");

    client.connectionPool().evictAll();
    assertEquals(0, client.connectionPool().connectionCount());
  }
```

",2019-03-07 01:55:54,"[{'commitHash': 'c13c8fa897b8f33198226db9ed7f9cf471cc624c', 'commitGHEventType': 'referenced', 'commitUser': 'swankjesse', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': 'dff5a61fc6045f5849a2a7cd4ae2eadbfd773dd7', 'commitGHEventType': 'referenced', 'commitUser': 'swankjesse', 'commitParents': ['8c3709689650eec64ecab12a9a6e9a667fc82062'], 'nameRev': 'dff5a61fc6045f5849a2a7cd4ae2eadbfd773dd7 tags/parent-3.14.0~11^2', 'commitMessage': ""Don't leak a connection if a WebSocket handshake fails\n\nI'm not particularly happy with all of the moving parts here. I think\nperhaps doing web sockets over duplex is a possible fix here.\n\nCloses: https://github.com/square/okhttp/issues/4658\n"", 'commitDateTime': '2019-03-06 20:40:33', 'authoredDateTime': '2019-03-05 23:25:20', 'commitGitStats': [{'filePath': 'okhttp-tests/src/test/java/okhttp3/internal/ws/WebSocketHttpTest.java', 'insertions': 3, 'deletions': 0, 'lines': 3}, {'filePath': 'okhttp/src/main/java/okhttp3/internal/connection/Exchange.java', 'insertions': 4, 'deletions': 0, 'lines': 4}, {'filePath': 'okhttp/src/main/java/okhttp3/internal/ws/RealWebSocket.java', 'insertions': 5, 'deletions': 4, 'lines': 9}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebSocketHttpTest.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.internal.ws.WebSocketHttpTest.missingConnectionHeader()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'Exchange.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.internal.connection.Exchange.webSocketUpgradeFailed()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RealWebSocket.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.internal.ws.RealWebSocket.extractStreamsFromResponse(okhttp3.Response)', 'TOT': 4, 'UPD': 2, 'INS': 0, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealWebSocket.connect(okhttp3.OkHttpClient).1.onResponse(okhttp3.Call,okhttp3.Response)', 'TOT': 4, 'UPD': 1, 'INS': 2, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/square/okhttp/issues/4658,9.000277777777777,['bug'],Connection leaks if WebSocket handshake fails,1.0,"['okhttp3.internal.ws.RealWebSocket.connect(okhttp3.OkHttpClient).1.onResponse(okhttp3.Call,okhttp3.Response)', 'okhttp3.internal.connection.Exchange.webSocketUpgradeFailed()', 'okhttp3.internal.ws.RealWebSocket.extractStreamsFromResponse(okhttp3.Response)']",['dff5a61fc6045f5849a2a7cd4ae2eadbfd773dd7'],,"['okhttp/src/main/java/okhttp3/internal/ws', 'okhttp/src/main/java/okhttp3/internal/connection']",9.0,4.0,13.0,2.0,3.0,3.0,9.0,2.0,3.0,1.0,2.0,0.0,0.0,0.0,1.0,0.0,0.0,okhttp
39459,2018-09-09 07:00:22,rohanKanojia,"Hi All,

Where exactly we are supposed to do response.close() in case of WebSocket operations? I don't see any in the example i.e [WebSocketEcho](https://github.com/square/okhttp/blob/master/samples/guide/src/main/java/okhttp3/recipes/WebSocketEcho.java) provided in okhttp repo.

We're trying to get rid of these OkHttp connection leaks generated during WebSocket operations in [fabric8io/kubernetes-client](https://github.com/fabric8io/kubernetes-client). For example, There is one websocket operation happening in [PodOperationsImpl](https://github.com/fabric8io/kubernetes-client/blob/master/kubernetes-client/src/main/java/io/fabric8/kubernetes/client/dsl/internal/PodOperationsImpl.java#L267)""
```
        try {
            URL url = new URL(URLUtils.join(getResourceUrl().toString(), sb.toString()));
            Request.Builder r = new Request.Builder().url(url).header(""Sec-WebSocket-Protocol"", ""v4.channel.k8s.io"").get();
            OkHttpClient clone = client.newBuilder().readTimeout(0, TimeUnit.MILLISECONDS).build();
            final ExecWebSocketListener execWebSocketListener = new ExecWebSocketListener(getConfig(), in, out, err, errChannel, inPipe, outPipe, errPipe, errChannelPipe, execListener);
            clone.newWebSocket(r.build(), execWebSocketListener);
            execWebSocketListener.waitUntilReady();
            return execWebSocketListener;
        } catch (Throwable t) {
            throw KubernetesClientException.launderThrowable(forOperationType(""exec""), t);
        }
```
Which gets handled on [ExecWebSocketListener](https://github.com/fabric8io/kubernetes-client/blob/7ea9ce885f9fad72949db6e3f5cc8dceb8ce8766/kubernetes-client/src/main/java/io/fabric8/kubernetes/client/dsl/internal/ExecWebSocketListener.java#L212) , We're closing socket in [close(..)](https://github.com/fabric8io/kubernetes-client/blob/7ea9ce885f9fad72949db6e3f5cc8dceb8ce8766/kubernetes-client/src/main/java/io/fabric8/kubernetes/client/dsl/internal/ExecWebSocketListener.java#L138) callback here:
```
    private void closeWebSocketOnce(int code, String reason) {
      if (closed.get()) {
        return;
      }

      try {
        WebSocket ws = webSocketRef.get();
        if (ws != null) {
          ws.close(code, reason);
        }
      } catch (Throwable t) {
        LOGGER.debug(""Error closing WebSocket."", t);
      }
    }
```
But somehow we're still getting connection leaks, In logs I can see that stacktrace points to the WebSocket opening operation in PodOperationsImpl:
```

Sep 09, 2018 12:08:43 PM okhttp3.internal.platform.Platform log
WARNING: A connection to http://localhost:55231/ was leaked. Did you forget to close a response body?
java.lang.Throwable: response.body().close()
    at okhttp3.internal.platform.Platform.getStackTraceForCloseable(Platform.java:144)
    at okhttp3.RealCall.captureCallStackTrace(RealCall.java:89)
    at okhttp3.RealCall.enqueue(RealCall.java:98)
    at okhttp3.internal.ws.RealWebSocket.connect(RealWebSocket.java:183)
    at okhttp3.OkHttpClient.newWebSocket(OkHttpClient.java:436)
    at io.fabric8.kubernetes.client.dsl.internal.PodOperationsImpl.exec(PodOperationsImpl.java:267)
    at io.fabric8.kubernetes.client.dsl.internal.PodOperationsImpl.exec(PodOperationsImpl.java:61)
    at io.fabric8.kubernetes.client.mock.ExecTest.doExec(ExecTest.java:99)
    at io.fabric8.kubernetes.client.mock.ExecTest.doIteration(ExecTest.java:81)
    at io.fabric8.kubernetes.client.mock.ExecTest.testConnectionLeaks(ExecTest.java:73)
    at io.fabric8.kubernetes.client.mock.ExecTest.testMockServer(ExecTest.java:50)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
    at org.junit.rules.RunRules.evaluate(RunRules.java:20)
    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
    at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:369)
    at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:275)
    at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:239)
    at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:160)
    at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:373)
    at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:334)
    at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:119)
    at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:407)
```

There is a PR already in progress which tries to close response body and reduce leaks(not working though): https://github.com/fabric8io/kubernetes-client/pull/1198 . Could anyone please check what we're doing wrong here? Any kind of help would be highly appreciated :-). 

* **Steps to reproduce:**

1. Clone kubernetes-client repository:
```
git clone -b reduceOkHttpLeaks https://github.com/rohanKanojia/kubernetes-client.git
```

2. Navigate to `kubernetes-tests` directory and run:
```
 mvn -Dtest=""io.fabric8.kubernetes.client.mock.ExecTest#testMockServer"" test
```

3. Wait ~10 minutes. For me after 5th iteration(after 5 minutes) logs appears.
* OkHttp Version: 3.9.1
",2018-11-07 08:37:43,"[{'commitHash': '949439ae5b0c5fd70687d1f946cac80552a5a7f9', 'commitGHEventType': 'referenced', 'commitUser': 'rohanKanojia', 'commitParents': ['14521ebe5f85654f3955e1d14bc62a9c45f5a591'], 'nameRev': '949439ae5b0c5fd70687d1f946cac80552a5a7f9 tags/parent-3.5.0~14^2', 'commitMessage': 'Rename NewWebSocket to WebSocket.\n\nThe synchronous WebSocket class is gone.\n', 'commitDateTime': '2016-11-19 15:16:58', 'authoredDateTime': '2016-11-19 15:16:58', 'commitGitStats': [{'filePath': 'mockwebserver/src/main/java/okhttp3/mockwebserver/MockResponse.java', 'insertions': 4, 'deletions': 4, 'lines': 8}, {'filePath': 'mockwebserver/src/main/java/okhttp3/mockwebserver/MockWebServer.java', 'insertions': 3, 'deletions': 3, 'lines': 6}, {'filePath': 'okhttp-tests/src/main/java/okhttp3/AutobahnTester.java', 'insertions': 14, 'deletions': 14, 'lines': 28}, {'filePath': 'okhttp-tests/src/test/java/okhttp3/RecordedResponse.java', 'insertions': 2, 'deletions': 2, 'lines': 4}, {'filePath': 'okhttp-tests/src/test/java/okhttp3/WebSocketHttpTest.java', 'insertions': 25, 'deletions': 25, 'lines': 50}, {'filePath': 'okhttp-tests/src/test/java/okhttp3/internal/ws/RealWebSocketTest.java', 'insertions': 8, 'deletions': 8, 'lines': 16}, {'filePath': 'okhttp-tests/src/test/java/okhttp3/internal/ws/WebSocketReaderTest.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'okhttp-tests/src/test/java/okhttp3/internal/ws/{NewWebSocketRecorder.java => WebSocketRecorder.java}', 'insertions': 21, 'deletions': 20, 'lines': 41}, {'filePath': 'okhttp/src/main/java/okhttp3/OkHttpClient.java', 'insertions': 4, 'deletions': 4, 'lines': 8}, {'filePath': 'okhttp/src/main/java/okhttp3/{NewWebSocket.java => WebSocket.java}', 'insertions': 3, 'deletions': 39, 'lines': 42}, {'filePath': 'okhttp/src/main/java/okhttp3/WebSocketListener.java', 'insertions': 54, 'deletions': 0, 'lines': 54}, {'filePath': 'okhttp/src/main/java/okhttp3/internal/ws/{RealNewWebSocket.java => RealWebSocket.java}', 'insertions': 7, 'deletions': 6, 'lines': 13}, {'filePath': 'samples/guide/src/main/java/okhttp3/recipes/WebSocketEcho.java', 'insertions': 8, 'deletions': 7, 'lines': 15}, {'filePath': 'samples/slack/src/main/java/okhttp3/slack/RtmSession.java', 'insertions': 9, 'deletions': 8, 'lines': 17}, {'filePath': 'samples/slack/src/main/java/okhttp3/slack/SlackApi.java', 'insertions': 3, 'deletions': 2, 'lines': 5}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'MockResponse.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.mockwebserver.MockResponse', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.mockwebserver.MockResponse.getWebSocketListener()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.mockwebserver.MockResponse.withWebSocketUpgrade(okhttp3.NewWebSocket$Listener)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'MockWebServer.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.mockwebserver.MockWebServer.handleWebSocketUpgrade(java.net.Socket,okio.BufferedSource,okio.BufferedSink,okhttp3.mockwebserver.RecordedRequest,okhttp3.mockwebserver.MockResponse)', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.mockwebserver.MockWebServer.handleWebSocketUpgrade(java.net.Socket,okio.BufferedSource,okio.BufferedSink,okhttp3.mockwebserver.RecordedRequest,okhttp3.mockwebserver.MockResponse).5', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'AutobahnTester.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.AutobahnTester.newWebSocket(java.lang.String,okhttp3.NewWebSocket$Listener)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.runTest(long,long)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.getTestCount()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.updateReports()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.runTest(long,long).1', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.getTestCount().2', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.updateReports().3', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.runTest(long,long).1.onOpen(okhttp3.NewWebSocket,okhttp3.Response)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.runTest(long,long).1.onMessage(okhttp3.NewWebSocket,okio.ByteString)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.runTest(long,long).1.onMessage(okhttp3.NewWebSocket,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.runTest(long,long).1.onClosing(okhttp3.NewWebSocket,int,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.runTest(long,long).1.onFailure(okhttp3.NewWebSocket,java.lang.Throwable,okhttp3.Response)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.getTestCount().2.onMessage(okhttp3.NewWebSocket,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.getTestCount().2.onClosing(okhttp3.NewWebSocket,int,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.getTestCount().2.onFailure(okhttp3.NewWebSocket,java.lang.Throwable,okhttp3.Response)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.updateReports().3.onClosing(okhttp3.NewWebSocket,int,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.AutobahnTester.updateReports().3.onFailure(okhttp3.NewWebSocket,java.lang.Throwable,okhttp3.Response)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RecordedResponse.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.RecordedResponse', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.RecordedResponse.priorResponse()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.RecordedResponse.networkResponse()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.RecordedResponse.cacheResponse()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'WebSocketHttpTest.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.WebSocketHttpTest', 'TOT': 4, 'UPD': 4, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.enqueueClientWebSocket()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.enqueueClientWebSocket(okhttp3.Request)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.textMessage()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.binaryMessage()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.nullStringThrows()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.nullByteStringThrows()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.serverMessage()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.throwingOnOpenFailsImmediately()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.throwingOnFailLogs()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.throwingOnMessageClosesImmediatelyAndFails()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.throwingOnClosingClosesImmediatelyAndFails()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.clientTimeoutClosesBody()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.websocketScheme(java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.throwingOnOpenFailsImmediately().2', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.throwingOnFailLogs().3', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.throwingOnMessageClosesImmediatelyAndFails().4', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.throwingOnClosingClosesImmediatelyAndFails().5', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.throwingOnOpenFailsImmediately().2.onOpen(okhttp3.NewWebSocket,okhttp3.Response)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.throwingOnFailLogs().3.onFailure(okhttp3.NewWebSocket,java.lang.Throwable,okhttp3.Response)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.throwingOnMessageClosesImmediatelyAndFails().4.onMessage(okhttp3.NewWebSocket,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.WebSocketHttpTest.throwingOnClosingClosesImmediatelyAndFails().5.onClosing(okhttp3.NewWebSocket,int,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RealWebSocketTest.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.internal.ws.RealWebSocketTest', 'TOT': 6, 'UPD': 6, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealWebSocketTest.setUp()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealWebSocketTest.setUp().1', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealWebSocketTest.setUp().2', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'WebSocketReaderTest.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.internal.ws.WebSocketReaderTest', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'WebSocketRecorder.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder', 'TOT': 4, 'UPD': 4, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.assertOpen()', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.setNextEventDelegate(okhttp3.NewWebSocket$Listener)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.onOpen(okhttp3.NewWebSocket,okhttp3.Response)', 'TOT': 7, 'UPD': 7, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.onMessage(okhttp3.NewWebSocket,okio.ByteString)', 'TOT': 8, 'UPD': 8, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.onMessage(okhttp3.NewWebSocket,java.lang.String)', 'TOT': 8, 'UPD': 8, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.onClosing(okhttp3.NewWebSocket,int,java.lang.String)', 'TOT': 7, 'UPD': 7, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.onClosed(okhttp3.NewWebSocket,int,java.lang.String)', 'TOT': 7, 'UPD': 7, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.onFailure(okhttp3.NewWebSocket,java.lang.Throwable,okhttp3.Response)', 'TOT': 7, 'UPD': 7, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.assertTextMessage(java.lang.String)', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.assertBinaryMessage(byte[])', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.assertPing(okio.ByteString)', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.assertPong(okio.ByteString)', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.assertClosing(int,java.lang.String)', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.assertClosed(int,java.lang.String)', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.assertExhausted()', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.assertFailure(java.lang.Throwable)', 'TOT': 5, 'UPD': 5, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.assertFailure(java.lang.Class,java.lang.String)', 'TOT': 6, 'UPD': 6, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.assertFailure(int,java.lang.String,java.lang.Class,java.lang.String)', 'TOT': 7, 'UPD': 7, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Open', 'TOT': 4, 'UPD': 4, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.nextEvent()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Failure', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Failure.toString()', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Message', 'TOT': 4, 'UPD': 4, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Ping', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Ping.hashCode()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Ping.equals(java.lang.Object)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Pong', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Pong.hashCode()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Pong.equals(java.lang.Object)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Closing', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Closed', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.asFrameCallback().1.onReadMessage(java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.asFrameCallback().1.onReadMessage(okio.ByteString)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.asFrameCallback().1.onReadPing(okio.ByteString)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.asFrameCallback().1.onReadPong(okio.ByteString)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.asFrameCallback().1.onReadClose(int,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Open.toString()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Message.hashCode()', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Message.equals(java.lang.Object)', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Ping.toString()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Pong.toString()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Closing.toString()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Closing.hashCode()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Closing.equals(java.lang.Object)', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Closed.toString()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Closed.hashCode()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Closed.equals(java.lang.Object)', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.NewWebSocketRecorder.Message.toString()', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'OkHttpClient.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.OkHttpClient.newWebSocket(okhttp3.Request,okhttp3.NewWebSocket$Listener)', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'WebSocket.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.newWebSocket(okhttp3.Request,okhttp3.NewWebSocket$Listener)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'WebSocketListener.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.WebSocketListener', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RealWebSocket.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket', 'TOT': 9, 'UPD': 9, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.initReaderAndWriter(okhttp3.internal.ws.RealNewWebSocket$Streams)', 'TOT': 9, 'UPD': 9, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.onReadPing(okio.ByteString)', 'TOT': 5, 'UPD': 5, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.onReadClose(int,java.lang.String)', 'TOT': 13, 'UPD': 13, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.send(okio.ByteString,int)', 'TOT': 8, 'UPD': 8, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.pong(okio.ByteString)', 'TOT': 5, 'UPD': 5, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.close(int,java.lang.String)', 'TOT': 6, 'UPD': 6, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.writeOneFrame()', 'TOT': 21, 'UPD': 21, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.failWebSocket(java.lang.Exception,okhttp3.Response)', 'TOT': 8, 'UPD': 8, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.ClientStreams', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.request()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.queueSize()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.cancel()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.connect(okhttp3.OkHttpClient)', 'TOT': 4, 'UPD': 4, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.onReadMessage(java.lang.String)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.onReadMessage(okio.ByteString)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.send(java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.send(okio.ByteString)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.loopReader()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.processNextFrame()', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.runWriter()', 'TOT': 4, 'UPD': 4, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.ClientStreams.close()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.Message', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.Close', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.Streams', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.connect(okhttp3.OkHttpClient).2.onResponse(okhttp3.Call,okhttp3.Response)', 'TOT': 9, 'UPD': 9, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.connect(okhttp3.OkHttpClient).2.onFailure(okhttp3.Call,java.io.IOException)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.checkResponse(okhttp3.Response)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.internal.ws.RealNewWebSocket.1.execute()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'WebSocketEcho.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.recipes.WebSocketEcho', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.recipes.WebSocketEcho.onOpen(okhttp3.NewWebSocket,okhttp3.Response)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.recipes.WebSocketEcho.onMessage(okhttp3.NewWebSocket,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.recipes.WebSocketEcho.onMessage(okhttp3.NewWebSocket,okio.ByteString)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.recipes.WebSocketEcho.onClosing(okhttp3.NewWebSocket,int,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.recipes.WebSocketEcho.onFailure(okhttp3.NewWebSocket,java.lang.Throwable,okhttp3.Response)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RtmSession.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.slack.RtmSession', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.slack.RtmSession.onOpen(okhttp3.NewWebSocket,okhttp3.Response)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.slack.RtmSession.onMessage(okhttp3.NewWebSocket,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.slack.RtmSession.onClosing(okhttp3.NewWebSocket,int,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.slack.RtmSession.onFailure(okhttp3.NewWebSocket,java.lang.Throwable,okhttp3.Response)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'okhttp3.slack.RtmSession.close()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'SlackApi.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.slack.SlackApi.rtm(okhttp3.HttpUrl,okhttp3.NewWebSocket$Listener)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'fbc36f96c04f4110f31109e0ee728f63d2a28aee', 'commitGHEventType': 'referenced', 'commitUser': 'swankjesse', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '62f2f823410661128d1d9549b9b727f824637f6c', 'commitGHEventType': 'referenced', 'commitUser': 'swankjesse', 'commitParents': ['550afce3f855115bbb7de9b2080684dd8a6e1fe0'], 'nameRev': '62f2f823410661128d1d9549b9b727f824637f6c tags/parent-3.12.0~8^2', 'commitMessage': 'Fix connection leaks on failed web socket upgrades.\n\nCloses: https://github.com/square/okhttp/issues/4258\n', 'commitDateTime': '2018-11-07 19:21:47', 'authoredDateTime': '2018-11-06 22:36:54', 'commitGitStats': [{'filePath': 'okhttp-tests/src/test/java/okhttp3/internal/ws/WebSocketHttpTest.java', 'insertions': 32, 'deletions': 0, 'lines': 32}, {'filePath': 'okhttp/src/main/java/okhttp3/internal/http/RetryAndFollowUpInterceptor.java', 'insertions': 1, 'deletions': 3, 'lines': 4}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebSocketHttpTest.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.internal.ws.WebSocketHttpTest.webSocketConnectionIsReleased()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RetryAndFollowUpInterceptor.java', 'spoonMethods': [{'spoonMethodName': 'okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(okhttp3.internal.http.Chain)', 'TOT': 4, 'UPD': 0, 'INS': 1, 'MOV': 2, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/square/okhttp/issues/4258,59.000277777777775,['bug'],Connection Leaks happening during WebSocket Operations,2.0,"['okhttp3.slack.RtmSession.onOpen(okhttp3.NewWebSocket,okhttp3.Response)', 'okhttp3.internal.ws.NewWebSocketRecorder.Closing', 'okhttp3.internal.ws.RealNewWebSocket.processNextFrame()', 'okhttp3.internal.ws.NewWebSocketRecorder.assertTextMessage(java.lang.String)', 'okhttp3.internal.ws.RealNewWebSocket.connect(okhttp3.OkHttpClient)', 'okhttp3.internal.ws.NewWebSocketRecorder.Pong.hashCode()', 'okhttp3.internal.ws.NewWebSocketRecorder.Pong', 'okhttp3.internal.ws.NewWebSocketRecorder.asFrameCallback().1.onReadMessage(okio.ByteString)', 'okhttp3.slack.RtmSession', 'okhttp3.internal.ws.NewWebSocketRecorder.Ping.toString()', 'okhttp3.internal.ws.NewWebSocketRecorder.Failure', 'okhttp3.internal.ws.RealNewWebSocket.onReadMessage(java.lang.String)', 'okhttp3.internal.ws.RealNewWebSocket.Close', 'okhttp3.recipes.WebSocketEcho.onOpen(okhttp3.NewWebSocket,okhttp3.Response)', 'okhttp3.WebSocketListener', 'okhttp3.internal.ws.NewWebSocketRecorder.Closing.equals(java.lang.Object)', 'okhttp3.internal.ws.NewWebSocketRecorder.Closed.hashCode()', 'okhttp3.internal.ws.NewWebSocketRecorder.asFrameCallback().1.onReadClose(int,java.lang.String)', 'okhttp3.slack.RtmSession.onClosing(okhttp3.NewWebSocket,int,java.lang.String)', 'okhttp3.newWebSocket(okhttp3.Request,okhttp3.NewWebSocket$Listener)', 'okhttp3.internal.ws.NewWebSocketRecorder.onMessage(okhttp3.NewWebSocket,java.lang.String)', 'okhttp3.internal.ws.NewWebSocketRecorder.onFailure(okhttp3.NewWebSocket,java.lang.Throwable,okhttp3.Response)', 'okhttp3.RecordedResponse', 'okhttp3.internal.ws.NewWebSocketRecorder.Message', 'okhttp3.slack.RtmSession.onMessage(okhttp3.NewWebSocket,java.lang.String)', 'okhttp3.internal.ws.NewWebSocketRecorder.Closed.toString()', 'okhttp3.RecordedResponse.priorResponse()', 'okhttp3.internal.ws.RealNewWebSocket.1.execute()', 'okhttp3.RecordedResponse.networkResponse()', 'okhttp3.internal.ws.NewWebSocketRecorder.assertClosed(int,java.lang.String)', 'okhttp3', 'okhttp3.internal.ws.NewWebSocketRecorder.onMessage(okhttp3.NewWebSocket,okio.ByteString)', 'okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(okhttp3.internal.http.Chain)', 'okhttp3.mockwebserver.MockResponse', 'okhttp3.slack.RtmSession.close()', 'okhttp3.slack.SlackApi.rtm(okhttp3.HttpUrl,okhttp3.NewWebSocket$Listener)', 'okhttp3.internal.ws.RealNewWebSocket.Streams', 'okhttp3.internal.ws.NewWebSocketRecorder.Ping.equals(java.lang.Object)', 'okhttp3.internal.ws.RealNewWebSocket.initReaderAndWriter(okhttp3.internal.ws.RealNewWebSocket$Streams)', 'okhttp3.internal.ws.NewWebSocketRecorder.Closing.hashCode()', 'okhttp3.internal.ws.RealNewWebSocket.ClientStreams.close()', 'okhttp3.mockwebserver.MockResponse.withWebSocketUpgrade(okhttp3.NewWebSocket$Listener)', 'okhttp3.recipes.WebSocketEcho.onClosing(okhttp3.NewWebSocket,int,java.lang.String)', 'okhttp3.internal.ws.RealNewWebSocket.close(int,java.lang.String)', 'okhttp3.internal.ws.NewWebSocketRecorder.Pong.equals(java.lang.Object)', 'okhttp3.internal.ws.NewWebSocketRecorder.assertPing(okio.ByteString)', 'okhttp3.internal.ws.RealNewWebSocket.runWriter()', 'okhttp3.internal.ws.NewWebSocketRecorder.nextEvent()', 'okhttp3.internal.ws.NewWebSocketRecorder.Closed.equals(java.lang.Object)', 'okhttp3.internal.ws.RealNewWebSocket.send(java.lang.String)', 'okhttp3.internal.ws.NewWebSocketRecorder.asFrameCallback().1.onReadMessage(java.lang.String)', 'okhttp3.internal.ws.RealNewWebSocket.send(okio.ByteString,int)', 'okhttp3.recipes.WebSocketEcho.onFailure(okhttp3.NewWebSocket,java.lang.Throwable,okhttp3.Response)', 'okhttp3.internal.ws.NewWebSocketRecorder.Ping.hashCode()', 'okhttp3.internal.ws.RealNewWebSocket.queueSize()', 'okhttp3.internal.ws.NewWebSocketRecorder.assertClosing(int,java.lang.String)', 'okhttp3.internal.ws.NewWebSocketRecorder.assertExhausted()', 'okhttp3.slack.RtmSession.onFailure(okhttp3.NewWebSocket,java.lang.Throwable,okhttp3.Response)', 'okhttp3.internal.ws.NewWebSocketRecorder.Closing.toString()', 'okhttp3.internal.ws.RealNewWebSocket.failWebSocket(java.lang.Exception,okhttp3.Response)', 'okhttp3.internal.ws.NewWebSocketRecorder.Pong.toString()', 'okhttp3.internal.ws.NewWebSocketRecorder.assertFailure(int,java.lang.String,java.lang.Class,java.lang.String)', 'okhttp3.internal.ws.NewWebSocketRecorder.Open', 'okhttp3.internal.ws.NewWebSocketRecorder.onClosing(okhttp3.NewWebSocket,int,java.lang.String)', 'okhttp3.internal.ws.NewWebSocketRecorder.assertOpen()', 'okhttp3.mockwebserver.MockWebServer.handleWebSocketUpgrade(java.net.Socket,okio.BufferedSource,okio.BufferedSink,okhttp3.mockwebserver.RecordedRequest,okhttp3.mockwebserver.MockResponse).5', 'okhttp3.recipes.WebSocketEcho', 'okhttp3.internal.ws.RealNewWebSocket', 'okhttp3.internal.ws.RealNewWebSocket.onReadMessage(okio.ByteString)', 'okhttp3.internal.ws.RealNewWebSocket.connect(okhttp3.OkHttpClient).2.onFailure(okhttp3.Call,java.io.IOException)', 'okhttp3.internal.ws.RealNewWebSocket.onReadClose(int,java.lang.String)', 'okhttp3.internal.ws.RealNewWebSocket.ClientStreams', 'okhttp3.internal.ws.NewWebSocketRecorder.Message.toString()', 'okhttp3.internal.ws.RealNewWebSocket.checkResponse(okhttp3.Response)', 'okhttp3.mockwebserver.MockResponse.getWebSocketListener()', 'okhttp3.internal.ws.RealNewWebSocket.request()', 'okhttp3.recipes.WebSocketEcho.onMessage(okhttp3.NewWebSocket,okio.ByteString)', 'okhttp3.internal.ws.NewWebSocketRecorder.Message.hashCode()', 'okhttp3.recipes.WebSocketEcho.onMessage(okhttp3.NewWebSocket,java.lang.String)', 'okhttp3.internal.ws.NewWebSocketRecorder.Failure.toString()', 'okhttp3.internal.ws.NewWebSocketRecorder.assertPong(okio.ByteString)', 'okhttp3.internal.ws.NewWebSocketRecorder.assertFailure(java.lang.Throwable)', 'okhttp3.internal.ws.RealNewWebSocket.onReadPing(okio.ByteString)', 'okhttp3.internal.ws.RealNewWebSocket.cancel()', 'okhttp3.internal.ws.RealNewWebSocket.loopReader()', 'okhttp3.OkHttpClient.newWebSocket(okhttp3.Request,okhttp3.NewWebSocket$Listener)', 'okhttp3.internal.ws.NewWebSocketRecorder.assertFailure(java.lang.Class,java.lang.String)', 'okhttp3.internal.ws.NewWebSocketRecorder.onOpen(okhttp3.NewWebSocket,okhttp3.Response)', 'okhttp3.internal.ws.NewWebSocketRecorder', 'okhttp3.internal.ws.NewWebSocketRecorder.Ping', 'okhttp3.internal.ws.RealNewWebSocket.Message', 'okhttp3.internal.ws.NewWebSocketRecorder.onClosed(okhttp3.NewWebSocket,int,java.lang.String)', 'okhttp3.internal.ws.NewWebSocketRecorder.Open.toString()', 'okhttp3.internal.ws.RealNewWebSocket.pong(okio.ByteString)', 'okhttp3.internal.ws.RealNewWebSocket.writeOneFrame()', 'okhttp3.internal.ws.NewWebSocketRecorder.assertBinaryMessage(byte[])', 'okhttp3.internal.ws.NewWebSocketRecorder.Closed', 'okhttp3.internal.ws.NewWebSocketRecorder.Message.equals(java.lang.Object)', 'okhttp3.internal.ws.RealNewWebSocket.send(okio.ByteString)', 'okhttp3.internal.ws.RealNewWebSocket.connect(okhttp3.OkHttpClient).2.onResponse(okhttp3.Call,okhttp3.Response)', 'okhttp3.internal.ws.NewWebSocketRecorder.setNextEventDelegate(okhttp3.NewWebSocket$Listener)', 'okhttp3.RecordedResponse.cacheResponse()', 'okhttp3.mockwebserver.MockWebServer.handleWebSocketUpgrade(java.net.Socket,okio.BufferedSource,okio.BufferedSink,okhttp3.mockwebserver.RecordedRequest,okhttp3.mockwebserver.MockResponse)', 'okhttp3.internal.ws.NewWebSocketRecorder.asFrameCallback().1.onReadPong(okio.ByteString)', 'okhttp3.internal.ws.NewWebSocketRecorder.asFrameCallback().1.onReadPing(okio.ByteString)']","['949439ae5b0c5fd70687d1f946cac80552a5a7f9', '62f2f823410661128d1d9549b9b727f824637f6c']",,"['samples/slack/src/main/java/okhttp3/slack', 'mockwebserver/src/main/java/okhttp3/mockwebserver', 'okhttp/src/main/java/okhttp3', 'okhttp/src/main/java/okhttp3/internal/http', 'samples/guide/src/main/java/okhttp3/recipes', 'okhttp/src/main/java/okhttp3/internal/ws']",96.0,76.0,172.0,10.0,315.0,105.0,320.0,2.0,2.0,1.0,12.0,0.0,0.0,0.0,1.0,0.0,0.0,okhttp
41848,2015-05-11 18:52:57,kishikawakatsumi,"Reported by @zaki50 

`RealmChangeListener` is added to `Realm` when `automaticUpdate` is true. Then the listener instance was not released until the `Realm` instance is released because the `RealmChangeListener` is never deleted.

Since a listener instance is an anonymous inner class of `RealmBaseAdapter`, it holds a reference to the `RealmBaseAdapter` as an enclosing instance. `RealmBaseAdapter` usually holds a reference to the `Activity` that uses it as `Context`. So these instances will not be released until the `Realm` instance is released.

If you use `Realm` in only one Activity, there is no problem because `Realm#close()` is called when the `Activity`  is destroyed. (Strictly speaking, adapters may be accumulated if re-create a `RealmBaseAdapter` while the Activity is alive.)

On the other hand, if you use two activities, there are main activity and another activity that has `ListView`, each activity uses `Realm`, the `Realm` instance is held in cache until `onDestroy` of main activity is called. For example if you transition between the two Activities as follows, Main -> List-> back -> List -> back -> List... I think the `RealmChangeListener` may be accumulated in the `Realm`.

What do you think? @cmelchior @emanuelez 
",2015-05-12 13:05:09,"[{'commitHash': '757b726b73ca63f6ffd505ab9751e7b86159855c', 'commitGHEventType': 'referenced', 'commitUser': 'emanuelez', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '96bf95a8b3bc8bfc357eac190368d4e87f3c806a', 'commitGHEventType': 'referenced', 'commitUser': 'emanuelez', 'commitParents': ['2b7474f0484dcb2835285aec6615f7d444b1ffc3'], 'nameRev': '96bf95a8b3bc8bfc357eac190368d4e87f3c806a tags/v0.80.3~22^2', 'commitMessage': 'Fix a memory leak in RealmBaseAdapter\n\nFixes #1109\nWe now use WeakReferences to store the change listeners.\nThis allows the Garbage Collector to clean up the adapters.', 'commitDateTime': '2015-05-12 15:03:59', 'authoredDateTime': '2015-05-12 13:25:51', 'commitGitStats': [{'filePath': 'changelog.txt', 'insertions': 1, 'deletions': 0, 'lines': 1}, {'filePath': 'realm/src/main/java/io/realm/Realm.java', 'insertions': 14, 'deletions': 7, 'lines': 21}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'Realm.java', 'spoonMethods': [{'spoonMethodName': 'io.realm.Realm.sendNotifications()', 'TOT': 7, 'UPD': 2, 'INS': 1, 'MOV': 3, 'DEL': 1}, {'spoonMethodName': 'io.realm.Realm.addChangeListener(io.realm.RealmChangeListener)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'io.realm.Realm.removeChangeListener(io.realm.RealmChangeListener)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/realm/realm-java/issues/1109,0.0002777777777777778,['T-Bug'],Possibility of a memory leak due to a combination of `RealmChangeListener` and `automaticUpdate`,1.0,"['io.realm.Realm.sendNotifications()', 'io.realm.Realm.addChangeListener(io.realm.RealmChangeListener)', 'io.realm.Realm.removeChangeListener(io.realm.RealmChangeListener)']",['96bf95a8b3bc8bfc357eac190368d4e87f3c806a'],,['realm/src/main/java/io/realm'],14.0,7.0,21.0,1.0,2.0,3.0,11.0,3.0,3.0,3.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,realm-java
42095,2020-06-17 04:58:19,mrniko,,2020-06-17 05:00:03,"[{'commitHash': 'b707fe8e297bcc9dbf36e83684e667ecc387769b', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['75e320663f0d5dbcac1691f29344d20cc9046820'], 'nameRev': 'b707fe8e297bcc9dbf36e83684e667ecc387769b tags/redisson-3.13.2~22', 'commitMessage': 'Fixed - Connection leak if SSL connection got reconnected. #2845\n', 'commitDateTime': '2020-06-17 08:02:11', 'authoredDateTime': '2020-06-17 08:02:11', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/client/RedisConnection.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'redisson/src/main/java/org/redisson/client/handler/RedisChannelInitializer.java', 'insertions': 1, 'deletions': 0, 'lines': 1}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'RedisConnection.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.client.RedisConnection.close()', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'RedisChannelInitializer.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.client.handler.RedisChannelInitializer.initSsl(org.redisson.client.RedisClientConfig,org.redisson.client.handler.Channel).1.userEventTriggered(org.redisson.client.handler.ChannelHandlerContext,java.lang.Object)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/2845,0.0002777777777777778,['bug'],Connection leak if SSL connection got reconnected,1.0,"['org.redisson.client.RedisConnection.close()', 'org.redisson.client.handler.RedisChannelInitializer.initSsl(org.redisson.client.RedisClientConfig,org.redisson.client.handler.Channel).1.userEventTriggered(org.redisson.client.handler.ChannelHandlerContext,java.lang.Object)']",['b707fe8e297bcc9dbf36e83684e667ecc387769b'],,"['redisson/src/main/java/org/redisson/client/handler', 'redisson/src/main/java/org/redisson/client']",3.0,1.0,4.0,2.0,0.0,2.0,3.0,1.0,2.0,0.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,redisson
42129,2020-04-03 15:26:00,DingQianWen,"Redisson version:3.11.6

```java
RRateLimiter rateLimiter = redissonClient.getRateLimiter(""key"");
rateLimiter.trySetRate(RateType.OVERALL, 3, 10, RateIntervalUnit.MINUTES);
//Delete the invalid
rateLimiter.delete();
```

Delete the invalid",2020-04-07 05:41:47,"[{'commitHash': 'e4315b8cd7dffc1ea06b4ccb79e68298a7ab4d30', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['65e4d2c7af2cbd35147ae111ea5a8007e6c028fe'], 'nameRev': 'e4315b8cd7dffc1ea06b4ccb79e68298a7ab4d30 tags/redisson-3.12.5~17', 'commitMessage': ""Fixed - RRateLimiter.delete() method doesn't delete all allocated Redis objects. #2670\n"", 'commitDateTime': '2020-04-07 08:42:36', 'authoredDateTime': '2020-04-07 08:42:36', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/RedissonRateLimiter.java', 'insertions': 4, 'deletions': 0, 'lines': 4}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'RedissonRateLimiter.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.RedissonRateLimiter.deleteAsync()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/2670,3.000277777777778,['bug'],RRateLimiter delete,1.0,['org.redisson.RedissonRateLimiter.deleteAsync()'],['e4315b8cd7dffc1ea06b4ccb79e68298a7ab4d30'],,['redisson/src/main/java/org/redisson'],4.0,0.0,4.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,redisson
42143,2020-02-13 08:48:14,semistone,"Relate to https://github.com/redisson/redisson/issues/2043
## Expected behavior 
When using a fixed connection pool of min=64 and max=64 to every node (masters and slaves) on cluster config. Redisson is able to open a healthy connection pool of 64 to each of the nodes

## Actual behavior
 Connection never recover
## Redis version
4.0.8 and use utils/create-cluster to create local cluster
## Redission version
3.11.5
## Reproduce step


Redisson configuration


```	clusterServersConfig = {
		connectTimeout = 500
		timeout = 100
		masterConnectionMinimumIdleSize = 1 <== just to make it easier to reproduce.
		masterConnectionPoolSize = 1
		slaveConnectionMinimumIdleSize = 1
		slaveConnectionPoolSize = 1
		retryAttempts = 3
		retryInterval = 25
		keepAlive = true
		tcpNoDelay = true
		readMode = MASTER_SLAVE
		pingConnectionInterval = 2000
		nodeAddresses = [
							""redis://127.0.0.1:30001"",
							""redis://127.0.0.1:30002"",
							""redis://127.0.0.1:30003"",
							""redis://127.0.0.1:30004"",
							""redis://127.0.0.1:30005"",
							""redis://127.0.0.1:30006""
		]
					}
```



and request controller, each HTTP GET request will fetch 100 keys from Redis cluster in batch mode.

```
	@GetMapping(path = ""/get/{id}"", produces = MediaType.APPLICATION_JSON_VALUE)
	public CompletionStage<Map<String, String>> get(@PathVariable(""id"") int id) {

		Set<String> req = new HashSet<>();
		for (int i = 0; i< 100; i++) {
			req.add(""test""+ (id * 100  + i));
		}
		CompletionStage<Map<String, String>> test = myRedisClusterWithPrefix.getAllAsync(req);
		test.thenAccept(mm -> {
			//System.out.println(""return ""+ mm);
		});
		return test;
	}
```

stress test 100 concurrency
`ab -n 10000  -c 100 http://localhost:8080/rapid-samples-minimal-spring-boot/get/5 `


just after running about 20 seconds and stop the stress test tool.

then I call curl http://localhost:8080/rapid-samples-minimal-spring-boot/get/5 again
it will already return an error and never recover.
error log is
```
17:34:10.813 [DEBUG] r.s.o.r.c.ClusterConnectionManager - slot 3699 for api:rapid:test:test560
17:34:10.813 [DEBUG] r.s.o.r.c.RedisExecutor - connection released for command null and params null from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=1, freeConnectionsCounter=value:1:queue:0, freezed=false, freezeReason=null, client=[addr=redis://127.0.0.1:30004], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@9214847 [redisClient=[addr=redis://127.0.0.1:30004], channel=[id: 0x25f4bc57, L:/127.0.0.1:53318 - R:127.0.0.1/127.0.0.1:30004], currentCommand=null]
17:34:10.846 [DEBUG] r.s.o.r.c.RedisExecutor - attempt 1 for command null and params null
17:34:10.846 [DEBUG] r.s.o.r.c.RedisExecutor - attempt 1 for command null and params null
17:34:10.881 [DEBUG] r.s.o.r.c.RedisExecutor - attempt 2 for command null and params null
17:34:10.881 [DEBUG] r.s.o.r.c.RedisExecutor - attempt 2 for command null and params null
17:34:10.916 [DEBUG] r.s.o.r.c.RedisExecutor - attempt 3 for command null and params null
17:34:10.917 [DEBUG] r.s.o.r.c.RedisExecutor - attempt 3 for command null and params null
17:34:10.957 [ERROR] c.r.r.e.h.RapidSpringErrorHandler - Unable to process unhandled exception
rapid.shaded.org.redisson.client.RedisTimeoutException: Unable to acquire connection! Increase connection pool size and/or retryIntervalNode source: NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=1, freeConnectionsCounter=value:1:queue:0, freezed=false, freezeReason=null, client=[addr=redis://127.0.0.1:30005], nodeType=MASTER, firstFail=0]]], command: null, params: null after 0 retry attempts
	at rapid.shaded.org.redisson.command.RedisExecutor$2.run(RedisExecutor.java:191)
	at rapid.shaded.io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:680)
	at rapid.shaded.io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:755)
	at rapid.shaded.io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:483)
	at rapid.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
```


Connection status, still connected.
```
~ » lsof -P -p `jps |grep Application |awk '{print $1}'` |grep IPv     |grep 3000                                                         yinchin.chen@P49945
java    14825 yinchin.chen  237u     IPv6 0x3dec6b4ca72da4d1        0t0      TCP localhost:53301->localhost:30001 (ESTABLISHED)
java    14825 yinchin.chen  239u     IPv6 0x3dec6b4ca72dcd11        0t0      TCP localhost:53302->localhost:30006 (ESTABLISHED)
java    14825 yinchin.chen  241u     IPv6 0x3dec6b4ca72db051        0t0      TCP localhost:53303->localhost:30004 (ESTABLISHED)
java    14825 yinchin.chen  243u     IPv6 0x3dec6b4ca72dd2d1        0t0      TCP localhost:53304->localhost:30005 (ESTABLISHED)
java    14825 yinchin.chen  245u     IPv6 0x3dec6b4ca8fb3611        0t0      TCP localhost:53305->localhost:30002 (ESTABLISHED)
java    14825 yinchin.chen  246u     IPv6 0x3dec6b4ca8fb3051        0t0      TCP localhost:53306->localhost:30003 (ESTABLISHED)
java    14825 yinchin.chen  247u     IPv6 0x3dec6b4ca8fb3bd1        0t0      TCP localhost:53309->localhost:30001 (ESTABLISHED)
java    14825 yinchin.chen  248u     IPv6 0x3dec6b4ca8fb4191        0t0      TCP localhost:53311->localhost:30002 (ESTABLISHED)
java    14825 yinchin.chen  249u     IPv6 0x3dec6b4ca8fb4751        0t0      TCP localhost:53307->localhost:30001 (ESTABLISHED)
java    14825 yinchin.chen  250u     IPv6 0x3dec6b4ca8fb2a91        0t0      TCP localhost:53310->localhost:30003 (ESTABLISHED)
java    14825 yinchin.chen  253u     IPv6 0x3dec6b4ca8fb24d1        0t0      TCP localhost:53314->localhost:30005 (ESTABLISHED)
java    14825 yinchin.chen  254u     IPv6 0x3dec6b4ca8fb4d11        0t0      TCP localhost:53315->localhost:30006 (ESTABLISHED)
java    14825 yinchin.chen  255u     IPv6 0x3dec6b4ca8fb1f11        0t0      TCP localhost:53308->localhost:30005 (ESTABLISHED)
java    14825 yinchin.chen  256u     IPv6 0x3dec6b4ca8fb1951        0t0      TCP localhost:53313->localhost:30004 (ESTABLISHED)
java    14825 yinchin.chen  260u     IPv6 0x3dec6b4ca8fb52d1        0t0      TCP localhost:53316->localhost:30006 (ESTABLISHED)
java    14825 yinchin.chen  261u     IPv6 0x3dec6b4ca9512611        0t0      TCP localhost:53312->localhost:30004 (ESTABLISHED)
java    14825 yinchin.chen  277u     IPv6 0x3dec6b4ca9513751        0t0      TCP localhost:53318->localhost:30004 (ESTABLISHED)
java    14825 yinchin.chen  279u     IPv6 0x3dec6b4ca9513d11        0t0      TCP localhost:53319->localhost:30006 (ESTABLISHED)
java    14825 yinchin.chen  380u     IPv6 0x3dec6b4cabc0da91        0t0      TCP localhost:53419->localhost:30005 (ESTABLISHED)
```",2020-02-17 12:42:12,"[{'commitHash': '45b7438c7caf836c650ff2ac4ae767caf2dd011f', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['80141fc918734090a90e86933dd2df1d9f55519f'], 'nameRev': '45b7438c7caf836c650ff2ac4ae767caf2dd011f tags/redisson-3.12.2~5', 'commitMessage': 'Fixed - connection leak #2587\n', 'commitDateTime': '2020-02-17 15:42:24', 'authoredDateTime': '2020-02-17 15:42:24', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/command/CommandBatchService.java', 'insertions': 11, 'deletions': 21, 'lines': 32}, {'filePath': 'redisson/src/main/java/org/redisson/command/RedisExecutor.java', 'insertions': 6, 'deletions': 15, 'lines': 21}, {'filePath': 'redisson/src/test/java/org/redisson/RedissonBatchTest.java', 'insertions': 81, 'deletions': 26, 'lines': 107}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'CommandBatchService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.command.CommandBatchService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],org.redisson.misc.RPromise,boolean)', 'TOT': 2, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.command.CommandBatchService.executeAsync(org.redisson.api.BatchOptions)', 'TOT': 4, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'org.redisson.command.CommandBatchService.executeRedisBasedQueue().1.run()', 'TOT': 4, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'RedisExecutor.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.command.RedisExecutor.execute()', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.command.RedisExecutor.scheduleRetryTimeout(org.redisson.api.RFuture,org.redisson.misc.RPromise)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.command.RedisExecutor.scheduleRetryTimeout(org.redisson.api.RFuture,org.redisson.misc.RPromise).1.run(io.netty.util.Timeout)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'RedissonBatchTest.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.RedissonBatchTest', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testDifferentCodecs()', 'TOT': 17, 'UPD': 4, 'INS': 1, 'MOV': 11, 'DEL': 1}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testConvertor()', 'TOT': 15, 'UPD': 11, 'INS': 1, 'MOV': 3, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testExceptionHandling()', 'TOT': 3, 'UPD': 2, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testBatchCancel()', 'TOT': 14, 'UPD': 12, 'INS': 0, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testBatchRedirect()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testConnectionLeakAfterError()', 'TOT': 6, 'UPD': 4, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testPerformance()', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testBigRequestAtomic()', 'TOT': 4, 'UPD': 2, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testSyncSlaves()', 'TOT': 6, 'UPD': 4, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testWriteTimeout()', 'TOT': 4, 'UPD': 4, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testSkipResult()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testBatchNPE()', 'TOT': 3, 'UPD': 1, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testAtomic()', 'TOT': 6, 'UPD': 6, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testAtomicSyncSlaves()', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testBatchList()', 'TOT': 4, 'UPD': 3, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testDifferentCodecsAtomic()', 'TOT': 5, 'UPD': 3, 'INS': 0, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testBatchBigRequest()', 'TOT': 4, 'UPD': 2, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.test()', 'TOT': 2, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testEmpty()', 'TOT': 4, 'UPD': 1, 'INS': 1, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testTwice()', 'TOT': 2, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testOrdering()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.before()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.data()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testOrdering().1.run()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.testConnectionLeak()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonBatchTest.executeBatch(org.redisson.RedissonClient)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/2587,4.000277777777778,['bug'],broken connections on the pool,1.0,"['org.redisson.command.CommandBatchService.executeRedisBasedQueue().1.run()', 'org.redisson.command.CommandBatchService.executeAsync(org.redisson.api.BatchOptions)', 'org.redisson.command.RedisExecutor.scheduleRetryTimeout(org.redisson.api.RFuture,org.redisson.misc.RPromise).1.run(io.netty.util.Timeout)', 'org.redisson.command.CommandBatchService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],org.redisson.misc.RPromise,boolean)', 'org.redisson.command.RedisExecutor.execute()', 'org.redisson.command.RedisExecutor.scheduleRetryTimeout(org.redisson.api.RFuture,org.redisson.misc.RPromise)']",['45b7438c7caf836c650ff2ac4ae767caf2dd011f'],,['redisson/src/main/java/org/redisson/command'],17.0,36.0,53.0,2.0,6.0,6.0,14.0,1.0,2.0,5.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,redisson
42246,2019-02-25 07:33:24,douyux,"```java
public CacheKey toCacheKey(Object key) {
    ByteBuf encoded = object.encodeMapKey(key);
    try {
        return toCacheKey(encoded);
    } finally {
        encoded.release();
    }
}
```",2019-02-25 10:09:44,"[{'commitHash': 'de7c115542f770ba25c2fc5712f88c2184324dcc', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['4400c929e660df9886ddd32837282e1aaa1389f7'], 'nameRev': 'de7c115542f770ba25c2fc5712f88c2184324dcc tags/redisson-3.10.3~8', 'commitMessage': 'Fixed - StackOverflowError arise in LocalCacheView.toCacheKey #1935\n', 'commitDateTime': '2019-02-25 13:09:01', 'authoredDateTime': '2019-02-25 13:09:01', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/cache/LocalCacheView.java', 'insertions': 4, 'deletions': 1, 'lines': 5}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'LocalCacheView.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.cache.LocalCacheView.toCacheKey(io.netty.buffer.ByteBuf)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/1935,0.0002777777777777778,['bug'],LocalCacheView.toCacheKey StackOverflowError,1.0,['org.redisson.cache.LocalCacheView.toCacheKey(io.netty.buffer.ByteBuf)'],['de7c115542f770ba25c2fc5712f88c2184324dcc'],,['redisson/src/main/java/org/redisson/cache'],4.0,1.0,5.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,redisson
42248,2019-02-21 08:21:14,astmuc,"several puts (5-10) into a MapCache guarded with a Lock seems to accumulate the payloads in thread locals. The payload is large (several Mb) and the pod (dockered spring boot app with 700 Mb max) goes out of heap. The app running with redisson 3.7.5 has no such problems.

redisson 3.10.2

      config
        .useMasterSlaveServers()
        .setMasterAddress(redisHost)
        .addSlaveAddress(redisSlave)
        .setPassword(redisPassword)
        .setTimeout(10000);

redis 4.0.1 (master, slave)

![mat-1](https://user-images.githubusercontent.com/37765839/53153947-d331f800-35b9-11e9-8903-e1e021632545.png)

",2019-02-25 09:57:11,"[{'commitHash': 'b77fda1e7e2c8746ce90e4c188577f89568c03cc', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['ff4c2f71f2bfd6284aed7b8bc185c24b8aa57716'], 'nameRev': 'b77fda1e7e2c8746ce90e4c188577f89568c03cc tags/redisson-3.10.3~14', 'commitMessage': 'Fixed - FSTCodec memory leak #1927\n', 'commitDateTime': '2019-02-22 13:12:09', 'authoredDateTime': '2019-02-22 13:12:09', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/codec/FstCodec.java', 'insertions': 4, 'deletions': 0, 'lines': 4}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'FstCodec.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.codec.FstCodec.1.decode(io.netty.buffer.ByteBuf,org.redisson.client.handler.State)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.codec.FstCodec.2.encode(java.lang.Object)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'e2c134e1a6f14460106a73c4dbd9c1f67a24bac8', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['c16a31b09bf3eec3df0abd4b50ab11bf273c16ed'], 'nameRev': 'e2c134e1a6f14460106a73c4dbd9c1f67a24bac8 tags/redisson-3.10.3~12', 'commitMessage': 'Fixed - FSTCodec memory leak #1927\n', 'commitDateTime': '2019-02-25 12:49:21', 'authoredDateTime': '2019-02-25 12:49:21', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/codec/FstCodec.java', 'insertions': 83, 'deletions': 8, 'lines': 91}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'FstCodec.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.codec.FstCodec.2.encode(java.lang.Object)', 'TOT': 5, 'UPD': 1, 'INS': 0, 'MOV': 3, 'DEL': 1}, {'spoonMethodName': 'org.redisson.codec.FstCodec.1.decode(io.netty.buffer.ByteBuf,org.redisson.client.handler.State)', 'TOT': 4, 'UPD': 0, 'INS': 0, 'MOV': 3, 'DEL': 1}, {'spoonMethodName': 'org.redisson.codec.FstCodec.FSTDefaultStreamCoderFactory', 'TOT': 3, 'UPD': 0, 'INS': 3, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.codec.FstCodec', 'TOT': 5, 'UPD': 0, 'INS': 1, 'MOV': 4, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '4c216e257c445d69f5b4a6a2a3962e01f5685afc', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['e2c134e1a6f14460106a73c4dbd9c1f67a24bac8'], 'nameRev': '4c216e257c445d69f5b4a6a2a3962e01f5685afc tags/redisson-3.10.3~11', 'commitMessage': 'Fixed - FSTCodec memory leak #1927\n', 'commitDateTime': '2019-02-25 12:56:36', 'authoredDateTime': '2019-02-25 12:56:36', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/codec/FstCodec.java', 'insertions': 0, 'deletions': 1, 'lines': 1}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'FstCodec.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.codec.FstCodec', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/1927,4.000277777777778,['bug'],FSTCodec memory leak,1.0,"['org.redisson.codec.FstCodec.2.encode(java.lang.Object)', 'org.redisson.codec.FstCodec.1.decode(io.netty.buffer.ByteBuf,org.redisson.client.handler.State)']",['b77fda1e7e2c8746ce90e4c188577f89568c03cc'],,['redisson/src/main/java/org/redisson/codec'],4.0,0.0,4.0,1.0,0.0,2.0,2.0,0.0,2.0,0.0,1.0,0.0,0.0,0.0,2.0,0.0,0.0,redisson
42254,2019-01-31 12:26:01,mrniko,,2019-01-31 12:30:39,"[{'commitHash': '483ac35f6d4848752fc80d1848c255ad00486c2b', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['f659c58c8c4d7524e00654931fc4b39fc5f9a10e'], 'nameRev': '483ac35f6d4848752fc80d1848c255ad00486c2b tags/redisson-2.15.2~13', 'commitMessage': 'Fixed - Buffer leak during failover and RBatch object execution. #1896\n', 'commitDateTime': '2019-01-31 15:28:59', 'authoredDateTime': '2019-01-31 15:26:45', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/misc/LogHelper.java', 'insertions': 9, 'deletions': 8, 'lines': 17}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'LogHelper.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.misc.LogHelper', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.misc.LogHelper.toString(java.lang.Object)', 'TOT': 6, 'UPD': 0, 'INS': 1, 'MOV': 3, 'DEL': 2}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/1896,0.0002777777777777778,['bug'],Netty buffer leak during failover and RBatch object exection,1.0,"['org.redisson.misc.LogHelper', 'org.redisson.misc.LogHelper.toString(java.lang.Object)']",['483ac35f6d4848752fc80d1848c255ad00486c2b'],,['redisson/src/main/java/org/redisson/misc'],9.0,8.0,17.0,1.0,1.0,2.0,7.0,3.0,1.0,2.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,redisson
42333,2018-08-08 07:51:56,sappy5678,"<!--
Please consider to take commercial 24x7 support included in PRO version https://redisson.pro
-->

### Expected behavior
It should't have memory leak.
### Actual behavior
```
[main] ERROR io.netty.util.ResourceLeakDetector  - LEAK: HashedWheelTimer.release() was not called before it's garbage-collected. See http://netty.io/wiki/reference-counted-objects.html for more information.
Recent access records: 
Created at:
	io.netty.util.HashedWheelTimer.<init>(HashedWheelTimer.java:272)
	io.netty.util.HashedWheelTimer.<init>(HashedWheelTimer.java:216)
	io.netty.util.HashedWheelTimer.<init>(HashedWheelTimer.java:195)
	org.redisson.connection.MasterSlaveConnectionManager.initTimer(MasterSlaveConnectionManager.java:318)
	org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:161)
	org.redisson.connection.SingleConnectionManager.<init>(SingleConnectionManager.java:34)
	org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:192)
	org.redisson.Redisson.<init>(Redisson.java:122)
	org.redisson.Redisson.create(Redisson.java:159)
	test.main(test.java:32)
```

### Steps to reproduce or test case
```java=
        Codec stringCodec = new StringCodec();

        for (int i = 0; i < 10; i++) {
            RedissonClient client;
            Config config = new Config();
            config.useSingleServer().setAddress(RedisConfig.Address);
            config.useSingleServer().setPassword(RedisConfig.Password);
            config.setCodec(stringCodec);
            client = Redisson.create(config);

            BatchOptions options = BatchOptions.defaults();
            RBatch pipe = client.createBatch(options);

            pipe.getBucket(""test"", stringCodec).getAsync();
            BatchResult res = pipe.execute();

            System.out.println(res.getResponses().get(0));

            client.shutdown();

            System.gc();
        }

```

### Redis version
4.0.10
### Redisson version
3.7.5
### Redisson configuration
```
Config config = new Config();
config.useSingleServer().setAddress(RedisConfig.Address);
config.useSingleServer().setPassword(RedisConfig.Password);
config.setCodec(stringCodec);
client = Redisson.create(config);
```
",2018-08-29 09:02:40,"[{'commitHash': '404c90c4913d78087731673a42184654db8ea74b', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['b7c44b530f11eb845cc344a27084d1ed1c1d28f0'], 'nameRev': '404c90c4913d78087731673a42184654db8ea74b tags/redisson-3.8.0~11^2~11', 'commitMessage': 'Fixed - false HashedWheelTimer resource leak message #1584\n', 'commitDateTime': '2018-08-29 12:04:59', 'authoredDateTime': '2018-08-29 12:04:59', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/connection/MasterSlaveConnectionManager.java', 'insertions': 1, 'deletions': 10, 'lines': 11}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'MasterSlaveConnectionManager.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.connection.MasterSlaveConnectionManager.initTimer(org.redisson.config.MasterSlaveServersConfig)', 'TOT': 2, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/1584,21.00027777777778,['bug'],Memory Leak when I try to create client,1.0,['org.redisson.connection.MasterSlaveConnectionManager.initTimer(org.redisson.config.MasterSlaveServersConfig)'],['404c90c4913d78087731673a42184654db8ea74b'],,['redisson/src/main/java/org/redisson/connection'],1.0,10.0,11.0,1.0,1.0,1.0,2.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,redisson
42366,2018-05-19 13:35:54,pawelgrzes,"﻿### Expected behavior
Weak references should be cleared.

### Actual behavior
It seems that even when using static Strings for keys and values and only ```fastPut``` method the OOM error occurs after several thousands of invocations.
  
### Steps to reproduce or test case
I have created a separate repo to easier reproduce the problem:
https://github.com/pawelgrzes/redisson-mem-leak

### Redis version
4.0.9

### Redisson version
3.7.0

### Redisson configuration
```
RedissonClient redissonClient = Redisson.create();

LocalCachedMapOptions ops = LocalCachedMapOptions.defaults()
  .cacheSize(0)
  .timeToLive(0)
  .maxIdle(0)
  .reconnectionStrategy(LocalCachedMapOptions.ReconnectionStrategy.CLEAR)
  .syncStrategy(LocalCachedMapOptions.SyncStrategy.INVALIDATE)
  .evictionPolicy(LocalCachedMapOptions.EvictionPolicy.WEAK);

RLocalCachedMap<String, String> map = redissonClient.getLocalCachedMap(""sample-cache"", ops);
```

",2018-11-05 18:13:05,"[{'commitHash': 'a71460624e844335aa8d0268d411e3d3308c1445', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['a3fec2c062867c6a2a5a5ca778105a43b928b047'], 'nameRev': 'a71460624e844335aa8d0268d411e3d3308c1445 tags/redisson-2.14.1~39', 'commitMessage': 'Fixed - OOM when using RLocalCachedMap.fastPut and Reference based EvictionPolicy. #1442\n', 'commitDateTime': '2018-11-05 21:12:05', 'authoredDateTime': '2018-11-05 21:12:05', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/cache/AbstractCacheMap.java', 'insertions': 1, 'deletions': 8, 'lines': 9}, {'filePath': 'redisson/src/main/java/org/redisson/cache/CachedValueReference.java', 'insertions': 27, 'deletions': 0, 'lines': 27}, {'filePath': 'redisson/src/main/java/org/redisson/cache/CachedValueSoftReference.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'redisson/src/main/java/org/redisson/cache/CachedValueWeakReference.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'redisson/src/main/java/org/redisson/cache/ReferenceCacheMap.java', 'insertions': 7, 'deletions': 1, 'lines': 8}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AbstractCacheMap.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.cache.AbstractCacheMap.isFull(java.lang.Object)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.cache.AbstractCacheMap.isFull()', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'CachedValueReference.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.cache', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'CachedValueSoftReference.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.cache.CachedValueSoftReference.getOwner()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'CachedValueWeakReference.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.cache.CachedValueWeakReference.getOwner()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ReferenceCacheMap.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.cache.ReferenceCacheMap.removeExpiredEntries()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.cache.ReferenceCacheMap.isFull(java.lang.Object)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.cache.ReferenceCacheMap.create(java.lang.Object,java.lang.Object,long,long)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/1442,170.00027777777777,['bug'],RLocalCachedMap memory leak when using EvictionPolicy.WEAK,1.0,"['org.redisson.cache.AbstractCacheMap.isFull(java.lang.Object)', 'org.redisson.cache.AbstractCacheMap.isFull()', 'org.redisson.cache.ReferenceCacheMap.create(java.lang.Object,java.lang.Object,long,long)', 'org.redisson.cache.ReferenceCacheMap.isFull(java.lang.Object)', 'org.redisson.cache.ReferenceCacheMap.removeExpiredEntries()', 'org.redisson.cache', 'org.redisson.cache.CachedValueSoftReference.getOwner()', 'org.redisson.cache.CachedValueWeakReference.getOwner()']",['a71460624e844335aa8d0268d411e3d3308c1445'],,['redisson/src/main/java/org/redisson/cache'],39.0,11.0,50.0,5.0,2.0,8.0,8.0,0.0,5.0,1.0,5.0,0.0,0.0,0.0,0.0,0.0,0.0,redisson
42391,2018-03-06 22:30:20,kaduparag,"I'm using RLock and seeing memory leak via org.redisson.client.handler.CommandPubSubDecoder 
 
![image](https://user-images.githubusercontent.com/443442/37062360-0f201f60-214b-11e8-81a2-d2fab78261c4.png)


Retained objects delta between heap dumps taken apart
![image 1](https://user-images.githubusercontent.com/443442/37062341-01519f12-214b-11e8-8d35-4bc50413fd50.png)

Around 10MB leak per day
![image 2](https://user-images.githubusercontent.com/443442/37062443-5150dfdc-214b-11e8-944f-fb46ec393693.png)
",2018-03-07 07:46:39,"[{'commitHash': '7ca8d857a8f6aeb34c3ef8b7da0c7a2bc40998d9', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['767e0871258188044157db76112d091e3e7d399b'], 'nameRev': '7ca8d857a8f6aeb34c3ef8b7da0c7a2bc40998d9 tags/redisson-2.11.3~13', 'commitMessage': 'Fixed - memory leak in publish subscribe. #1326\n', 'commitDateTime': '2018-03-07 12:46:56', 'authoredDateTime': '2018-03-07 12:46:56', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/client/handler/CommandPubSubDecoder.java', 'insertions': 8, 'deletions': 5, 'lines': 13}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'CommandPubSubDecoder.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.client.handler.CommandPubSubDecoder.decodeResult(org.redisson.client.protocol.CommandData,java.util.List,io.netty.channel.Channel,java.lang.Object)', 'TOT': 6, 'UPD': 4, 'INS': 1, 'MOV': 1, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '8fd4fd69b8e55676050ccb54c225d7ed9deb2dc2', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['7ca8d857a8f6aeb34c3ef8b7da0c7a2bc40998d9'], 'nameRev': '8fd4fd69b8e55676050ccb54c225d7ed9deb2dc2 tags/redisson-2.11.3~12', 'commitMessage': 'Fixed - memory leak in publish subscribe. #1326\n', 'commitDateTime': '2018-03-07 20:05:18', 'authoredDateTime': '2018-03-07 20:05:18', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/client/handler/CommandPubSubDecoder.java', 'insertions': 12, 'deletions': 7, 'lines': 19}, {'filePath': 'redisson/src/test/java/org/redisson/RedissonTopicTest.java', 'insertions': 16, 'deletions': 4, 'lines': 20}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'CommandPubSubDecoder.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.client.handler.CommandPubSubDecoder.decodeResult(org.redisson.client.protocol.CommandData,java.util.List,io.netty.channel.Channel,java.lang.Object)', 'TOT': 13, 'UPD': 3, 'INS': 3, 'MOV': 6, 'DEL': 1}]}, {'spoonFilePath': 'RedissonTopicTest.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.RedissonTopicTest.testTopicState()', 'TOT': 7, 'UPD': 3, 'INS': 3, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testMultiTypeConnection().3', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testMultiTypeConnection().4', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testRemoveByInstance().7', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testReattach().8', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testReattach().9', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testReattachInSentinel().10', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testReattachInSentinel().11', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testReattachInSentinel()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testReattachInCluster().12', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testReattachInCluster().13', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testStatus().5', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testStatus().6', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testMultiTypeConnection().4.onMessage(java.lang.String,java.lang.Long)', 'TOT': 2, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testTopicState().2.onMessage(java.lang.String,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testMultiTypeConnection().4.onMessage(java.lang.String,java.lang.String)', 'TOT': 3, 'UPD': 0, 'INS': 3, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testMultiTypeConnection().5.onMessage(java.lang.String,java.lang.Long)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonTopicTest.testMultiTypeConnection().3.onMessage(java.lang.String,java.lang.String)', 'TOT': 4, 'UPD': 0, 'INS': 0, 'MOV': 4, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/1326,0.0002777777777777778,['bug'],Redisson 3.5.7 memory leak with locks,1.0,"['org.redisson.client.handler.CommandPubSubDecoder.decodeResult(org.redisson.client.protocol.CommandData,java.util.List,io.netty.channel.Channel,java.lang.Object)']",['7ca8d857a8f6aeb34c3ef8b7da0c7a2bc40998d9'],,['redisson/src/main/java/org/redisson/client/handler'],8.0,5.0,13.0,1.0,4.0,1.0,6.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,redisson
42425,2017-11-22 03:08:23,yjain3326,"Hi,

We are seeing out of memory when trying to use RedissonExecutorService. 
Please find attached the file you can use to reproduce the issue.
Usage:
nohup java -Xmx512m -XX:MaxMetaspaceSize=80m -cp testredisscheduler-1.0-SNAPSHOT-jar-with-dependencies.jar com.test.redis.scheduler.TestRedisScheduler 120 10 10 > output.log &

Running it for about 20-30 min produces the issue.

[final.zip](https://github.com/redisson/redisson/files/1493727/final.zip)

",2017-12-07 14:08:09,"[{'commitHash': '959cca4fe1461d80a9940caf398928281dd2e9d2', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['84f5629143586cfe9ec325916fb5f07e3512c2bb'], 'nameRev': '959cca4fe1461d80a9940caf398928281dd2e9d2 tags/redisson-2.10.6~13', 'commitMessage': 'Fixed Out of memory problem during RedissonExecutorService usage. #1158\n', 'commitDateTime': '2017-11-22 18:15:55', 'authoredDateTime': '2017-11-22 18:15:55', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/BaseRemoteService.java', 'insertions': 53, 'deletions': 24, 'lines': 77}, {'filePath': 'redisson/src/main/java/org/redisson/remote/ResponseEntry.java', 'insertions': 7, 'deletions': 0, 'lines': 7}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'BaseRemoteService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String,java.lang.String)', 'TOT': 16, 'UPD': 3, 'INS': 4, 'MOV': 8, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry,java.lang.String).5.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 16, 'UPD': 3, 'INS': 2, 'MOV': 9, 'DEL': 2}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String,java.lang.String).4.run()', 'TOT': 10, 'UPD': 3, 'INS': 1, 'MOV': 5, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.sync(java.lang.Class,org.redisson.api.RemoteInvocationOptions).6.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ResponseEntry.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.remote.ResponseEntry', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.remote.ResponseEntry.getTimeouts()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '156be4dab6c5e575733d6b5e1563197bca96233a', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['044ebebbf2a5992a1e8aa8b9e799ed31696fd673'], 'nameRev': '156be4dab6c5e575733d6b5e1563197bca96233a tags/redisson-2.10.6~10', 'commitMessage': 'ExecutorService memory consumption optimization.  #1158\n', 'commitDateTime': '2017-11-24 16:13:12', 'authoredDateTime': '2017-11-24 16:13:12', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/BaseRemoteService.java', 'insertions': 11, 'deletions': 9, 'lines': 20}, {'filePath': 'redisson/src/main/java/org/redisson/remote/ResponseEntry.java', 'insertions': 50, 'deletions': 5, 'lines': 55}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'BaseRemoteService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String,java.lang.String)', 'TOT': 3, 'UPD': 2, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry,java.lang.String).5.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 6, 'UPD': 1, 'INS': 2, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String,java.lang.String).4.run()', 'TOT': 6, 'UPD': 3, 'INS': 1, 'MOV': 1, 'DEL': 1}]}, {'spoonFilePath': 'ResponseEntry.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.remote.ResponseEntry.Key', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '4c8f966713b38a76bbbc7f21713c472bdd273678', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['8661de67f144b544f5cf93f583cca338081dd7ab'], 'nameRev': '4c8f966713b38a76bbbc7f21713c472bdd273678 tags/redisson-2.10.6~8', 'commitMessage': 'Memory consumption reduced during scheduled tasks processing #1158\n', 'commitDateTime': '2017-11-26 13:44:37', 'authoredDateTime': '2017-11-26 13:44:37', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/BaseRemoteService.java', 'insertions': 78, 'deletions': 67, 'lines': 145}, {'filePath': 'redisson/src/main/java/org/redisson/RedissonRemoteService.java', 'insertions': 6, 'deletions': 7, 'lines': 13}, {'filePath': 'redisson/src/main/java/org/redisson/executor/ScheduledTasksService.java', 'insertions': 3, 'deletions': 3, 'lines': 6}, {'filePath': 'redisson/src/main/java/org/redisson/executor/TasksService.java', 'insertions': 1, 'deletions': 4, 'lines': 5}, {'filePath': 'redisson/src/main/java/org/redisson/remote/RemoteServiceRequest.java', 'insertions': 0, 'deletions': 5, 'lines': 5}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'BaseRemoteService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.BaseRemoteService.getMethodSignatures(java.lang.reflect.Method)', 'TOT': 8, 'UPD': 2, 'INS': 2, 'MOV': 3, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class)', 'TOT': 12, 'UPD': 1, 'INS': 1, 'MOV': 9, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String)', 'TOT': 3, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])', 'TOT': 16, 'UPD': 6, 'INS': 2, 'MOV': 5, 'DEL': 3}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String).3.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).2.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 5, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 3}, {'spoonMethodName': 'org.redisson.BaseRemoteService.getCancelRequestMapName(java.lang.Class)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.getCancelResponseMapName(java.lang.Class)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.getResponseQueueName(java.lang.Class,java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.getAckName(java.lang.Class,java.lang.String)', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.getRequestQueueName(java.lang.Class)', 'TOT': 6, 'UPD': 0, 'INS': 1, 'MOV': 4, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).1.cancel(boolean)', 'TOT': 8, 'UPD': 0, 'INS': 4, 'MOV': 0, 'DEL': 4}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).1.cancel(java.lang.Class,java.lang.String,org.redisson.remote.RemoteServiceRequest,boolean)', 'TOT': 4, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 4}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).2.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).2.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String,java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String,java.lang.String).2.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String,java.lang.String)', 'TOT': 7, 'UPD': 0, 'INS': 0, 'MOV': 2, 'DEL': 5}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String,java.lang.String).4.run()', 'TOT': 4, 'UPD': 0, 'INS': 0, 'MOV': 2, 'DEL': 2}, {'spoonMethodName': 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry,java.lang.String)', 'TOT': 3, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 3}, {'spoonMethodName': 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry,java.lang.String).5.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 5, 'UPD': 0, 'INS': 0, 'MOV': 2, 'DEL': 3}, {'spoonMethodName': 'org.redisson.BaseRemoteService.sync(java.lang.Class,org.redisson.api.RemoteInvocationOptions).6.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])', 'TOT': 4, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 3}, {'spoonMethodName': 'org.redisson.BaseRemoteService.tryPollAckAgainAsync(org.redisson.api.RemoteInvocationOptions,java.lang.String,java.lang.String,java.lang.String)', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'org.redisson.BaseRemoteService.tryPollAckAgainAsync(org.redisson.api.RemoteInvocationOptions,java.lang.String,java.lang.String,java.lang.String).7.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.cancelExecution(org.redisson.api.RemoteInvocationOptions,java.lang.String,org.redisson.remote.RemoteServiceRequest,boolean,java.lang.String,org.redisson.executor.RemotePromise)', 'TOT': 4, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 4}, {'spoonMethodName': 'org.redisson.BaseRemoteService', 'TOT': 8, 'UPD': 0, 'INS': 8, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.cancelExecution(org.redisson.api.RemoteInvocationOptions,org.redisson.remote.RemoteServiceRequest,boolean,org.redisson.executor.RemotePromise)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry).5.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 4, 'UPD': 0, 'INS': 4, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String).4.run()', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RedissonRemoteService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.RedissonRemoteService.subscribe(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService).1.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'org.redisson.RedissonRemoteService.executeMethod(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService,org.redisson.remote.RemoteServiceRequest)', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'org.redisson.RedissonRemoteService.executeMethod(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService,org.redisson.remote.RemoteServiceRequest).3.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 2}]}, {'spoonFilePath': 'ScheduledTasksService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String)', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String).1.run()', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'TasksService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.executor.TasksService.cancelExecutionAsync(java.lang.String).2.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 6, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 4}, {'spoonMethodName': 'org.redisson.executor.TasksService.cancelExecutionAsync(java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'RemoteServiceRequest.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.remote.RemoteServiceRequest', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '353f9aa24df14eaa6999c0b4527da8260543d670', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['4c8f966713b38a76bbbc7f21713c472bdd273678'], 'nameRev': '353f9aa24df14eaa6999c0b4527da8260543d670 tags/redisson-2.10.6~7', 'commitMessage': 'ScheduledFuture memory allocation optimization. #1158\n', 'commitDateTime': '2017-11-30 12:10:29', 'authoredDateTime': '2017-11-30 12:10:29', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/BaseRemoteService.java', 'insertions': 117, 'deletions': 40, 'lines': 157}, {'filePath': 'redisson/src/main/java/org/redisson/executor/ScheduledTasksService.java', 'insertions': 4, 'deletions': 3, 'lines': 7}, {'filePath': 'redisson/src/main/java/org/redisson/remote/ResponseEntry.java', 'insertions': 26, 'deletions': 9, 'lines': 35}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'BaseRemoteService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.BaseRemoteService.sync(java.lang.Class,org.redisson.api.RemoteInvocationOptions)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry).5', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.sync(java.lang.Class,org.redisson.api.RemoteInvocationOptions).6', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.tryPollAckAgainAsync(org.redisson.api.RemoteInvocationOptions,java.lang.String,java.lang.String).7', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.scheduleCheck(java.lang.String,java.lang.String,org.redisson.misc.RPromise).8', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String)', 'TOT': 19, 'UPD': 4, 'INS': 0, 'MOV': 12, 'DEL': 3}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String).4', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry).5.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 20, 'UPD': 8, 'INS': 0, 'MOV': 9, 'DEL': 3}, {'spoonMethodName': 'org.redisson.BaseRemoteService.sync(java.lang.Class,org.redisson.api.RemoteInvocationOptions).6.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])', 'TOT': 5, 'UPD': 5, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.tryPollAckAgainAsync(org.redisson.api.RemoteInvocationOptions,java.lang.String,java.lang.String).7.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String).4.run()', 'TOT': 9, 'UPD': 2, 'INS': 0, 'MOV': 5, 'DEL': 2}, {'spoonMethodName': 'org.redisson.BaseRemoteService.scheduleCheck(java.lang.String,java.lang.String,org.redisson.misc.RPromise).8.run(io.netty.util.Timeout).1.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).2.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 6, 'UPD': 0, 'INS': 4, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest)', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String,org.redisson.api.RFuture)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,org.redisson.api.RFuture)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String,boolean)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.cancelExecution(org.redisson.api.RemoteInvocationOptions,org.redisson.remote.RemoteServiceRequest,boolean,org.redisson.executor.RemotePromise,org.redisson.api.RFuture)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])', 'TOT': 4, 'UPD': 0, 'INS': 4, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String,org.redisson.api.RFuture).2.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry).6.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 7, 'UPD': 0, 'INS': 7, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.tryPollAckAgainAsync(org.redisson.api.RemoteInvocationOptions,java.lang.String,java.lang.String).8.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).1.cancel(java.lang.String,org.redisson.remote.RemoteServiceRequest,boolean)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String,boolean).5.run()', 'TOT': 5, 'UPD': 0, 'INS': 5, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).2.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).2.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ScheduledTasksService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,org.redisson.api.RFuture)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,org.redisson.api.RFuture).1.run()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ResponseEntry.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.remote.ResponseEntry', 'TOT': 6, 'UPD': 2, 'INS': 1, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'org.redisson.remote.ResponseEntry.getTimeouts()', 'TOT': 6, 'UPD': 4, 'INS': 0, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'org.redisson.remote.ResponseEntry.getResponses()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.remote.ResponseEntry.Result', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'a5c26a13dca405b56138e6da4f4a0c36d8223346', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['6d39a91a551cacc46abdf80ad0be081f6ca775da'], 'nameRev': 'a5c26a13dca405b56138e6da4f4a0c36d8223346 tags/redisson-2.10.6~1', 'commitMessage': 'Scheduled tasks memory consumption reduced. #1158\n', 'commitDateTime': '2017-12-07 17:11:08', 'authoredDateTime': '2017-12-07 17:11:08', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/BaseRemoteService.java', 'insertions': 82, 'deletions': 54, 'lines': 136}, {'filePath': 'redisson/src/main/java/org/redisson/RedissonExecutorService.java', 'insertions': 4, 'deletions': 4, 'lines': 8}, {'filePath': 'redisson/src/main/java/org/redisson/RedissonRemoteService.java', 'insertions': 84, 'deletions': 61, 'lines': 145}, {'filePath': 'redisson/src/main/java/org/redisson/executor/RedissonExecutorFuture.java', 'insertions': 4, 'deletions': 3, 'lines': 7}, {'filePath': 'redisson/src/main/java/org/redisson/executor/RedissonScheduledFuture.java', 'insertions': 3, 'deletions': 2, 'lines': 5}, {'filePath': 'redisson/src/main/java/org/redisson/executor/RemotePromise.java', 'insertions': 10, 'deletions': 3, 'lines': 13}, {'filePath': 'redisson/src/main/java/org/redisson/executor/ScheduledTasksService.java', 'insertions': 22, 'deletions': 16, 'lines': 38}, {'filePath': 'redisson/src/main/java/org/redisson/executor/TasksRunnerService.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'redisson/src/main/java/org/redisson/executor/TasksService.java', 'insertions': 13, 'deletions': 17, 'lines': 30}, {'filePath': 'redisson/src/main/java/org/redisson/remote/RequestId.java', 'insertions': 84, 'deletions': 0, 'lines': 84}, {'filePath': 'redisson/src/main/java/org/redisson/remote/ResponseEntry.java', 'insertions': 2, 'deletions': 49, 'lines': 51}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'BaseRemoteService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String,org.redisson.api.RFuture)', 'TOT': 13, 'UPD': 3, 'INS': 0, 'MOV': 9, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.generateRequestId()', 'TOT': 3, 'UPD': 1, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.addAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest,org.redisson.executor.RemotePromise)', 'TOT': 6, 'UPD': 4, 'INS': 0, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.removeAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest)', 'TOT': 7, 'UPD': 6, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String,boolean)', 'TOT': 5, 'UPD': 4, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.tryPollAckAgainAsync(org.redisson.api.RemoteInvocationOptions,java.lang.String,java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.scheduleCheck(java.lang.String,java.lang.String,org.redisson.misc.RPromise)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.cancelExecution(org.redisson.api.RemoteInvocationOptions,org.redisson.remote.RemoteServiceRequest,boolean,org.redisson.executor.RemotePromise,org.redisson.api.RFuture)', 'TOT': 5, 'UPD': 2, 'INS': 0, 'MOV': 1, 'DEL': 2}, {'spoonMethodName': 'org.redisson.BaseRemoteService.sync(java.lang.Class,org.redisson.api.RemoteInvocationOptions).7.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])', 'TOT': 8, 'UPD': 3, 'INS': 3, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])', 'TOT': 9, 'UPD': 3, 'INS': 2, 'MOV': 2, 'DEL': 2}, {'spoonMethodName': 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry).6.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 10, 'UPD': 3, 'INS': 3, 'MOV': 3, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).1.cancel(java.lang.String,org.redisson.remote.RemoteServiceRequest,boolean)', 'TOT': 3, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).1.cancel(boolean)', 'TOT': 10, 'UPD': 5, 'INS': 1, 'MOV': 2, 'DEL': 2}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String,boolean).4.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,java.lang.String,boolean).5.run()', 'TOT': 2, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).2.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 2, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).2.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).2.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String,org.redisson.api.RFuture).2.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,org.redisson.api.RFuture)', 'TOT': 3, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 2}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,org.redisson.api.RFuture).3.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.BaseRemoteService.getAckName(org.redisson.remote.RequestId)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.getParam(org.redisson.remote.RemoteServiceRequest)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,java.lang.String,org.redisson.api.RFuture)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.cancelExecution(org.redisson.api.RemoteInvocationOptions,boolean,org.redisson.executor.RemotePromise,org.redisson.api.RFuture)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.scheduleCheck(java.lang.String,org.redisson.remote.RequestId,org.redisson.misc.RPromise).9.run(io.netty.util.Timeout)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.api.RFuture).3.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.poll(long,org.redisson.remote.RequestId,boolean).5.run()', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.BaseRemoteService.scheduleCheck(java.lang.String,java.lang.String,org.redisson.misc.RPromise).9.run(io.netty.util.Timeout)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'RedissonExecutorService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.RedissonExecutorService.registerWorkers(int,java.util.concurrent.ExecutorService).1.pushTaskAsync()', 'TOT': 11, 'UPD': 8, 'INS': 0, 'MOV': 1, 'DEL': 2}, {'spoonMethodName': 'org.redisson.RedissonExecutorService.cancelTask(java.lang.String)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'RedissonRemoteService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.RedissonRemoteService.subscribe(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService).1.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 16, 'UPD': 4, 'INS': 0, 'MOV': 10, 'DEL': 2}, {'spoonMethodName': 'org.redisson.RedissonRemoteService.register(java.lang.Class,java.lang.Object,int,java.util.concurrent.ExecutorService)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.RedissonRemoteService.executeMethod(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService,org.redisson.remote.RemoteServiceRequest)', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.redisson.RedissonRemoteService.subscribe(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonRemoteService.subscribe(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService).1.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 9, 'UPD': 0, 'INS': 6, 'MOV': 3, 'DEL': 0}, {'spoonMethodName': 'org.redisson.RedissonRemoteService.subscribe(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService).1.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 3, 'UPD': 0, 'INS': 3, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RedissonExecutorFuture.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.executor.RedissonExecutorFuture', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.RedissonExecutorFuture.getTaskId()', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'RedissonScheduledFuture.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.executor.RedissonScheduledFuture', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.RedissonScheduledFuture.getTaskId()', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'RemotePromise.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.executor.RemotePromise', 'TOT': 6, 'UPD': 2, 'INS': 4, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.RemotePromise.getRequestId()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.RemotePromise.getParam()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ScheduledTasksService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.executor.ScheduledTasksService', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.addAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.removeAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest)', 'TOT': 9, 'UPD': 6, 'INS': 0, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.generateRequestId()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.setRequestId(java.lang.String)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,org.redisson.api.RFuture)', 'TOT': 4, 'UPD': 0, 'INS': 0, 'MOV': 2, 'DEL': 2}, {'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,org.redisson.api.RFuture).1.run()', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.getParam(org.redisson.remote.RemoteServiceRequest)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.api.RFuture)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.ScheduledTasksService.removeAsync(java.lang.String,org.redisson.remote.RequestId)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'TasksRunnerService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.executor.TasksRunnerService.asyncScheduledServiceAtFixed(java.lang.String,java.lang.String)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'TasksService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.executor.TasksService.addAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest,org.redisson.executor.RemotePromise)', 'TOT': 3, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.TasksService.addAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest)', 'TOT': 7, 'UPD': 5, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.redisson.executor.TasksService.removeAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest)', 'TOT': 12, 'UPD': 8, 'INS': 0, 'MOV': 2, 'DEL': 2}, {'spoonMethodName': 'org.redisson.executor.TasksService.cancelExecutionAsync(java.lang.String)', 'TOT': 5, 'UPD': 3, 'INS': 0, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'org.redisson.executor.TasksService.cancelExecutionAsync(org.redisson.remote.RequestId).2.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.executor.TasksService.cancelExecutionAsync(java.lang.String).2.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'RequestId.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.remote.RequestId', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ResponseEntry.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.remote.ResponseEntry.Key', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/1158,15.000277777777777,['bug'],OOM issue with RedissonExecutorService,5.0,"['org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).2.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])', 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry,java.lang.String).5.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.poll(long,java.lang.String,java.lang.String)', 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).2.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.poll(long,java.lang.String,java.lang.String).4.run()', 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).2.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.sync(java.lang.Class,org.redisson.api.RemoteInvocationOptions).6.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])', 'org.redisson.BaseRemoteService.poll(long,java.lang.String)', 'org.redisson.BaseRemoteService.poll(long,java.lang.String).4.run()', 'org.redisson.executor.TasksService.cancelExecutionAsync(java.lang.String)', 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String,org.redisson.api.RFuture).2.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.RedissonRemoteService.executeMethod(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService,org.redisson.remote.RemoteServiceRequest)', 'org.redisson.BaseRemoteService.poll(long,java.lang.String,boolean).5.run()', 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry).6.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.remote.ResponseEntry.getTimeouts()', 'org.redisson.executor.ScheduledTasksService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,org.redisson.api.RFuture)', 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).1.cancel(java.lang.String,org.redisson.remote.RemoteServiceRequest,boolean)', 'org.redisson.executor.TasksService.cancelExecutionAsync(java.lang.String).2.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.poll(long,java.lang.String,boolean)', 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String,org.redisson.api.RFuture)', 'org.redisson.remote.ResponseEntry', 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).1.cancel(boolean)', 'org.redisson.executor.ScheduledTasksService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,org.redisson.api.RFuture).1.run()', 'org.redisson.RedissonRemoteService.subscribe(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService).1.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.remote.ResponseEntry.Key', 'org.redisson.BaseRemoteService.cancelExecution(org.redisson.api.RemoteInvocationOptions,org.redisson.remote.RemoteServiceRequest,boolean,org.redisson.executor.RemotePromise,org.redisson.api.RFuture)', 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry).5.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,org.redisson.api.RFuture)', 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest)', 'org.redisson.executor.ScheduledTasksService', 'org.redisson.BaseRemoteService.getAckName(java.lang.Class,java.lang.String)', 'org.redisson.BaseRemoteService.tryPollAckAgainAsync(org.redisson.api.RemoteInvocationOptions,java.lang.String,java.lang.String,java.lang.String).7.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.tryPollAckAgainAsync(org.redisson.api.RemoteInvocationOptions,java.lang.String,java.lang.String).8.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.getCancelRequestMapName(java.lang.Class)', 'org.redisson.executor.ScheduledTasksService.removeAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest)', 'org.redisson.BaseRemoteService.cancelExecution(org.redisson.api.RemoteInvocationOptions,boolean,org.redisson.executor.RemotePromise,org.redisson.api.RFuture)', 'org.redisson.executor.ScheduledTasksService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String).1.run()', 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.api.RFuture).3.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry).5', 'org.redisson.BaseRemoteService.scheduleCheck(java.lang.String,java.lang.String,org.redisson.misc.RPromise).8.run(io.netty.util.Timeout).1.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.executor.ScheduledTasksService.getParam(org.redisson.remote.RemoteServiceRequest)', 'org.redisson.BaseRemoteService.sync(java.lang.Class,org.redisson.api.RemoteInvocationOptions)', 'org.redisson.BaseRemoteService.tryPollAckAgainAsync(org.redisson.api.RemoteInvocationOptions,java.lang.String,java.lang.String)', 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class)', 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,java.lang.String,org.redisson.api.RFuture)', 'org.redisson.executor.ScheduledTasksService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String)', 'org.redisson.BaseRemoteService.async(java.lang.Class,org.redisson.api.RemoteInvocationOptions,java.lang.Class).1.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[]).1.cancel(java.lang.Class,java.lang.String,org.redisson.remote.RemoteServiceRequest,boolean)', 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry,java.lang.String)', 'org.redisson.BaseRemoteService.cancelExecution(org.redisson.api.RemoteInvocationOptions,org.redisson.remote.RemoteServiceRequest,boolean,org.redisson.executor.RemotePromise)', 'org.redisson.BaseRemoteService', 'org.redisson.executor.RemotePromise.getRequestId()', 'org.redisson.remote.ResponseEntry.getResponses()', 'org.redisson.remote.RequestId', 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String).3.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.getCancelResponseMapName(java.lang.Class)', 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,org.redisson.api.RFuture).3.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.getAckName(org.redisson.remote.RequestId)', 'org.redisson.BaseRemoteService.getRequestQueueName(java.lang.Class)', 'org.redisson.executor.TasksService.cancelExecutionAsync(org.redisson.remote.RequestId).2.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.RedissonExecutorService.cancelTask(java.lang.String)', 'org.redisson.executor.TasksService.addAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest,org.redisson.executor.RemotePromise)', 'org.redisson.BaseRemoteService.poll(long,java.lang.String,boolean).4.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.poll(long,java.lang.String).4', 'org.redisson.executor.ScheduledTasksService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.api.RFuture)', 'org.redisson.BaseRemoteService.generateRequestId()', 'org.redisson.RedissonRemoteService.register(java.lang.Class,java.lang.Object,int,java.util.concurrent.ExecutorService)', 'org.redisson.BaseRemoteService.scheduleCheck(java.lang.String,java.lang.String,org.redisson.misc.RPromise).9.run(io.netty.util.Timeout)', 'org.redisson.BaseRemoteService.poll(long,org.redisson.remote.RequestId,boolean).5.run()', 'org.redisson.BaseRemoteService.scheduleCheck(java.lang.String,java.lang.String,org.redisson.misc.RPromise)', 'org.redisson.executor.TasksRunnerService.asyncScheduledServiceAtFixed(java.lang.String,java.lang.String)', 'org.redisson.BaseRemoteService.cancelExecution(org.redisson.api.RemoteInvocationOptions,java.lang.String,org.redisson.remote.RemoteServiceRequest,boolean,java.lang.String,org.redisson.executor.RemotePromise)', 'org.redisson.executor.ScheduledTasksService.generateRequestId()', 'org.redisson.executor.ScheduledTasksService.removeAsync(java.lang.String,org.redisson.remote.RequestId)', 'org.redisson.BaseRemoteService.removeAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest)', 'org.redisson.BaseRemoteService.tryPollAckAgainAsync(org.redisson.api.RemoteInvocationOptions,java.lang.String,java.lang.String,java.lang.String)', 'org.redisson.RedissonRemoteService.subscribe(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService)', 'org.redisson.executor.RedissonScheduledFuture.getTaskId()', 'org.redisson.BaseRemoteService.sync(java.lang.Class,org.redisson.api.RemoteInvocationOptions).7.invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])', 'org.redisson.executor.RedissonScheduledFuture', 'org.redisson.RedissonRemoteService.subscribe(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService).1.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String)', 'org.redisson.BaseRemoteService.tryPollAckAgainAsync(org.redisson.api.RemoteInvocationOptions,java.lang.String,java.lang.String).7', 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String,java.lang.String).2.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.pollTasks(org.redisson.remote.ResponseEntry)', 'org.redisson.executor.ScheduledTasksService.addAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest)', 'org.redisson.RedissonRemoteService.subscribe(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService).1.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.BaseRemoteService.scheduleCheck(java.lang.String,org.redisson.remote.RequestId,org.redisson.misc.RPromise).9.run(io.netty.util.Timeout)', 'org.redisson.executor.RedissonExecutorFuture', 'org.redisson.executor.TasksService.removeAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest)', 'org.redisson.BaseRemoteService.sync(java.lang.Class,org.redisson.api.RemoteInvocationOptions).6', 'org.redisson.BaseRemoteService.scheduleCheck(java.lang.String,java.lang.String,org.redisson.misc.RPromise).8', 'org.redisson.RedissonExecutorService.registerWorkers(int,java.util.concurrent.ExecutorService).1.pushTaskAsync()', 'org.redisson.BaseRemoteService.awaitResultAsync(org.redisson.api.RemoteInvocationOptions,org.redisson.executor.RemotePromise,org.redisson.remote.RemoteServiceRequest,java.lang.String,java.lang.String)', 'org.redisson.BaseRemoteService.addAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest,org.redisson.executor.RemotePromise)', 'org.redisson.BaseRemoteService.tryPollAckAgainAsync(org.redisson.api.RemoteInvocationOptions,java.lang.String,java.lang.String).7.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.executor.TasksService.addAsync(org.redisson.api.RBlockingQueue,org.redisson.remote.RemoteServiceRequest)', 'org.redisson.executor.RemotePromise.getParam()', 'org.redisson.remote.ResponseEntry.Result', 'org.redisson.RedissonRemoteService.executeMethod(java.lang.Class,org.redisson.api.RBlockingQueue,java.util.concurrent.ExecutorService,org.redisson.remote.RemoteServiceRequest).3.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.remote.RemoteServiceRequest', 'org.redisson.BaseRemoteService.getMethodSignatures(java.lang.reflect.Method)', 'org.redisson.BaseRemoteService.getParam(org.redisson.remote.RemoteServiceRequest)', 'org.redisson.BaseRemoteService.getResponseQueueName(java.lang.Class,java.lang.String)', 'org.redisson.executor.ScheduledTasksService.setRequestId(java.lang.String)', 'org.redisson.executor.RedissonExecutorFuture.getTaskId()', 'org.redisson.executor.RemotePromise']","['959cca4fe1461d80a9940caf398928281dd2e9d2', '156be4dab6c5e575733d6b5e1563197bca96233a', '4c8f966713b38a76bbbc7f21713c472bdd273678', '353f9aa24df14eaa6999c0b4527da8260543d670', 'a5c26a13dca405b56138e6da4f4a0c36d8223346']",,"['redisson/src/main/java/org/redisson', 'redisson/src/main/java/org/redisson/remote', 'redisson/src/main/java/org/redisson/executor']",666.0,386.0,1052.0,12.0,153.0,107.0,543.0,139.0,132.0,119.0,12.0,0.0,0.0,0.0,0.0,0.0,0.0,redisson
42493,2017-02-20 14:21:46,mabn,"URIBuilder is not thread-safe. Following scenario causes infinite recursion and StackOverflowException when someone tries to create new URL:

1. `URLBuilder.replaceURLFactory()` - URLBuilder.currentFactory set to null, URL.factory set to custom
2. `URLBuilder.replaceURLFactory()` - URLBuilder.currentFactory set to custom, URL.factory set to custom again
3. `new URL(""http://google.com"")` fails on StackOverflowException. Following code is an infinite loop because currentFactory points to ""this"":
```
public URLStreamHandler createURLStreamHandler(String protocol) {
    (...)
    if (currentFactory != null) {
        return currentFactory.createURLStreamHandler(protocol);
    }
    (...)
}
```

Sample stacktrace:
```
15:15:06.594 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.594 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.594 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.595 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.595 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.595 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.595 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.595 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.595 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.595 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.595 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.595 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.595 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
15:15:06.595 [DEBUG] [TestEventLogger]         at org.redisson.misc.URLBuilder$1.createURLStreamHandler(URLBuilder.java:78)
```

Affected version: 3.3.0",2017-02-22 14:37:08,"[{'commitHash': 'c7798412fdb66b72ace891c0dad65db7faed5a04', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['641063c9fc4414a954eb83afeea358cd1a35207b'], 'nameRev': 'c7798412fdb66b72ace891c0dad65db7faed5a04 tags/redisson-2.8.1~15', 'commitMessage': 'StackOverflowException in URLBuilder fixed.  #776\n', 'commitDateTime': '2017-02-22 17:37:18', 'authoredDateTime': '2017-02-22 17:37:18', 'commitGitStats': [{'filePath': 'redisson/src/main/java/org/redisson/misc/URLBuilder.java', 'insertions': 2, 'deletions': 0, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'URLBuilder.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.misc.URLBuilder.replaceURLFactory()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/776,2.000277777777778,['bug'],StackOverflowException in URLBuilder,1.0,['org.redisson.misc.URLBuilder.replaceURLFactory()'],['c7798412fdb66b72ace891c0dad65db7faed5a04'],,['redisson/src/main/java/org/redisson/misc'],2.0,0.0,2.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,redisson
42585,2015-12-17 13:23:43,lefay1982,"When I use redisson 2.1.3 the ubuntu's load average is 1.8 ~ 2.3; but I use 2.1.4 or greater, the load average is often greater than 3.00, my java application often overload.
",2016-01-09 05:31:26,"[{'commitHash': 'b0d9803593f619bd14531c6a88a58e8dce18e45e', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['9468dd6fc0718b6fc069f3f6aa495ce680861dad'], 'nameRev': 'b0d9803593f619bd14531c6a88a58e8dce18e45e tags/redisson-2.2.4~26', 'commitMessage': 'Object allocation optimization. #338\n', 'commitDateTime': '2015-12-18 13:35:07', 'authoredDateTime': '2015-12-18 13:35:07', 'commitGitStats': [{'filePath': 'src/main/java/org/redisson/cluster/ClusterConnectionManager.java', 'insertions': 3, 'deletions': 3, 'lines': 6}, {'filePath': 'src/main/java/org/redisson/command/CommandAsyncService.java', 'insertions': 3, 'deletions': 1, 'lines': 4}, {'filePath': 'src/main/java/org/redisson/connection/ConnectionManager.java', 'insertions': 2, 'deletions': 0, 'lines': 2}, {'filePath': 'src/main/java/org/redisson/connection/MasterSlaveConnectionManager.java', 'insertions': 2, 'deletions': 2, 'lines': 4}, {'filePath': 'src/main/java/org/redisson/misc/ConnectionPool.java', 'insertions': 28, 'deletions': 14, 'lines': 42}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ClusterConnectionManager.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.cluster.ClusterConnectionManager.addMasterEntry(org.redisson.cluster.ClusterPartition,org.redisson.ClusterServersConfig)', 'TOT': 3, 'UPD': 0, 'INS': 3, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'CommandAsyncService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.command.CommandAsyncService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.protocol.decoder.MultiDecoder,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],io.netty.util.concurrent.Promise,int).5.run(io.netty.util.Timeout)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.command.CommandAsyncService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.protocol.decoder.MultiDecoder,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],io.netty.util.concurrent.Promise,int)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'ConnectionManager.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.connection.newSucceededFuture(java.lang.Object)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'MasterSlaveConnectionManager.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.connection.MasterSlaveConnectionManager.newSucceededFuture()', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.connection.MasterSlaveConnectionManager.newSucceededFuture(java.lang.Object)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ConnectionPool.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.misc.ConnectionPool.connect(org.redisson.connection.ClientConnectionsEntry,io.netty.util.concurrent.Promise)', 'TOT': 12, 'UPD': 2, 'INS': 0, 'MOV': 6, 'DEL': 4}, {'spoonMethodName': 'org.redisson.misc.ConnectionPool.initConnections(org.redisson.connection.ClientConnectionsEntry,io.netty.util.concurrent.Promise,boolean)', 'TOT': 7, 'UPD': 1, 'INS': 1, 'MOV': 3, 'DEL': 2}, {'spoonMethodName': 'org.redisson.misc.ConnectionPool.get()', 'TOT': 6, 'UPD': 0, 'INS': 1, 'MOV': 2, 'DEL': 3}, {'spoonMethodName': 'org.redisson.misc.ConnectionPool.get(org.redisson.connection.ClientConnectionsEntry)', 'TOT': 7, 'UPD': 0, 'INS': 1, 'MOV': 4, 'DEL': 2}, {'spoonMethodName': 'org.redisson.misc.ConnectionPool.promiseSuccessful(org.redisson.connection.ClientConnectionsEntry,io.netty.util.concurrent.Promise,org.redisson.client.RedisConnection)', 'TOT': 2, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'org.redisson.misc.ConnectionPool.promiseSuccessful(org.redisson.connection.ClientConnectionsEntry,org.redisson.client.RedisConnection)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.misc.ConnectionPool.promiseFailure(org.redisson.connection.ClientConnectionsEntry,org.redisson.client.RedisConnection)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.misc.ConnectionPool.connectTo(org.redisson.connection.ClientConnectionsEntry)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'e17a9ce303793becf429b4223ebb931568d099f1', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['b0d9803593f619bd14531c6a88a58e8dce18e45e'], 'nameRev': 'e17a9ce303793becf429b4223ebb931568d099f1 tags/redisson-2.2.4~25', 'commitMessage': 'Success\\Failed Future listener notification optimization. #338\n', 'commitDateTime': '2015-12-18 15:12:57', 'authoredDateTime': '2015-12-18 15:12:57', 'commitGitStats': [{'filePath': 'src/main/java/org/redisson/command/AsyncDetails.java', 'insertions': 52, 'deletions': 0, 'lines': 52}, {'filePath': 'src/main/java/org/redisson/command/CommandAsyncService.java', 'insertions': 45, 'deletions': 47, 'lines': 92}, {'filePath': 'src/main/java/org/redisson/command/CommandBatchService.java', 'insertions': 20, 'deletions': 19, 'lines': 39}, {'filePath': 'src/main/java/org/redisson/connection/ConnectionManager.java', 'insertions': 3, 'deletions': 3, 'lines': 6}, {'filePath': 'src/main/java/org/redisson/connection/FastCompleteFuture.java', 'insertions': 75, 'deletions': 0, 'lines': 75}, {'filePath': 'src/main/java/org/redisson/connection/FastFailedFuture.java', 'insertions': 65, 'deletions': 0, 'lines': 65}, {'filePath': 'src/main/java/org/redisson/connection/FastSuccessFuture.java', 'insertions': 47, 'deletions': 0, 'lines': 47}, {'filePath': 'src/main/java/org/redisson/connection/MasterSlaveConnectionManager.java', 'insertions': 10, 'deletions': 8, 'lines': 18}, {'filePath': 'src/main/java/org/redisson/connection/balancer/LoadBalancerManagerImpl.java', 'insertions': 1, 'deletions': 1, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AsyncDetails.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.command.AsyncDetails', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'CommandAsyncService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.command.CommandAsyncService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.protocol.decoder.MultiDecoder,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],io.netty.util.concurrent.Promise,int)', 'TOT': 7, 'UPD': 5, 'INS': 0, 'MOV': 0, 'DEL': 2}, {'spoonMethodName': 'org.redisson.command.CommandAsyncService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.protocol.decoder.MultiDecoder,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],io.netty.util.concurrent.Promise,int).6.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 12, 'UPD': 10, 'INS': 0, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'org.redisson.command.CommandAsyncService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.protocol.decoder.MultiDecoder,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],io.netty.util.concurrent.Promise,int).7.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.command.CommandAsyncService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.protocol.decoder.MultiDecoder,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],io.netty.util.concurrent.Promise,int).5.run(io.netty.util.Timeout)', 'TOT': 8, 'UPD': 8, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.command.CommandAsyncService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.protocol.decoder.MultiDecoder,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],io.netty.util.concurrent.Promise,int).6.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.channel.ChannelFuture)', 'TOT': 25, 'UPD': 8, 'INS': 5, 'MOV': 11, 'DEL': 1}, {'spoonMethodName': 'org.redisson.command.CommandAsyncService.evalReadAsync(java.lang.String,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.String,java.util.List,java.lang.Object[])', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.command.CommandAsyncService.evalReadAsync(java.net.InetSocketAddress,java.lang.String,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.String,java.util.List,java.lang.Object[])', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.command.CommandAsyncService.evalWriteAsync(java.lang.String,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.String,java.util.List,java.lang.Object[])', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.command.CommandAsyncService.evalAsync(org.redisson.connection.NodeSource,boolean,java.lang.String,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.String,java.util.List,java.lang.Object[])', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}]}, {'spoonFilePath': 'CommandBatchService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.command.CommandBatchService.execute(org.redisson.command.CommandBatchService$Entry,org.redisson.connection.NodeSource,io.netty.util.concurrent.Promise,java.util.concurrent.atomic.AtomicInteger,int)', 'TOT': 9, 'UPD': 5, 'INS': 0, 'MOV': 1, 'DEL': 3}, {'spoonMethodName': 'org.redisson.command.CommandBatchService.execute(org.redisson.command.CommandBatchService$Entry,org.redisson.connection.NodeSource,io.netty.util.concurrent.Promise,java.util.concurrent.atomic.AtomicInteger,int).4.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 10, 'UPD': 10, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.command.CommandBatchService.execute(org.redisson.command.CommandBatchService$Entry,org.redisson.connection.NodeSource,io.netty.util.concurrent.Promise,java.util.concurrent.atomic.AtomicInteger,int).5.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.command.CommandBatchService.execute(org.redisson.command.CommandBatchService$Entry,org.redisson.connection.NodeSource,io.netty.util.concurrent.Promise,java.util.concurrent.atomic.AtomicInteger,int).3.run(io.netty.util.Timeout)', 'TOT': 5, 'UPD': 4, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.command.CommandBatchService.execute(org.redisson.command.CommandBatchService$Entry,org.redisson.connection.NodeSource,io.netty.util.concurrent.Promise,java.util.concurrent.atomic.AtomicInteger,int).4.operationComplete(io.netty.util.concurrent.Future).2.operationComplete(io.netty.channel.ChannelFuture)', 'TOT': 6, 'UPD': 6, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ConnectionManager.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.connection.createReleaseReadListener(org.redisson.connection.NodeSource,org.redisson.client.RedisConnection,java.util.concurrent.atomic.AtomicReference)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.connection.createReleaseWriteListener(org.redisson.connection.NodeSource,org.redisson.client.RedisConnection,java.util.concurrent.atomic.AtomicReference)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'FastCompleteFuture.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.connection.FastCompleteFuture', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'FastFailedFuture.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.connection.FastFailedFuture', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'FastSuccessFuture.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.connection.FastSuccessFuture', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'MasterSlaveConnectionManager.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.connection.MasterSlaveConnectionManager.createReleaseWriteListener(org.redisson.connection.NodeSource,org.redisson.client.RedisConnection,java.util.concurrent.atomic.AtomicReference)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.connection.MasterSlaveConnectionManager.createReleaseReadListener(org.redisson.connection.NodeSource,org.redisson.client.RedisConnection,java.util.concurrent.atomic.AtomicReference)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.connection.MasterSlaveConnectionManager.createReleaseWriteListener(org.redisson.connection.NodeSource,org.redisson.client.RedisConnection,java.util.concurrent.atomic.AtomicReference).2.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.connection.MasterSlaveConnectionManager.createReleaseReadListener(org.redisson.connection.NodeSource,org.redisson.client.RedisConnection,java.util.concurrent.atomic.AtomicReference).3.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.connection.MasterSlaveConnectionManager.psubscribe(java.lang.String,org.redisson.client.codec.Codec)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.connection.MasterSlaveConnectionManager.newSucceededFuture(java.lang.Object)', 'TOT': 3, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.connection.MasterSlaveConnectionManager.newFailedFuture(java.lang.Throwable)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.redisson.connection.MasterSlaveConnectionManager.getEntry(java.net.InetSocketAddress)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'LoadBalancerManagerImpl.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.connection.balancer.LoadBalancerManagerImpl.getConnection(java.net.InetSocketAddress)', 'TOT': 3, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'ca6be04b0ee3822072185b7b2570a8845eaeb284', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['e17a9ce303793becf429b4223ebb931568d099f1'], 'nameRev': 'ca6be04b0ee3822072185b7b2570a8845eaeb284 tags/redisson-2.2.4~24', 'commitMessage': 'SuccessFuture allocation optimization. #338\n', 'commitDateTime': '2015-12-18 16:30:26', 'authoredDateTime': '2015-12-18 16:30:26', 'commitGitStats': [{'filePath': 'src/main/java/org/redisson/client/RedisConnection.java', 'insertions': 6, 'deletions': 0, 'lines': 6}, {'filePath': 'src/main/java/org/redisson/client/RedisPubSubConnection.java', 'insertions': 0, 'deletions': 2, 'lines': 2}, {'filePath': 'src/main/java/org/redisson/connection/FastSuccessFuture.java', 'insertions': 1, 'deletions': 1, 'lines': 2}, {'filePath': 'src/main/java/org/redisson/misc/ConnectionPool.java', 'insertions': 1, 'deletions': 1, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'RedisConnection.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.client.RedisConnection', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.client.RedisConnection.getAcquireFuture()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RedisPubSubConnection.java', 'spoonMethods': []}, {'spoonFilePath': 'FastSuccessFuture.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.connection.FastSuccessFuture', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ConnectionPool.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.misc.ConnectionPool.promiseSuccessful(org.redisson.connection.ClientConnectionsEntry,org.redisson.client.RedisConnection)', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '7a64333f0f209e3e3709aec3886cfe3db27f22d6', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['ca6be04b0ee3822072185b7b2570a8845eaeb284'], 'nameRev': '7a64333f0f209e3e3709aec3886cfe3db27f22d6 tags/redisson-2.2.4~23', 'commitMessage': 'CommandsQueue object allocations optimization. #338\n', 'commitDateTime': '2015-12-18 16:40:33', 'authoredDateTime': '2015-12-18 16:40:33', 'commitGitStats': [{'filePath': 'src/main/java/org/redisson/client/handler/CommandDecoder.java', 'insertions': 2, 'deletions': 2, 'lines': 4}, {'filePath': 'src/main/java/org/redisson/client/handler/CommandsQueue.java', 'insertions': 20, 'deletions': 16, 'lines': 36}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'CommandDecoder.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.client.handler.CommandDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,java.util.List)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.client.handler.CommandDecoder.handleCommandsDataResponse(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,org.redisson.client.protocol.QueueCommand,org.redisson.client.protocol.Decoder,org.redisson.client.protocol.CommandsData)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'CommandsQueue.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.client.handler.CommandsQueue.sendNextCommand(io.netty.channel.ChannelHandlerContext)', 'TOT': 6, 'UPD': 4, 'INS': 0, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.redisson.client.handler.CommandsQueue.sendData(io.netty.channel.ChannelHandlerContext)', 'TOT': 10, 'UPD': 5, 'INS': 0, 'MOV': 3, 'DEL': 2}, {'spoonMethodName': 'org.redisson.client.handler.CommandsQueue', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.client.handler.CommandsQueue.sendData(io.netty.channel.Channel)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.client.handler.CommandsQueue.sendData(io.netty.channel.ChannelHandlerContext).1', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.client.handler.CommandsQueue.sendData(io.netty.channel.ChannelHandlerContext).1.operationComplete(io.netty.channel.ChannelFuture)', 'TOT': 3, 'UPD': 0, 'INS': 0, 'MOV': 3, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '35870151801c8a4e308164f5b401cbed55f51118', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['7a64333f0f209e3e3709aec3886cfe3db27f22d6'], 'nameRev': '35870151801c8a4e308164f5b401cbed55f51118 tags/redisson-2.2.4~22', 'commitMessage': 'Minor optimization. #338\n', 'commitDateTime': '2015-12-18 16:50:00', 'authoredDateTime': '2015-12-18 16:50:00', 'commitGitStats': [{'filePath': 'src/main/java/org/redisson/client/protocol/CommandData.java', 'insertions': 1, 'deletions': 2, 'lines': 3}, {'filePath': 'src/main/java/org/redisson/client/protocol/CommandsData.java', 'insertions': 1, 'deletions': 3, 'lines': 4}, {'filePath': 'src/main/java/org/redisson/client/protocol/QueueCommand.java', 'insertions': 5, 'deletions': 0, 'lines': 5}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'CommandData.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.client.protocol.CommandData.getPubSubOperations()', 'TOT': 3, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 1}]}, {'spoonFilePath': 'CommandsData.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.client.protocol.CommandsData.getPubSubOperations()', 'TOT': 3, 'UPD': 1, 'INS': 0, 'MOV': 1, 'DEL': 1}]}, {'spoonFilePath': 'QueueCommand.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.client.protocol', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'ae72c05b93816a5211f60ca94b3cbfe192d6c6aa', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['35870151801c8a4e308164f5b401cbed55f51118'], 'nameRev': 'ae72c05b93816a5211f60ca94b3cbfe192d6c6aa tags/redisson-2.2.4~21', 'commitMessage': 'Sentinel connection optimization. #338\n', 'commitDateTime': '2015-12-18 17:08:10', 'authoredDateTime': '2015-12-18 17:08:10', 'commitGitStats': [{'filePath': 'src/main/java/org/redisson/connection/SentinelConnectionManager.java', 'insertions': 52, 'deletions': 35, 'lines': 87}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'SentinelConnectionManager.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.connection.SentinelConnectionManager.registerSentinel(org.redisson.SentinelServersConfig,java.net.URI,org.redisson.MasterSlaveServersConfig)', 'TOT': 19, 'UPD': 3, 'INS': 5, 'MOV': 10, 'DEL': 1}, {'spoonMethodName': 'org.redisson.connection.SentinelConnectionManager.registerSentinel(org.redisson.SentinelServersConfig,java.net.URI,org.redisson.MasterSlaveServersConfig).1.onMessage(java.lang.String,java.lang.String)', 'TOT': 5, 'UPD': 5, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.redisson.connection.SentinelConnectionManager', 'TOT': 5, 'UPD': 0, 'INS': 4, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.redisson.connection.SentinelConnectionManager.registerSentinel(org.redisson.SentinelServersConfig,java.net.URI,org.redisson.MasterSlaveServersConfig).1.operationComplete(io.netty.util.concurrent.Future)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': 'fac418e9f675262c9c01157a50d18a9ce6b1d0b6', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['f45244b979f1115addad39732e6063a9b2e246d3'], 'nameRev': 'fac418e9f675262c9c01157a50d18a9ce6b1d0b6 tags/redisson-2.2.4~17', 'commitMessage': 'Memory allocation optimization. #338\n', 'commitDateTime': '2015-12-21 15:41:18', 'authoredDateTime': '2015-12-21 15:41:18', 'commitGitStats': [{'filePath': 'src/main/java/org/redisson/command/AsyncDetails.java', 'insertions': 104, 'deletions': 1, 'lines': 105}, {'filePath': 'src/main/java/org/redisson/command/CommandAsyncService.java', 'insertions': 195, 'deletions': 127, 'lines': 322}, {'filePath': 'src/main/java/org/redisson/command/CommandBatchService.java', 'insertions': 3, 'deletions': 3, 'lines': 6}, {'filePath': 'src/main/java/org/redisson/connection/ClientConnectionsEntry.java', 'insertions': 5, 'deletions': 0, 'lines': 5}, {'filePath': 'src/main/java/org/redisson/connection/ConnectionManager.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'src/main/java/org/redisson/connection/NodeSource.java', 'insertions': 2, 'deletions': 0, 'lines': 2}], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': 'tooManyChanges'}, {'commitHash': '4c897806f6a84a5bc9347ff92c007ae517a03fa1', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['b70dd92b6d867b79e4b457040f4f355aecc6941e'], 'nameRev': '4c897806f6a84a5bc9347ff92c007ae517a03fa1 tags/redisson-2.2.4~14', 'commitMessage': 'Connection leak fixed. #338\n', 'commitDateTime': '2015-12-22 15:18:08', 'authoredDateTime': '2015-12-22 15:17:56', 'commitGitStats': [{'filePath': 'src/main/java/org/redisson/command/CommandAsyncService.java', 'insertions': 1, 'deletions': 1, 'lines': 2}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'CommandAsyncService.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.command.CommandAsyncService.releaseConnection(org.redisson.connection.NodeSource,org.redisson.command.AsyncDetails,org.redisson.client.RedisConnection)', 'TOT': 4, 'UPD': 1, 'INS': 1, 'MOV': 1, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/338,22.00027777777778,['bug'],New version 2.1.4 or greater performance is low.,8.0,"['org.redisson.command.CommandAsyncService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.protocol.decoder.MultiDecoder,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],io.netty.util.concurrent.Promise,int)', 'org.redisson.connection.FastSuccessFuture', 'org.redisson.misc.ConnectionPool.promiseSuccessful(org.redisson.connection.ClientConnectionsEntry,org.redisson.client.RedisConnection)', 'org.redisson.command.CommandAsyncService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.protocol.decoder.MultiDecoder,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],io.netty.util.concurrent.Promise,int).5.run(io.netty.util.Timeout)', 'org.redisson.connection.MasterSlaveConnectionManager.newSucceededFuture(java.lang.Object)', 'org.redisson.connection.FastFailedFuture', 'org.redisson.misc.ConnectionPool.connect(org.redisson.connection.ClientConnectionsEntry,io.netty.util.concurrent.Promise)', 'org.redisson.client.handler.CommandsQueue.sendNextCommand(io.netty.channel.ChannelHandlerContext)', 'org.redisson.connection.balancer.LoadBalancerManagerImpl.getConnection(java.net.InetSocketAddress)', 'org.redisson.command.CommandBatchService.execute(org.redisson.command.CommandBatchService$Entry,org.redisson.connection.NodeSource,io.netty.util.concurrent.Promise,java.util.concurrent.atomic.AtomicInteger,int).4.operationComplete(io.netty.util.concurrent.Future).2.operationComplete(io.netty.channel.ChannelFuture)', 'org.redisson.client.handler.CommandsQueue.sendData(io.netty.channel.ChannelHandlerContext)', 'org.redisson.connection.MasterSlaveConnectionManager.createReleaseWriteListener(org.redisson.connection.NodeSource,org.redisson.client.RedisConnection,java.util.concurrent.atomic.AtomicReference).2.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.command.CommandBatchService.execute(org.redisson.command.CommandBatchService$Entry,org.redisson.connection.NodeSource,io.netty.util.concurrent.Promise,java.util.concurrent.atomic.AtomicInteger,int).5.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.command.CommandAsyncService.evalAsync(org.redisson.connection.NodeSource,boolean,java.lang.String,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.String,java.util.List,java.lang.Object[])', 'org.redisson.command.CommandAsyncService.releaseConnection(org.redisson.connection.NodeSource,org.redisson.command.AsyncDetails,org.redisson.client.RedisConnection)', 'org.redisson.misc.ConnectionPool.get(org.redisson.connection.ClientConnectionsEntry)', 'org.redisson.command.CommandAsyncService.evalWriteAsync(java.lang.String,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.String,java.util.List,java.lang.Object[])', 'org.redisson.misc.ConnectionPool.get()', 'org.redisson.connection.MasterSlaveConnectionManager.getEntry(java.net.InetSocketAddress)', 'org.redisson.command.CommandAsyncService.evalReadAsync(java.lang.String,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.String,java.util.List,java.lang.Object[])', 'org.redisson.client.RedisConnection.getAcquireFuture()', 'org.redisson.misc.ConnectionPool.initConnections(org.redisson.connection.ClientConnectionsEntry,io.netty.util.concurrent.Promise,boolean)', 'org.redisson.connection.newSucceededFuture(java.lang.Object)', 'org.redisson.command.CommandAsyncService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.protocol.decoder.MultiDecoder,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],io.netty.util.concurrent.Promise,int).6.operationComplete(io.netty.util.concurrent.Future).1.operationComplete(io.netty.channel.ChannelFuture)', 'org.redisson.connection.FastCompleteFuture', 'org.redisson.connection.MasterSlaveConnectionManager.createReleaseReadListener(org.redisson.connection.NodeSource,org.redisson.client.RedisConnection,java.util.concurrent.atomic.AtomicReference)', 'org.redisson.connection.SentinelConnectionManager.registerSentinel(org.redisson.SentinelServersConfig,java.net.URI,org.redisson.MasterSlaveServersConfig).1.onMessage(java.lang.String,java.lang.String)', 'org.redisson.connection.createReleaseWriteListener(org.redisson.connection.NodeSource,org.redisson.client.RedisConnection,java.util.concurrent.atomic.AtomicReference)', 'org.redisson.client.RedisConnection', 'org.redisson.command.AsyncDetails', 'org.redisson.misc.ConnectionPool.connectTo(org.redisson.connection.ClientConnectionsEntry)', 'org.redisson.client.handler.CommandsQueue.sendData(io.netty.channel.ChannelHandlerContext).1', 'org.redisson.misc.ConnectionPool.promiseFailure(org.redisson.connection.ClientConnectionsEntry,org.redisson.client.RedisConnection)', 'org.redisson.command.CommandAsyncService.evalReadAsync(java.net.InetSocketAddress,java.lang.String,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.String,java.util.List,java.lang.Object[])', 'org.redisson.cluster.ClusterConnectionManager.addMasterEntry(org.redisson.cluster.ClusterPartition,org.redisson.ClusterServersConfig)', 'org.redisson.connection.SentinelConnectionManager.registerSentinel(org.redisson.SentinelServersConfig,java.net.URI,org.redisson.MasterSlaveServersConfig).1.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.command.CommandBatchService.execute(org.redisson.command.CommandBatchService$Entry,org.redisson.connection.NodeSource,io.netty.util.concurrent.Promise,java.util.concurrent.atomic.AtomicInteger,int)', 'org.redisson.client.handler.CommandsQueue', 'org.redisson.client.handler.CommandDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,java.util.List)', 'org.redisson.connection.MasterSlaveConnectionManager.newFailedFuture(java.lang.Throwable)', 'org.redisson.client.protocol.CommandsData.getPubSubOperations()', 'org.redisson.client.handler.CommandsQueue.sendData(io.netty.channel.ChannelHandlerContext).1.operationComplete(io.netty.channel.ChannelFuture)', 'org.redisson.client.protocol.CommandData.getPubSubOperations()', 'org.redisson.connection.createReleaseReadListener(org.redisson.connection.NodeSource,org.redisson.client.RedisConnection,java.util.concurrent.atomic.AtomicReference)', 'org.redisson.connection.SentinelConnectionManager', 'org.redisson.command.CommandAsyncService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.protocol.decoder.MultiDecoder,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],io.netty.util.concurrent.Promise,int).7.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.command.CommandBatchService.execute(org.redisson.command.CommandBatchService$Entry,org.redisson.connection.NodeSource,io.netty.util.concurrent.Promise,java.util.concurrent.atomic.AtomicInteger,int).3.run(io.netty.util.Timeout)', 'org.redisson.client.protocol', 'org.redisson.connection.MasterSlaveConnectionManager.createReleaseReadListener(org.redisson.connection.NodeSource,org.redisson.client.RedisConnection,java.util.concurrent.atomic.AtomicReference).3.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.command.CommandAsyncService.async(boolean,org.redisson.connection.NodeSource,org.redisson.client.protocol.decoder.MultiDecoder,org.redisson.client.codec.Codec,org.redisson.client.protocol.RedisCommand,java.lang.Object[],io.netty.util.concurrent.Promise,int).6.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.misc.ConnectionPool.promiseSuccessful(org.redisson.connection.ClientConnectionsEntry,io.netty.util.concurrent.Promise,org.redisson.client.RedisConnection)', 'org.redisson.command.CommandBatchService.execute(org.redisson.command.CommandBatchService$Entry,org.redisson.connection.NodeSource,io.netty.util.concurrent.Promise,java.util.concurrent.atomic.AtomicInteger,int).4.operationComplete(io.netty.util.concurrent.Future)', 'org.redisson.client.handler.CommandsQueue.sendData(io.netty.channel.Channel)', 'org.redisson.connection.SentinelConnectionManager.registerSentinel(org.redisson.SentinelServersConfig,java.net.URI,org.redisson.MasterSlaveServersConfig)', 'org.redisson.connection.MasterSlaveConnectionManager.createReleaseWriteListener(org.redisson.connection.NodeSource,org.redisson.client.RedisConnection,java.util.concurrent.atomic.AtomicReference)', 'org.redisson.connection.MasterSlaveConnectionManager.psubscribe(java.lang.String,org.redisson.client.codec.Codec)', 'org.redisson.client.handler.CommandDecoder.handleCommandsDataResponse(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,org.redisson.client.protocol.QueueCommand,org.redisson.client.protocol.Decoder,org.redisson.client.protocol.CommandsData)', 'org.redisson.connection.MasterSlaveConnectionManager.newSucceededFuture()']","['b0d9803593f619bd14531c6a88a58e8dce18e45e', 'e17a9ce303793becf429b4223ebb931568d099f1', 'ca6be04b0ee3822072185b7b2570a8845eaeb284', '7a64333f0f209e3e3709aec3886cfe3db27f22d6', '35870151801c8a4e308164f5b401cbed55f51118', 'ae72c05b93816a5211f60ca94b3cbfe192d6c6aa', 'fac418e9f675262c9c01157a50d18a9ce6b1d0b6', '4c897806f6a84a5bc9347ff92c007ae517a03fa1']",,"['src/main/java/org/redisson/command', 'src/main/java/org/redisson/connection', 'src/main/java/org/redisson/misc', 'src/main/java/org/redisson/client', 'src/main/java/org/redisson/cluster', 'src/main/java/org/redisson/connection/balancer', 'src/main/java/org/redisson/client/protocol', 'src/main/java/org/redisson/client/handler']",757.0,293.0,1050.0,21.0,96.0,58.0,233.0,55.0,47.0,35.0,18.0,0.0,0.0,0.0,0.0,0.0,0.0,redisson
42604,2015-09-04 20:21:46,liuyin-ocous,"We have a production system using Redisson to handle notification. However, recently we constantly run into subscription connection exhausted issue. After investigation, I found Redisson doesn't release the subscription connection after the last listener is removed. 

Eventually, this issue is caused by the following line. It seems ConcurrentLinedQueue doesn't fully implement equals method to compare 2 linked list. Therefore, an empty linked list will never equals to another empty linked list, which eventually leaks all subscription connections.

```
public void removeListener(String channelName, RedisPubSubListener listener) {

  channelListeners.remove(channelName, new ConcurrentLinkedQueue<RedisPubSubListener>());

}
```

This is a very urgent issue to us. Any help or workaround will be greatly appreciated.
",2015-09-05 09:00:10,"[{'commitHash': '48dea3709e5b4f6b2389777ae4066036c08cf4f9', 'commitGHEventType': 'referenced', 'commitUser': 'mrniko', 'commitParents': ['2f99a27103db931b8c372b880afa3b4adcffbd8c'], 'nameRev': '48dea3709e5b4f6b2389777ae4066036c08cf4f9 tags/redisson-2.1.2~1', 'commitMessage': 'Subscription connection leak in PubSubConnectionEntry::removeListener\n& unsubscribe process optimization. #237\n', 'commitDateTime': '2015-09-05 11:59:51', 'authoredDateTime': '2015-09-05 11:59:51', 'commitGitStats': [{'filePath': 'src/main/java/org/redisson/connection/PubSubConnectionEntry.java', 'insertions': 19, 'deletions': 17, 'lines': 36}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'PubSubConnectionEntry.java', 'spoonMethods': [{'spoonMethodName': 'org.redisson.connection.PubSubConnectionEntry.unsubscribe(java.lang.String,org.redisson.client.RedisPubSubListener).1.onStatus(org.redisson.client.protocol.pubsub.PubSubType,java.lang.String)', 'TOT': 12, 'UPD': 1, 'INS': 2, 'MOV': 7, 'DEL': 2}, {'spoonMethodName': 'org.redisson.connection.PubSubConnectionEntry.removeListener(java.lang.String,org.redisson.client.RedisPubSubListener)', 'TOT': 4, 'UPD': 1, 'INS': 1, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.redisson.connection.PubSubConnectionEntry.punsubscribe(java.lang.String,org.redisson.client.RedisPubSubListener).2.onStatus(org.redisson.client.protocol.pubsub.PubSubType,java.lang.String)', 'TOT': 8, 'UPD': 0, 'INS': 2, 'MOV': 4, 'DEL': 2}, {'spoonMethodName': 'org.redisson.connection.PubSubConnectionEntry.removeListeners(java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/redisson/redisson/issues/237,0.0002777777777777778,['bug'],Subscription connection leak in PubSubConnectionEntry::removeListener,1.0,"['org.redisson.connection.PubSubConnectionEntry.removeListeners(java.lang.String)', 'org.redisson.connection.PubSubConnectionEntry.punsubscribe(java.lang.String,org.redisson.client.RedisPubSubListener).2.onStatus(org.redisson.client.protocol.pubsub.PubSubType,java.lang.String)', 'org.redisson.connection.PubSubConnectionEntry.unsubscribe(java.lang.String,org.redisson.client.RedisPubSubListener).1.onStatus(org.redisson.client.protocol.pubsub.PubSubType,java.lang.String)', 'org.redisson.connection.PubSubConnectionEntry.removeListener(java.lang.String,org.redisson.client.RedisPubSubListener)']",['48dea3709e5b4f6b2389777ae4066036c08cf4f9'],,['src/main/java/org/redisson/connection'],19.0,17.0,36.0,1.0,2.0,4.0,25.0,12.0,6.0,5.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,redisson
45754,2020-04-09 14:40:22,dreis2211,"Hi,

recently the following tests started to fail sporadically:

- `LogFileWebEndpointAutoConfigurationTests.logFileWebEndpointIsAutoConfiguredWhenExternalFileIsSet `
- `DiskSpaceHealthContributorAutoConfigurationTests.runWhenPathDoesNotExistShouldCreateIndicator `

Both seem to be throwing similar errors like this:

```
Caused by: org.springframework.core.convert.ConversionFailedException: Failed to convert from type [java.lang.String] to type [java.io.File] for value 'external.log'; nested exception is java.lang.IllegalStateException: Illegal access: this web application instance has been stopped already. Could not load [external.log]. The following stack trace is thrown for debugging purposes as well as to attempt to terminate the thread which caused the illegal access.
 	at org.springframework.core.convert.support.ConversionUtils.invokeConverter(ConversionUtils.java:47)
 	at org.springframework.core.convert.support.GenericConversionService.convert(GenericConversionService.java:191)
 	at org.springframework.boot.context.properties.bind.BindConverter$CompositeConversionService.convert(BindConverter.java:170)
 	at org.springframework.boot.context.properties.bind.BindConverter.convert(BindConverter.java:96)
 	at org.springframework.boot.context.properties.bind.BindConverter.convert(BindConverter.java:88)
 	at org.springframework.boot.context.properties.bind.Binder.bindProperty(Binder.java:434)
 	at org.springframework.boot.context.properties.bind.Binder.bindObject(Binder.java:379)
 	at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:319)
 	... 142 more
 Caused by: java.lang.IllegalStateException: Illegal access: this web application instance has been stopped already. Could not load [external.log]. The following stack trace is thrown for debugging purposes as well as to attempt to terminate the thread which caused the illegal access.
 	at org.apache.catalina.loader.WebappClassLoaderBase.checkStateForResourceLoading(WebappClassLoaderBase.java:1385)
 	at org.apache.catalina.loader.WebappClassLoaderBase.getResource(WebappClassLoaderBase.java:1038)
 	at org.springframework.core.io.ClassPathResource.resolveURL(ClassPathResource.java:155)
 	at org.springframework.core.io.ClassPathResource.exists(ClassPathResource.java:142)
 	at org.springframework.boot.convert.StringToFileConverter.convert(StringToFileConverter.java:48)
 	at org.springframework.boot.convert.StringToFileConverter.convert(StringToFileConverter.java:34)
 	at org.springframework.core.convert.support.GenericConversionService$ConverterAdapter.convert(GenericConversionService.java:385)
 	at org.springframework.core.convert.support.ConversionUtils.invokeConverter(ConversionUtils.java:41)
```

I tried fixing it directly, but I can't see what's going wrong in these cases.

Cheers,
Christoph",2020-04-24 15:22:53,"[{'commitHash': 'dc75ca3942fba9a7773fdd0536b9289037b33668', 'commitGHEventType': 'closed', 'commitUser': 'wilkinsona', 'commitParents': ['d53be185825400a9f7d78d058de1f24f9d142fcb'], 'nameRev': 'dc75ca3942fba9a7773fdd0536b9289037b33668 tags/v2.3.0.RC1~120', 'commitMessage': ""Avoid capturing TCCL when creating DefaultResourceLoaders\n\nPreviously, DefaultResourceLoader instances were created using the\ndefault constructor. This causes the resource loader to capture the\nTCCL that was in place at that time. This can lead to a class loader\nleak if the resource loader is referenced directly or indirectly from\na static field of a class loaded by a different class loader.\n\nThis commit updates the creation of DefaultResourceLoader instances\nin main code so that the resource load will use the class loader of\nthe creating class. In almost all cases this will be the same class\nloader as was the thread context class loader that was being captured\nso the change in behavior is minimal. Crucially, it will still address\nthe situation where the TCCL was different.\n\nNote the DevTools' ApplicationContextResourceLoader has been updated\nto explicitly use the TCCL. This ensures that it uses the restart\nclass loader which is required for DevTools to function correctly.\n\nFixes gh-20900\n"", 'commitDateTime': '2020-04-24 13:29:29', 'authoredDateTime': '2020-04-24 12:41:51', 'commitGitStats': [{'filePath': 'spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/DataSourceInitializer.java', 'insertions': 3, 'deletions': 2, 'lines': 5}, {'filePath': 'spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/mustache/MustacheResourceTemplateLoader.java', 'insertions': 2, 'deletions': 2, 'lines': 4}, {'filePath': 'spring-boot-project/spring-boot-devtools/src/main/java/org/springframework/boot/devtools/restart/ClassLoaderFilesResourcePatternResolver.java', 'insertions': 3, 'deletions': 1, 'lines': 4}, {'filePath': 'spring-boot-project/spring-boot/src/main/java/org/springframework/boot/context/config/ConfigFileApplicationListener.java', 'insertions': 2, 'deletions': 1, 'lines': 3}, {'filePath': 'spring-boot-project/spring-boot/src/main/java/org/springframework/boot/convert/StringToFileConverter.java', 'insertions': 3, 'deletions': 2, 'lines': 5}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'DataSourceInitializer.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.autoconfigure.jdbc.DataSourceInitializer', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'MustacheResourceTemplateLoader.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.autoconfigure.mustache.MustacheResourceTemplateLoader', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ClassLoaderFilesResourcePatternResolver.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.devtools.restart.ClassLoaderFilesResourcePatternResolver.ApplicationContextResourceLoader', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ConfigFileApplicationListener.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.context.config.ConfigFileApplicationListener.Loader', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'StringToFileConverter.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.convert.StringToFileConverter', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-boot/issues/20900,15.000277777777777,['type: bug'],Use of new DefaultResourceLoader() is dangerous as it captures the thread context classloader at the time of the call,1.0,"['org.springframework.boot.autoconfigure.jdbc.DataSourceInitializer', 'org.springframework.boot.convert.StringToFileConverter', 'org.springframework.boot.context.config.ConfigFileApplicationListener.Loader', 'org.springframework.boot.devtools.restart.ClassLoaderFilesResourcePatternResolver.ApplicationContextResourceLoader', 'org.springframework.boot.autoconfigure.mustache.MustacheResourceTemplateLoader']",['dc75ca3942fba9a7773fdd0536b9289037b33668'],,"['spring-boot-project/spring-boot-devtools/src/main/java/org/springframework/boot/devtools/restart', 'spring-boot-project/spring-boot/src/main/java/org/springframework/boot/convert', 'spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/mustache', 'spring-boot-project/spring-boot/src/main/java/org/springframework/boot/context/config', 'spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc']",13.0,8.0,21.0,5.0,4.0,5.0,5.0,0.0,1.0,0.0,5.0,0.0,0.0,0.0,0.0,0.0,0.0,spring-boot
46092,2019-06-12 11:51:01,wilkinsona,"Due to how Undertow's `URLResource` and the JDK's `JarURLConnection` work, if `JarResourceManager` is asked for an entry for the root of a jar (a path of `""""` or `""/""`), it will open an `InputStream` and never close it. To avoid this, we need to avoid asking the `URLResource` for its content length for such resources.",2019-06-12 11:55:01,"[{'commitHash': '4222c5b8ce9df6403a5abadd6a088b4d7214f4e6', 'commitGHEventType': 'closed', 'commitUser': 'wilkinsona', 'commitParents': ['df9a6a0f4f275a72dcb21ff9b124c36a5809cf4b'], 'nameRev': '4222c5b8ce9df6403a5abadd6a088b4d7214f4e6 tags/v2.1.6.RELEASE~55', 'commitMessage': 'Prevent URLResource and JarURLConnection from leaking an InputStream\n\nFixes gh-17121\n', 'commitDateTime': '2019-06-12 12:53:16', 'authoredDateTime': '2019-06-12 12:53:16', 'commitGitStats': [{'filePath': 'spring-boot-project/spring-boot/src/main/java/org/springframework/boot/web/embedded/undertow/JarResourceManager.java', 'insertions': 3, 'deletions': 1, 'lines': 4}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'JarResourceManager.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.web.embedded.undertow.JarResourceManager.getResource(java.lang.String)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-boot/issues/17121,0.0002777777777777778,['type: bug'],JarResourceManager leaks an InputStream when asked for a Resource for the root of a jar,1.0,['org.springframework.boot.web.embedded.undertow.JarResourceManager.getResource(java.lang.String)'],['4222c5b8ce9df6403a5abadd6a088b4d7214f4e6'],,['spring-boot-project/spring-boot/src/main/java/org/springframework/boot/web/embedded'],3.0,1.0,4.0,1.0,0.0,1.0,2.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,spring-boot
46242,2018-10-18 21:40:46,filiphr,"Let me try and explain the problem that I am seeing.

With https://github.com/spring-projects/spring-boot/issues/13186 support for lazy loading `DispatcherServlet` when hitting `/actuator/mappings` has been added to Spring Boot 2.0.6. However, when that happens and one tries to close the application it takes 2s per `DispatcherServlet` to close its `WebApplicationContext` (this is on 2.0.6.RELEASE). However, if each context was initialized by hitting it's path then everything is fine. Therefore, I think that there might be some problem with the way the async `DispatcherServlet`(s) are initialized in the Actuator.

I have created a small project that displays the problem. You can find it [here](https://github.com/filiphr/spring-boot-issues/tree/master/multi-dispatcher-issue).

Note: #13186 actually does not work with 2.1.0.RC1 (which means that you won't see the problem there, as the other contexts are not initialized).",2018-10-19 10:42:11,"[{'commitHash': '76ad1975844550609ff58caa0ce6255be15a9cb7', 'commitGHEventType': 'closed', 'commitUser': 'wilkinsona', 'commitParents': ['9b8ead825cc1f2c60a4836dbcd3a456f1eaae692'], 'nameRev': '76ad1975844550609ff58caa0ce6255be15a9cb7 tags/v2.1.0.RELEASE~1^2~28', 'commitMessage': ""Deallocate servlet after forcing initialization in mappings endpoint\n\nPreviously, when using Tomcat, a call to mappings endpoint would force\nthe initialization of any DispatcherServlets in the context. This was\ndone by calling allocate on Tomcat's StandardWrapper. This left the\nwrapper in a state that would cause it to block for two seconds during\nshutdown as the wrapper has an outstanding allocation.\n\nThis commit immediately deallocates the servlet after it has been\nallocated. This ensures that the DispatcherServlet has been initialized\nwhile also leaving the wrapper in a state that it can shut down\nimmediately when asked to do so.\n\nCloses gh-14898\n"", 'commitDateTime': '2018-10-19 10:43:23', 'authoredDateTime': '2018-10-19 10:43:23', 'commitGitStats': [{'filePath': 'spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/web/mappings/servlet/DispatcherServletHandlerMappings.java', 'insertions': 2, 'deletions': 1, 'lines': 3}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'DispatcherServletHandlerMappings.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.actuate.web.mappings.servlet.DispatcherServletHandlerMappings.TomcatServletInitializer.initializeServlet(org.apache.catalina.Context,java.lang.String)', 'TOT': 5, 'UPD': 1, 'INS': 2, 'MOV': 1, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-boot/issues/14898,0.0002777777777777778,['type: bug'],"When using Tomcat, closing the application context blocks for two seconds for each DispatcherServlet initialised by a request to the mappings endpoint",1.0,"['org.springframework.boot.actuate.web.mappings.servlet.DispatcherServletHandlerMappings.TomcatServletInitializer.initializeServlet(org.apache.catalina.Context,java.lang.String)']",['76ad1975844550609ff58caa0ce6255be15a9cb7'],,['spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/web'],2.0,1.0,3.0,1.0,1.0,1.0,5.0,1.0,2.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,spring-boot
46471,2017-12-13 09:46:57,chenjinkai,"maybe this jar will caused the OOM problem

<dependency>
    <groupId>org.latencyutils</groupId>
    <artifactId>LatencyUtils</artifactId>
    <version>2.0.3</version>
</dependency>",2018-01-30 08:37:40,"[{'commitHash': '2612b4317904292162236ea5993dda03f7519e69', 'commitGHEventType': 'closed', 'commitUser': 'philwebb', 'commitParents': ['8f23ee4e58e8d78dae7f6dd15441fb4b5ec86933'], 'nameRev': '2612b4317904292162236ea5993dda03f7519e69 tags/v2.0.0.RC1~24', 'commitMessage': 'Restrict maximum URI tags to prevent memory issues\n\nAdd MeterFilter to restrict the maximum number of web client URI tags\ncreated. Prior to this commit, if a user was manually building URIs for\nuse with a RestTemplate (rather than using uriVariables) the JVM could\nrun out of memory.\n\nFixes gh-11338\n\nCo-authored-by: Phillip Webb <pwebb@pivotal.io>\n', 'commitDateTime': '2018-01-30 00:32:09', 'authoredDateTime': '2018-01-25 20:21:02', 'commitGitStats': [{'filePath': 'spring-boot-project/spring-boot-actuator-autoconfigure/src/main/java/org/springframework/boot/actuate/autoconfigure/metrics/MetricsProperties.java', 'insertions': 15, 'deletions': 0, 'lines': 15}, {'filePath': 'spring-boot-project/spring-boot-actuator-autoconfigure/src/main/java/org/springframework/boot/actuate/autoconfigure/metrics/web/client/RestTemplateMetricsConfiguration.java', 'insertions': 51, 'deletions': 0, 'lines': 51}, {'filePath': 'spring-boot-project/spring-boot-actuator-autoconfigure/src/test/java/org/springframework/boot/actuate/autoconfigure/metrics/web/client/RestTemplateMetricsConfigurationTests.java', 'insertions': 31, 'deletions': 0, 'lines': 31}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'MetricsProperties.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.actuate.autoconfigure.metrics.MetricsProperties.Web.Client', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.actuate.autoconfigure.metrics.MetricsProperties.Web.Client.getMaxUriTags()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.actuate.autoconfigure.metrics.MetricsProperties.Web.Client.setMaxUriTags(int)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RestTemplateMetricsConfiguration.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.actuate.autoconfigure.metrics.web.client.RestTemplateMetricsConfiguration.metricsWebClientUriTagFilter(org.springframework.boot.actuate.autoconfigure.metrics.MetricsProperties)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.actuate.autoconfigure.metrics.web.client.RestTemplateMetricsConfiguration.MaximumUriTagsReachedMeterFilter', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RestTemplateMetricsConfigurationTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.actuate.autoconfigure.metrics.web.client.RestTemplateMetricsConfigurationTests', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.actuate.autoconfigure.metrics.web.client.RestTemplateMetricsConfigurationTests.afterMaxUrisReachedFurtherUrisAreDenied()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-boot/issues/11338,47.000277777777775,['type: bug'],2.0.0.M7 “spring-boot-starter-actuator”  caused OOM,1.0,"['org.springframework.boot.actuate.autoconfigure.metrics.web.client.RestTemplateMetricsConfiguration.metricsWebClientUriTagFilter(org.springframework.boot.actuate.autoconfigure.metrics.MetricsProperties)', 'org.springframework.boot.actuate.autoconfigure.metrics.web.client.RestTemplateMetricsConfiguration.MaximumUriTagsReachedMeterFilter', 'org.springframework.boot.actuate.autoconfigure.metrics.MetricsProperties.Web.Client.getMaxUriTags()', 'org.springframework.boot.actuate.autoconfigure.metrics.MetricsProperties.Web.Client.setMaxUriTags(int)', 'org.springframework.boot.actuate.autoconfigure.metrics.MetricsProperties.Web.Client']",['2612b4317904292162236ea5993dda03f7519e69'],,['spring-boot-project/spring-boot-actuator-autoconfigure/src/main/java/org/springframework/boot/actuate/autoconfigure'],66.0,0.0,66.0,2.0,0.0,5.0,5.0,0.0,5.0,0.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,spring-boot
46841,2016-06-03 11:23:44,pcornelissen,"We're using spring boot 1.3.2 with Angel.SR6 for spring cloud. The service is a reverse proxy with zuul and occasionally we get this exception in the log:

```
2016-05-26T13:33:09.221+0200;1.3;0.0.0;http-nio-10.5.31.21-8080-exec-74:140;-;-;WARN ;org.springframework.boot.actuate.autoconfigure.MetricsFilter;[Unable to submit counter metric 'status.500.userservice-rest.star-star']
    java.lang.NullPointerException: null
    at org.springframework.boot.actuate.metrics.util.SimpleInMemoryRepository.update(SimpleInMemoryRepository.java:44)
    at org.springframework.boot.actuate.metrics.repository.InMemoryMetricRepository.increment(InMemoryMetricRepository.java:51)
    at org.springframework.boot.actuate.metrics.writer.DefaultCounterService.increment(DefaultCounterService.java:44)
    at org.springframework.boot.actuate.autoconfigure.MetricsFilter.incrementCounter(MetricsFilter.java:205)
    at org.springframework.boot.actuate.autoconfigure.MetricsFilter.recordMetrics(MetricsFilter.java:138)
    at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:110)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:212)
    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106)
    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502)
    at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:616)
    at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:616)
    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:141)
    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88)
    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:521)
    at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1096)
    at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:674)
    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1500)
    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1456)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
    at java.lang.Thread.run(Thread.java:745)
```

It usually occurs at night on a test system with not much traffic.
",2016-06-17 12:16:58,"[{'commitHash': 'a2446080bc06219673b44453127277d14568dd08', 'commitGHEventType': 'closed', 'commitUser': 'wilkinsona', 'commitParents': ['13635201ffcad9bb3c81e9a626fb96f490f51764'], 'nameRev': 'a2446080bc06219673b44453127277d14568dd08 tags/v1.3.6.RELEASE~33', 'commitMessage': 'Prevent GC pressure from causing an NPE in SimpleInMemoryRepository\n\nPreviously, SimpleInMemoryRepository used a ConcurrentReferenceHashMap\nto store its locks. The type of map will discard its entries when the\nJVM comes under GC pressure. With the code in its previous form, this\ncould lead to a NullPointerException when the following occurred:\n\n1. putIfAbsent returned null indicating that a new entry has been added\n   to the map\n2. GC pressure caused the map to discard the new entry\n3. get returned null as the entry has been discard\n\nThere are two problems with the existing code:\n\n1. Its usage of a ConcurrentMap is incorrect. The correct usage is:\n   a. Call get to see if the map already contains a lock\n   b. If the lock is null, create a new one\n   c. Call putIfAbsent to add the new lock\n   d. If the return value is non-null, another thread has created the\n      lock and it should be used. If the return value is null, use the\n      new lock created in b.\n2. Once the use of ConcurrentMap has been corrected, the fact that it is\n   a ConcurrentReferenceHashMap means that different threads could\n   access the same value using different locks. This would occur if one\n   thread has retrieved a lock from the map and is using it, while GC\n   causes the lock to be removed from the map. Another thread then\n   attempts to get the lock and, as GC pressure has remove it, a new\n   lock is created allowing concurrent access to the same value.\n\nThis commit updates the code to use the ConcurrentMap correctly and also\nreplaces the ConcurrentReferenceHashMap with a ConcurrentHashMap. This\nmeans that the repository will now use slightly more memory but this is\noutweighed by the benefits of thread-safe updates and no risk of an NPE.\n\nCloses gh-6115', 'commitDateTime': '2016-06-17 13:13:49', 'authoredDateTime': '2016-06-17 13:10:02', 'commitGitStats': [{'filePath': 'spring-boot-actuator/src/main/java/org/springframework/boot/actuate/metrics/util/SimpleInMemoryRepository.java', 'insertions': 17, 'deletions': 8, 'lines': 25}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'SimpleInMemoryRepository.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.actuate.metrics.util.SimpleInMemoryRepository', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.actuate.metrics.util.SimpleInMemoryRepository.update(java.lang.String,org.springframework.boot.actuate.metrics.util.SimpleInMemoryRepository$Callback)', 'TOT': 13, 'UPD': 1, 'INS': 1, 'MOV': 10, 'DEL': 1}, {'spoonMethodName': 'org.springframework.boot.actuate.metrics.util.SimpleInMemoryRepository.getLock(java.lang.String)', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-boot/issues/6115,14.000277777777777,['type: bug'],Nullpointer in SimpleInMemoryRepository,1.0,"['org.springframework.boot.actuate.metrics.util.SimpleInMemoryRepository.getLock(java.lang.String)', 'org.springframework.boot.actuate.metrics.util.SimpleInMemoryRepository', 'org.springframework.boot.actuate.metrics.util.SimpleInMemoryRepository.update(java.lang.String,org.springframework.boot.actuate.metrics.util.SimpleInMemoryRepository$Callback)']",['a2446080bc06219673b44453127277d14568dd08'],,['spring-boot-actuator/src/main/java/org/springframework/boot/actuate/metrics/util'],17.0,8.0,25.0,1.0,2.0,3.0,16.0,10.0,3.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,spring-boot
46940,2016-01-10 14:29:34,a-monty-only,"I want to use SpringBoot, SpringDevtool, Mustache, Gradle, and Eclipse on Windows10.
But not work.
1. I run as ""Spring Boot app"" at Eclipse, and Tomcat start.
2. I can change html in ""src/main/templates""
3. I access ""localhost:8080"" by chrome browser.
4. I change html, then Eclipse error `The project was not built due to ""Could not delete '/${projectname}/bin/templates'."". Fix the problem, then try refreshing this project and building it since it may be inconsistent` occurred, so ""localhost:8080"" return error.

Are SpringBoot and Mustache and Eclipse bad combination?

My build.gradle is ...

```
apply plugin: 'java'
apply plugin: 'eclipse'
apply plugin: 'spring-boot' 

sourceCompatibility = '1.8'
targetCompatibility = '1.8'

repositories {
    mavenCentral()
}

buildscript {
    repositories {
        mavenCentral()
    }
    dependencies {
        classpath(""org.springframework.boot:spring-boot-gradle-plugin:1.3.1.RELEASE"")
    }
}

dependencies {
    compile 'org.springframework.boot:spring-boot-starter-web:1.3.1.RELEASE'
    compile 'org.springframework.boot:spring-boot-starter-mustache:1.3.1.RELEASE'
}
```
",2016-01-15 11:20:25,"[{'commitHash': 'b56eef236e40ee0fa739957700fdfc9bb7a3bfad', 'commitGHEventType': 'closed', 'commitUser': 'wilkinsona', 'commitParents': ['681a866cceae12d69b46a7cd047eed14a898c579'], 'nameRev': 'b56eef236e40ee0fa739957700fdfc9bb7a3bfad tags/v1.3.2.RELEASE~14^2~8', 'commitMessage': ""Close Reader used by MustacheViewResolver when compiling a Template\n\nPreviously, MustacheViewResolver would create an InputStreamReader\nthat wraps the template Resource's InputStream but would fail to close\nthe Reader. When the InputStream was a FileInputStream, this caused\nthe resolver to leak file handles.\n\nThis commit updates the resolver to close the Reader once the Template\nhas been compiled, thereby allowing any underlying resources to be\ncleaned up immediately, rather than having to wait for the JVM to exit.\n\nCloses gh-4921"", 'commitDateTime': '2016-01-15 11:19:24', 'authoredDateTime': '2016-01-15 11:19:24', 'commitGitStats': [{'filePath': 'spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/mustache/web/MustacheViewResolver.java', 'insertions': 8, 'deletions': 2, 'lines': 10}, {'filePath': 'spring-boot-autoconfigure/src/test/java/org/springframework/boot/autoconfigure/mustache/web/MustacheViewResolverTests.java', 'insertions': 29, 'deletions': 1, 'lines': 30}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'MustacheViewResolver.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.autoconfigure.mustache.web.MustacheViewResolver.createTemplate(org.springframework.core.io.Resource)', 'TOT': 6, 'UPD': 0, 'INS': 3, 'MOV': 2, 'DEL': 1}]}, {'spoonFilePath': 'MustacheViewResolverTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.autoconfigure.mustache.web.MustacheViewResolverTests.templateResourceInputStreamIsClosed()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-boot/issues/4921,4.000277777777778,['type: bug'],"Can't change html when using ""spring-boot-starter-mustache"" with Eclipse.",1.0,['org.springframework.boot.autoconfigure.mustache.web.MustacheViewResolver.createTemplate(org.springframework.core.io.Resource)'],['b56eef236e40ee0fa739957700fdfc9bb7a3bfad'],,['spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/mustache/web'],8.0,2.0,10.0,1.0,0.0,1.0,6.0,2.0,3.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,spring-boot
47170,2015-01-10 11:31:25,topu,"During startup Spring Boot invokes `SLF4JBridgeHandler.install()` to add a logging handler to container's LogManager, but during application shutdown (undeploy) adequate `SLF4JBridgeHandler.uninstall()` or `SLF4JBridgeHandler.removeHandlersForRootLogger()` is not called. I think it should be.

The bug manifests itself in taking metaspace memory space and following message is displayed after invoking Tomcat's find leaks method:
Message:    

```
The following web applications were stopped (reloaded, undeployed), but their
classes from previous runs are still loaded in memory, thus causing a memory
leak (use a profiler to confirm):
/spring-boot-logging-issue
```

Below is my workaround that solves the issue. It removes the logging handler during ContextClosedEvent.

```
@Bean
public ApplicationListener<ContextClosedEvent> uninstallSLF4JBridgeHandlerWorkaround() {
    return new ApplicationListener<ContextClosedEvent>() {
        @Override
        public void onApplicationEvent(ContextClosedEvent event) {
            try {
                SLF4JBridgeHandler.removeHandlersForRootLogger();
            } catch (NoSuchMethodError ex) {
                SLF4JBridgeHandler.uninstall();
            }
        }
    };
}
```

Tested with Tomcat 8.0.15 and OpenJDK 1.8.0_25 on Linux 3.17.6
",2015-01-14 15:23:21,"[{'commitHash': '9744d282991c8ac4c9e06200a9868d8531469603', 'commitGHEventType': 'closed', 'commitUser': 'wilkinsona', 'commitParents': ['92c8b75a7313077548e1520c373d482bf4c701b6'], 'nameRev': '9744d282991c8ac4c9e06200a9868d8531469603 tags/v1.1.11.RELEASE~33', 'commitMessage': 'Uninstall SLF4J’s Java logging bridge handler during shutdown\n\nPreviously, when LogbackLoggingSystem or Log4JLoggingSystem were\ninitialized during application start up, they would install SLF4J’s Java\nlogging bridge handler, however no corresponding uninstall was performed\nduring application shutdown. When deployed to a servlet container, where\nthe application’s lifecycle doesn’t match the JVM’s lifecycle, this lead\nto a memory leak.\n\nThis commit updates LoggingSystem to introduce a new cleanUp method. An\nempty implementation is provided to preserve backwards compatibility\nwith existing LoggingSystem subclasses. Both LogbackLoggingSystem and\nLog4JLoggingSystem have been updated to implement cleanUp and uninstall\nthe SLF4J bridge handler. LoggingApplicationListener has been updated\nto call LoggingSystem.cleanUp in response to a ContextClosedEvent.\n\nCloses gh-2324', 'commitDateTime': '2015-01-14 14:37:58', 'authoredDateTime': '2015-01-14 14:37:58', 'commitGitStats': [{'filePath': 'spring-boot/src/main/java/org/springframework/boot/logging/LoggingApplicationListener.java', 'insertions': 25, 'deletions': 10, 'lines': 35}, {'filePath': 'spring-boot/src/main/java/org/springframework/boot/logging/LoggingSystem.java', 'insertions': 10, 'deletions': 1, 'lines': 11}, {'filePath': 'spring-boot/src/main/java/org/springframework/boot/logging/log4j/Log4JLoggingSystem.java', 'insertions': 42, 'deletions': 5, 'lines': 47}, {'filePath': 'spring-boot/src/main/java/org/springframework/boot/logging/logback/LogbackLoggingSystem.java', 'insertions': 30, 'deletions': 10, 'lines': 40}, {'filePath': 'spring-boot/src/test/java/org/springframework/boot/logging/LoggingApplicationListenerTests.java', 'insertions': 24, 'deletions': 1, 'lines': 25}, {'filePath': 'spring-boot/src/test/java/org/springframework/boot/logging/log4j/Log4JLoggingSystemTests.java', 'insertions': 28, 'deletions': 1, 'lines': 29}, {'filePath': 'spring-boot/src/test/java/org/springframework/boot/logging/logback/LogbackLoggingSystemTests.java', 'insertions': 25, 'deletions': 1, 'lines': 26}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'LoggingApplicationListener.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.logging.LoggingApplicationListener.supportsEventType(java.lang.Class)', 'TOT': 5, 'UPD': 0, 'INS': 1, 'MOV': 3, 'DEL': 1}, {'spoonMethodName': 'org.springframework.boot.logging.LoggingApplicationListener', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.LoggingApplicationListener.isAssignableFrom(java.lang.Class,java.lang.Class[])', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(org.springframework.context.ApplicationEvent)', 'TOT': 7, 'UPD': 0, 'INS': 3, 'MOV': 4, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.LoggingApplicationListener.supportsSourceType(java.lang.Class)', 'TOT': 3, 'UPD': 0, 'INS': 2, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'LoggingSystem.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.logging.LoggingSystem.cleanUp()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'Log4JLoggingSystem.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.logging.log4j.Log4JLoggingSystem.beforeInitialize()', 'TOT': 9, 'UPD': 0, 'INS': 1, 'MOV': 7, 'DEL': 1}, {'spoonMethodName': 'org.springframework.boot.logging.log4j.Log4JLoggingSystem.cleanUp()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.log4j.Log4JLoggingSystem.configureJdkLoggingBridgeHandler()', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.log4j.Log4JLoggingSystem.bridgeHandlerIsAvailable()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.log4j.Log4JLoggingSystem.removeJdkLoggingBridgeHandler()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'LogbackLoggingSystem.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.logging.logback.LogbackLoggingSystem.cleanUp()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.logback.LogbackLoggingSystem.bridgeHandlerIsAvailable()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.logback.LogbackLoggingSystem.removeJdkLoggingBridgeHandler()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.logback.LogbackLoggingSystem.configureJdkLoggingBridgeHandler()', 'TOT': 9, 'UPD': 0, 'INS': 4, 'MOV': 5, 'DEL': 0}]}, {'spoonFilePath': 'LoggingApplicationListenerTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.logging.LoggingApplicationListenerTests.bridgeHandlerLifecycle()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.LoggingApplicationListenerTests.bridgeHandlerInstalled()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'Log4JLoggingSystemTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.logging.log4j.Log4JLoggingSystemTests.bridgeHandlerLifecycle()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.log4j.Log4JLoggingSystemTests.bridgeHandlerInstalled()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.log4j.Log4JLoggingSystemTests.clear()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'LogbackLoggingSystemTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.boot.logging.logback.LogbackLoggingSystemTests.bridgeHandlerLifecycle()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.logback.LogbackLoggingSystemTests.bridgeHandlerInstalled()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.boot.logging.logback.LogbackLoggingSystemTests.clear()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-boot/issues/2324,4.000277777777778,['type: bug'],War deployment in standalone Tomcat causes webclassloader memory leak,1.0,"['org.springframework.boot.logging.log4j.Log4JLoggingSystem.configureJdkLoggingBridgeHandler()', 'org.springframework.boot.logging.logback.LogbackLoggingSystem.removeJdkLoggingBridgeHandler()', 'org.springframework.boot.logging.log4j.Log4JLoggingSystem.removeJdkLoggingBridgeHandler()', 'org.springframework.boot.logging.LoggingApplicationListener.supportsEventType(java.lang.Class)', 'org.springframework.boot.logging.logback.LogbackLoggingSystem.cleanUp()', 'org.springframework.boot.logging.logback.LogbackLoggingSystem.configureJdkLoggingBridgeHandler()', 'org.springframework.boot.logging.LoggingApplicationListener', 'org.springframework.boot.logging.log4j.Log4JLoggingSystem.bridgeHandlerIsAvailable()', 'org.springframework.boot.logging.logback.LogbackLoggingSystem.bridgeHandlerIsAvailable()', 'org.springframework.boot.logging.log4j.Log4JLoggingSystem.cleanUp()', 'org.springframework.boot.logging.LoggingApplicationListener.isAssignableFrom(java.lang.Class,java.lang.Class[])', 'org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(org.springframework.context.ApplicationEvent)', 'org.springframework.boot.logging.log4j.Log4JLoggingSystem.beforeInitialize()', 'org.springframework.boot.logging.LoggingSystem.cleanUp()', 'org.springframework.boot.logging.LoggingApplicationListener.supportsSourceType(java.lang.Class)']",['9744d282991c8ac4c9e06200a9868d8531469603'],,"['spring-boot/src/main/java/org/springframework/boot/logging', 'spring-boot/src/main/java/org/springframework/boot/logging/logback', 'spring-boot/src/main/java/org/springframework/boot/logging/log4j']",107.0,26.0,133.0,4.0,0.0,15.0,45.0,20.0,23.0,2.0,4.0,0.0,0.0,0.0,0.0,0.0,0.0,spring-boot
47756,2020-04-09 09:22:33,bclozel,"In then current LRUCache implementation, the queue tracking recently used cached values is thread safe, at least each call to offer/add values to it is.

But in the case of highly concurrent calls for the same cached value, the current implementation can add multiple instances of the same value to the queue. Since the queue is unbounded, this can lead to memory leak issues or large queues which increases the time spent when going over the queue to find values to remove.

We'll also use this issue to improve queue lookup for recently used values by starting from the end and using a different queue implementation.",2020-04-09 13:42:52,"[{'commitHash': '39536acf9f28ddcae59bf89ae2c31b8e6a615494', 'commitGHEventType': 'closed', 'commitUser': 'bclozel', 'commitParents': ['de0d06fab51558ecf0414d1a7199ca48fa67e237'], 'nameRev': '39536acf9f28ddcae59bf89ae2c31b8e6a615494 tags/v5.2.6.RELEASE~61', 'commitMessage': ""Fix potential leak in MimeTypeUtils LRUCache\n\nPrior to this commit, the `MimeTypeUtils` LRUCache would maintain a\nqueue to track least recently used cached values. In some cases,\nconcurrent access could create more entries in that unbounded queue than\nexpected and spend a significant amount of time removing entries in that\nqueue (i.e. iterating over a long list of elements).\n\nThis commit ensures that recently used entries are only added to the\nqueue if they've been removed by the current thread, in case of\nconcurrent access.\n\nFixes gh-24886\n"", 'commitDateTime': '2020-04-09 15:38:01', 'authoredDateTime': '2020-04-09 15:38:01', 'commitGitStats': [{'filePath': 'spring-core/src/main/java/org/springframework/util/MimeTypeUtils.java', 'insertions': 9, 'deletions': 7, 'lines': 16}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'MimeTypeUtils.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.util.MimeTypeUtils.ConcurrentLruCache', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.util.MimeTypeUtils.ConcurrentLruCache.get(java.lang.Object)', 'TOT': 11, 'UPD': 5, 'INS': 2, 'MOV': 4, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-framework/issues/24886,0.0002777777777777778,['type: bug'],Memory leak in MimeTypeUtils LRUCache,1.0,"['org.springframework.util.MimeTypeUtils.ConcurrentLruCache.get(java.lang.Object)', 'org.springframework.util.MimeTypeUtils.ConcurrentLruCache']",['39536acf9f28ddcae59bf89ae2c31b8e6a615494'],,['spring-core/src/main/java/org/springframework/util'],9.0,7.0,16.0,1.0,7.0,2.0,13.0,4.0,2.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,spring-framework
47800,2020-01-13 15:41:51,spring-issuemaster,Backport of gh-24339,2020-01-13 20:47:32,"[{'commitHash': '9969cb6d83916a8e8a68885f3b32cd89c42b483c', 'commitGHEventType': 'referenced', 'commitUser': 'rstoyanchev', 'commitParents': ['04b3f5a247e1d89df0f12b6a176eb2ed522754be'], 'nameRev': '9969cb6d83916a8e8a68885f3b32cd89c42b483c tags/v5.1.13.RELEASE~1', 'commitMessage': 'Improve limit handling in StringDecoder\n\nThe case of one data buffer containing multiple lines can could cause\na buffer leak due to a suspected issue in concatMapIterable. This\ncommit adds workarounds for that until the underlying issue is\naddressed.\n\nCloses gh-24346\n', 'commitDateTime': '2020-01-13 20:46:51', 'authoredDateTime': '2020-01-13 20:46:51', 'commitGitStats': [{'filePath': 'spring-core/src/main/java/org/springframework/core/codec/StringDecoder.java', 'insertions': 70, 'deletions': 30, 'lines': 100}, {'filePath': 'spring-core/src/test/java/org/springframework/core/codec/StringDecoderTests.java', 'insertions': 22, 'deletions': 9, 'lines': 31}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'StringDecoder.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.core.codec.StringDecoder.LimitedDataBufferConsumer', 'TOT': 8, 'UPD': 5, 'INS': 0, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'org.springframework.core.codec.StringDecoder.LimitedDataBufferConsumer.accept(org.springframework.core.io.buffer.DataBuffer)', 'TOT': 15, 'UPD': 5, 'INS': 0, 'MOV': 10, 'DEL': 0}, {'spoonMethodName': 'org.springframework.core.codec.StringDecoder.decode(org.reactivestreams.Publisher,org.springframework.core.ResolvableType,org.springframework.util.MimeType,java.util.Map)', 'TOT': 27, 'UPD': 7, 'INS': 5, 'MOV': 12, 'DEL': 3}, {'spoonMethodName': 'org.springframework.core.codec.StringDecoder.splitOnDelimiter(org.springframework.core.io.buffer.DataBuffer,java.util.List,org.springframework.core.io.buffer.LimitedDataBufferList)', 'TOT': 4, 'UPD': 0, 'INS': 4, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'StringDecoderTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.core.codec.StringDecoderTests.decodeNewLineWithLimit()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.core.codec.StringDecoderTests.maxInMemoryLimitReleaseUnprocessedLinesFromCurrentBuffer()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.core.codec.StringDecoderTests.maxInMemoryLimitReleaseUnprocessedLinesWhenUnlimited()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-framework/issues/24346,0.0002777777777777778,"['in: web', 'type: backport', 'type: bug']",StringDecoder buffer leak related to maxInMemorySize limit,1.0,"['org.springframework.core.codec.StringDecoder.splitOnDelimiter(org.springframework.core.io.buffer.DataBuffer,java.util.List,org.springframework.core.io.buffer.LimitedDataBufferList)', 'org.springframework.core.codec.StringDecoder.decode(org.reactivestreams.Publisher,org.springframework.core.ResolvableType,org.springframework.util.MimeType,java.util.Map)', 'org.springframework.core.codec.StringDecoder.LimitedDataBufferConsumer.accept(org.springframework.core.io.buffer.DataBuffer)', 'org.springframework.core.codec.StringDecoder.LimitedDataBufferConsumer']",['9969cb6d83916a8e8a68885f3b32cd89c42b483c'],,['spring-core/src/main/java/org/springframework/core/codec'],70.0,30.0,100.0,1.0,17.0,4.0,54.0,24.0,9.0,4.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,spring-framework
47801,2020-01-13 13:03:07,rstoyanchev,"This was discovered while working on implementing the same type of limit for `ServerSentEventsMessageReader` which depends on `StringDecoder` to split the stream into lines (see #24312). 

When a single input buffer contains multiple lines in which case slices for each line are retained, and if one of the earlier lines exceeds the limit, then subsequent lines are not released. This is due to a suspected issue with  `concatMapIterable` not respecting `doOnDiscard`. I've added a https://github.com/reactor/reactor-core/issues/1925#issuecomment-573630082 related to that. 

The goal for this issue is to add a workaround.",2020-01-13 14:57:54,"[{'commitHash': 'a741ae422b75e330dac655718ad91e0067a2caeb', 'commitGHEventType': 'closed', 'commitUser': 'rstoyanchev', 'commitParents': ['850cbf032bf763f6f648a3d621cd56d94171b81a'], 'nameRev': 'a741ae422b75e330dac655718ad91e0067a2caeb tags/v5.2.3.RELEASE~9', 'commitMessage': 'Improve limit handling in StringDecoder\n\nThe case of one data buffer containing multiple lines can could cause\na buffer leak due to a suspected issue in concatMapIterable. This\ncommit adds workarounds for that until the underlying issue is\naddressed.\n\nCloses gh-24339\n', 'commitDateTime': '2020-01-13 14:57:14', 'authoredDateTime': '2020-01-13 14:55:29', 'commitGitStats': [{'filePath': 'spring-core/src/main/java/org/springframework/core/codec/StringDecoder.java', 'insertions': 87, 'deletions': 45, 'lines': 132}, {'filePath': 'spring-core/src/test/java/org/springframework/core/codec/StringDecoderTests.java', 'insertions': 22, 'deletions': 9, 'lines': 31}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'StringDecoder.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.core.codec.StringDecoder.LimitedDataBufferConsumer', 'TOT': 8, 'UPD': 5, 'INS': 0, 'MOV': 2, 'DEL': 1}, {'spoonMethodName': 'org.springframework.core.codec.StringDecoder.LimitedDataBufferConsumer.accept(org.springframework.core.io.buffer.DataBuffer)', 'TOT': 14, 'UPD': 5, 'INS': 0, 'MOV': 9, 'DEL': 0}, {'spoonMethodName': 'org.springframework.core.codec.StringDecoder.decode(org.reactivestreams.Publisher,org.springframework.core.ResolvableType,org.springframework.util.MimeType,java.util.Map)', 'TOT': 31, 'UPD': 6, 'INS': 6, 'MOV': 16, 'DEL': 3}, {'spoonMethodName': 'org.springframework.core.codec.StringDecoder.endFrameAfterDelimiter(org.springframework.core.io.buffer.DataBuffer,org.springframework.core.io.buffer.DataBufferUtils$Matcher)', 'TOT': 6, 'UPD': 0, 'INS': 0, 'MOV': 5, 'DEL': 1}, {'spoonMethodName': 'org.springframework.core.codec.StringDecoder.endFrameAfterDelimiter(org.springframework.core.io.buffer.DataBuffer,org.springframework.core.io.buffer.DataBufferUtils$Matcher,org.springframework.core.io.buffer.LimitedDataBufferList)', 'TOT': 6, 'UPD': 0, 'INS': 6, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'StringDecoderTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.core.codec.StringDecoderTests.decodeNewLineWithLimit()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.core.codec.StringDecoderTests.maxInMemoryLimitReleaseUnprocessedLinesFromCurrentBuffer()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.core.codec.StringDecoderTests.maxInMemoryLimitReleaseUnprocessedLinesWhenUnlimited()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-framework/issues/24339,0.0002777777777777778,"['in: web', 'status: backported', 'type: bug']",StringDecoder buffer leak related to maxInMemorySize limit,1.0,"['org.springframework.core.codec.StringDecoder.endFrameAfterDelimiter(org.springframework.core.io.buffer.DataBuffer,org.springframework.core.io.buffer.DataBufferUtils$Matcher)', 'org.springframework.core.codec.StringDecoder.decode(org.reactivestreams.Publisher,org.springframework.core.ResolvableType,org.springframework.util.MimeType,java.util.Map)', 'org.springframework.core.codec.StringDecoder.LimitedDataBufferConsumer.accept(org.springframework.core.io.buffer.DataBuffer)', 'org.springframework.core.codec.StringDecoder.LimitedDataBufferConsumer', 'org.springframework.core.codec.StringDecoder.endFrameAfterDelimiter(org.springframework.core.io.buffer.DataBuffer,org.springframework.core.io.buffer.DataBufferUtils$Matcher,org.springframework.core.io.buffer.LimitedDataBufferList)']",['a741ae422b75e330dac655718ad91e0067a2caeb'],,['spring-core/src/main/java/org/springframework/core/codec'],87.0,45.0,132.0,1.0,16.0,5.0,65.0,32.0,12.0,5.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,spring-framework
51965,2019-09-03 09:58:39,arian,"<!--
!!! For Security Vulnerabilities, please go to https://pivotal.io/security !!!
-->
**Affects:** 5.2.0.RC1

---

In our application I upgraded from spring-framework 5.1.9 to 5.2.0.RC1 and our tests started leaking memory.

Previously it looked like this in VisualVM:

![image](https://user-images.githubusercontent.com/109243/64158877-8d43cf80-ce39-11e9-8582-85357e439198.png)

And now it looks like this:

![image](https://user-images.githubusercontent.com/109243/64158907-9b91eb80-ce39-11e9-963a-e2c08716f55a.png)

I've made a heapdump to see where the memory is going:

![image](https://user-images.githubusercontent.com/109243/64163425-8325cf00-ce41-11e9-922d-886c6feac4e4.png)

I've seen something similar in our application previously, but that was solved by using `@MockBean` instead of a lot of `@ContextConfiguration` with `@Configuration` classes inside our test classes to override beans with mocked objects :thinking:...",2019-09-18 12:30:57,"[{'commitHash': 'e1e072b75c8e36835799e8ab6166368e24d04808', 'commitGHEventType': 'closed', 'commitUser': 'sbrannen', 'commitParents': ['2e7d3449307ff6545e4ccf93fb46a41464b1cb63'], 'nameRev': 'e1e072b75c8e36835799e8ab6166368e24d04808 tags/v5.2.0.RELEASE~92', 'commitMessage': ""Fix memory leak regression involving @Async methods\n\nSpring Framework 5.2 M1 introduced a memory leak for applications using\n@Async methods. Specifically, in a large test suite with multiple\nApplicationContexts that were closed (e.g., via @DirtiesContext,\n@MockBean, or context cache eviction), the JVM process could run out of\nmemory.\n\nUnderlying cause: Due to a missing equals() implementation in Spring's\nnew AnnotationCandidateClassFilter, CGLIB's static cache of generated\nclasses indirectly retained references to BeanFactory instances for the\nclosed ApplicationContexts for the duration of the test suite.\n\nThis commit fixes this regression by introducing a proper equals()\nimplementation in AnnotationCandidateClassFilter. This commit also\nintroduces corresponding hashCode() and toString() implementations.\n\nCloses gh-23571\n"", 'commitDateTime': '2019-09-18 14:28:54', 'authoredDateTime': '2019-09-18 14:28:54', 'commitGitStats': [{'filePath': 'spring-aop/src/main/java/org/springframework/aop/support/annotation/AnnotationMatchingPointcut.java', 'insertions': 29, 'deletions': 5, 'lines': 34}, {'filePath': 'spring-aop/src/test/java/org/springframework/aop/support/AnnotationMatchingPointcutTests.java', 'insertions': 109, 'deletions': 0, 'lines': 109}, {'filePath': 'spring-test/src/test/java/org/springframework/test/context/async/AsyncMethodsSpringTestContextIntegrationTests.java', 'insertions': 68, 'deletions': 0, 'lines': 68}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'AnnotationMatchingPointcut.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.annotation.AnnotationMatchingPointcut.AnnotationCandidateClassFilter', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.springframework.aop.support.annotation.AnnotationMatchingPointcut.AnnotationCandidateClassFilter.equals(java.lang.Object)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.support.annotation.AnnotationMatchingPointcut.AnnotationCandidateClassFilter.hashCode()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.support.annotation.AnnotationMatchingPointcut.AnnotationCandidateClassFilter.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'AnnotationMatchingPointcutTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.AnnotationMatchingPointcutTests', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'AsyncMethodsSpringTestContextIntegrationTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.test.context.async.AsyncMethodsSpringTestContextIntegrationTests', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '8f6846827d41f22c2b6dfac6fc12b56cc63f69a9', 'commitGHEventType': 'referenced', 'commitUser': 'sbrannen', 'commitParents': ['b2aad1c3b1091ed0e4e1d1f337ffdb8714463762'], 'nameRev': '8f6846827d41f22c2b6dfac6fc12b56cc63f69a9 tags/v5.1.10.RELEASE~17', 'commitMessage': ""Ensure ClassFilter and MethodMatcher implementations are cacheable\n\nWhile resolving the regression raised in gh-23571, it came to our\nattention that not all of our ClassFilter and MethodMatcher\nimplementations were properly cacheable with CGLIB generated proxies\ndue to missing (or improper) equals() and hashCode() implementations.\n\nAlthough such deficiencies may not manifest themselves as bugs in Core\nSpring's default arrangements, these might cause issues in custom\narrangements in user applications.\n\nThis commit addresses this by ensuring that ClassFilter and\nMethodMatcher implementations properly implement equals() and\nhashCode(). In addition, missing toString() implementations have been\nadded to improve diagnostics for logging and debugging.\n\nCloses gh-23659\n"", 'commitDateTime': '2019-09-19 15:35:17', 'authoredDateTime': '2019-09-18 17:13:33', 'commitGitStats': [{'filePath': 'spring-aop/src/main/java/org/springframework/aop/ClassFilter.java', 'insertions': 6, 'deletions': 1, 'lines': 7}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/MethodMatcher.java', 'insertions': 6, 'deletions': 1, 'lines': 7}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/aspectj/AbstractAspectJAdvice.java', 'insertions': 6, 'deletions': 1, 'lines': 7}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/aspectj/TypePatternClassFilter.java', 'insertions': 20, 'deletions': 1, 'lines': 21}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/support/ClassFilters.java', 'insertions': 19, 'deletions': 5, 'lines': 24}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/support/ComposablePointcut.java', 'insertions': 10, 'deletions': 7, 'lines': 17}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/support/ControlFlowPointcut.java', 'insertions': 8, 'deletions': 2, 'lines': 10}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/support/DefaultIntroductionAdvisor.java', 'insertions': 2, 'deletions': 2, 'lines': 4}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/support/MethodMatchers.java', 'insertions': 17, 'deletions': 1, 'lines': 18}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/support/NameMatchMethodPointcut.java', 'insertions': 8, 'deletions': 3, 'lines': 11}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/support/Pointcuts.java', 'insertions': 12, 'deletions': 2, 'lines': 14}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/support/RootClassFilter.java', 'insertions': 21, 'deletions': 2, 'lines': 23}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/support/annotation/AnnotationMatchingPointcut.java', 'insertions': 4, 'deletions': 4, 'lines': 8}, {'filePath': 'spring-aop/src/main/java/org/springframework/aop/support/annotation/AnnotationMethodMatcher.java', 'insertions': 3, 'deletions': 2, 'lines': 5}, {'filePath': 'spring-aop/src/test/java/org/springframework/aop/aspectj/TypePatternClassFilterTests.java', 'insertions': 32, 'deletions': 1, 'lines': 33}, {'filePath': 'spring-aop/src/test/java/org/springframework/aop/support/ClassFiltersTests.java', 'insertions': 17, 'deletions': 10, 'lines': 27}, {'filePath': 'spring-aop/src/test/java/org/springframework/aop/support/ControlFlowPointcutTests.java', 'insertions': 8, 'deletions': 0, 'lines': 8}, {'filePath': 'spring-aop/src/test/java/org/springframework/aop/support/RootClassFilterTests.java', 'insertions': 66, 'deletions': 0, 'lines': 66}, {'filePath': 'spring-aop/src/test/java/org/springframework/aop/support/annotation/AnnotationMatchingPointcutTests.java', 'insertions': 108, 'deletions': 0, 'lines': 108}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'ClassFilter.java', 'spoonMethods': []}, {'spoonFilePath': 'MethodMatcher.java', 'spoonMethods': []}, {'spoonFilePath': 'AbstractAspectJAdvice.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.aspectj.AbstractAspectJAdvice.AdviceExcludingMethodMatcher.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'TypePatternClassFilter.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.aspectj.TypePatternClassFilter.equals(java.lang.Object)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.aspectj.TypePatternClassFilter.hashCode()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.aspectj.TypePatternClassFilter.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ClassFilters.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.ClassFilters.UnionClassFilter', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.springframework.aop.support.ClassFilters.IntersectionClassFilter', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 1}, {'spoonMethodName': 'org.springframework.aop.support.ClassFilters.UnionClassFilter.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.support.ClassFilters.IntersectionClassFilter.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ComposablePointcut.java', 'spoonMethods': []}, {'spoonFilePath': 'ControlFlowPointcut.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.ControlFlowPointcut.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.support.ControlFlowPointcut', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'DefaultIntroductionAdvisor.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.DefaultIntroductionAdvisor.toString()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'MethodMatchers.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.MethodMatchers.UnionMethodMatcher.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.support.MethodMatchers.ClassFilterAwareUnionMethodMatcher.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.support.MethodMatchers.IntersectionMethodMatcher.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'NameMatchMethodPointcut.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.NameMatchMethodPointcut.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'Pointcuts.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.Pointcuts.SetterPointcut.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.support.Pointcuts.GetterPointcut.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RootClassFilter.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.RootClassFilter.equals(java.lang.Object)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.support.RootClassFilter.hashCode()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.support.RootClassFilter.toString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.support.RootClassFilter', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'AnnotationMatchingPointcut.java', 'spoonMethods': []}, {'spoonFilePath': 'AnnotationMethodMatcher.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.annotation.AnnotationMethodMatcher.equals(java.lang.Object)', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'TypePatternClassFilterTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.aspectj.TypePatternClassFilterTests.testEquals()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.aspectj.TypePatternClassFilterTests.testHashCode()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.aspectj.TypePatternClassFilterTests.testToString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ClassFiltersTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.ClassFiltersTests', 'TOT': 4, 'UPD': 1, 'INS': 3, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.support.ClassFiltersTests.testUnion()', 'TOT': 4, 'UPD': 4, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.aop.support.ClassFiltersTests.testIntersection()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'ControlFlowPointcutTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.ControlFlowPointcutTests.testToString()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RootClassFilterTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.RootClassFilterTests', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'AnnotationMatchingPointcutTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.aop.support.annotation.AnnotationMatchingPointcutTests', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-framework/issues/23571,15.000277777777777,"['in: core', 'status: feedback-provided', 'type: regression']",Memory leak when using @Async after upgrading from 5.1 to 5.2,2.0,"['org.springframework.aop.support.Pointcuts.GetterPointcut.toString()', 'org.springframework.aop.aspectj.TypePatternClassFilter.equals(java.lang.Object)', 'org.springframework.aop.aspectj.TypePatternClassFilter.hashCode()', 'org.springframework.aop.support.Pointcuts.SetterPointcut.toString()', 'org.springframework.aop.aspectj.TypePatternClassFilter.toString()', 'org.springframework.aop.support.RootClassFilter.toString()', 'org.springframework.aop.support.RootClassFilter', 'org.springframework.aop.support.MethodMatchers.ClassFilterAwareUnionMethodMatcher.toString()', 'org.springframework.aop.support.ClassFilters.IntersectionClassFilter.toString()', 'org.springframework.aop.support.annotation.AnnotationMatchingPointcut.AnnotationCandidateClassFilter.equals(java.lang.Object)', 'org.springframework.aop.support.MethodMatchers.IntersectionMethodMatcher.toString()', 'org.springframework.aop.support.ControlFlowPointcut.toString()', 'org.springframework.aop.support.annotation.AnnotationMatchingPointcut.AnnotationCandidateClassFilter', 'org.springframework.aop.support.annotation.AnnotationMatchingPointcut.AnnotationCandidateClassFilter.toString()', 'org.springframework.aop.support.annotation.AnnotationMatchingPointcut.AnnotationCandidateClassFilter.hashCode()', 'org.springframework.aop.support.RootClassFilter.hashCode()', 'org.springframework.aop.support.NameMatchMethodPointcut.toString()', 'org.springframework.aop.support.ClassFilters.IntersectionClassFilter', 'org.springframework.aop.support.ClassFilters.UnionClassFilter', 'org.springframework.aop.aspectj.AbstractAspectJAdvice.AdviceExcludingMethodMatcher.toString()', 'org.springframework.aop.support.ClassFilters.UnionClassFilter.toString()', 'org.springframework.aop.support.DefaultIntroductionAdvisor.toString()', 'org.springframework.aop.support.annotation.AnnotationMethodMatcher.equals(java.lang.Object)', 'org.springframework.aop.support.RootClassFilter.equals(java.lang.Object)', 'org.springframework.aop.support.MethodMatchers.UnionMethodMatcher.toString()', 'org.springframework.aop.support.ControlFlowPointcut']","['e1e072b75c8e36835799e8ab6166368e24d04808', '8f6846827d41f22c2b6dfac6fc12b56cc63f69a9']",,"['spring-aop/src/main/java/org/springframework/aop/support/annotation', 'spring-aop/src/main/java/org/springframework/aop/support', 'spring-aop/src/main/java/org/springframework/aop', 'spring-aop/src/main/java/org/springframework/aop/aspectj']",171.0,39.0,210.0,14.0,1.0,26.0,31.0,1.0,26.0,3.0,11.0,0.0,0.0,0.0,0.0,0.0,0.0,spring-framework
52503,2019-08-21 17:42:48,rwinch,"<!--
For Security Vulnerabilities, please use https://pivotal.io/security#reporting
-->

### Summary

The [documentation](https://docs.spring.io/spring-framework/docs/current/spring-framework-reference/web-reactive.html#webflux-client-exchange) states:

> When you use exchange(), you must always use any of the body or toEntity methods of ClientResponse to ensure resources are released and to avoid potential issues with HTTP connection pooling. You can use bodyToMono(Void.class) if no response content is expected. However, if the response does have content, the connection is closed and is not placed back in the pool.

There are multiple places where the status is looked at and if it isn't 2xx then it throws an exception without consuming the body which causes a leak.
",2019-08-21 17:46:22,"[{'commitHash': 'a377581951fce551c536b35ff2ba1c06c2f7bf36', 'commitGHEventType': 'closed', 'commitUser': 'rwinch', 'commitParents': ['11f423511dc688f1d4d98cbb4d279ea66e6c3d58'], 'nameRev': 'a377581951fce551c536b35ff2ba1c06c2f7bf36 tags/5.2.0.RC1~71', 'commitMessage': 'Fix WebClient Memory Leaks\n\nWebClient exchange requires that the body is consumed. Before this commit\nthere were places where an Exception was thrown without consuming the body\nif the status was not successful. There was also the potential for the\nstatusCode invocation to throw an Exception of the status code was not\ndefined which would cause a leak.\n\nThis commit ensures that before the Exception is thrown the body is\nconsumed. It also uses the http status in a way that will ensure an\nException is not thrown.\n\nFixes gh-7293\n', 'commitDateTime': '2019-08-21 12:46:11', 'authoredDateTime': '2019-08-21 08:31:30', 'commitGitStats': [{'filePath': 'oauth2/oauth2-client/src/main/java/org/springframework/security/oauth2/client/endpoint/WebClientReactiveClientCredentialsTokenResponseClient.java', 'insertions': 10, 'deletions': 4, 'lines': 14}, {'filePath': 'oauth2/oauth2-resource-server/src/main/java/org/springframework/security/oauth2/server/resource/introspection/NimbusReactiveOpaqueTokenIntrospector.java', 'insertions': 6, 'deletions': 2, 'lines': 8}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebClientReactiveClientCredentialsTokenResponseClient.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.security.oauth2.client.endpoint.WebClientReactiveClientCredentialsTokenResponseClient.getTokenResponse(org.springframework.security.oauth2.client.endpoint.OAuth2ClientCredentialsGrantRequest)', 'TOT': 9, 'UPD': 1, 'INS': 3, 'MOV': 2, 'DEL': 3}]}, {'spoonFilePath': 'NimbusReactiveOpaqueTokenIntrospector.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.security.oauth2.server.resource.introspection.NimbusReactiveOpaqueTokenIntrospector.adaptToNimbusResponse(org.springframework.web.reactive.function.client.ClientResponse)', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 1}]}], 'spoonStatsSkippedReason': ''}, {'commitHash': '5114190cb6e2c59fa451be1f5f7ecc179387a2bf', 'commitGHEventType': 'referenced', 'commitUser': 'rwinch', 'commitParents': ['93d1c7f59f11e0f7ea3899fb2fa72fc7c22ba3a1'], 'nameRev': '5114190cb6e2c59fa451be1f5f7ecc179387a2bf tags/5.1.7.RELEASE~15', 'commitMessage': 'Fix WebClient Memory Leaks\n\nWebClient exchange requires that the body is consumed. Before this commit\nthere were places where an Exception was thrown without consuming the body\nif the status was not successful. There was also the potential for the\nstatusCode invocation to throw an Exception of the status code was not\ndefined which would cause a leak.\n\nThis commit ensures that before the Exception is thrown the body is\nconsumed. It also uses the http status in a way that will ensure an\nException is not thrown.\n\nFixes gh-7293\n', 'commitDateTime': '2019-08-21 12:46:54', 'authoredDateTime': '2019-08-21 08:31:30', 'commitGitStats': [{'filePath': 'oauth2/oauth2-client/src/main/java/org/springframework/security/oauth2/client/endpoint/WebClientReactiveClientCredentialsTokenResponseClient.java', 'insertions': 10, 'deletions': 4, 'lines': 14}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'WebClientReactiveClientCredentialsTokenResponseClient.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.security.oauth2.client.endpoint.WebClientReactiveClientCredentialsTokenResponseClient.getTokenResponse(org.springframework.security.oauth2.client.endpoint.OAuth2ClientCredentialsGrantRequest)', 'TOT': 9, 'UPD': 1, 'INS': 3, 'MOV': 2, 'DEL': 3}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-security/issues/7293,0.0002777777777777778,"['in: oauth2', 'status: backported', 'type: bug']",Fix WebClient Memory Leaks,1.0,"['org.springframework.security.oauth2.server.resource.introspection.NimbusReactiveOpaqueTokenIntrospector.adaptToNimbusResponse(org.springframework.web.reactive.function.client.ClientResponse)', 'org.springframework.security.oauth2.client.endpoint.WebClientReactiveClientCredentialsTokenResponseClient.getTokenResponse(org.springframework.security.oauth2.client.endpoint.OAuth2ClientCredentialsGrantRequest)']",['a377581951fce551c536b35ff2ba1c06c2f7bf36'],,"['oauth2/oauth2-resource-server/src/main/java/org/springframework/security/oauth2/server', 'oauth2/oauth2-client/src/main/java/org/springframework/security/oauth2/client']",16.0,6.0,22.0,2.0,1.0,2.0,12.0,3.0,4.0,4.0,2.0,0.0,0.0,0.0,1.0,0.0,0.0,spring-security
54410,2014-12-18 23:28:02,rwinch,"The websocket sample is not receiving session destroyed events from Redis despite being configured to receive keyspace notifications.
",2014-12-23 23:30:44,"[{'commitHash': '7f9b5c0515662397e0b9f936e1c22bcc724b9ade', 'commitGHEventType': 'referenced', 'commitUser': 'rwinch', 'commitParents': ['b3130edd98537d866b7095ecd06b0cffc250c284'], 'nameRev': '7f9b5c0515662397e0b9f936e1c22bcc724b9ade tags/1.0.0.RELEASE~33', 'commitMessage': 'Ensure Redis Configured to Send Keyspace Notifications\n\nPreviously there was a possibility that Session to WebSocket mapping was\nleaked if keyspace notifications were not enabled in Redis.\n\nTo resolve this the RedisHttpSessionConfiguration now ensures that Redis\nis configured to enable Keyspace notifications.\n\nFixes gh-76 gh-81\n', 'commitDateTime': '2014-12-23 16:38:42', 'authoredDateTime': '2014-12-15 16:13:03', 'commitGitStats': [{'filePath': 'samples/boot/src/main/java/sample/config/EmbeddedRedisConfiguration.java', 'insertions': 19, 'deletions': 3, 'lines': 22}, {'filePath': 'samples/security/src/main/java/sample/EmbeddedRedisConfiguration.java', 'insertions': 19, 'deletions': 3, 'lines': 22}, {'filePath': 'samples/users/src/main/java/sample/EmbeddedRedisConfiguration.java', 'insertions': 17, 'deletions': 1, 'lines': 18}, {'filePath': 'samples/web/src/main/java/sample/EmbeddedRedisConfiguration.java', 'insertions': 19, 'deletions': 3, 'lines': 22}, {'filePath': 'samples/websocket/src/main/java/sample/config/EmbeddedRedisConfig.java', 'insertions': 19, 'deletions': 3, 'lines': 22}, {'filePath': 'spring-session/src/integration-test/java/org/springframework/session/data/redis/RedisOperationsSessionRepositoryITests.java', 'insertions': 84, 'deletions': 11, 'lines': 95}, {'filePath': 'spring-session/src/integration-test/java/org/springframework/session/data/redis/config/annotation/web/http/EnableRedisHttpSessionExpireSessionDestroyedTests.java', 'insertions': 177, 'deletions': 0, 'lines': 177}, {'filePath': 'spring-session/src/main/java/org/springframework/session/data/redis/SessionMessageListener.java', 'insertions': 10, 'deletions': 6, 'lines': 16}, {'filePath': 'spring-session/src/main/java/org/springframework/session/data/redis/config/annotation/web/http/RedisHttpSessionConfiguration.java', 'insertions': 56, 'deletions': 1, 'lines': 57}, {'filePath': 'spring-session/src/main/java/org/springframework/session/web/socket/handler/WebSocketRegistryListener.java', 'insertions': 15, 'deletions': 9, 'lines': 24}, {'filePath': 'spring-session/src/test/java/org/springframework/session/data/redis/SessionMessageListenerTests.java', 'insertions': 16, 'deletions': 7, 'lines': 23}, {'filePath': 'spring-session/src/test/java/org/springframework/session/data/redis/config/annotation/web/http/EnableRedisKeyspaceNotificationsInitializerTests.java', 'insertions': 151, 'deletions': 0, 'lines': 151}, {'filePath': 'spring-session/src/test/java/org/springframework/session/web/socket/handler/WebSocketRegistryListenerTests.java', 'insertions': 15, 'deletions': 0, 'lines': 15}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'EmbeddedRedisConfiguration.java', 'spoonMethods': [{'spoonMethodName': 'sample.EmbeddedRedisConfiguration.redisServer()', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'sample.EmbeddedRedisConfiguration.RedisServerBean', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'sample.EmbeddedRedisConfiguration.RedisServerBean.postProcessBeanDefinitionRegistry(org.springframework.beans.factory.support.BeanDefinitionRegistry)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'sample.EmbeddedRedisConfiguration.RedisServerBean.postProcessBeanFactory(org.springframework.beans.factory.config.ConfigurableListableBeanFactory)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'EmbeddedRedisConfig.java', 'spoonMethods': [{'spoonMethodName': 'sample.config.EmbeddedRedisConfig.redisServer()', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'sample.config.EmbeddedRedisConfig.RedisServerBean', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'sample.config.EmbeddedRedisConfig.RedisServerBean.postProcessBeanDefinitionRegistry(org.springframework.beans.factory.support.BeanDefinitionRegistry)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'sample.config.EmbeddedRedisConfig.RedisServerBean.postProcessBeanFactory(org.springframework.beans.factory.config.ConfigurableListableBeanFactory)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RedisOperationsSessionRepositoryITests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.setup()', 'TOT': 6, 'UPD': 4, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.shutdown()', 'TOT': 5, 'UPD': 3, 'INS': 0, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.getPort()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.Config', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.SessionDestroyedEventRegistry', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.saves()', 'TOT': 3, 'UPD': 0, 'INS': 3, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.Config.connectionFactory()', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'EnableRedisHttpSessionExpireSessionDestroyedTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.data.redis.config.annotation.web.http.EnableRedisHttpSessionExpireSessionDestroyedTests', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'SessionMessageListener.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListener.onMessage(org.springframework.data.redis.connection.Message,byte[])', 'TOT': 15, 'UPD': 7, 'INS': 4, 'MOV': 3, 'DEL': 1}]}, {'spoonFilePath': 'RedisHttpSessionConfiguration.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration.redisMessageListenerContainer(org.springframework.data.redis.connection.RedisConnectionFactory)', 'TOT': 3, 'UPD': 1, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration.enableRedisKeyspaceNotificationsInitializer(org.springframework.data.redis.connection.RedisConnectionFactory)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration.EnableRedisKeyspaceNotificationsInitializer', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'WebSocketRegistryListener.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.afterConnectionEstablished(org.springframework.web.socket.WebSocketSession)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.registerWsSession(java.lang.String,org.springframework.web.socket.WebSocketSession)', 'TOT': 6, 'UPD': 4, 'INS': 0, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.closeWsSessions(java.lang.String)', 'TOT': 4, 'UPD': 3, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.afterConnectionClosed(java.lang.String,java.lang.String)', 'TOT': 7, 'UPD': 0, 'INS': 2, 'MOV': 4, 'DEL': 1}]}, {'spoonFilePath': 'SessionMessageListenerTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageDel()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageSource()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageExpired()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageHset()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageRename()', 'TOT': 8, 'UPD': 2, 'INS': 3, 'MOV': 3, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageEventPublisherErrorCaught()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageWrongKeyPrefix()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.mockMessage(java.lang.String,java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'EnableRedisKeyspaceNotificationsInitializerTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.data.redis.config.annotation.web.http.EnableRedisKeyspaceNotificationsInitializerTests', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'WebSocketRegistryListenerTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.web.socket.handler.WebSocketRegistryListenerTests.onApplicationEventConnectDisconnectCleanup()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-session/issues/81,5.000277777777778,['type: bug'],websocket sample does not receive session expired events,1.0,"['sample.EmbeddedRedisConfiguration.RedisServerBean.postProcessBeanDefinitionRegistry(org.springframework.beans.factory.support.BeanDefinitionRegistry)', 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration.EnableRedisKeyspaceNotificationsInitializer', 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.registerWsSession(java.lang.String,org.springframework.web.socket.WebSocketSession)', 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.afterConnectionClosed(java.lang.String,java.lang.String)', 'sample.EmbeddedRedisConfiguration.RedisServerBean', 'sample.config.EmbeddedRedisConfig.redisServer()', 'sample.EmbeddedRedisConfiguration.RedisServerBean.postProcessBeanFactory(org.springframework.beans.factory.config.ConfigurableListableBeanFactory)', 'sample.config.EmbeddedRedisConfig.RedisServerBean.postProcessBeanDefinitionRegistry(org.springframework.beans.factory.support.BeanDefinitionRegistry)', 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration', 'sample.config.EmbeddedRedisConfig.RedisServerBean', 'sample.config.EmbeddedRedisConfig.RedisServerBean.postProcessBeanFactory(org.springframework.beans.factory.config.ConfigurableListableBeanFactory)', 'sample.EmbeddedRedisConfiguration.redisServer()', 'org.springframework.session.data.redis.SessionMessageListener.onMessage(org.springframework.data.redis.connection.Message,byte[])', 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration.redisMessageListenerContainer(org.springframework.data.redis.connection.RedisConnectionFactory)', 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration.enableRedisKeyspaceNotificationsInitializer(org.springframework.data.redis.connection.RedisConnectionFactory)', 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.afterConnectionEstablished(org.springframework.web.socket.WebSocketSession)', 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.closeWsSessions(java.lang.String)']",['7f9b5c0515662397e0b9f936e1c22bcc724b9ade'],,"['spring-session/src/main/java/org/springframework/session/data/redis', 'samples/web/src/main/java/sample', 'samples/users/src/main/java/sample', 'samples/websocket/src/main/java/sample/config', 'spring-session/src/main/java/org/springframework/session/data/redis/config', 'spring-session/src/main/java/org/springframework/session/web/socket/handler', 'samples/boot/src/main/java/sample/config', 'samples/security/src/main/java/sample']",174.0,29.0,203.0,8.0,17.0,17.0,50.0,13.0,18.0,2.0,5.0,0.0,0.0,0.0,0.0,0.0,0.0,spring-session
54413,2014-12-12 21:08:56,rwinch,"If no SessionDestroyedEvent is fired, then WebSocketRegistryListener will have a memory leak. This would happen if Redis is not configured to send events.

We should be proactive in ensuring that Redis is configured for send session expiration events (which then get translated to SessionDestroyedEvent). We should also ensure empty session to WebSocket connections are removed.
",2014-12-23 23:26:38,"[{'commitHash': 'f40e10b135fbf7d8298bac4f68863efc9a2e379a', 'commitGHEventType': 'closed', 'commitUser': 'rwinch', 'commitParents': [], 'nameRev': '', 'commitMessage': '', 'commitDateTime': '', 'authoredDateTime': '', 'commitGitStats': [], 'commitSpoonAstDiffStats': [], 'spoonStatsSkippedReason': ''}, {'commitHash': '7f9b5c0515662397e0b9f936e1c22bcc724b9ade', 'commitGHEventType': 'referenced', 'commitUser': 'rwinch', 'commitParents': ['b3130edd98537d866b7095ecd06b0cffc250c284'], 'nameRev': '7f9b5c0515662397e0b9f936e1c22bcc724b9ade tags/1.0.0.RELEASE~33', 'commitMessage': 'Ensure Redis Configured to Send Keyspace Notifications\n\nPreviously there was a possibility that Session to WebSocket mapping was\nleaked if keyspace notifications were not enabled in Redis.\n\nTo resolve this the RedisHttpSessionConfiguration now ensures that Redis\nis configured to enable Keyspace notifications.\n\nFixes gh-76 gh-81\n', 'commitDateTime': '2014-12-23 16:38:42', 'authoredDateTime': '2014-12-15 16:13:03', 'commitGitStats': [{'filePath': 'samples/boot/src/main/java/sample/config/EmbeddedRedisConfiguration.java', 'insertions': 19, 'deletions': 3, 'lines': 22}, {'filePath': 'samples/security/src/main/java/sample/EmbeddedRedisConfiguration.java', 'insertions': 19, 'deletions': 3, 'lines': 22}, {'filePath': 'samples/users/src/main/java/sample/EmbeddedRedisConfiguration.java', 'insertions': 17, 'deletions': 1, 'lines': 18}, {'filePath': 'samples/web/src/main/java/sample/EmbeddedRedisConfiguration.java', 'insertions': 19, 'deletions': 3, 'lines': 22}, {'filePath': 'samples/websocket/src/main/java/sample/config/EmbeddedRedisConfig.java', 'insertions': 19, 'deletions': 3, 'lines': 22}, {'filePath': 'spring-session/src/integration-test/java/org/springframework/session/data/redis/RedisOperationsSessionRepositoryITests.java', 'insertions': 84, 'deletions': 11, 'lines': 95}, {'filePath': 'spring-session/src/integration-test/java/org/springframework/session/data/redis/config/annotation/web/http/EnableRedisHttpSessionExpireSessionDestroyedTests.java', 'insertions': 177, 'deletions': 0, 'lines': 177}, {'filePath': 'spring-session/src/main/java/org/springframework/session/data/redis/SessionMessageListener.java', 'insertions': 10, 'deletions': 6, 'lines': 16}, {'filePath': 'spring-session/src/main/java/org/springframework/session/data/redis/config/annotation/web/http/RedisHttpSessionConfiguration.java', 'insertions': 56, 'deletions': 1, 'lines': 57}, {'filePath': 'spring-session/src/main/java/org/springframework/session/web/socket/handler/WebSocketRegistryListener.java', 'insertions': 15, 'deletions': 9, 'lines': 24}, {'filePath': 'spring-session/src/test/java/org/springframework/session/data/redis/SessionMessageListenerTests.java', 'insertions': 16, 'deletions': 7, 'lines': 23}, {'filePath': 'spring-session/src/test/java/org/springframework/session/data/redis/config/annotation/web/http/EnableRedisKeyspaceNotificationsInitializerTests.java', 'insertions': 151, 'deletions': 0, 'lines': 151}, {'filePath': 'spring-session/src/test/java/org/springframework/session/web/socket/handler/WebSocketRegistryListenerTests.java', 'insertions': 15, 'deletions': 0, 'lines': 15}], 'commitSpoonAstDiffStats': [{'spoonFilePath': 'EmbeddedRedisConfiguration.java', 'spoonMethods': [{'spoonMethodName': 'sample.EmbeddedRedisConfiguration.redisServer()', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'sample.EmbeddedRedisConfiguration.RedisServerBean', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'sample.EmbeddedRedisConfiguration.RedisServerBean.postProcessBeanDefinitionRegistry(org.springframework.beans.factory.support.BeanDefinitionRegistry)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'sample.EmbeddedRedisConfiguration.RedisServerBean.postProcessBeanFactory(org.springframework.beans.factory.config.ConfigurableListableBeanFactory)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'EmbeddedRedisConfig.java', 'spoonMethods': [{'spoonMethodName': 'sample.config.EmbeddedRedisConfig.redisServer()', 'TOT': 2, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'sample.config.EmbeddedRedisConfig.RedisServerBean', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'sample.config.EmbeddedRedisConfig.RedisServerBean.postProcessBeanDefinitionRegistry(org.springframework.beans.factory.support.BeanDefinitionRegistry)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'sample.config.EmbeddedRedisConfig.RedisServerBean.postProcessBeanFactory(org.springframework.beans.factory.config.ConfigurableListableBeanFactory)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'RedisOperationsSessionRepositoryITests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.setup()', 'TOT': 6, 'UPD': 4, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.shutdown()', 'TOT': 5, 'UPD': 3, 'INS': 0, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.getPort()', 'TOT': 1, 'UPD': 1, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.Config', 'TOT': 3, 'UPD': 0, 'INS': 1, 'MOV': 1, 'DEL': 1}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests', 'TOT': 2, 'UPD': 0, 'INS': 2, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.SessionDestroyedEventRegistry', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.saves()', 'TOT': 3, 'UPD': 0, 'INS': 3, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.RedisOperationsSessionRepositoryITests.Config.connectionFactory()', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'EnableRedisHttpSessionExpireSessionDestroyedTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.data.redis.config.annotation.web.http.EnableRedisHttpSessionExpireSessionDestroyedTests', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'SessionMessageListener.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListener.onMessage(org.springframework.data.redis.connection.Message,byte[])', 'TOT': 15, 'UPD': 7, 'INS': 4, 'MOV': 3, 'DEL': 1}]}, {'spoonFilePath': 'RedisHttpSessionConfiguration.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration.redisMessageListenerContainer(org.springframework.data.redis.connection.RedisConnectionFactory)', 'TOT': 3, 'UPD': 1, 'INS': 1, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration.enableRedisKeyspaceNotificationsInitializer(org.springframework.data.redis.connection.RedisConnectionFactory)', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration.EnableRedisKeyspaceNotificationsInitializer', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'WebSocketRegistryListener.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.afterConnectionEstablished(org.springframework.web.socket.WebSocketSession)', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.registerWsSession(java.lang.String,org.springframework.web.socket.WebSocketSession)', 'TOT': 6, 'UPD': 4, 'INS': 0, 'MOV': 2, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.closeWsSessions(java.lang.String)', 'TOT': 4, 'UPD': 3, 'INS': 0, 'MOV': 1, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.afterConnectionClosed(java.lang.String,java.lang.String)', 'TOT': 7, 'UPD': 0, 'INS': 2, 'MOV': 4, 'DEL': 1}]}, {'spoonFilePath': 'SessionMessageListenerTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageDel()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageSource()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageExpired()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageHset()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageRename()', 'TOT': 8, 'UPD': 2, 'INS': 3, 'MOV': 3, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageEventPublisherErrorCaught()', 'TOT': 2, 'UPD': 2, 'INS': 0, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.onMessageWrongKeyPrefix()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}, {'spoonMethodName': 'org.springframework.session.data.redis.SessionMessageListenerTests.mockMessage(java.lang.String,java.lang.String)', 'TOT': 1, 'UPD': 0, 'INS': 0, 'MOV': 1, 'DEL': 0}]}, {'spoonFilePath': 'EnableRedisKeyspaceNotificationsInitializerTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.data.redis.config.annotation.web.http.EnableRedisKeyspaceNotificationsInitializerTests', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}, {'spoonFilePath': 'WebSocketRegistryListenerTests.java', 'spoonMethods': [{'spoonMethodName': 'org.springframework.session.web.socket.handler.WebSocketRegistryListenerTests.onApplicationEventConnectDisconnectCleanup()', 'TOT': 1, 'UPD': 0, 'INS': 1, 'MOV': 0, 'DEL': 0}]}], 'spoonStatsSkippedReason': ''}]",https://github.com/spring-projects/spring-session/issues/76,11.000277777777777,['type: bug'],WebSocketRegistryListener leaks if no SessionDestroyedEvent fired,1.0,"['sample.EmbeddedRedisConfiguration.RedisServerBean.postProcessBeanDefinitionRegistry(org.springframework.beans.factory.support.BeanDefinitionRegistry)', 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration.EnableRedisKeyspaceNotificationsInitializer', 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.registerWsSession(java.lang.String,org.springframework.web.socket.WebSocketSession)', 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.afterConnectionClosed(java.lang.String,java.lang.String)', 'sample.EmbeddedRedisConfiguration.RedisServerBean', 'sample.config.EmbeddedRedisConfig.redisServer()', 'sample.EmbeddedRedisConfiguration.RedisServerBean.postProcessBeanFactory(org.springframework.beans.factory.config.ConfigurableListableBeanFactory)', 'sample.config.EmbeddedRedisConfig.RedisServerBean.postProcessBeanDefinitionRegistry(org.springframework.beans.factory.support.BeanDefinitionRegistry)', 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration', 'sample.config.EmbeddedRedisConfig.RedisServerBean', 'sample.config.EmbeddedRedisConfig.RedisServerBean.postProcessBeanFactory(org.springframework.beans.factory.config.ConfigurableListableBeanFactory)', 'sample.EmbeddedRedisConfiguration.redisServer()', 'org.springframework.session.data.redis.SessionMessageListener.onMessage(org.springframework.data.redis.connection.Message,byte[])', 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration.redisMessageListenerContainer(org.springframework.data.redis.connection.RedisConnectionFactory)', 'org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration.enableRedisKeyspaceNotificationsInitializer(org.springframework.data.redis.connection.RedisConnectionFactory)', 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.afterConnectionEstablished(org.springframework.web.socket.WebSocketSession)', 'org.springframework.session.web.socket.handler.WebSocketRegistryListener.closeWsSessions(java.lang.String)']",['7f9b5c0515662397e0b9f936e1c22bcc724b9ade'],,"['spring-session/src/main/java/org/springframework/session/data/redis', 'samples/web/src/main/java/sample', 'samples/users/src/main/java/sample', 'samples/websocket/src/main/java/sample/config', 'spring-session/src/main/java/org/springframework/session/data/redis/config', 'spring-session/src/main/java/org/springframework/session/web/socket/handler', 'samples/boot/src/main/java/sample/config', 'samples/security/src/main/java/sample']",174.0,29.0,203.0,8.0,17.0,17.0,50.0,13.0,18.0,2.0,5.0,0.0,0.0,0.0,1.0,0.0,0.0,spring-session
